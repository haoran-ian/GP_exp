{"id": "aa521839-c803-44f6-b305-b0c967d53561", "fitness": 0.09399713912916925, "name": "HybridPSOSA", "description": "A novel hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Simulated Annealing (SA) to effectively explore and exploit the search space for robust black box optimization under strict evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.5  # social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.99  # cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11389454307741842, 0.11391633432495185, 0.1139010643485644, 0.07347307682257453, 0.07348081525603267, 0.07347541217890297, 0.0946052404550376, 0.0946185287307818, 0.09460923696825907]}}
{"id": "a542be04-3c35-4dad-bcf2-52394ba86508", "fitness": 0.09400149576683416, "name": "HybridPSOSA", "description": "A refined hybrid metaheuristic integrating dynamic particle inertia and adaptive simulated annealing to enhance convergence in black box optimization under strict evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.5  # social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.97  # modified cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Dynamic inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["aa521839-c803-44f6-b305-b0c967d53561"], "operator": null, "metadata": {"aucs": [0.11390548524458188, 0.11390860744428133, 0.11391775715926078, 0.0734769878855207, 0.0734780579486145, 0.07348137385753528, 0.09461193859442696, 0.09461380346636972, 0.09461945030091623]}}
{"id": "35e80deb-ced8-4cf0-b716-94e83c0d4809", "fitness": 0.09399983308160581, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA by fine-tuning particle updating strategy and cooling schedule for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1 = 1.5  # cognitive weight\n        self.c2 = 1.8  # slightly increased social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.95  # slightly increased cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            # Evaluate current fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Update personal best\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                # Update global best\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            # Dynamic inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n\n            # Update velocities and positions using PSO\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                # Clipping to remain within bounds\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Apply Simulated Annealing perturbation\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.1139165834498791, 0.11390562858379838, 0.11390203726668369, 0.07348095055433956, 0.07347699474489244, 0.07347576050105997, 0.0946187279413645, 0.09461198157034989, 0.09460983312208482]}}
{"id": "c68bc87c-3351-4104-93cc-573b07972216", "fitness": 0.09399882570103447, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive learning rates and swarm diversity preservation for improved convergence under constrained evaluation budgets.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.c1_initial = 1.5  # initial cognitive weight\n        self.c2_initial = 1.5  # initial social weight\n        self.c1_final = 0.5    # final cognitive weight\n        self.c2_final = 2.0    # final social weight\n        self.temperature = 1.0  # initial temperature for SA\n        self.alpha = 0.97  # modified cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb), \n            high=abs(func.bounds.ub - func.bounds.lb), \n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            c1 = self.c1_initial + ((self.c1_final - self.c1_initial) * (self.current_evals / self.budget))\n            c2 = self.c2_initial + ((self.c2_final - self.c2_initial) * (self.current_evals / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                candidate_position = particles[i] + np.random.normal(0, self.temperature, self.dim)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n                \n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.11391360240326454, 0.11391493768134897, 0.11389110110014822, 0.07347988767163838, 0.07348031700120705, 0.07347185875918305, 0.09461690584750515, 0.09461767476988803, 0.09460314607512688]}}
{"id": "7f65eff1-4c07-489d-b91b-31352f7f1654", "fitness": 0.09400231670874698, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid metaheuristic combining adaptive neighborhood-based perturbation and dynamic convergence acceleration for improved black box optimization performance under limited evaluation budgets.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["a542be04-3c35-4dad-bcf2-52394ba86508"], "operator": null, "metadata": {"aucs": [0.11390703503713984, 0.11391782324313982, 0.11391074286777592, 0.07347754130077422, 0.07348134663378947, 0.07347887259943586, 0.09461288673881652, 0.09461943932301853, 0.0946151626348326]}}
{"id": "26b5456f-ae2c-45ce-8d74-b7e3b78356aa", "fitness": 0.0939984986959961, "name": "EnhancedHybridPSOSA", "description": "A refined hybrid metaheuristic introducing adaptive inertia weight updating and neighborhood search strategy to enhance convergence and exploration in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget)**0.5)  # Adaptive inertia weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * np.random.rand() * (func.bounds.ub - func.bounds.lb)  # Improved neighborhood search\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391592148130869, 0.11391068017818318, 0.11389154652198286, 0.07348071444730242, 0.07347879750917818, 0.07347201661618763, 0.09461832324147001, 0.09461507092792332, 0.09460341734042854]}}
{"id": "10642da7-15ae-4abe-8023-c163682f70ed", "fitness": 0.09400137886227374, "name": "EnhancedHybridPSOSA", "description": "Fine-tune inertia weight adaptation for better balance between exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * ((self.current_evals + 1) / self.budget))  # Adjusted\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391107891766694, 0.11391471663239328, 0.11390551999066578, 0.07347898544301767, 0.07348023781060686, 0.07347700556661807, 0.09461536085360467, 0.09461753926950434, 0.09461196527638605]}}
{"id": "7f05ad1a-aa8d-496a-b277-9b7a29a63c32", "fitness": 0.09399925310737546, "name": "RefinedHybridPSOSA", "description": "A refined hybrid metaheuristic integrating adaptive neighborhood mutation and temperature-based convergence control for enhanced black box optimization efficiency within constrained evaluation budgets.", "code": "import numpy as np\n\nclass RefinedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                adaptive_radius = np.random.rand() * self.neighbor_radius # Adaptive neighborhood\n                perturbation = np.random.uniform(-adaptive_radius, adaptive_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.98  # Modified shrink rate\n\n        return self.best_global_position", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11391048367780199, 0.11390132618155002, 0.11390978714285638, 0.073478773845716, 0.07347545988865656, 0.07347852607949967, 0.09461499768273773, 0.09460935095179102, 0.09461457251576977]}}
{"id": "50763132-1545-414e-955d-a9528e17a26b", "fitness": 0.09400232204793393, "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic adaptation of personal best update to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                # Changed line: Introduce dynamic adaptation of personal best update\n                if fitness_value < personal_best_values[i] or np.random.rand() < np.exp(-(self.current_evals / self.budget)):\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99  # shrink neighborhood as optimization progresses\n        \n        return self.best_global_position", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7f65eff1-4c07-489d-b91b-31352f7f1654"], "operator": null, "metadata": {"aucs": [0.11390602049845722, 0.11391786776482449, 0.11391173764592533, 0.07347717904386886, 0.07348136251836501, 0.07347922747033031, 0.09461226608146867, 0.09461946654655506, 0.09461577086161044]}}
{"id": "c3b5a1c1-b624-4cc4-816a-212f90dc5f53", "fitness": 0.09400326869802461, "name": "GeneticHybridPSOSA", "description": "Introduce adaptive crossover and mutation strategies inspired by genetic algorithms to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass GeneticHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.neighbor_radius = 0.1\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i] or np.random.rand() < np.exp(-(self.current_evals / self.budget)):\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.crossover_rate:\n                    cross_point = np.random.randint(1, self.dim)\n                    particles[i, cross_point:], particles[i+1, cross_point:] = particles[i+1, cross_point:], particles[i, cross_point:]\n                    \n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        particles[i][j] += np.random.uniform(-self.neighbor_radius, self.neighbor_radius)\n                        particles[i+1][j] += np.random.uniform(-self.neighbor_radius, self.neighbor_radius)\n\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                particles[i+1] = np.clip(particles[i+1], func.bounds.lb, func.bounds.ub)\n            \n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                perturbation = np.random.uniform(-self.neighbor_radius, self.neighbor_radius, self.dim)\n                candidate_position = particles[i] + perturbation * (func.bounds.ub - func.bounds.lb)\n                candidate_position = np.clip(candidate_position, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate_position)\n                self.current_evals += 1\n\n                if candidate_fitness < personal_best_values[i]:\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n                elif np.exp((personal_best_values[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    personal_best_values[i] = candidate_fitness\n                    personal_best_positions[i] = candidate_position\n\n            self.temperature *= self.alpha\n            self.neighbor_radius *= 0.99\n        \n        return self.best_global_position", "configspace": "", "generation": 9, "feedback": "The algorithm GeneticHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["50763132-1545-414e-955d-a9528e17a26b"], "operator": null, "metadata": {"aucs": [0.1139157178645962, 0.11391518940320478, 0.11390904800871804, 0.07348064227636808, 0.07348040682312806, 0.07347826386823875, 0.09461819922843495, 0.09461782870262048, 0.09461412210691222]}}
{"id": "cd7a1185-d2c6-4142-86f5-68ad396ddd8d", "fitness": 0.09400092785351156, "name": "GeneticHybridPSOSA", "description": "Introduce a dynamic swarm neighborhood adjustment and elitist selection strategy to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass GeneticHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1.0\n        self.alpha = 0.97\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        particles = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        velocities = np.random.uniform(\n            low=-abs(func.bounds.ub - func.bounds.lb),\n            high=abs(func.bounds.ub - func.bounds.lb),\n            size=(self.population_size, self.dim)\n        )\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(particles[i])\n                self.current_evals += 1\n\n                if fitness_value < personal_best_values[i]:\n                    personal_best_values[i] = fitness_value\n                    personal_best_positions[i] = particles[i]\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = particles[i]\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evals / self.budget))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                    + self.c2 * r2 * (self.best_global_position - particles[i])\n                )\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            elite_indices = np.argsort(personal_best_values)[:10]\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.crossover_rate:\n                    parent1, parent2 = np.random.choice(elite_indices, 2, replace=False)\n                    cross_point = np.random.randint(1, self.dim)\n                    particles[parent1, cross_point:], particles[parent2, cross_point:] = particles[parent2, cross_point:], particles[parent1, cross_point:]\n                    \n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        particles[i][j] += np.random.uniform(-w, w)\n                        particles[i+1][j] += np.random.uniform(-w, w)\n\n                particles[i] = np.clip(particles[i], func.bounds.lb, func.bounds.ub)\n                particles[i+1] = np.clip(particles[i+1], func.bounds.lb, func.bounds.ub)\n            \n            self.temperature *= self.alpha\n        \n        return self.best_global_position", "configspace": "", "generation": 10, "feedback": "The algorithm GeneticHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["c3b5a1c1-b624-4cc4-816a-212f90dc5f53"], "operator": null, "metadata": {"aucs": [0.1138982012009665, 0.11391810731259311, 0.11391294427910414, 0.07347439061017746, 0.073481447928058, 0.07347965478609897, 0.09460748621685022, 0.09461961296420052, 0.09461650538355515]}}
{"id": "b21aab3e-1683-4a76-8a02-c1ba62fd445d", "fitness": 0.09400349177819146, "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration and exploitation by incorporating adaptive differential evolution strategies with self-adaptive control of crossover and mutation rates.  ", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["c3b5a1c1-b624-4cc4-816a-212f90dc5f53"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "2d1ea307-247b-48cc-86cb-59bced543056", "fitness": 0.0939573917098222, "name": "AdaptiveDifferentialEvolution", "description": "Improve convergence by introducing chaotic local search using tent map for exploration and diversity enhancement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n                \n                # Chaotic local search using tent map\n                chaotic_factor = 0.7\n                chaotic_factor = 2 * chaotic_factor if chaotic_factor < 0.5 else 2 * (1 - chaotic_factor)\n                mutant_vector = chaotic_factor * func.bounds.lb + (1 - chaotic_factor) * func.bounds.ub\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09396 with standard deviation 0.01649.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11388294193892678, 0.11387229845824298, 0.11377500949598018, 0.07346894454097186, 0.0734650979540401, 0.0734303825751893, 0.09459815374012903, 0.09459159583225862, 0.09453210085266095]}}
{"id": "27d201a4-374d-4892-af7a-b51f83df7113", "fitness": 0.09399813569328608, "name": "AdaptiveDifferentialEvolution", "description": "Integrate a dynamic mutation factor adjustment and enhance exploration by introducing a greedy selection mechanism.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            if self.best_global_value < fitness_values.mean():  # Greedy selection mechanism\n                self.mutation_f *= 1.1\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391167732180452, 0.11391781869547923, 0.1138869889269869, 0.07347919973226058, 0.07348134497542091, 0.07347039371863351, 0.09461572757606618, 0.09461943650507665, 0.09460063378784622]}}
{"id": "6982793b-d006-4474-9741-f7155844c2da", "fitness": 0.09400186303079035, "name": "AdaptiveDifferentialEvolution", "description": "Enhance the algorithm by incorporating dynamic scaling of the mutation factor based on improvement in fitness values to maintain diversity.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Dynamic adjustment of mutation factor based on fitness improvement\n            improvement = np.max(fitness_values) - np.min(fitness_values)\n            self.mutation_f = 0.8 * (1 - improvement / (np.max(fitness_values) + 1e-6))\n        \n        return self.best_global_position", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391164047332059, 0.11391781869547923, 0.11390068265721098, 0.0734803040986598, 0.07348158764263701, 0.07347556486820495, 0.09461563655251182, 0.09461964096149744, 0.09461389132759135]}}
{"id": "af543eb9-3647-418f-9faa-5bdc7523ddc9", "fitness": 0.09400108233767701, "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population size adjustment and adaptive mutation scaling to enhance convergence.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.population_size = max(20, int(self.population_size * (1 - self.current_evals / self.budget)))\n            self.mutation_f *= 1 + self.adaptive_factor * np.sin(np.pi * self.current_evals / self.budget)\n        \n        return self.best_global_position", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391167894445564, 0.11391781869547923, 0.11390045933924975, 0.07347920031186095, 0.07348134497542091, 0.07347520141243469, 0.09461572856898404, 0.09461943650507665, 0.09460887228613124]}}
{"id": "0e8fbcbb-6855-43f5-bc77-4e4193c2d1c6", "fitness": 0.0939971459542645, "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by incorporating a dynamic learning rate factor for adaptive mutation control and introduce a probabilistic selection of trial vectors based on fitness improvement.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i] and np.random.rand() < 0.5 + 0.5 * (fitness_values[i] - trial_fitness) / (fitness_values[i] + 1e-9):\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f = 0.5 + 0.5 * (self.best_global_value / (np.mean(fitness_values) + 1e-9))  # Dynamic learning rate\n        \n        return self.best_global_position", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391077991834264, 0.11389838943953534, 0.11389186381607486, 0.07347974003449931, 0.07347697043207724, 0.07347782781148204, 0.09461517837407973, 0.09461193229306197, 0.09461163146922735]}}
{"id": "3092ff6f-4357-448f-9ae3-f07987215072", "fitness": 0.09400327717253457, "name": "DynamicAdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and adaptive selection pressure to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing to enhance exploration-exploitation\n            if self.current_evals < self.budget / 2:\n                self.population_size = min(self.population_size + 1, 2 * self.initial_population_size)\n            else:\n                self.population_size = max(self.population_size - 1, self.initial_population_size // 2)\n            new_population = np.random.uniform(\n                low=func.bounds.lb,\n                high=func.bounds.ub,\n                size=(self.population_size, self.dim)\n            )\n            population = np.vstack((population[:self.population_size], new_population))\n            fitness_values = np.concatenate((fitness_values[:self.population_size], np.full(self.population_size, float('inf'))))\n\n        return self.best_global_position", "configspace": "", "generation": 17, "feedback": "The algorithm DynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11391064493504754, 0.07347914662019295, 0.07348134497542091, 0.07347883637596953, 0.09461563655251182, 0.09461943650507665, 0.09461510142571505]}}
{"id": "ba5f134b-67cf-4e09-8376-0278783e286a", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment based on convergence to enhance adaptability and improve optimization performance.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Dynamic adjustment of population size\n            self.population_size = max(20, int(50 * (1 - (self.current_evals / self.budget))))\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "3f40d5be-a9eb-4c81-85cf-1d02feabca01", "fitness": 0.09400349177819146, "name": "DynamicAdaptiveDifferentialEvolution", "description": "Enhance exploration and exploitation by introducing dynamic population size adaptation and differential evolution strategies with adaptive crossover and mutation rates.", "code": "import numpy as np\n\nclass DynamicAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        dynamic_population_size = self.initial_population_size\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(dynamic_population_size, self.dim)\n        )\n        fitness_values = np.full(dynamic_population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(dynamic_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(dynamic_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(dynamic_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population size adjustment\n            if (self.current_evals / self.budget) > 0.5 and dynamic_population_size > 10:\n                dynamic_population_size = int(dynamic_population_size * 0.9)\n                population = population[:dynamic_population_size]\n                fitness_values = fitness_values[:dynamic_population_size]\n        \n        return self.best_global_position", "configspace": "", "generation": 19, "feedback": "The algorithm DynamicAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "08f2ee16-06f1-4aad-ab15-14bf6f5b0b26", "fitness": 0.09400349177819146, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate adaptive differential evolution with a dynamic population size and diversity preservation to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.current_population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.initial_population_size, self.dim)\n        )\n        fitness_values = np.full(self.initial_population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.current_population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust population size based on diversity\n            diversity = np.std(population, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                self.current_population_size = max(10, self.current_population_size // 2)\n            else:\n                self.current_population_size = min(self.initial_population_size, self.current_population_size + 1)\n\n        return self.best_global_position", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391826775337466, 0.1139111773851913, 0.07347914662019295, 0.0734815051894172, 0.07347902614798674, 0.09461563655251182, 0.09461971108845968, 0.09461542679919144]}}
{"id": "9d53ed28-b73d-4b74-a246-338669e31d61", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive population size to enhance convergence dynamics and improve solution quality.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Adaptive population size adjustment\n            self.population_size = max(10, int(50 * (1 - self.current_evals / self.budget)))\n        \n        return self.best_global_position", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "9a3fa871-f586-4102-b02c-743131fb607f", "fitness": 0.09400342035688133, "name": "AdaptiveDifferentialEvolution", "description": "Integrate dynamic population resizing to improve the balance between exploration and exploitation over time.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            current_population_size = max(5, int(self.population_size * (1 - self.current_evals / self.budget)))  # Dynamic resizing\n            for i in range(current_population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391406921795144, 0.11391781869547923, 0.11390875925580168, 0.07348005316766171, 0.07348134497542091, 0.07347816320907896, 0.09461719019922987, 0.09461943650507665, 0.09461394798623157]}}
{"id": "1a739c43-7b5e-439e-a608-38a8c8b297ac", "fitness": 0.09398692769068676, "name": "SwarmAdaptiveDifferentialEvolution", "description": "Introduce a novel swarm-inspired mechanism that dynamically adjusts mutation strategies based on convergence trends to enhance optimization performance.", "code": "import numpy as np\n\nclass SwarmAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.inertia_weight = 0.5\n        self.velocity = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = (\n                    self.inertia_weight * self.velocity[i]\n                    + (1 - self.inertia_weight) * (a + self.mutation_f * (b - c))\n                )\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    self.velocity[i] = mutant_vector - population[i]\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Dynamic adjustment of parameters\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f *= 1 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.inertia_weight = 0.4 + 0.6 * (1 - self.current_evals / self.budget)\n        \n        return self.best_global_position", "configspace": "", "generation": 23, "feedback": "The algorithm SwarmAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11388391290736932, 0.1138988011764841, 0.11388255239995837, 0.07346928561455324, 0.07347455857305696, 0.07346879031956444, 0.09459874192472528, 0.094607806533749, 0.09459789976672006]}}
{"id": "b427629a-2afb-49d7-865c-24309c4989fe", "fitness": 0.09399647120254967, "name": "AdaptiveDifferentialEvolution", "description": "Introduce tournament selection for improved diversity and exploration in adaptive differential evolution.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                tournament_indices = np.random.choice(idxs, 5, replace=False)\n                tournament_winner = min(tournament_indices, key=lambda idx: fitness_values[idx])\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n        \n        return self.best_global_position", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11390626094115464, 0.11390268407875004, 0.11389993433863743, 0.0734772673037355, 0.07347594380831379, 0.07347500851283728, 0.09461241566416534, 0.09461018069151006, 0.0946085454838429]}}
{"id": "35c2ec21-8d90-4202-a0dd-bf6f11ea938e", "fitness": 0.09400259257452487, "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size adjustment based on convergence to enhance solution diversity and adaptability.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate, mutation factor, and population size\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.population_size = max(10, int(50 * (1 - (self.current_evals / self.budget))))  # Adjust population size\n\n        return self.best_global_position", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390751525499776, 0.07347914662019295, 0.07348134497542091, 0.07347771908201417, 0.09461563655251182, 0.09461943650507665, 0.09461318701763288]}}
{"id": "a76716b6-36f7-4fd4-b7fd-179be2c73df7", "fitness": 0.09399344592562955, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and elitism to enhance convergence speed and solution quality by adjusting exploration-exploitation balance based on budget exhaustion.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elitism_rate = 0.2\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            elite_size = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness_values)[:elite_size]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i and idx not in elite_indices]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamically resize population based on budget utilization\n            if self.current_evals < self.budget * 0.5:\n                self.population_size = int(self.initial_population_size * 1.2)\n            else:\n                self.population_size = int(self.initial_population_size * 0.8) \n\n            # Maintain the elite solutions\n            new_population = np.copy(population[elite_indices])\n            new_population = np.vstack([new_population, np.random.uniform(\n                low=func.bounds.lb,\n                high=func.bounds.ub,\n                size=(self.population_size - elite_size, self.dim)\n            )])\n            population = new_population\n            fitness_values = np.full(self.population_size, float('inf'))\n            for idx in range(elite_size):\n                fitness_values[idx] = func(population[idx])\n        \n        return self.best_global_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11390492544266051, 0.11388941582509071, 0.11390070906541949, 0.0734767894517474, 0.07347120820139519, 0.07347528384912816, 0.09461159762973115, 0.09460206576608488, 0.09460901809940847]}}
{"id": "a7e817d1-6401-4345-a74b-0fce2a3af9d2", "fitness": 0.09400274073045863, "name": "DynamicPopulationAdaptiveDE", "description": "Introduce dynamic population size and adaptive local search to enhance convergence and diversity in adaptive differential evolution.", "code": "import numpy as np\n\nclass DynamicPopulationAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 50\n        self.current_pop_size = self.initial_pop_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.initial_pop_size, self.dim)\n        )\n        fitness_values = np.full(self.initial_pop_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.current_pop_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.current_pop_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.current_pop_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.mutation_f += self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing\n            self.current_pop_size = max(5, self.initial_pop_size - int((self.current_evals / self.budget) * self.initial_pop_size))\n            population = population[:self.current_pop_size]\n            fitness_values = fitness_values[:self.current_pop_size]\n\n            # Local search around the current best position\n            local_search_radius = (func.bounds.ub - func.bounds.lb) * 0.01\n            local_search = self.best_global_position + np.random.uniform(-local_search_radius, local_search_radius, self.dim)\n            local_search = np.clip(local_search, func.bounds.lb, func.bounds.ub)\n            local_fitness = func(local_search)\n            self.current_evals += 1\n\n            if local_fitness < self.best_global_value:\n                self.best_global_value = local_fitness\n                self.best_global_position = local_search\n        \n        return self.best_global_position", "configspace": "", "generation": 27, "feedback": "The algorithm DynamicPopulationAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391349447372767, 0.11391781869547923, 0.11390622634397396, 0.07347984808919206, 0.07348134497542091, 0.07347725953707207, 0.09461683873986804, 0.09461943650507665, 0.09461239921431708]}}
{"id": "7ba94d92-5fad-419a-9cd1-38fd789df81f", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce dynamic population sizing and adaptive mutation strategies to enhance convergence and exploration in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["b21aab3e-1683-4a76-8a02-c1ba62fd445d"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "386bfb57-e427-4323-9d1c-02803ddb9122", "fitness": 0.09400298470624124, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce a random restart mechanism to enhance diversification and escape local optima in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.restart_threshold = 20  # New restart threshold parameter\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n            \n            # Random restart mechanism\n            if self.current_evals % self.restart_threshold == 0:\n                population = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(self.population_size, self.dim)\n                )\n                fitness_values = np.full(self.population_size, float('inf'))\n\n        return self.best_global_position", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391477465801392, 0.11391781869547923, 0.11390606156021554, 0.07348030486136248, 0.07348134497542091, 0.0734772009129917, 0.09461762155990783, 0.09461943650507665, 0.09461229862770293]}}
{"id": "41e2ea10-da2e-44f9-8653-fb2f4c3f1868", "fitness": 0.09400273400705013, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive scaling of mutation factor based on fitness variance to improve convergence in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + np.var(fitness_values) * self.adaptive_factor\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391390686754743, 0.11391781869547923, 0.11390477287841383, 0.0734799952733679, 0.07348134497542091, 0.07347818754656632, 0.09461709092979753, 0.09461943650507665, 0.09461205239178139]}}
{"id": "752ab317-7bec-47f6-b541-597fe0d65bce", "fitness": 0.09399708307119192, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Modify the trial vector selection criterion to include a small probability for random exploration, enhancing diversity and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate or np.random.rand() < 0.05:  # Added exploration\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11389191361948969, 0.11390229947436525, 0.11391746060477947, 0.07347214577956884, 0.07347580696970235, 0.07348126721500625, 0.09460363996428611, 0.09460994591237626, 0.09461926810115306]}}
{"id": "83375837-0b84-4c1e-9c6c-6d55c25be1b1", "fitness": 0.09400283789767978, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce fitness sharing and temporal diversity preservation to balance exploration and exploitation in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.sharing_sigma = 0.1\n\n    def fitness_sharing(self, fitness_values, population):\n        shared_fitness = np.copy(fitness_values)\n        for i in range(self.population_size):\n            sharing_sum = 0\n            for j in range(self.population_size):\n                distance = np.linalg.norm(population[i] - population[j])\n                if distance < self.sharing_sigma:\n                    sharing_sum += 1 - (distance / self.sharing_sigma)\n            if sharing_sum > 0:\n                shared_fitness[i] /= sharing_sum\n        return shared_fitness\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            shared_fitness = self.fitness_sharing(fitness_values, population)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < shared_fitness[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(shared_fitness)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391650885072802, 0.11391781869547923, 0.11390365670249047, 0.07348092359604208, 0.07348134497542091, 0.07347634228797895, 0.09461868197185297, 0.09461943650507665, 0.09461082749404881]}}
{"id": "d8a5e15f-c2b8-4d5e-9b39-af683db73d9f", "fitness": 0.09400115555352656, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation scaling that increases exploitation as evaluations progress in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust mutation factor dynamically to enhance exploitation\n            self.mutation_f *= (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391439135827375, 0.11391849593811465, 0.11389740497505152, 0.07348016810632108, 0.07348158660011117, 0.07347411112970204, 0.0946173871831314, 0.0946198506148741, 0.0946070040761593]}}
{"id": "b4c656c3-5594-42b7-bbc5-197e09062256", "fitness": 0.09400115555352656, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation factor decay to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n\n            # Adjust mutation factor decay to favor exploitation towards the end\n            self.mutation_f *= (1 - (self.current_evals / self.budget))\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391439135827375, 0.11391849593811465, 0.11389740497505152, 0.07348016810632108, 0.07348158660011117, 0.07347411112970204, 0.0946173871831314, 0.0946198506148741, 0.0946070040761593]}}
{"id": "6a6f7721-2de5-40cb-8ac8-503ae0298d9c", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce an adaptive learning rate to fine-tune exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "738ee77a-5bbb-4b4b-aee3-69508bb19122", "fitness": 0.09400220605920807, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance exploration by dynamically adjusting mutation factor's range to improve search capability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.5 + 0.3 * np.random.rand()  # Adjusted line to add randomness\n           \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.1139165643729938, 0.11391781869547923, 0.11390071197337781, 0.07348094341033384, 0.07348134497542091, 0.07347529172516487, 0.09461871592721749, 0.09461943650507665, 0.09460902694780804]}}
{"id": "c3f66284-9856-4c1a-b35d-368c2b3495af", "fitness": 0.0940017574374914, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Introduce adaptive learning rates and topological neighborhood restructuring to enhance convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.learning_rate = 0.1  # Initial learning rate for adaptive adjustments\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                # Select neighborhood dynamically\n                idxs = np.random.choice(range(self.population_size), size=3, replace=False)\n                while i in idxs:\n                    idxs = np.random.choice(range(self.population_size), size=3, replace=False)\n                a, b, c = population[idxs]\n                \n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = max(0.1, 0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Learning rate adaptation\n            self.learning_rate *= (1 - self.current_evals / self.budget)\n\n            # Dynamic population resizing with learning rate influence\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.learning_rate)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 37, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.1139079537037857, 0.11391756123468211, 0.11390752920843095, 0.07347786973793224, 0.07348125306297493, 0.07347772513671191, 0.0946134491718631, 0.09461927901868317, 0.09461319666235846]}}
{"id": "1d39ffac-f938-4897-8954-e936d2fb62f3", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance exploration by integrating a random reinitialization strategy and adjusting mutation dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Random reinitialization for exploration\n            if self.current_evals % (self.budget // 10) == 0:  # Line 1 change\n                random_idx = np.random.choice(self.population_size)  # Line 2 change\n                population[random_idx] = np.random.uniform(func.bounds.lb, func.bounds.ub, self.dim)  # Line 3 change\n\n        return self.best_global_position", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "52b6bc9a-5e54-47f6-bf51-d6030d0c4c99", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate a selection diversity mechanism and restart strategy to mitigate premature convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 1e-5\n        self.restart_allowed = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Check for diversity and restart if necessary\n            if np.std(population) < self.diversity_threshold and self.restart_allowed:\n                population = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(self.population_size, self.dim)\n                )\n                fitness_values = np.full(self.population_size, float('inf'))\n                self.restart_allowed = False  # Allow only one restart\n\n        return self.best_global_position", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "8fa993ec-cc70-4100-80f7-ca936d019680", "fitness": 0.09400454616722916, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Integrate a diversity maintenance strategy and mutation rate self-adaptation in Enhanced Adaptive Differential Evolution to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Diversity maintenance strategy\n            if np.std(fitness_values) < self.diversity_threshold:\n                self.mutation_f = min(1.0, self.mutation_f + 0.1)\n\n            # Dynamic population resizing\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391364082376187, 0.11391781869547923, 0.11391433499628267, 0.07347990031409302, 0.07348134497542091, 0.07348015304494149, 0.09461692823874368, 0.09461943650507665, 0.09461735791126291]}}
{"id": "3ae59c20-5388-47b2-88e3-bde1f3d5e112", "fitness": 0.09399648236229843, "name": "EnhancedAdaptiveDifferentialEvolutionWithOBL", "description": "Integrate opposition-based learning and a dynamic inertia weight in Enhanced Adaptive Differential Evolution to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionWithOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def opposition_based_learning(self, population, bounds):\n        min_b, max_b = bounds.lb, bounds.ub\n        return min_b + max_b - population\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = np.random.uniform(\n            low=bounds.lb,\n            high=bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            opposite_population = self.opposition_based_learning(population, bounds)\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                fitness_value_opp = func(opposite_population[i])\n                self.current_evals += 1\n\n                if fitness_value_opp < fitness_values[i]:\n                    population[i] = opposite_population[i]\n                    fitness_values[i] = fitness_value_opp\n                    if fitness_value_opp < self.best_global_value:\n                        self.best_global_value = fitness_value_opp\n                        self.best_global_position = opposite_population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, bounds.lb, bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionWithOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391968519705487, 0.11391743307319502, 0.11387180933572794, 0.07348205805305463, 0.07348120727985574, 0.07346497419817466, 0.0946206254455153, 0.09461920059242268, 0.09459134808568503]}}
{"id": "7dbd42ce-72c3-4695-97f8-991c5d47646c", "fitness": 0.09400203621332472, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce chaotic maps for parameter adaptation and an elitism mechanism to improve convergence and robustness in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\nimport math\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elitism_rate = 0.1\n        self.logistic_map_r = 4.0\n        self.logistic_map_x = 0.5\n\n    def chaotic_map(self):\n        self.logistic_map_x = self.logistic_map_r * self.logistic_map_x * (1 - self.logistic_map_x)\n        return self.logistic_map_x\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Adaptive adjustment using chaotic maps\n            self.crossover_rate = 0.7 + 0.2 * self.chaotic_map()\n            self.mutation_f = 0.5 + 0.3 * self.chaotic_map()\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            # Elitism mechanism\n            num_elites = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(fitness_values)[:num_elites]\n            elites = population[elite_indices]\n\n            # Replace some non-elite individuals with elites\n            non_elite_indices = np.setdiff1d(range(self.population_size), elite_indices)\n            np.random.shuffle(non_elite_indices)\n            replace_indices = non_elite_indices[:num_elites]\n            population[replace_indices] = elites\n\n        return self.best_global_position", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391574877852217, 0.11391781869547923, 0.11390075092089125, 0.07348065240815471, 0.07348134497542091, 0.07347530564524218, 0.09461821720287455, 0.09461943650507665, 0.09460905078826076]}}
{"id": "b97eb8da-b2c4-434c-a73d-78200b61a008", "fitness": 0.0935420964539772, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Introduce fitness diversity-based mutation and a memory-based adaptive control strategy to improve convergence in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.memory_mutation = self.mutation_f  # New line\n        self.memory_crossover = self.crossover_rate  # New line\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            # Calculate diversity (new block)\n            fitness_std = np.std(fitness_values)\n            diversity_factor = 1.0 / (1.0 + fitness_std)\n            \n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                # Use diversity-based mutation\n                mutant_vector = a + self.memory_mutation * diversity_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Memory-based adaptive control\n            self.memory_crossover = (self.memory_crossover + self.crossover_rate) / 2\n            self.memory_mutation = (self.memory_mutation + self.mutation_f) / 2\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget) + self.memory_crossover / 5\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget)) + self.memory_mutation / 5\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09354 with standard deviation 0.01652.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11346592539446954, 0.11346193981918484, 0.11344572022745736, 0.07301466049105043, 0.07301318961565073, 0.07301040113760204, 0.09416101553729894, 0.09415708382538823, 0.09414893203769259]}}
{"id": "de3155a6-2652-4a52-bb4f-626a2897bcf8", "fitness": 0.09400102946214273, "name": "ImprovedAdaptiveDifferentialEvolution", "description": "Introduce self-adaptive mechanisms for both crossover rate and mutation factor, along with fitness-based dynamic population resizing to further enhance convergence and exploration in Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass ImprovedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Self-adaptive adjustment of crossover rate and mutation factor\n            successful_trials = (fitness_values < self.best_global_value).sum()\n            success_ratio = successful_trials / self.population_size\n            self.crossover_rate = np.clip(0.9 - success_ratio * self.adaptive_factor, 0.1, 0.9)\n            self.mutation_f = np.clip(0.8 + success_ratio * self.adaptive_factor, 0.4, 1.2)\n            \n            # Fitness-based dynamic population resizing\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 44, "feedback": "The algorithm ImprovedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391185853817909, 0.11391796136714916, 0.11389989513708543, 0.07347926438740593, 0.07348139587747027, 0.07347500026976783, 0.09461583838476428, 0.09461952374379978, 0.09460852745366277]}}
{"id": "1b96dcf3-f0bc-4cc7-8bc3-56ed2d5c4dad", "fitness": 0.09399139673497237, "name": "RefinedEnhancedAdaptiveDifferentialEvolution", "description": "Incorporate a self-adaptive learning mechanism for mutation and crossover rates along with a memory-based elitism strategy to optimize performance in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.elite_memory = []\n        self.memory_size = 5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n                    self.elite_memory.append((fitness_value, population[i]))\n                    self.elite_memory.sort(key=lambda x: x[0])\n                    if len(self.elite_memory) > self.memory_size:\n                        self.elite_memory.pop()\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                if np.random.rand() < 0.1 and self.elite_memory:\n                    a, _ = self.elite_memory[np.random.randint(len(self.elite_memory))]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            self.crossover_rate = np.tanh(0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = np.tanh(0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget)))\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01650.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11389947375800535, 0.11388651759247825, 0.11388038689612567, 0.07347384399036416, 0.07347907675358545, 0.07347167153555068, 0.09460498165512587, 0.09461725107949148, 0.09460936735402437]}}
{"id": "cc120213-2294-4460-8916-452533c79702", "fitness": 0.09400212700455371, "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Adjust the adaptive factor to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.08  # Modified adaptive factor for improved performance\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391390938505053, 0.11391823438129323, 0.11390258969413103, 0.07347999614365874, 0.07348149328290576, 0.07347596177255, 0.0946170924679195, 0.09461969068245757, 0.094610175231017]}}
{"id": "8f345c86-9b1f-4af8-ab56-578f3400cc74", "fitness": 0.09400174631386352, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Incorporate adaptive learning rates and self-adaptive differential weights to enhance convergence efficiency in an advanced differential evolution algorithm.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.learning_rate = 0.1  # New adaptive learning rate\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n            \n            # Adaptive adjustment of crossover rate, mutation factor, and learning rate\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - (self.current_evals / self.budget))\n            self.learning_rate *= (1 - self.adaptive_factor * (self.current_evals / self.budget))  # New update rule\n            \n            # Self-adaptive differential weights\n            if np.random.rand() < self.learning_rate:\n                self.mutation_f *= np.random.uniform(0.9, 1.1)\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391341955696932, 0.11391781869547923, 0.11390175461779506, 0.07347982136617037, 0.07348134497542091, 0.07347566370037284, 0.09461679293677272, 0.09461943650507665, 0.0946096644707145]}}
{"id": "f2b6b33c-800a-436e-bd1e-75de73200594", "fitness": 0.09400100007835546, "name": "SelfAdaptiveCrowdedDifferentialEvolution", "description": "Implement a self-adaptive crowding distance and mutation strategy in Differential Evolution to balance exploration and exploitation and improve solution diversity.", "code": "import numpy as np\n\nclass SelfAdaptiveCrowdedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n\n                if fitness_value < self.best_global_value:\n                    self.best_global_value = fitness_value\n                    self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Self-adaptive crowding distance calculation\n            distances = np.zeros(self.population_size)\n            for i in range(self.population_size):\n                distances[i] = np.sum((population[i] - self.best_global_position) ** 2)\n            distances = np.sqrt(distances)\n\n            # Adaptive adjustment of crossover rate and mutation factor based on crowding distance\n            max_distance = np.max(distances)\n            min_distance = np.min(distances)\n            if max_distance > 0:\n                crowding_factor = (distances - min_distance) / (max_distance - min_distance)\n            else:\n                crowding_factor = np.zeros_like(distances)\n            \n            self.crossover_rate = 0.9 - self.adaptive_factor * crowding_factor.mean()\n            self.mutation_f = 0.8 + self.adaptive_factor * (1 - crowding_factor.mean())\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 48, "feedback": "The algorithm SelfAdaptiveCrowdedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390023349650358, 0.07347914662019295, 0.07348134497542091, 0.07347512101594444, 0.09461563655251182, 0.09461943650507665, 0.09460873437667217]}}
{"id": "fe28d493-db58-479b-b1ca-27d6a31e96d7", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Integrate a dynamic mutation factor adjustment based on fitness improvement history and incorporate elitism to retain the best solutions in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["7ba94d92-5fad-419a-9cd1-38fd789df81f"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "f613bb00-b2fa-42a6-90b9-28da4a7f947b", "fitness": 0.09400329026602998, "name": "RefinedEnhancedAdaptiveDifferentialEvolution", "description": "Incorporate a strategy that dynamically adjusts learning rates and implements adaptive parameter control based on diversity and convergence metrics in an Enhanced Adaptive Differential Evolution framework to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor based on diversity\n            diversity = np.mean(np.std(population, axis=0))\n            self.crossover_rate = max(0.5, 0.9 - self.adaptive_factor * diversity)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing with minimum size and based on convergence\n            convergence_metric = np.std(fitness_values)\n            new_population_size = max(5, int(self.initial_population_size * (1 - self.current_evals / self.budget) * (convergence_metric / self.diversity_threshold)))\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 50, "feedback": "The algorithm RefinedEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391327150633057, 0.11391781869547923, 0.11390896214115076, 0.07347976854016314, 0.07348134497542091, 0.07347823558864974, 0.09461670240401743, 0.09461943650507665, 0.09461407203798133]}}
{"id": "3944d372-b3cc-46af-afdd-bb429bf0c851", "fitness": 0.0939924941000826, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Refine mutation strategy by introducing random scaling of difference vectors and a probability-based elitism mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                scaling_factor = np.random.rand()  # Randomized scaling factor\n                mutant_vector = a + scaling_factor * self.mutation_f * (b - c)  # Random scaling\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11387829531199745, 0.11391376349749815, 0.11389863867674321, 0.07346728323427731, 0.07347989815435063, 0.07347454762352479, 0.09459530887567213, 0.09461695687593397, 0.09460775465074578]}}
{"id": "a469c46f-c4e1-4e5a-9a6e-ccfcf19bcd9b", "fitness": 0.09399979682696981, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a stochastic crossover rate in Enhanced Adaptive Differential Evolution to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:  # Stochastic crossover rate\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            self.crossover_rate = np.random.rand() * (0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391275675025003, 0.11391781869547923, 0.11389350412233679, 0.07347958487721917, 0.07348134497542091, 0.07347271921773302, 0.0946163876388012, 0.09461943650507665, 0.09460461866041125]}}
{"id": "a05717d9-1ba0-46d4-9886-083902714b80", "fitness": 0.09399563154612763, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a conditional mutation strategy to adaptively vary the mutation factor to guide convergence more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                self.mutation_f = 0.5 if self.best_global_value - fitness_values[i] > 1e-3 else 0.9  # Changed line\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391378747392311, 0.11391264464457673, 0.11387862167530316, 0.07347995394807671, 0.07347949877611204, 0.07346738861651014, 0.09461701926758814, 0.0946162725331583, 0.09459549697990033]}}
{"id": "b3474ec5-6df4-4a83-a8f2-0eaa9b6193d9", "fitness": 0.09400410610817853, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce adaptive mutation scaling based on population diversity in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) * diversity\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391585263856985, 0.11391781869547923, 0.11391011112240768, 0.07348068947408959, 0.07348134497542091, 0.07347864587444719, 0.094618280720981, 0.09461943650507665, 0.09461477496713466]}}
{"id": "67991d1d-b119-4bc3-ae5b-28e60e1bafc5", "fitness": -Infinity, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a diversity preservation mechanism by incorporating a niche-based selection strategy to maintain exploration while dynamically adjusting mutation and crossover rates in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.niche_radius = 0.1  # New parameter to help preserve diversity\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing with niche-based selection\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = self.niche_preserving_selection(population, fitness_values, new_population_size)\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position\n    \n    def niche_preserving_selection(self, population, fitness_values, new_population_size):\n        sorted_indices = np.argsort(fitness_values)\n        niche_population = []\n        niche_fitness = []\n        \n        for idx in sorted_indices:\n            candidate = population[idx]\n            if len(niche_population) < new_population_size:\n                if all(np.linalg.norm(candidate - np.array(niche_population), axis=1) > self.niche_radius):\n                    niche_population.append(candidate)\n                    niche_fitness.append(fitness_values[idx])\n                    \n        if len(niche_population) < new_population_size:\n            niche_population.extend(population[sorted_indices[len(niche_population):new_population_size]])\n        \n        return np.array(niche_population), np.array(niche_fitness)", "configspace": "", "generation": 55, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,) (0,) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,) (0,) ')", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {}}
{"id": "f7247ad8-944a-4ff2-966a-f30a59d80544", "fitness": 0.093987043874196, "name": "LearningEnhancedDifferentialEvolution", "description": "Integrate a learning-based mutation strategy and adaptive crossover mechanism to enhance solution convergence in an adaptive differential evolution framework. ", "code": "import numpy as np\n\nclass LearningEnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n        historical_mutation_factors = np.full(self.population_size, self.mutation_f)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Learning-based mutation factor\n                learning_rate = 0.01\n                historical_mutation_factors[i] = ((1 - learning_rate) * historical_mutation_factors[i] +\n                                                  learning_rate * np.random.rand())\n                mutant_vector = a + historical_mutation_factors[i] * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate\n            self.crossover_rate = 0.9 * (1 - np.exp(-0.1 * (self.current_evals / self.budget)))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                historical_mutation_factors = historical_mutation_factors[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 56, "feedback": "The algorithm LearningEnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11387549405493846, 0.1138823494558876, 0.11390793708795455, 0.07346627740241896, 0.0734686860699928, 0.07347787105595804, 0.09459358937821494, 0.09459774388472608, 0.09461344647767256]}}
{"id": "bd58e242-a8a9-4748-b0e2-d5cdf412d1db", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a dynamic learning rate for mutation based on population diversity and implement a restart mechanism to escape local minima in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.diversity_threshold = 1e-5  # Threshold for triggering restart\n        self.restart_factor = 0.1  # Percentage of population to restart\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            # Evaluate population fitness\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0))\n            \n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Restart mechanism\n            if diversity < self.diversity_threshold:\n                restart_size = int(self.population_size * self.restart_factor)\n                new_individuals = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(restart_size, self.dim)\n                )\n                worst_indices = np.argsort(fitness_values)[-restart_size:]\n                population[worst_indices] = new_individuals\n                fitness_values[worst_indices] = np.array([func(ind) for ind in new_individuals])\n                self.current_evals += restart_size\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "7ebd993a-ff0e-4900-8452-bf48c9abb64d", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a new adaptive mechanism that dynamically adjusts the crossover rate based on recent fitness improvements to enhance convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - (0.5 * self.adaptive_factor * (self.current_evals - self.last_improvement) / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "0bc27730-2afc-485b-81ff-465159488ccb", "fitness": -Infinity, "name": "PredatorPreyDifferentialEvolution", "description": "Incorporate competitive learning by introducing a predator-prey dynamic in the population, promoting exploration and exploitation balance in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass PredatorPreyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            # Evaluate current population\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            # Predator-prey dynamic\n            predators = np.argsort(fitness_values)[:int(self.population_size * 0.1)]\n            prey = np.argsort(fitness_values)[-int(self.population_size * 0.3):]\n            \n            for i in prey:\n                if self.current_evals >= self.budget:\n                    break\n\n                predator = np.random.choice(predators)\n                mutant_vector = population[predator] + self.mutation_f * (population[i] - population[predator])\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 59, "feedback": "An exception occurred: ValueError(\"'a' cannot be empty unless no samples are taken\").", "error": "ValueError(\"'a' cannot be empty unless no samples are taken\")", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {}}
{"id": "02908d2f-6e2e-4d3e-95bb-80032a4716f6", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a fitness diversity mechanism and adaptively adjust crossover and mutation factors based on convergence speed and population diversity in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.diversity_threshold = 1e-5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            diversity = np.std(population, axis=0).mean()\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            if diversity < self.diversity_threshold:\n                self.crossover_rate *= 1.5\n                self.mutation_f *= 1.5\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "44b3b970-8b40-4879-b15c-ab03914b9e85", "fitness": 0.09400361678654477, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Implement a mechanism to dynamically adapt crossover rates based on population diversity and incorporate a restart strategy to escape local minima in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.no_improvement_threshold = 50\n\n    def __call__(self, func):\n        def diversity_measure(population):\n            return np.mean(np.std(population, axis=0))\n\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            if self.current_evals > 0 and (self.current_evals - self.last_improvement) > self.no_improvement_threshold:\n                population = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(self.population_size, self.dim)\n                )\n                fitness_values = np.full(self.population_size, float('inf'))\n                self.last_improvement = self.current_evals\n                continue\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate based on diversity\n            population_diversity = diversity_measure(population)\n            self.crossover_rate = 0.9 - self.adaptive_factor * population_diversity\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11391219789864482, 0.07347914662019295, 0.07348134497542091, 0.07347939039787488, 0.09461563655251182, 0.09461943650507665, 0.09461605096630432]}}
{"id": "11f2b83a-38ef-4b45-8c7d-841abacbaaf8", "fitness": 0.093994268199908, "name": "HybridAdaptiveDifferentialEvolution", "description": "Implement a multi-phase approach combining adaptive differential evolution with a hybrid local search to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Hybrid mutation strategy\n                if np.random.rand() < 0.5:\n                    mutant_vector = a + self.mutation_f * (b - c)\n                else:\n                    mutant_vector = self.best_global_position + self.mutation_f * (a - b)\n                \n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 62, "feedback": "The algorithm HybridAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11388006226665759, 0.11391144266190756, 0.11390730318406184, 0.07346791119310991, 0.0734790693961751, 0.07347764369347398, 0.09459638677240068, 0.09461553700463576, 0.09461305762674954]}}
{"id": "bf2353b0-a90d-447b-80db-66bc5c5eeee7", "fitness": 0.09399121845924097, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a scaling factor in the mutation strategy for diversity and adjust crossover rate to be dynamic in the Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c) * np.random.rand()\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.5 + 0.4 * (1 - self.current_evals / self.budget) # Modified line\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11388855644285723, 0.11391018484084947, 0.11388612436206391, 0.07347094498295126, 0.07347862123963789, 0.07347008099331354, 0.0946015840331399, 0.09461476851829542, 0.09460010072006009]}}
{"id": "358f4757-a2cf-4b7e-9b21-0ad5ffe729c5", "fitness": 0.09399891879189211, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Integrate stochastic local search post-evaluation for fine-tuning solutions in Enhanced Adaptive Differential Evolution with dynamic control of mutation and crossover rates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.local_search_prob = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n                        \n                # Stochastic local search for fine-tuning\n                if np.random.rand() < self.local_search_prob:\n                    local_vector = trial_vector + np.random.normal(0, 0.1, self.dim)\n                    local_vector = np.clip(local_vector, func.bounds.lb, func.bounds.ub)\n                    local_fitness = func(local_vector)\n                    self.current_evals += 1\n\n                    if local_fitness < fitness_values[i]:\n                        fitness_values[i] = local_fitness\n                        population[i] = local_vector\n                        if local_fitness < self.best_global_value:\n                            self.best_global_value = local_fitness\n                            self.best_global_position = local_vector\n                            self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.1139157464314533, 0.11390408064270063, 0.1139002423109784, 0.07348065149959937, 0.07347644277460419, 0.07347511947893404, 0.09461821569404505, 0.09461103536951532, 0.09460873492519872]}}
{"id": "8576eb57-307c-4619-b83f-d469959a78e0", "fitness": 0.09400069779708162, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Adjust the mutation factor to a smaller adaptive range to refine convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / (2 * self.budget))  # Adjust mutation factor range\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391317728069783, 0.11391781869547923, 0.1138972033099187, 0.07347973492733373, 0.07348134497542091, 0.07347403905302274, 0.09461664479323595, 0.09461943650507665, 0.09460688063354883]}}
{"id": "1dbf16f5-a27d-4843-b006-3044215418f9", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a memory mechanism to adaptively influence mutation factor based on historical best improvements in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.improvement_memory = []\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n                        self.improvement_memory.append(fitness_value)\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n                        self.improvement_memory.append(trial_fitness)\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "df13003f-c981-4886-a2dc-895b1bfd6a26", "fitness": 0.09400102946214273, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a self-adaptive mutation and crossover strategy with a memory mechanism to enhance exploration-exploitation balance and maintain diversity in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.memory = []\n        self.mutation_f = 0.8\n        self.crossover_rate = 0.9\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            self.adapt_parameters()\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position\n\n    def adapt_parameters(self):\n        # Adaptive adjustment of crossover rate based on memory\n        if len(self.memory) > 0:\n            success_rate = sum(1 for val in self.memory if val) / len(self.memory)\n            self.crossover_rate = 0.9 - 0.5 * success_rate\n            self.mutation_f = 0.8 + 0.3 * (1 - success_rate)\n        else:\n            self.crossover_rate = 0.9\n            self.mutation_f = 0.8\n\n        if len(self.memory) > 50:\n            self.memory.pop(0)", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391185853817909, 0.11391796136714916, 0.11389989513708543, 0.07347926438740593, 0.07348139587747027, 0.07347500026976783, 0.09461583838476428, 0.09461952374379978, 0.09460852745366277]}}
{"id": "8235e1eb-6809-41f3-bcc9-ce2094b85241", "fitness": 0.09399980875772916, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce dynamic scaling of the mutation factor based on distance to the best solution found to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                # Introduce dynamic scaling of the mutation factor\n                distance_to_best = np.linalg.norm(population[i] - self.best_global_position)\n                dynamic_mutation_f = self.mutation_f * (1 + self.adaptive_factor * distance_to_best)\n\n                mutant_vector = a + dynamic_mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391270868632941, 0.11390050459467138, 0.11391092117851875, 0.07347956588335636, 0.0734751664428831, 0.07347893600251854, 0.09461635633989696, 0.09460884824701388, 0.0946152714443741]}}
{"id": "6121403c-b252-4e90-9253-ff8badab2123", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a dynamic selection pressure mechanism by replacing one selection criterion to improve convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "75e1aef1-91f1-4813-8bf6-1e9ac9a2ab8a", "fitness": 0.09399884160388833, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Introduce a decay factor to reduce mutation rate over time, enhancing local search capabilities progressively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            # Introduce a decay factor to the mutation factor\n            self.mutation_f = (0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)) * (1 - 0.5 * (self.current_evals / self.budget))\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391368788451994, 0.11391781869547923, 0.11388820597234472, 0.0734799171115953, 0.07348134497542091, 0.07347082811339456, 0.09461695702222217, 0.09461943650507665, 0.09460137815494152]}}
{"id": "763f3648-e3ed-4726-882e-584f94a19af5", "fitness": 0.09399633080150469, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Slightly update the mutation strategy by complementing static mutation with adaptive scaling based on population diversity for Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                diversity_scale = np.std(population, axis=0)  # Calculate population diversity\n                mutant_vector = a + self.mutation_f * (b - c) * (1 + diversity_scale)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11389574900292265, 0.11390732050765728, 0.1139051653735832, 0.07347351162001148, 0.0734775982024155, 0.07347688226445581, 0.09460598254101094, 0.09461301593291016, 0.09461175176857517]}}
{"id": "3b138d43-d81e-4b65-a57a-18e13fa3ba83", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Integrate a dynamic mutation factor adjustment based on fitness improvement history and incorporate elitism to retain the best solutions in Enhanced Adaptive Differential Evolution with an adaptive crossover rate adjustment mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = max(0.1, 0.9 - self.adaptive_factor * (self.current_evals / self.budget))\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "e33a7eb1-9fd3-4a55-8e98-968529abf0a4", "fitness": -Infinity, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Implement a self-adaptive mutation strategy combined with a diversity-based population resizing approach in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            diversity = np.mean(np.std(population, axis=0)) / (func.bounds.ub - func.bounds.lb)\n            if diversity < self.diversity_threshold:\n                self.mutation_f = 0.9 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            # Diversity-based population resizing\n            new_population_size = int(self.initial_population_size * (1 - diversity))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 73, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {}}
{"id": "97ef3a60-3b12-4736-af9b-73f062b006ce", "fitness": 0.09398972479618847, "name": "RefinedAdaptiveDifferentialEvolution", "description": "Introduce a dynamic scaling factor and a search history memory mechanism for improved diversity and faster convergence in a refined adaptive differential evolution algorithm.", "code": "import numpy as np\n\nclass RefinedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.scaling_factor_min = 0.4\n        self.scaling_factor_max = 1.2\n        self.search_history = []\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n                        self.search_history.append(population[i])\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                dynamic_f = self.scaling_factor_min + (self.scaling_factor_max - self.scaling_factor_min) * np.random.rand()\n                mutant_vector = a + dynamic_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n                        self.search_history.append(trial_vector)\n            \n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            \n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 74, "feedback": "The algorithm RefinedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11389124474404011, 0.11390469480349918, 0.11388209582310571, 0.07347190364367662, 0.07347666160943522, 0.07346864540203901, 0.09460322735515014, 0.09461141061335676, 0.09459763917139352]}}
{"id": "2c7f97ef-4da5-4837-a683-a483f777e4b6", "fitness": 0.09400102946214273, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Enhance adaptive differential evolution by integrating a self-adaptive learning strategy for control parameters and incorporating historical guidance to dynamically adjust mutation and crossover rates.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.success_params = []\n        self.failure_params = []\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n                        self.success_params.append((self.crossover_rate, self.mutation_f))\n                    else:\n                        self.failure_params.append((self.crossover_rate, self.mutation_f))\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n                        self.success_params.append((self.crossover_rate, self.mutation_f))\n                    else:\n                        self.failure_params.append((self.crossover_rate, self.mutation_f))\n            \n            # Self-adaptive learning strategy for control parameters\n            if self.success_params:\n                avg_success_rate = np.mean([cr for cr, _ in self.success_params])\n                avg_success_mutation = np.mean([mf for _, mf in self.success_params])\n                self.crossover_rate = 0.7 * self.crossover_rate + 0.3 * avg_success_rate\n                self.mutation_f = 0.7 * self.mutation_f + 0.3 * avg_success_mutation\n            \n            if self.failure_params:\n                avg_failure_rate = np.mean([cr for cr, _ in self.failure_params])\n                avg_failure_mutation = np.mean([mf for _, mf in self.failure_params])\n                self.crossover_rate = 0.9 * self.crossover_rate + 0.1 * avg_failure_rate\n                self.mutation_f = 0.9 * self.mutation_f + 0.1 * avg_failure_mutation\n            \n            self.success_params.clear()\n            self.failure_params.clear()\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391185853817909, 0.11391796136714916, 0.11389989513708543, 0.07347926438740593, 0.07348139587747027, 0.07347500026976783, 0.09461583838476428, 0.09461952374379978, 0.09460852745366277]}}
{"id": "2f14e81e-59ac-4140-8465-04816d77d0d8", "fitness": 0.09400462170123561, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Integrate a dynamic mutation factor adjustment based on fitness improvement history and incorporate elitism to retain the best solutions in Enhanced Adaptive Differential Evolution with a refined mutation factor for higher diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            self.mutation_f = 0.9 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)  # Adjusted line\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11391679274152622, 0.07347914662019295, 0.07348134497542091, 0.07348102996442307, 0.09461563655251182, 0.09461943650507665, 0.09461886078909221]}}
{"id": "2c452355-a163-4dd4-9e10-603331cf9df2", "fitness": 0.09400452682194957, "name": "EnhancedAdaptiveDifferentialEvolutionV2", "description": "Implement a self-adjusting mutation factor based on variance in the fitness values to improve convergence in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                \n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n            \n            # Adaptive adjustment of crossover rate and mutation factor\n            self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n            fitness_variance = np.var(fitness_values)  # Change here\n            self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) + 0.1 * fitness_variance\n            \n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391624452301641, 0.11391781869547923, 0.11391174318556219, 0.0734808295635756, 0.07348134497542091, 0.07347923679764545, 0.09461852035286089, 0.09461951432273163, 0.09461548898125383]}}
{"id": "fb1e30bd-98a9-4bec-bd2e-8c88862bafe4", "fitness": 0.09400496929608945, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a multi-phase population strategy with adaptive learning rates to dynamically optimize exploration and exploitation in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fe28d493-db58-479b-b1ca-27d6a31e96d7"], "operator": null, "metadata": {"aucs": [0.11391201193138156, 0.11391781869547923, 0.11391789864218205, 0.07347931912299277, 0.07348134497542091, 0.07348142455979179, 0.0946159321879646, 0.09461943650507665, 0.09461953704451553]}}
{"id": "aab12f26-00c0-4501-ac8a-9715732d7b0a", "fitness": 0.09400496929608945, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce strategic reinitialization and cooperative coevolution to diversify and enhance the optimization process in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.subcomponent_size = max(1, dim // 5)\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n            if self.current_evals % int(0.1 * self.budget) == 0:\n                subcomponents = [np.random.permutation(self.dim)[:self.subcomponent_size] for _ in range(self.population_size)]\n                for i, subcomponent in enumerate(subcomponents):\n                    # Cooperative Coevolution with subcomponents\n                    trial_vector = np.copy(population[i])\n                    trial_vector[subcomponent] = np.random.uniform(\n                        low=func.bounds.lb[subcomponent],\n                        high=func.bounds.ub[subcomponent],\n                        size=self.subcomponent_size\n                    )\n                    trial_fitness = func(trial_vector)\n                    self.current_evals += 1\n                    if trial_fitness < fitness_values[i]:\n                        fitness_values[i] = trial_fitness\n                        population[i] = trial_vector\n                        if trial_fitness < self.best_global_value:\n                            self.best_global_value = trial_fitness\n                            self.best_global_position = trial_vector\n\n        return self.best_global_position", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["fb1e30bd-98a9-4bec-bd2e-8c88862bafe4"], "operator": null, "metadata": {"aucs": [0.11391201193138156, 0.11391781869547923, 0.11391789864218205, 0.07347931912299277, 0.07348134497542091, 0.07348142455979179, 0.0946159321879646, 0.09461943650507665, 0.09461953704451553]}}
{"id": "81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3", "fitness": 0.09400507132729104, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Enhance the adaptive mutation strategy based on the stagnation period in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)  # Modified\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["fb1e30bd-98a9-4bec-bd2e-8c88862bafe4"], "operator": null, "metadata": {"aucs": [0.11391247996597398, 0.11391781869547923, 0.1139178971436775, 0.07347948611934818, 0.07348134497542091, 0.073481424025163, 0.09461621838724188, 0.09461943650507665, 0.09461953612823804]}}
{"id": "37192596-d79f-4ddb-af74-84cd8708d663", "fitness": 0.09399878882434703, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduced a slight modification to the formula for the adaptive adjustment of the mutation factor, aiming for better adaptability in both exploration and exploitation phases.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * 0.5 * ((self.current_evals - self.last_improvement) / self.budget)  # Modified\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391415584062747, 0.11391781869547923, 0.11388749675947973, 0.07348008407022788, 0.07348134497542091, 0.0734705749990695, 0.09461724316349895, 0.09461943650507665, 0.09460094441024303]}}
{"id": "d7759db8-bed2-4e28-82e8-8a89911cf41e", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Improve the mutation factor adaptation mechanism to enhance convergence speed in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 1.5) * ((self.current_evals - self.last_improvement) / self.budget)  # Modified\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "86919325-4e0a-4214-b56d-f1719c3b6b62", "fitness": 0.09399152342262661, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce adaptive learning of mutation and crossover rates based on historical performance in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.base_crossover_rate = 0.7\n        self.base_mutation_f = 0.5\n        self.learning_rate = 0.1\n        self.historical_crossover = []\n        self.historical_mutation_f = []\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.base_mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.base_crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n\n            # Update historical performance\n            self.historical_crossover.append(self.base_crossover_rate)\n            self.historical_mutation_f.append(self.base_mutation_f)\n\n            # Adaptive adjustment based on historical performance\n            if len(self.historical_crossover) > 5:\n                performance_improvement = np.diff(self.historical_crossover[-5:])\n                if np.mean(performance_improvement) > 0:\n                    self.base_crossover_rate += self.learning_rate * np.mean(performance_improvement)\n                else:\n                    self.base_crossover_rate -= self.learning_rate * np.mean(performance_improvement)\n\n                performance_improvement = np.diff(self.historical_mutation_f[-5:])\n                if np.mean(performance_improvement) > 0:\n                    self.base_mutation_f += self.learning_rate * np.mean(performance_improvement)\n                else:\n                    self.base_mutation_f -= self.learning_rate * np.mean(performance_improvement)\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09399 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11388832439847674, 0.11390739248456505, 0.11389053876821675, 0.07347086507427458, 0.07347762415969517, 0.0734716582309386, 0.09460144512454538, 0.09461306023156035, 0.09460280233136686]}}
{"id": "8515f220-39d3-4474-a53d-87a7412598ed", "fitness": 0.09399503957258007, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce multi-strategy mutation and adaptive control of exploration-exploitation balance in Enhanced Adaptive Differential Evolution to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.strategy_switch_threshold = 0.5\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                if np.random.rand() < self.strategy_switch_threshold:\n                    # DE/rand/1 mutation strategy\n                    mutant_vector = a + self.mutation_f * (b - c)\n                else:\n                    # DE/best/1 mutation strategy\n                    mutant_vector = self.best_global_position + self.mutation_f * (b - c)\n\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.1138971434246604, 0.1139069506304713, 0.11389823553460643, 0.07347401192824154, 0.07347746687612544, 0.07347440738411803, 0.09460683808812798, 0.09461279042590143, 0.09460751186096805]}}
{"id": "13222500-87db-4782-91c3-40fa7360ac60", "fitness": 0.09400311147036386, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Improve adaptive parameter adjustment by incorporating feedback from convergence speed into Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.prev_best_global_value = float('inf')\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.prev_best_global_value = self.best_global_value\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.prev_best_global_value = self.best_global_value\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor based on convergence speed\n            improvement_rate = (self.prev_best_global_value - self.best_global_value) / (self.best_global_value + 1e-10)\n            if self.exploration_phase:\n                self.crossover_rate = max(0.1, 0.9 - self.adaptive_factor * (self.current_evals / self.budget) * (1 + improvement_rate))\n                self.mutation_f = min(1.2, 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) * (1 - improvement_rate))\n            else:\n                self.crossover_rate = max(0.2, 0.5 + self.adaptive_factor * (self.current_evals / self.budget) * (1 + improvement_rate))\n                self.mutation_f = min(1.5, 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget) * (1 - improvement_rate))\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391304242264444, 0.11391781869547923, 0.1139099398063117, 0.07347968873805943, 0.07348134497542091, 0.07347707980267215, 0.09461563655251182, 0.09461943650507665, 0.09461401573509842]}}
{"id": "ecee3bb5-6a98-472c-aeab-1d57c3840a7d", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Refine the mutation factor formula during exploitation to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 1.5) * ((self.current_evals - self.last_improvement) / self.budget)  # Modified\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "6e47c5b7-3162-495f-bc83-eae9a957d8b4", "fitness": 0.09400217918934707, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Minor adjustment to the adaptive mutation factor calculation for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) * 0.95  # Changed\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390562489590161, 0.07347914662019295, 0.07348134497542091, 0.07347704475162875, 0.09461563655251182, 0.09461943650507665, 0.09461203124051432]}}
{"id": "f4d7b006-b9f0-41dd-91ba-f86d302175e9", "fitness": 0.09400494854299062, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Slightly refine the mutation factor adaptive adjustment for improved diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 1.8) * ((self.current_evals - self.last_improvement) / self.budget)  # Modified\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391820877630054, 0.1139178971436775, 0.07347914662019295, 0.07348148414759237, 0.073481424025163, 0.09461563655251182, 0.0946196750258419, 0.09461953612823804]}}
{"id": "7ca44c8d-6626-4874-90d3-8dd46a3eb1f3", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce a self-adaptive mutation rate using fitness diversity and restart mechanism to Enhanced Adaptive Differential Evolution for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.base_mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.diversity_threshold = 0.01\n        self.stagnation_limit = 0.1 * self.budget\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.base_mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            fitness_std = np.std(fitness_values)\n            if fitness_std < self.diversity_threshold and self.current_evals - self.last_improvement > self.stagnation_limit:\n                self.crossover_rate = 0.9\n                self.base_mutation_f = 0.8 + np.random.rand() * 0.2\n                # Restart mechanism by reinitializing half of the population\n                indices_to_restart = np.random.choice(self.population_size, self.population_size // 2, replace=False)\n                population[indices_to_restart] = np.random.uniform(\n                    low=func.bounds.lb,\n                    high=func.bounds.ub,\n                    size=(len(indices_to_restart), self.dim)\n                )\n                self.last_improvement = self.current_evals\n            else:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.base_mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "6a7a0e7b-c63e-4b3f-ab5e-53b409aae1fb", "fitness": 0.09400486323479527, "name": "ConfidenceAdaptiveDifferentialEvolution", "description": "Introduce a confidence-based mutation strategy to dynamically adjust exploration and exploitation in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass ConfidenceAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.confidence_threshold = 0.1  # New confidence-based parameter\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor using confidence\n            confidence = (self.best_global_value - np.min(fitness_values)) / np.abs(self.best_global_value)\n            if confidence < self.confidence_threshold:\n                self.exploration_phase = True\n            else:\n                self.exploration_phase = False\n                \n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 90, "feedback": "The algorithm ConfidenceAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "c5b8716f-ae16-4110-bd64-626ca9434d4a", "fitness": 0.09400164740429308, "name": "FeedbackDrivenDifferentialEvolution", "description": "Introduce a feedback-driven dynamic strategy adapting both mutation and crossover based on diversity and stagnation metrics to refine Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass FeedbackDrivenDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Calculate population diversity\n            population_std = np.std(population, axis=0)\n            diversity = np.mean(population_std / (func.bounds.ub - func.bounds.lb))\n\n            # Feedback-driven adaptive adjustment of crossover rate and mutation factor\n            if diversity < self.diversity_threshold:\n                self.crossover_rate = max(0.5, self.crossover_rate - self.adaptive_factor)\n                self.mutation_f = min(1.0, self.mutation_f + self.adaptive_factor)\n            else:\n                self.crossover_rate = min(0.9, self.crossover_rate + self.adaptive_factor)\n                self.mutation_f = max(0.5, self.mutation_f - self.adaptive_factor)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            new_population_size = max(5, new_population_size)\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 91, "feedback": "The algorithm FeedbackDrivenDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11390319374840208, 0.07347914662019295, 0.07348134497542091, 0.07347617689227592, 0.09461563655251182, 0.09461943650507665, 0.09461054418188075]}}
{"id": "3f566d75-1b3d-4d7c-b6db-45a8631bf992", "fitness": 0.09400507132729104, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce adaptive local search and elitist selection to enhance convergence and exploitation in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def local_search(self, pos, func):\n        \"\"\"Perform a simple local search by perturbing the position slightly.\"\"\"\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        new_pos = np.clip(pos + perturbation, func.bounds.lb, func.bounds.ub)\n        return new_pos\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n                # Local search on the best-known position\n                if trial_fitness < self.best_global_value:\n                    improved_pos = self.local_search(trial_vector, func)\n                    improved_fitness = func(improved_pos)\n                    self.current_evals += 1\n                    if improved_fitness < self.best_global_value:\n                        self.best_global_value = improved_fitness\n                        self.best_global_position = improved_pos\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Elitist selection\n            sorted_indices = np.argsort(fitness_values)\n            population = population[sorted_indices]\n            fitness_values = fitness_values[sorted_indices]\n            self.population_size = min(self.population_size, len(sorted_indices))\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                population = population[:new_population_size]\n                fitness_values = fitness_values[:new_population_size]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391247996597398, 0.11391781869547923, 0.1139178971436775, 0.07347948611934818, 0.07348134497542091, 0.073481424025163, 0.09461621838724188, 0.09461943650507665, 0.09461953612823804]}}
{"id": "8fc0f7e6-23ac-46ee-99e5-93b66e31a9d1", "fitness": 0.09399727803174945, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce the concept of adaptive local search with dynamic scaling to enhance exploitation in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.local_search_scale = 0.02\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n                # Adaptive local search\n                if np.random.rand() < 0.1:  # 10% chance to perform local search\n                    local_trial_vector = population[i] + np.random.normal(0, self.local_search_scale, self.dim)\n                    local_trial_vector = np.clip(local_trial_vector, func.bounds.lb, func.bounds.ub)\n                    local_trial_fitness = func(local_trial_vector)\n                    self.current_evals += 1\n                    if local_trial_fitness < fitness_values[i]:\n                        fitness_values[i] = local_trial_fitness\n                        population[i] = local_trial_vector\n                        if local_trial_fitness < self.best_global_value:\n                            self.best_global_value = local_trial_fitness\n                            self.best_global_position = local_trial_vector\n                            self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391059131663561, 0.11390427898044819, 0.11389769836707353, 0.07347881210786522, 0.07347651338523076, 0.07347421040001145, 0.09461506335440795, 0.09461115648896001, 0.0946071778851123]}}
{"id": "2b1f138f-33f6-4ef7-8cb5-dfaf52748587", "fitness": 0.09400486323479527, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Integrate dynamic scaling and adaptive mutation strategies with multi-phase evolution to enhance balance between exploration and exploitation.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.phase_switch = self.budget // 3  # Divide the budget into phases\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adjust parameters based on the phase\n            if self.current_evals < self.phase_switch:\n                # Exploration phase\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            elif self.current_evals < 2 * self.phase_switch:\n                # Transition phase\n                self.crossover_rate = 0.7 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.6 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                # Exploitation phase\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            new_population_size = max(new_population_size, 5)\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.1139178971436775, 0.07347914662019295, 0.07348134497542091, 0.073481424025163, 0.09461563655251182, 0.09461943650507665, 0.09461953612823804]}}
{"id": "820d3eac-697f-4b22-bca2-f92ad3cf04e6", "fitness": 0.09400484280983304, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Integrate a dynamic archival and replacement mechanism to the adaptive mutation strategy in Enhanced Adaptive Differential Evolution for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.archive = []  # Initialize an archive for maintaining diversity\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n                else:\n                    # Add trial vector to archive if not improving\n                    self.archive.append((trial_vector, trial_fitness))\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n                # Incorporate archival elements if possible\n                if self.archive:\n                    archive_indices = np.argsort([fit for _, fit in self.archive])[:self.population_size]\n                    for idx in archive_indices:\n                        candidate, candidate_fitness = self.archive[idx]\n                        if candidate_fitness < max(fitness_values):\n                            worst_idx = np.argmax(fitness_values)\n                            population[worst_idx] = candidate\n                            fitness_values[worst_idx] = candidate_fitness\n\n        return self.best_global_position", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391679321686476, 0.11391781869547923, 0.11391253914757804, 0.07348102506503174, 0.07348134497542091, 0.07347951216813597, 0.09461885586588292, 0.09461943650507665, 0.09461625964902709]}}
{"id": "d3e52397-32ba-43c2-b5a7-edcb86f1f7a3", "fitness": 0.09399884887904769, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Introduce dual mutation factors and adaptive decay to balance exploration and exploitation dynamically in Enhanced Adaptive Differential Evolution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f1 = 0.8\n        self.mutation_f2 = 0.5\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n        self.dynamic_decay = 0.99\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                if np.random.rand() > 0.5:\n                    mutation_factor = self.mutation_f1\n                else:\n                    mutation_factor = self.mutation_f2\n                mutant_vector = a + mutation_factor * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f1 *= self.dynamic_decay\n                self.mutation_f2 *= self.dynamic_decay\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f1 *= (self.dynamic_decay ** 2)\n                self.mutation_f2 *= (self.dynamic_decay ** 2)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11390693344584146, 0.11390897424051993, 0.11390384053516922, 0.07347750669596109, 0.07347818888836, 0.07347640501716313, 0.09461282631640833, 0.09461402782716011, 0.0946109369448459]}}
{"id": "99acfe80-ebe7-49d7-9466-64b016a960c2", "fitness": 0.09400205471387983, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Refine Enhanced Adaptive Differential Evolution by adjusting adaptive factors for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.1  # Changed from 0.05 to 0.1\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget)\n            else:\n                self.crossover_rate = 0.6 + self.adaptive_factor * (self.current_evals / self.budget)  # Changed from 0.5 to 0.6\n                self.mutation_f = 0.6 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)  # Changed from 0.5 to 0.6\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391337984002681, 0.11391781869547923, 0.11390320437467216, 0.07347980719876257, 0.07348134497542091, 0.07347618108567988, 0.0946167686540087, 0.09461943650507665, 0.09461055109579153]}}
{"id": "a91647c2-34b6-47cb-b4a2-c11db03e541d", "fitness": 0.09399885398938912, "name": "EnhancedAdaptiveDifferentialEvolutionV4", "description": "Integrate a learning-based approach for dynamic parameter tuning and introduce a feedback mechanism to enhance the adaptive mutation strategy in Enhanced Adaptive Differential Evolution.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor with feedback mechanism\n            improvement_rate = (self.current_evals - self.last_improvement) / self.budget\n            self.crossover_rate = 0.9 - self.adaptive_factor * (improvement_rate if self.exploration_phase else (1 - improvement_rate))\n            self.mutation_f = 0.8 + self.adaptive_factor * (improvement_rate if not self.exploration_phase else (1 - improvement_rate)) \n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing with learning-based approach\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391496174957505, 0.11391781869547923, 0.1138869889269869, 0.07348037159878773, 0.07348134497542091, 0.07347039371863351, 0.09461773594669587, 0.09461943650507665, 0.09460063378784622]}}
{"id": "e3b5038d-7951-4549-b307-07277ec7fa05", "fitness": 0.09400447510249113, "name": "EnhancedAdaptiveDifferentialEvolutionV3", "description": "Introduce a dynamic mutation factor adjustment based on the difference between current and best global fitness values to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolutionV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.best_global_position = None\n        self.best_global_value = float('inf')\n        self.current_evals = 0\n        self.crossover_rate = 0.9\n        self.mutation_f = 0.8\n        self.adaptive_factor = 0.05\n        self.last_improvement = 0\n        self.exploration_phase = True\n\n    def __call__(self, func):\n        population = np.random.uniform(\n            low=func.bounds.lb,\n            high=func.bounds.ub,\n            size=(self.population_size, self.dim)\n        )\n        fitness_values = np.full(self.population_size, float('inf'))\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n                fitness_value = func(population[i])\n                self.current_evals += 1\n\n                if fitness_value < fitness_values[i]:\n                    fitness_values[i] = fitness_value\n                    if fitness_value < self.best_global_value:\n                        self.best_global_value = fitness_value\n                        self.best_global_position = population[i]\n                        self.last_improvement = self.current_evals\n\n            for i in range(self.population_size):\n                if self.current_evals >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant_vector = a + self.mutation_f * (b - c)\n                mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n\n                trial_vector = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_rate:\n                        trial_vector[j] = mutant_vector[j]\n\n                trial_fitness = func(trial_vector)\n                self.current_evals += 1\n\n                if trial_fitness < fitness_values[i]:\n                    fitness_values[i] = trial_fitness\n                    population[i] = trial_vector\n                    if trial_fitness < self.best_global_value:\n                        self.best_global_value = trial_fitness\n                        self.best_global_position = trial_vector\n                        self.last_improvement = self.current_evals\n\n            # Adaptive adjustment of crossover rate and mutation factor\n            if self.exploration_phase:\n                self.crossover_rate = 0.9 - self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.8 + self.adaptive_factor * ((self.current_evals - self.last_improvement) / self.budget) + 0.1 * (fitness_values.mean() - self.best_global_value)  # Modified\n            else:\n                self.crossover_rate = 0.5 + self.adaptive_factor * (self.current_evals / self.budget)\n                self.mutation_f = 0.5 + (self.adaptive_factor * 2) * ((self.current_evals - self.last_improvement) / self.budget)\n\n            # Switch between exploration and exploitation phases\n            if self.current_evals > self.budget * 0.5:\n                self.exploration_phase = False\n\n            # Dynamic population resizing\n            new_population_size = int(self.initial_population_size * (1 - self.current_evals / self.budget))\n            if new_population_size < 5:\n                new_population_size = 5\n            if new_population_size < self.population_size:\n                indices_to_keep = np.argsort(fitness_values)[:new_population_size]\n                population = population[indices_to_keep]\n                fitness_values = fitness_values[indices_to_keep]\n                self.population_size = new_population_size\n\n        return self.best_global_position", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolutionV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["81eeeb3f-b775-4b7f-a6ae-cb934b86b4b3"], "operator": null, "metadata": {"aucs": [0.11391152846739738, 0.11391781869547923, 0.11391590432125276, 0.0734795763919921, 0.07348134497542091, 0.07348071284415658, 0.09461563655251182, 0.09461943650507665, 0.09461831716913272]}}
