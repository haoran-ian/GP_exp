{"id": "255c67fb-3c3c-41d9-bef1-161eae5436d4", "fitness": 0.0688089430912362, "name": "HybridOptimizer", "description": "A hybrid metaheuristic algorithm combining differential evolution and simulated annealing for enhanced exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f=0.8):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.7):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / self.temperature)\n\n    def _anneal(self, candidate, current, func):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                population[i], fitness[i] = self._anneal(trial, population[i], func)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            self.temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 0, "feedback": "The algorithm HybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06881 with standard deviation 0.00954.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05787376382172882, 0.08112477691391207, 0.0674282885380677]}}
{"id": "eae9f036-2694-4362-9660-5c98b7db7e34", "fitness": 0.06671369109085139, "name": "EnhancedHybridOptimizer", "description": "Enhanced HybridOptimizer using adaptive parameter control and local search for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.f = 0.8\n        self.cr = 0.7\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant):\n        mask = np.random.rand(self.dim) < self.cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / self.temperature)\n\n    def _anneal(self, candidate, current, func):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _local_search(self, current, func):\n        perturbation = np.random.normal(0, 0.1, size=current.shape)\n        candidate = np.clip(current + perturbation, self.bounds.lb, self.bounds.ub)\n        return self._anneal(candidate, current, func)\n\n    def _adaptive_parameters(self, evaluations):\n        self.f = max(0.5, 1.0 - (evaluations / self.budget))\n        self.cr = min(0.9, 0.5 + (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self._adaptive_parameters(evaluations)\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                population[i], fitness[i] = self._anneal(trial, population[i], func)\n                population[i], fitness[i] = self._local_search(population[i], func)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            self.temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06671 with standard deviation 0.01325.", "error": "", "parent_ids": ["255c67fb-3c3c-41d9-bef1-161eae5436d4"], "operator": null, "metadata": {"aucs": [0.05208283531841629, 0.0841749183234175, 0.06388331963072036]}}
{"id": "ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d", "fitness": 0.08631052716602623, "name": "ImprovedHybridOptimizer", "description": "Improved HybridOptimizer using adaptive differential evolution and dynamic simulated annealing for better convergence speed and precision.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f_min=0.5, f_max=0.9):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = np.random.uniform(f_min, f_max)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08631 with standard deviation 0.00340.", "error": "", "parent_ids": ["255c67fb-3c3c-41d9-bef1-161eae5436d4"], "operator": null, "metadata": {"aucs": [0.08531974135623255, 0.09088075309342958, 0.08273108704841659]}}
{"id": "8a4a7dc1-3868-45ff-a37c-a7523e457740", "fitness": 0.06867369175358817, "name": "EnhancedHybridOptimizer", "description": "Enhanced Adaptive HybridOptimizer leveraging self-adjusting differential evolution strategies and adaptive cooling for robust optimization performance.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f_min=0.5, f_max=0.9):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = np.random.uniform(f_min, f_max)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                f_min_adaptive = 0.4 + 0.5 * (1 - evaluations / self.budget)\n                f_max_adaptive = 0.8 + 0.2 * (1 - evaluations / self.budget)\n                mutant = self._mutate(i, population, f_min=f_min_adaptive, f_max=f_max_adaptive)\n                cr_adaptive = 0.3 + 0.7 * (1 - fitness[i] / np.max(fitness))\n                trial = self._crossover(population[i], mutant, cr=cr_adaptive)\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06867 with standard deviation 0.00970.", "error": "", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {"aucs": [0.059843245757828845, 0.08218081782226982, 0.06399701168066585]}}
{"id": "02b51953-fa90-45d1-a20e-af1e0c977e00", "fitness": -Infinity, "name": "ImprovedHybridOptimizer", "description": "Enhanced mutation strategy with adaptive crossover rate to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f_min=0.5, f_max=0.9):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = np.random.uniform(f_min, f_max)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.1 + 0.9 * np.exp(-0.005 * self.budget)):  # Adjusted crossover rate\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 4, "feedback": "An exception occurred: NameError(\"name 'self' is not defined\").", "error": "NameError(\"name 'self' is not defined\")", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {}}
{"id": "2424b4aa-5471-4ad1-9b9c-b49aa147787f", "fitness": 0.08444004551176205, "name": "ImprovedHybridOptimizer", "description": "Enhanced mutation strategy with self-adaptive scaling factor for improved exploration.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f_min=0.5, f_max=0.9):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = np.random.uniform(f_min, f_max) * (self.budget - self.evaluations) / self.budget  # Self-adaptive scaling factor\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 5, "feedback": "The algorithm ImprovedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08444 with standard deviation 0.00506.", "error": "", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {"aucs": [0.08790452923624925, 0.07729060784148756, 0.08812499945754937]}}
{"id": "e6a7a361-8b49-4384-b5b5-fb83065f9695", "fitness": 0.07451235645448025, "name": "ImprovedHybridOptimizer", "description": "Enhanced ImprovedHybridOptimizer by integrating a self-adaptive mutation factor and a temperature-dependent crossover rate for more robust exploration and exploitation.", "code": "import numpy as np\n\nclass ImprovedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.mutation_memory = [0.5, 0.9]  # Track successful mutation factors\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = np.random.choice(self.mutation_memory)  # Use self-adaptive mutation factor\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            cr = 0.5 * (1 + np.tanh((self.initial_temp - temperature) / 50))  # Temperature-dependent crossover rate\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant, cr)\n                old_fitness = fitness[i]\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                if fitness[i] < old_fitness:  # Update mutation memory\n                    self.mutation_memory.append(np.random.uniform(0.5, 0.9))\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 6, "feedback": "The algorithm ImprovedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07451 with standard deviation 0.00592.", "error": "", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {"aucs": [0.07241839269833894, 0.08257487462573887, 0.06854380203936294]}}
{"id": "1916b460-6f8e-4720-9975-660994e04e58", "fitness": 0.08238713677615368, "name": "EnhancedHybridOptimizer", "description": "EnhancedHybridOptimizer incorporates a self-adaptive learning scheme for mutation rates and crossover probabilities to dynamically adjust exploration and exploitation, improving convergence efficiency and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        \n        # Self-adaptive parameters\n        self.f_min = 0.4\n        self.f_max = 0.9\n        self.cr_min = 0.3\n        self.cr_max = 0.8\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, f):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Self-adaptive learning for f and cr\n                f = np.random.uniform(self.f_min, self.f_max)\n                cr = np.random.uniform(self.cr_min, self.cr_max)\n                \n                mutant = self._mutate(i, population, f)\n                trial = self._crossover(population[i], mutant, cr)\n                population[i], fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08239 with standard deviation 0.00589.", "error": "", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {"aucs": [0.09064704315309846, 0.07729060784148756, 0.07922375933387504]}}
{"id": "32dae497-d98f-4143-8209-724367256e95", "fitness": 0.11921913208416297, "name": "RefinedHybridOptimizer", "description": "Refined HybridOptimizer integrating adaptive mutation control and elitism strategy to enhance convergence efficiency and precision.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    # Preserve elite individuals\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update population with elitism\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 8, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11922 with standard deviation 0.01696.", "error": "", "parent_ids": ["ccb8a231-9dd6-4bcb-b4e0-da893ba8ff7d"], "operator": null, "metadata": {"aucs": [0.11751438305614759, 0.14078914174621115, 0.0993538714501302]}}
{"id": "0475e54b-8ac9-40e6-8cc5-6505c38b7198", "fitness": -Infinity, "name": "EnhancedHybridOptimizer", "description": "EnhancedHybridOptimizer utilizing an adaptive population size and stochastic tunneling to improve exploration and convergence precision.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.1\n        self.adaptive_rate = 0.1\n\n    def _initialize_population(self, size):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (size, self.dim))\n\n    def _adaptive_population_size(self, evaluations):\n        return int(self.initial_population_size * (1 + self.adaptive_rate * (1 - evaluations / self.budget)))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _stochastic_tunneling(self, fitness, q=0.1):\n        min_fitness = np.min(fitness)\n        return np.exp(-q * (fitness - min_fitness))\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population_size = self.initial_population_size\n        population = self._initialize_population(population_size)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * population_size)\n\n        while evaluations < self.budget:\n            # Adaptive population size\n            population_size = self._adaptive_population_size(evaluations)\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Include stochastic tunneling\n            tunneled_fitness = self._stochastic_tunneling(new_fitness)\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, tunneled_fitness))\n            best_indices = np.argsort(combined_fitness)[:population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 9, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["32dae497-d98f-4143-8209-724367256e95"], "operator": null, "metadata": {}}
{"id": "deec2c89-9006-46e5-8c69-794684b6340d", "fitness": 0.10959423864783428, "name": "RefinedHybridOptimizer", "description": "Refined HybridOptimizer with enhanced temperature initialization and updated crossover strategy to boost convergence efficiency.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 10.0  # Change 1: Lower initial temperature for faster convergence\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.9):  # Change 2: Increase crossover rate to enhance diversity\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    # Preserve elite individuals\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update population with elitism\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10959 with standard deviation 0.00550.", "error": "", "parent_ids": ["32dae497-d98f-4143-8209-724367256e95"], "operator": null, "metadata": {"aucs": [0.10854410266090564, 0.1167981735915441, 0.1034404396910531]}}
{"id": "d6762403-eab6-4965-936a-cb396d99b207", "fitness": 0.1317218241483129, "name": "RefinedHybridOptimizer", "description": "Enhanced RefinedHybridOptimizer with improved adaptive mutation and elitism strategy to boost exploration and convergence efficiency.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98  # Increased cooling rate for better exploration\n        self.bounds = None\n        self.elitism_rate = 0.2  # Increased elitism rate to preserve more top-performing individuals\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):  # Adjusted f_min to increase mutation rate\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    # Preserve elite individuals\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update population with elitism\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 11, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13172 with standard deviation 0.02096.", "error": "", "parent_ids": ["32dae497-d98f-4143-8209-724367256e95"], "operator": null, "metadata": {"aucs": [0.1592789120420347, 0.12739616292988032, 0.10849039747302369]}}
{"id": "11ccdbdf-ce08-4f1d-8af7-1e8bfc4d68f0", "fitness": 0.1317218241483129, "name": "RefinedHybridOptimizer", "description": "Optimized mutation and cooling strategies to enhance exploration-convergence balance in RefinedHybridOptimizer.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate for gradual temperature reduction\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):  # Adjusted f_min for greater mutation diversity\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 12, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13172 with standard deviation 0.02096.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.1592789120420347, 0.12739616292988032, 0.10849039747302369]}}
{"id": "998a9dfb-0fb5-49ae-8372-57259cab4098", "fitness": 0.12569192565531598, "name": "RefinedHybridOptimizer", "description": "Enhanced HybridOptimized with integrated differential mutation strategy for improved convergence and solution accuracy.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + 0.1 * (population[a] - population[target_idx])  # Modified differential strategy\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 13, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12569 with standard deviation 0.01384.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.11295713320892642, 0.14492944514804185, 0.1191891986089797]}}
{"id": "54fb4a36-d285-48df-a844-97b9f3277d95", "fitness": 0.0974612957796976, "name": "HybridAdaptiveExplorationOptimizer", "description": "Hybrid Adaptive Exploration Optimizer integrates dynamic self-adaptation and clustering to enhance global exploration and local exploitation.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass HybridAdaptiveExplorationOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.99  # Increased cooling rate for gradual cooling\n        self.bounds = None\n        self.elitism_rate = 0.15\n        self.cluster_rate = 0.5  # Percentage of population used for clustering\n        self.diversity_threshold = 0.1  # Minimum diversity needed for effective exploration\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _calculate_diversity(self, population):\n        # Measure population diversity by average pairwise distance\n        distances = []\n        for i in range(len(population)):\n            for j in range(i + 1, len(population)):\n                distances.append(np.linalg.norm(population[i] - population[j]))\n        return np.mean(distances)\n\n    def _dynamic_mutation(self, fitness, diversity):\n        f_min, f_max = 0.3, 0.8  # Dynamic mutation range\n        diversity_factor = max(0, (diversity - self.diversity_threshold) / self.diversity_threshold)\n        return f_min + (f_max - f_min) * diversity_factor\n\n    def _mutate(self, target_idx, population, fitness, diversity):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._dynamic_mutation(fitness[target_idx], diversity)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _cluster_population(self, population, func):\n        k = max(2, int(self.cluster_rate * self.population_size))\n        kmeans = KMeans(n_clusters=k, n_init=5).fit(population)\n        # Return the centroids as representatives of clusters\n        cluster_centroids = kmeans.cluster_centers_\n        cluster_fitness = np.array([func(ind) for ind in cluster_centroids])\n        return cluster_centroids, cluster_fitness\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            diversity = self._calculate_diversity(population)\n            cluster_centroids, cluster_fitness = self._cluster_population(population, func)\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    # Preserve elite individuals\n                    continue\n                mutant = self._mutate(i, population, fitness, diversity)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Combine original population, new population, and cluster centroids for selection\n            combined_pop = np.vstack((population, new_population, cluster_centroids))\n            combined_fitness = np.hstack((fitness, new_fitness, cluster_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 14, "feedback": "The algorithm HybridAdaptiveExplorationOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09746 with standard deviation 0.01583.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.09021682068504155, 0.11943347063667098, 0.08273359601738028]}}
{"id": "42108966-12a7-4648-904d-84a2bd02f651", "fitness": 0.1317218241483129, "name": "DynamicAnnealingOptimizer", "description": "DynamicAnnealingOptimizer enhances convergence by dynamically adjusting the cooling rate based on fitness improvement trends, while applying an adaptive differential evolution strategy.", "code": "import numpy as np\n\nclass DynamicAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.trend_sensitivity = 0.1  # New parameter for adaptive cooling\n        self.improvement_threshold = 1e-6  # Threshold to detect fitness improvement trend\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _adaptive_cooling(self, previous_best_fitness, current_best_fitness, temperature):\n        if current_best_fitness < previous_best_fitness - self.improvement_threshold:\n            return temperature * (1 + self.trend_sensitivity)\n        return temperature * self.cooling_rate\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        previous_best_fitness = np.min(fitness)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            current_best_fitness = np.min(fitness)\n            temperature = self._adaptive_cooling(previous_best_fitness, current_best_fitness, temperature)\n            previous_best_fitness = current_best_fitness\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 15, "feedback": "The algorithm DynamicAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13172 with standard deviation 0.02096.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.1592789120420347, 0.12739616292988032, 0.10849039747302369]}}
{"id": "74df5838-4a12-43b6-8a7a-02e4a6d19ff4", "fitness": 0.11544756272636136, "name": "DynamicRefinedHybridOptimizer", "description": "Introducing a dynamic population sizing strategy and a self-adaptive crossover rate to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass DynamicRefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.bounds = None\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.elitism_rate = 0.2\n        self.min_population_size = 10\n        self.max_population_size = 50\n\n    def _initialize_population(self, size):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover_rate(self, generation):\n        return 0.1 + 0.9 * (1 - np.exp(-0.05 * generation))\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population_size = self.initial_population_size\n        population = self._initialize_population(population_size)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        temperature = self.initial_temp\n        generation = 0\n\n        while evaluations < self.budget:\n            generation += 1\n            cr = self._adaptive_crossover_rate(generation)\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            elite_size = int(self.elitism_rate * population_size)\n            for i in range(population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant, cr)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n            # Dynamically adjust population size\n            if generation % 10 == 0:\n                population_size = np.random.randint(self.min_population_size, self.max_population_size)\n                if population_size > len(population):\n                    additional_population = self._initialize_population(population_size - len(population))\n                    population = np.vstack((population, additional_population))\n                    additional_fitness = np.array([func(ind) for ind in additional_population])\n                    fitness = np.hstack((fitness, additional_fitness))\n                    evaluations += len(additional_population)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 16, "feedback": "The algorithm DynamicRefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11545 with standard deviation 0.01201.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.11744856446086471, 0.1290570202686223, 0.09983710344959706]}}
{"id": "be02dde6-2b14-4b2d-9a8e-059cece13744", "fitness": 0.13073774876766298, "name": "AdvancedHybridOptimizer", "description": "AdvancedHybridOptimizer with dynamic population adjustment and strategic diversification for enhanced exploration and convergence in black box optimization.", "code": "import numpy as np\n\nclass AdvancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.max_population_size = 50  # Allows dynamic population growth\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95  # Adjusted for strategic diversification\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self, size):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (size, self.dim))\n\n    def _dynamic_population_adjustment(self, current_gen):\n        # Increasing population for better exploration in later stages\n        return min(self.initial_population_size + current_gen * 2, self.max_population_size)\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population_size = self.initial_population_size\n        population = self._initialize_population(population_size)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        temperature = self.initial_temp\n        generation = 0\n\n        while evaluations < self.budget:\n            new_population_size = self._dynamic_population_adjustment(generation)\n            new_population = self._initialize_population(new_population_size)\n            new_fitness = np.full(new_population_size, np.inf)\n            elite_size = int(self.elitism_rate * new_population_size)\n\n            for i in range(new_population_size):\n                if i < elite_size and i < len(population):\n                    new_population[i] = population[np.argsort(fitness)[:elite_size]][i]\n                    new_fitness[i] = fitness[np.argsort(fitness)[:elite_size]][i]\n                    continue\n                if evaluations >= self.budget:\n                    break\n                mutant = self._mutate(i % len(population), population, fitness)\n                trial = self._crossover(population[i % len(population)], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i % len(population)], func, temperature)\n                evaluations += 1\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:new_population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n            generation += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 17, "feedback": "The algorithm AdvancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13074 with standard deviation 0.00467.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.13558443663918862, 0.1244330603203353, 0.132195749343465]}}
{"id": "33c20c19-4d45-4a63-b1c8-212d00efb670", "fitness": 0.10812890984859087, "name": "AdaptiveHybridOptimizer", "description": "AdaptiveHybridOptimizer with dynamic crossover rate and temperature adjustment for superior balance between exploration and exploitation in optimization.", "code": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95  # Slightly adjusted cooling rate for balanced convergence\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _dynamic_crossover_rate(self, fitness, cr_min=0.2, cr_max=0.8):\n        avg_fitness = np.mean(fitness)\n        cr = cr_max - (cr_max - cr_min) * (avg_fitness / (np.max(fitness) + 1e-6))\n        return cr\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            cr = self._dynamic_crossover_rate(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant, cr)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10813 with standard deviation 0.03845.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.06434567889806608, 0.15794151956475644, 0.10209953108295011]}}
{"id": "d28855fc-9226-467f-a618-3b5ecc3ee689", "fitness": 0.0989922813349599, "name": "RefinedHybridOptimizer", "description": "Further refined hybrid optimizer with dynamic population size adjustment and adaptive crossover for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant):\n        cr = np.random.rand() * 0.3 + 0.5  # Dynamic crossover rate\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size += int(self.budget * 0.05)  # Dynamic population enlargement\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09899 with standard deviation 0.00356.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.0940075777896785, 0.10210047734202699, 0.10086878887317419]}}
{"id": "e8c6f88b-2fb7-4ae1-97f8-e3a879898aec", "fitness": 0.0779387810319998, "name": "RefinedHybridOptimizer", "description": "Enhanced RefinedHybridOptimizer with improved exploration by increasing the mutation factor range and introducing dynamic crossover rate for diverse offspring.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=1.0):  # Changed range for more diversity\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr_min=0.4, cr_max=0.9):  # Introduced dynamic crossover rate\n        cr = np.random.uniform(cr_min, cr_max)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07794 with standard deviation 0.01659.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.06033495683713963, 0.10016568348212485, 0.07331570277673494]}}
{"id": "538fda6a-d2f6-4109-9285-cc4c0ffa6358", "fitness": 0.11002136738613844, "name": "RefinedHybridOptimizer", "description": "Enhanced RefinedHybridOptimizer with increased population size for better exploration.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98  # Increased cooling rate for better exploration\n        self.bounds = None\n        self.elitism_rate = 0.2  # Increased elitism rate to preserve more top-performing individuals\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):  # Adjusted f_min to increase mutation rate\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    # Preserve elite individuals\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            # Update population with elitism\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 21, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11002 with standard deviation 0.02562.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.11292869023160368, 0.07729060784148756, 0.13984480408532407]}}
{"id": "cfd8f1d6-a34a-4490-b9d5-beaaf61ef01d", "fitness": -Infinity, "name": "HybridAdaptiveDifferentialAnnealing", "description": "Hybrid Adaptive Differential Annealing (HADA) combines dynamic population sizing and adaptive differential mutation with simulated annealing to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HybridAdaptiveDifferentialAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95  # Fine-tuned cooling rate for better balance between exploration and exploitation\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self, size):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.5, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population_size = self.initial_population_size\n        population = self._initialize_population(population_size)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Dynamic population adjustment\n            if evaluations < self.budget * 0.5:\n                population_size = min(self.initial_population_size * 1.5, 50)\n            else:\n                population_size = max(self.initial_population_size, 10)\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 22, "feedback": "An exception occurred: TypeError(\"'float' object cannot be interpreted as an integer\").", "error": "TypeError(\"'float' object cannot be interpreted as an integer\")", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {}}
{"id": "22d372be-3b9c-4f73-ab0a-08c6a155d0ff", "fitness": 0.09691620838522241, "name": "QuantumInspiredRefinedHybridOptimizer", "description": "Quantum-Inspired RefinedHybridOptimizer integrates quantum-inspired superposition and entanglement concepts to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass QuantumInspiredRefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.q_superposition = 0.1  # Superposition rate for quantum-inspired exploration\n        self.q_entanglement = 0.5  # Entanglement influence in quantum mutation\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        if np.random.rand() < self.q_superposition:\n            q_mutant = (population[a] + population[b] + population[c]) / 3\n            mutant = (1 - self.q_entanglement) * mutant + self.q_entanglement * q_mutant\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.5):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 23, "feedback": "The algorithm QuantumInspiredRefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09692 with standard deviation 0.01584.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.09736930324605697, 0.07729060784148756, 0.11608871406812271]}}
{"id": "93e8a682-e184-488e-b799-7196429edc9d", "fitness": 0.12295191646094605, "name": "RefinedHybridOptimizer", "description": "Improved exploration by adjusting the crossover probability adaptively based on fitness diversity.", "code": "import numpy as np\n\nclass RefinedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant):\n        # Adjusted crossover probability based on fitness diversity\n        diversity = np.std(mutant) / (np.mean(mutant) + 1e-6)\n        cr = 0.3 + 0.7 * (1 - diversity)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12295 with standard deviation 0.00860.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.11732226598968476, 0.13510503080419456, 0.11642845258895884]}}
{"id": "a01a2c4f-e660-4cc0-9787-36a08817d7a2", "fitness": -Infinity, "name": "AdvancedHybridOptimizer", "description": "AdvancedHybridOptimizer with dynamic population resizing and adaptive crossover rates to enhance diversification and convergence control.", "code": "import numpy as np\n\nclass AdvancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.current_population_size = self.initial_population_size\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.97  # Further refined cooling rate for gradual exploration-exploitation balance\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.dynamic_population_scale = 0.5  # Rate to scale the population dynamically\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.current_population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):  # Refined mutation adaptability\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.current_population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, generation_ratio):\n        return 0.9 - 0.4 * generation_ratio  # Dynamic crossover rate based on progress\n\n    def _crossover(self, target, mutant, generation_ratio):\n        cr = self._adaptive_crossover(generation_ratio)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        if candidate < current:\n            return 1.0\n        else:\n            return np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.current_population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.current_population_size)\n\n        generation = 0\n        while evaluations < self.budget:\n            generation_ratio = evaluations / self.budget\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            for i in range(self.current_population_size):\n                if i < elite_size:\n                    continue\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant, generation_ratio)\n                new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.current_population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n            # Dynamic population resizing\n            if evaluations < self.budget * 0.5:\n                self.current_population_size = int(self.initial_population_size * (1 + self.dynamic_population_scale * (1 - generation_ratio)))\n\n            generation += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 25, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 20')", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {}}
{"id": "615a8e9b-e49f-48cb-97ad-9c1ebdfb585c", "fitness": 0.13488072574442148, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Hierarchical Adaptive Hybrid Optimizer which leverages a hierarchical population structure to enhance exploration and exploitation through dynamic group-based mutation and crossover.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 26, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13488 with standard deviation 0.02028.", "error": "", "parent_ids": ["d6762403-eab6-4965-936a-cb396d99b207"], "operator": null, "metadata": {"aucs": [0.1633908277752586, 0.12328030551909841, 0.11797104393890745]}}
{"id": "dbdb25fc-7c14-4c24-a753-05dff2f55800", "fitness": 0.10688403462868508, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer with improved crossover strategy for more diverse exploration. ", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.8):  # Changed crossover rate from 0.6 to 0.8\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 27, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10688 with standard deviation 0.01321.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1227194164699873, 0.09037657737826355, 0.10755611003780441]}}
{"id": "806a871e-40a5-4351-80ec-40691d970fda", "fitness": 0.13488072574442148, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhancing Hierarchical Adaptive Hybrid Optimizer by introducing a dynamic crossover probability.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n    \n    def _dynamic_crossover_probability(self, fitness):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return 0.4 + 0.2 * (1 - norm_fitness)\n\n    def _crossover(self, target, mutant, fitness):\n        cr = self._dynamic_crossover_probability(fitness)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant, fitness[i])\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 28, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13488 with standard deviation 0.02028.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1633908277752586, 0.12328030551909841, 0.11797104393890745]}}
{"id": "128c9370-a26f-40db-bccf-17f96266636c", "fitness": 0.12437024331548048, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Refining the Hierarchical Adaptive Hybrid Optimizer by introducing a dynamic cooling schedule and enhancing mutation diversity for better convergence.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        # Change: Enhance mutation diversity by using 4 random individuals\n        d = np.random.choice(indices)  \n        mutant = population[a] + f * (population[b] - population[c] + population[d] - population[a])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Change: Introduce a dynamic cooling schedule\n            temperature *= (self.cooling_rate + 0.02) if evaluations < self.budget / 2 else self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 29, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12437 with standard deviation 0.01774.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.10988208290230583, 0.11386990313067757, 0.14935874391345805]}}
{"id": "4e6811f5-5c5b-4ac0-9c42-11a9848a151c", "fitness": 0.09126989526119156, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer by fine-tuning the elitism rate and crossover probability for improved convergence.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.3  # Adjusted elitism rate\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.7):  # Adjusted crossover probability\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 30, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09127 with standard deviation 0.02192.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.07430234077488362, 0.07729060784148756, 0.12221673716720349]}}
{"id": "e0b0c2c6-2b47-4133-990e-d96b0a1ac8b8", "fitness": 0.12529542212851696, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer with dynamic crossover and mutation probabilities for improved search efficiency.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        dynamic_cr = cr * np.random.rand()  # Dynamic crossover rate\n        mask = np.random.rand(self.dim) < dynamic_cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 31, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12530 with standard deviation 0.01780.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.10753512027493817, 0.11872319692950273, 0.14962794918111]}}
{"id": "0c73b4fb-23e9-46be-a1e6-193b578ac4f6", "fitness": 0.10257092500648664, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer with adaptive crossover rate for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover_rate(self, fitness, cr_min=0.3, cr_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return cr_max - (cr_max - cr_min) * norm_fitness\n\n    def _crossover(self, target, mutant, fitness):\n        cr = self._adaptive_crossover_rate(fitness)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant, fitness[i])\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 32, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10257 with standard deviation 0.01501.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1212922327273811, 0.08454513395267937, 0.10187540833939945]}}
{"id": "4462a151-de78-4282-85b7-2cdf819f3438", "fitness": 0.1348786443597696, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Selective Annealing Scheme to improve convergence through dynamic acceptance based on distance from the elite solutions. ", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, distance, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / (t * distance))\n\n    def _anneal(self, candidate, current, func, temperature, elite):\n        candidate_fitness = func(candidate)\n        distance = np.linalg.norm(candidate - elite)\n        if self._acceptance_probability(func(current), candidate_fitness, distance, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            elite = population[np.argmin(fitness)]\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature, elite)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 33, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13488 with standard deviation 0.02028.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1633908277752586, 0.12328030551909841, 0.11796479978495178]}}
{"id": "7e1ae370-4d13-4e84-8586-fa39cd667629", "fitness": 0.0819026134602426, "name": "ImprovedHierarchicalAdaptiveHybridOptimizer", "description": "Improved Hierarchical Adaptive Hybrid Optimizer with dynamic group resizing and differential elitism to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass ImprovedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = max(1, int(self.elitism_rate * self.population_size))  # Ensure at least one elite\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamically adjust groups based on remaining budget\n            dynamic_groups = max(1, self.budget // (self.population_size * 10))\n            group_size = self.population_size // dynamic_groups\n\n            for g in range(dynamic_groups):\n                group_indices = range(g * group_size, min((g + 1) * group_size, self.population_size))\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 34, "feedback": "The algorithm ImprovedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08190 with standard deviation 0.02872.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.059614331309397195, 0.12245010069014994, 0.06364340838118066]}}
{"id": "e12cd21b-cc2e-419a-998b-b33ae89a752a", "fitness": 0.13488072574442148, "name": "HierarchicallyAdaptiveEnsembleOptimizer", "description": "Introducing the Hierarchically Adaptive Ensemble Optimizer which dynamically adapts mutation strategies and incorporates a multi-archive based strategy for balancing exploration and exploitation in a hierarchical framework.", "code": "import numpy as np\n\nclass HierarchicallyAdaptiveEnsembleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.archives = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _update_archive(self, candidate, candidate_fitness):\n        self.archives.append((candidate, candidate_fitness))\n        self.archives.sort(key=lambda x: x[1])\n        if len(self.archives) > self.population_size * 2:\n            self.archives = self.archives[:self.population_size * 2]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    self._update_archive(new_population[i], new_fitness[i])\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 35, "feedback": "The algorithm HierarchicallyAdaptiveEnsembleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13488 with standard deviation 0.02028.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1633908277752586, 0.12328030551909841, 0.11797104393890745]}}
{"id": "555ea126-bca7-4d8d-98ac-717d09c1693b", "fitness": -Infinity, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing weighted differential evolution based on fitness proportional scaling to enhance exploration capabilities in the Hierarchical Adaptive Hybrid Optimizer.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        weights = np.exp(-fitness / np.mean(fitness))  # Weighted differential evolution\n        weighted_indices = np.random.choice(indices, 3, replace=False, p=weights/weights.sum())\n        a, b, c = weighted_indices\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 36, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {}}
{"id": "244a553d-766e-4986-bc8f-08dc4ff00d8a", "fitness": 0.12243873852356635, "name": "ImprovedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Multi-Phase Hierarchical Adaptive Hybrid Optimizer which adds a multi-phase search strategy with adaptive learning rates to improve convergence by balancing exploration and exploitation dynamically across hierarchical populations.", "code": "import numpy as np\n\nclass ImprovedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.learning_phase_duration = self.population_size * 5\n        self.learning_factors = (0.1, 0.5, 0.9)\n        self.phase_factor = 1.0\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx]) * self.phase_factor\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        phase_counter = 0\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            if phase_counter % self.learning_phase_duration == 0:\n                self.phase_factor = np.random.choice(self.learning_factors)\n            \n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n            phase_counter += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 37, "feedback": "The algorithm ImprovedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12244 with standard deviation 0.00856.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.11927314705101999, 0.13413978383196457, 0.11390328468771449]}}
{"id": "63df47a1-9491-4132-bcad-974cf5d2a2ff", "fitness": 0.09880960827271253, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Refining the Hierarchical Adaptive Hybrid Optimizer by enhancing mutation diversity and introducing dynamic crossover probability for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.2, f_max=0.9):  # Changed mutation range for diversity\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=None):  # Introduce dynamic crossover probability\n        if cr is None:\n            cr = np.random.rand() * 0.5 + 0.5  # Dynamic crossover probability\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 38, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09881 with standard deviation 0.02298.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.11702416761789147, 0.11300587761687542, 0.0663987795833707]}}
{"id": "b3d6025a-a678-4930-826d-5469650a98de", "fitness": 0.12665051255364945, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer with improved crossover probability for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.7):  # Modified crossover probability\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 39, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12665 with standard deviation 0.03705.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.16653642281421022, 0.07729060784148756, 0.13612450700525058]}}
{"id": "4251a749-de3d-441a-8a15-1f5ae9265dfd", "fitness": 0.12238101684114244, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance the Hierarchical Adaptive Hybrid Optimizer by incorporating adaptive learning rates and dynamic group sizes to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.initial_groups = 5\n        self.learning_rate_min = 0.1\n        self.learning_rate_max = 1.0\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.initial_population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _dynamic_learning_rate(self, evaluations):\n        return self.learning_rate_min + (self.learning_rate_max - self.learning_rate_min) * (1 - evaluations / self.budget)\n\n    def _mutate(self, target_idx, population, fitness, evaluations):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx]) * self._dynamic_learning_rate(evaluations)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        self.population_size = self.initial_population_size\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        groups = self.initial_groups\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Adjust group size dynamically\n            if evaluations / self.budget > 0.5:\n                groups = max(1, groups - 1)\n\n            for g in range(groups):\n                group_indices = range(g, self.population_size, groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness, evaluations)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12238 with standard deviation 0.00765.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.12718872617757138, 0.11158837427288382, 0.12836595007297213]}}
{"id": "957a075e-6b2a-49fa-885f-d4f19eb83bbf", "fitness": 0.1343858584101625, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer which incorporates a dynamic grouping strategy and a diversity preservation mechanism to optimize exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.initial_groups = 5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _dynamic_grouping(self, evaluations):\n        max_groups = min(self.population_size // 2, 10)\n        return max(1, int(self.initial_groups + (max_groups - self.initial_groups) * (evaluations / self.budget)))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            groups = self._dynamic_grouping(evaluations)\n\n            for g in range(groups):\n                group_indices = range(g, self.population_size, groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            diversity_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[diversity_indices]\n            fitness = combined_fitness[diversity_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13439 with standard deviation 0.02023.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.16296363610357534, 0.12135574354777046, 0.11883819557914177]}}
{"id": "1e736465-687b-463a-9581-4d5d84b12730", "fitness": 0.10433991373451923, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Improved Hierarchical Adaptive Hybrid Optimizer with enhanced mutation diversity through noise addition.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        noise = np.random.normal(0, 0.1, self.dim)  # Adding noise to enhance diversity\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + noise\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 42, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10434 with standard deviation 0.01912.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.11978683807931334, 0.11583625113407814, 0.07739665199016621]}}
{"id": "7faa41f6-b13e-4099-88ec-d7146602b424", "fitness": 0.12423467949158884, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing the Enhanced Hierarchical Adaptive Hybrid Optimizer, which improves convergence by incorporating adaptive group sizes and dynamic crossover probabilities based on the diversity of solutions within groups.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.min_groups = 3\n        self.max_groups = 7\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _dynamic_crossover_rate(self, diversity, cr_min=0.4, cr_max=0.9):\n        return cr_min + (cr_max - cr_min) * (1 - diversity)\n\n    def _group_diversity(self, group_indices, population):\n        group_vectors = population[group_indices]\n        centroid = np.mean(group_vectors, axis=0)\n        diversity = np.mean(np.linalg.norm(group_vectors - centroid, axis=1))\n        return diversity / (np.linalg.norm(self.bounds.ub - self.bounds.lb))\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            groups = np.random.randint(self.min_groups, self.max_groups+1)\n            for g in range(groups):\n                group_indices = range(g, self.population_size, groups)\n\n                diversity = self._group_diversity(group_indices, population)\n                cr = self._dynamic_crossover_rate(diversity)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12423 with standard deviation 0.02496.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.14636370484074435, 0.08935852779016973, 0.13698180584385244]}}
{"id": "706549d4-607c-444e-a3e6-7071d8837765", "fitness": 0.08234798371031116, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer utilizing adaptive differential mutation and stochastic ranking to improve exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.cr = 0.6  # Crossover rate\n        self.sr_prob = 0.45  # Stochastic ranking probability\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant):\n        mask = np.random.rand(self.dim) < self.cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _stochastic_ranking(self, population, fitness):\n        pairwise_comp = np.random.rand(self.population_size) < self.sr_prob\n        for i in range(self.population_size - 1):\n            for j in range(i + 1, self.population_size):\n                if pairwise_comp[i] or fitness[i] < fitness[j]:\n                    if np.random.rand() < 0.5:\n                        population[i], population[j] = population[j], population[i]\n                        fitness[i], fitness[j] = fitness[j], fitness[i]\n        return population, fitness\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            combined_pop, combined_fitness = self._stochastic_ranking(combined_pop, combined_fitness)\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08235 with standard deviation 0.00546.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.0784161207648465, 0.07855541642436581, 0.09007241394172116]}}
{"id": "1c9deced-866b-406b-b9e8-c2c552117b4f", "fitness": 0.13189190894009375, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Hierarchical Adaptive Hybrid Optimizer with enhanced elitism by adjusting elitism_rate for improved convergence.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.25  # Adjusted elitism rate\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 45, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13189 with standard deviation 0.00334.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1361029211416105, 0.13163005610844358, 0.12794274957022722]}}
{"id": "d0702336-629d-46a1-9bea-924fa6b9e8f4", "fitness": 0.11803284487533645, "name": "HierarchicalAdaptiveHybridOptimizerV2", "description": "Introducing the Hierarchical Adaptive Hybrid Optimizer V2, enhancing exploration-exploitation balance through adaptive hierarchical regrouping and dynamic elitist strategy for improved convergence.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.9\n        self.bounds = None\n        self.elitism_rate = 0.1\n        self.groups = 5  # Hierarchical grouping\n        self.dynamic_grouping = True\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.4, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.7):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _dynamic_groups(self):\n        # Adjust group size dynamically based on budget usage\n        return max(2, self.groups - int(self.budget / 1000))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing with dynamic grouping\n            current_groups = self._dynamic_groups() if self.dynamic_grouping else self.groups\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 46, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11803 with standard deviation 0.00463.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.11179297699404345, 0.12287794112785244, 0.11942761650411349]}}
{"id": "79443117-62c9-41e9-8fdb-ed2e5db140de", "fitness": 0.11984329842236181, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer that incorporates adaptive group sizes and learning-based mutation strategies to improve convergence and diversity management.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = None  # Adaptive group sizes\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_grouping(self, evaluations):\n        # Adapt the number of groups based on the percentage of the budget used\n        percentage_used = evaluations / self.budget\n        return max(2, int(5 * (1 - percentage_used) + 2))\n\n    def _learning_based_mutation(self, fitness, population):\n        # Use current knowledge of population's fitness to guide mutation\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        return 0.5 + 0.3 * np.random.rand(), best_solution\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f, guiding_solution = self._learning_based_mutation(fitness, population)\n        mutant = population[a] + f * (population[b] - population[c]) + 0.1 * (guiding_solution - population[target_idx])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            self.groups = self._adaptive_grouping(evaluations)\n\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11984 with standard deviation 0.00886.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.126492254671416, 0.12571934492634007, 0.10731829566932938]}}
{"id": "ddbcb946-895e-4bfb-ba7c-f4df4cfb3c1d", "fitness": 0.11708845215198808, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer that incorporates a dynamic re-ranking mechanism and adaptive strategy selection to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.strategy_weights = np.ones(3)  # Weights for adaptive strategy selection\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n    \n    def _adaptive_strategy_selection(self):\n        # Normalize strategy weights to probabilities\n        probabilities = self.strategy_weights / np.sum(self.strategy_weights)\n        return np.random.choice(3, p=probabilities)\n\n    def _anneal(self, candidate, current, func, temperature, method='anneal'):\n        candidate_fitness = func(candidate)\n        if method == 'anneal':\n            prob = self._acceptance_probability(func(current), candidate_fitness, temperature)\n        elif method == 'deterministic':\n            prob = 1.0 if candidate_fitness < func(current) else 0.0\n        else:\n            raise ValueError(\"Unknown method\")\n        \n        if prob > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    \n                    # Select strategy based on adaptive weights\n                    strategy = self._adaptive_strategy_selection()\n                    if strategy == 0:\n                        anneal_method = 'anneal'\n                    else:\n                        anneal_method = 'deterministic'\n                    \n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature, method=anneal_method)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n            \n            # Combine and select best individuals\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            # Update weights based on success\n            improvements = (new_fitness < fitness)[:self.population_size]\n            success_rate = np.sum(improvements) / len(improvements)\n            self.strategy_weights[strategy] *= (1.0 + success_rate)\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11709 with standard deviation 0.03669.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1658215337990966, 0.07729060784148756, 0.1081532148153801]}}
{"id": "35968987-ff93-49a8-bc7d-153f263e7352", "fitness": 0.07828638543063023, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Hierarchical Adaptive Hybrid Optimizer with enhanced mutation scaling factors for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.35, f_max=0.85):  # Adjusted mutation scaling factors\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 49, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07829 with standard deviation 0.00560.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.07197435604157676, 0.07729060784148756, 0.08559419240882638]}}
{"id": "54a5bc34-166b-4b1e-9532-94bc6131aede", "fitness": 0.11508965049721469, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Enhance the Hierarchical Adaptive Hybrid Optimizer by including dynamic crossover rates based on fitness diversity to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _dynamic_crossover_rate(self, fitness, cr_min=0.5, cr_max=0.9):\n        fitness_range = np.max(fitness) - np.min(fitness)\n        return cr_min + (cr_max - cr_min) * (1 - fitness_range / (np.max(fitness) + 1e-6))\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    cr = self._dynamic_crossover_rate(fitness)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 50, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11509 with standard deviation 0.02990.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.117575979169109, 0.07729060784148756, 0.1504023644810475]}}
{"id": "5514225d-688d-45da-86e8-14287f98fa28", "fitness": 0.13405708167866906, "name": "HierarchicalDynamicScalingOptimizer", "description": "Introducing Hierarchical Dynamic Scaling Optimizer which refines the search process by incorporating dynamic scaling with hierarchical grouping to enhance both convergence speed and solution quality.", "code": "import numpy as np\n\nclass HierarchicalDynamicScalingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.dynamic_scale_factor = 0.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _dynamic_scaling(self, step, max_steps):\n        scale = self.dynamic_scale_factor * (1 - (step / max_steps))\n        return scale\n\n    def _mutate(self, target_idx, population, fitness, step, max_steps):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx]) * self._dynamic_scaling(step, max_steps)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        max_steps = self.budget // self.population_size\n\n        step = 0\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness, step, max_steps)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n            step += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 51, "feedback": "The algorithm HierarchicalDynamicScalingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13406 with standard deviation 0.01974.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.16060628642734287, 0.128261447815761, 0.11330351079290335]}}
{"id": "492d8f43-1eca-402b-9bf6-02bfdeb414db", "fitness": 0.09249004383386154, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing selective crossover and adaptive temperature scaling for enhanced convergence and diversity maintenance.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        # Selective crossover based on improvement\n        return np.where(mask & (mutant < target), mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate * (1 + 0.01 * np.std(fitness))  # Adaptive temperature scaling\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 52, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09249 with standard deviation 0.00969.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.07881330553162835, 0.10004453359746779, 0.09861229237248847]}}
{"id": "d3f3e3d0-987f-4417-959b-494ffbabafe9", "fitness": 0.12684319866398527, "name": "DynamicGroupAdaptiveHybridOptimizer", "description": "Introducing a Dynamic Group Adaptive Hybrid Optimizer which enhances convergence speed by dynamically adjusting group sizes based on fitness variance, leveraging differential evolution and simulated annealing.", "code": "import numpy as np\n\nclass DynamicGroupAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.min_groups = 2\n        self.max_groups = 10\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _dynamic_groups(self, fitness):\n        variance = np.var(fitness)\n        group_count = int(self.min_groups + ((self.max_groups - self.min_groups) * (1 - (variance / (np.max(fitness) - np.min(fitness) + 1e-6)))))\n        return max(self.min_groups, min(self.max_groups, group_count))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on fitness variance\n            groups = self._dynamic_groups(fitness)\n\n            for g in range(groups):\n                group_indices = range(g, self.population_size, groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 53, "feedback": "The algorithm DynamicGroupAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12684 with standard deviation 0.00115.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1278720968796988, 0.12523976070595666, 0.12741773840630033]}}
{"id": "add5e34e-9868-4623-96df-9357d075521e", "fitness": 0.12304316761562857, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer, incorporating a self-adaptive mechanism for dynamically tuning crossover and mutation rates to improve convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.cr_min = 0.1\n        self.cr_max = 0.9\n        self.f_min = 0.3\n        self.f_max = 0.8\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return self.f_min + (self.f_max - self.f_min) * (1 - norm_fitness)\n\n    def _adaptive_crossover(self, fitness):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return self.cr_min + (self.cr_max - self.cr_min) * norm_fitness\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    cr = self._adaptive_crossover(fitness[i])\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12304 with standard deviation 0.01459.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.10943160166248878, 0.14327153873373266, 0.11642636245066429]}}
{"id": "31ac62b8-0829-4276-a21d-c62f49614f59", "fitness": 0.12675955943077563, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing the Enhanced Hierarchical Adaptive Hybrid Optimizer which integrates a dynamic adaptive learning rate and stochastic elite strategy to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.learning_rate = 0.1  # Adaptive learning rate\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _adaptive_learning_rate(self, fitness):\n        return np.exp(-np.var(fitness))\n\n    def _stochastic_elite_selection(self, fitness, elite_size):\n        elite_indices = np.argsort(fitness)[:elite_size]\n        return np.random.choice(elite_indices, size=elite_size, replace=False)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            adaptive_lr = self._adaptive_learning_rate(fitness)\n            stochastic_elite = self._stochastic_elite_selection(fitness, elite_size)\n\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i in stochastic_elite:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n            self.learning_rate = adaptive_lr\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12676 with standard deviation 0.00823.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.1375608308081614, 0.11759115474812587, 0.1251266927360396]}}
{"id": "d89fa07c-eff5-4ab5-a18e-3a67ed104e87", "fitness": 0.10986465515795263, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhanced Hierarchical Adaptive Hybrid Optimizer with dynamic group restructuring and improved adaptive mutation strategy for better exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.dynamic_groups = 5  # Start with 5 groups, change dynamically\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * np.power((1 - norm_fitness), 2)  # Quadratic scaling\n    \n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _dynamic_restructure(self, generation):\n        # Dynamically adjust groups based on generation number\n        if generation % 10 == 0 and self.dynamic_groups < self.population_size // 2:\n            self.dynamic_groups += 1\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        generation = 0\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            \n            self._dynamic_restructure(generation)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.dynamic_groups):\n                group_indices = range(g, self.population_size, self.dynamic_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n            generation += 1\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10986 with standard deviation 0.02204.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.14058101575448045, 0.08995451324572123, 0.0990584364736562]}}
{"id": "1100486c-b040-4a86-b56e-4858325e55ba", "fitness": 0.07971017234482496, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Refining the Hierarchical Adaptive Hybrid Optimizer by integrating rotation-invariant mutation to improve exploration and convergence.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        direction = population[b] - population[c]\n        rotation_matrix = np.random.randn(self.dim, self.dim)  # Added for rotation-invariant mutation\n        direction = np.dot(rotation_matrix, direction)  # Modified line for rotation-invariant mutation\n        mutant = population[a] + f * direction  # Modified line for rotation-invariant mutation\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Group individuals for hierarchical processing\n            for g in range(self.groups):\n                group_indices = range(g, self.population_size, self.groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 57, "feedback": "The algorithm HierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07971 with standard deviation 0.02578.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.05939521847700835, 0.11609189017628585, 0.06364340838118066]}}
{"id": "7c4e4139-27fc-44e6-bb06-f127359ae8f4", "fitness": -Infinity, "name": "HierarchicalAdaptiveHybridOptimizer", "description": "Introducing a Hierarchical Adaptive Hybrid Optimizer with Dynamic Group Scheduling, which refines exploration and exploitation by adaptively managing group sizes and mutation scales based on population diversity.", "code": "import numpy as np\n\nclass HierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.9  # Faster cooling\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.dynamic_grouping = True\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, diversity, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        adaptive_scale = (1 - diversity) * (f_max - f_min)\n        return f_min + adaptive_scale * (1 - norm_fitness)\n\n    def _mutate(self, target_idx, population, fitness, diversity):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx], diversity)\n        mutant = population[a] + f * (population[b] - population[c])\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.7):  # Increased crossover rate\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / (t + 1e-6))\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _calculate_diversity(self, population):\n        pairwise_distances = np.linalg.norm(population[:, np.newaxis] - population, axis=-1)\n        return np.mean(pairwise_distances) / (np.abs(self.bounds.ub - self.bounds.lb) + 1e-6)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            diversity = self._calculate_diversity(population)\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            effective_groups = max(1, int(self.groups * (1 - diversity)))\n            for g in range(effective_groups):\n                group_indices = range(g, self.population_size, effective_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, diversity)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 58, "feedback": "An exception occurred: TypeError('only size-1 arrays can be converted to Python scalars').", "error": "TypeError('only size-1 arrays can be converted to Python scalars')", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {}}
{"id": "88b7dfd4-6581-4b16-8a45-28e1dcc7c311", "fitness": 0.14636458035113276, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing an Enhanced Hierarchical Adaptive Hybrid Optimizer that incorporates Lvy flight and dynamic grouping to promote better exploration and convergence in black-box optimization problems.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14636 with standard deviation 0.01355.", "error": "", "parent_ids": ["615a8e9b-e49f-48cb-97ad-9c1ebdfb585c"], "operator": null, "metadata": {"aucs": [0.13360484006168072, 0.16512865537368837, 0.14036024561802918]}}
{"id": "af8ff475-d927-4dd6-b15d-a8ec6c0ff6a1", "fitness": 0.1135596663422949, "name": "DynamicSynergisticEvolutionaryOptimizer", "description": "Introducing a Dynamic Synergistic Evolutionary Optimizer that combines adaptive differential evolution with chaotic Lvy flights and self-organizing hierarchies to optimize exploration and convergence in complex black-box problems.", "code": "import numpy as np\n\nclass DynamicSynergisticEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.tau = 0.1  # Chaotic parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _chaotic_levy_flight(self, size):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v)**(1 / beta)\n        return self.tau * step\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._chaotic_levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 60, "feedback": "The algorithm DynamicSynergisticEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11356 with standard deviation 0.00753.", "error": "", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {"aucs": [0.12293976818378505, 0.10449689502594428, 0.11324233581715537]}}
{"id": "e6ccc2a5-bd66-458d-aa6c-ad5d6f7b5962", "fitness": 0.14636265113001823, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Improved cooling schedule with linear decay enhances convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature -= self.initial_temp / self.budget  # Linear decay of temperature\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14636 with standard deviation 0.01360.", "error": "", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {"aucs": [0.13350604602173144, 0.16517937031324403, 0.1404025370550792]}}
{"id": "a689bef5-5995-4702-acb0-bf8849d6712f", "fitness": -Infinity, "name": "QuantumInspiredAdaptiveHybridOptimizer", "description": "Introduce a Quantum-inspired Adaptive Hybrid Optimizer that leverages quantum superposition and entanglement principles to enhance solution diversity and convergence efficiency in black-box optimization.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.quantum_prob = 0.1  # Probability for quantum operation\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _quantum_operation(self, population):\n        q_population = np.copy(population)\n        for i in range(self.population_size):\n            if np.random.rand() < self.quantum_prob:\n                indices = np.random.choice(self.dim, size=int(self.dim * 0.5), replace=False)\n                q_population[i, indices] = np.random.uniform(self.bounds.lb, self.bounds.ub, size=len(indices))\n        return q_population\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = self._quantum_operation(np.copy(population))\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, new_population, new_fitness)\n                    trial = self._crossover(new_population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, new_population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 62, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (10,) and arg 1 with shape (20,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (10,) and arg 1 with shape (20,).')", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {}}
{"id": "1c0a29a3-3a3f-441c-b340-4805d813ab5c", "fitness": 0.1358943190057045, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introducing a refined version of the Enhanced Hierarchical Adaptive Hybrid Optimizer by adjusting the elitism rate for better balance between exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.95\n        self.bounds = None\n        self.elitism_rate = 0.15  # Adjusted elitism rate\n        self.groups = 5  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13589 with standard deviation 0.01592.", "error": "", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {"aucs": [0.13176176372288262, 0.15712746413196121, 0.11879372916226971]}}
{"id": "dee95c7a-b3dc-4864-bbc0-05d450934b8a", "fitness": 0.0687669187450682, "name": "QuantumInspiredAdaptiveHybridOptimizer", "description": "Introducing a Quantum-inspired Adaptive Hybrid Optimizer by embedding quantum superposition principles and stochastic tunneling for improved exploration and convergence in black-box optimization problems.", "code": "import numpy as np\n\nclass QuantumInspiredAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.9\n        self.bounds = None\n        self.elitism_rate = 0.15\n        self.groups = 4  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n        self.tunneling_strength = 0.01\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.2, f_max=0.7):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _quantum_superposition(self, population):\n        # Simulate superposition by averaging with random perturbations\n        mean_position = np.mean(population, axis=0)\n        return mean_position + np.random.normal(0, self.tunneling_strength, self.dim)\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        # Stochastic tunneling acceptance\n        delta = candidate - current\n        return 1.0 if delta < 0 else np.exp(-delta / (t * self.tunneling_strength))\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    quantum_position = self._quantum_superposition(population)\n                    mutant = self._mutate(i, population, fitness) * quantum_position\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 64, "feedback": "The algorithm QuantumInspiredAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06877 with standard deviation 0.00976.", "error": "", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {"aucs": [0.05625035145548163, 0.08006153589515907, 0.0699888688845639]}}
{"id": "88077cee-825e-403d-9fc0-7dc138b0e303", "fitness": 0.14639772561701428, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance temperature cooling rate for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98  # Modified cooling rate\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.6):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14640 with standard deviation 0.01357.", "error": "", "parent_ids": ["88b7dfd4-6581-4b16-8a45-28e1dcc7c311"], "operator": null, "metadata": {"aucs": [0.13361225673462884, 0.1651783830613348, 0.1404025370550792]}}
{"id": "cec4a1d1-f54a-417c-9019-2ba572640f28", "fitness": 0.13092361082163262, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce an adaptive crossover mechanism and enhance elitism for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.25  # Increased elitism rate\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=None):\n        if cr is None:\n            cr = 0.6 + 0.2 * np.random.rand()  # Adaptive crossover rate\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13092 with standard deviation 0.01345.", "error": "", "parent_ids": ["88077cee-825e-403d-9fc0-7dc138b0e303"], "operator": null, "metadata": {"aucs": [0.11297533778870084, 0.1453477523589476, 0.13444774231724943]}}
{"id": "de0b4e24-c885-4580-9d97-490f22fe712d", "fitness": 0.14786830247642904, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance exploration with minor increase in crossover rate for diversity.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98  # Modified cooling rate\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5  # Hierarchical grouping\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.65):  # Slightly increased crossover rate\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamic grouping based on current evaluations\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14787 with standard deviation 0.00651.", "error": "", "parent_ids": ["88077cee-825e-403d-9fc0-7dc138b0e303"], "operator": null, "metadata": {"aucs": [0.15543327957753073, 0.13954106444177583, 0.1486305634099806]}}
{"id": "12d852b0-c59f-4ddb-bf1c-238d8e6dd1dd", "fitness": 0.12992097764285504, "name": "AdaptiveElitismDynamicCrossoverOptimizer", "description": "Introduce adaptive elitism and a dynamic crossover strategy for improved exploitation and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveElitismDynamicCrossoverOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.initial_elitism_rate = 0.1\n        self.final_elitism_rate = 0.3\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size):\n        return np.random.standard_cauchy(size) * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _dynamic_crossover(self, target, mutant, evaluations):\n        progress_ratio = evaluations / self.budget\n        cr_min, cr_max = 0.5, 0.9\n        cr = cr_min + (cr_max - cr_min) * (1 - progress_ratio)\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            current_elitism_rate = self.initial_elitism_rate + (self.final_elitism_rate - self.initial_elitism_rate) * (evaluations / self.budget)\n            elite_size = int(current_elitism_rate * self.population_size)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness)\n                    trial = self._dynamic_crossover(population[i], mutant, evaluations)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveElitismDynamicCrossoverOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12992 with standard deviation 0.01950.", "error": "", "parent_ids": ["de0b4e24-c885-4580-9d97-490f22fe712d"], "operator": null, "metadata": {"aucs": [0.12018294801021479, 0.15712988857845922, 0.11245009633989111]}}
{"id": "42881978-6a7a-4cb7-967a-c3433cadeac8", "fitness": 0.14029252925957195, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce a dynamic Lvy flight parameter and adaptive elitism to balance exploration and exploitation more effectively.  ", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.initial_elitism_rate = 0.2\n        self.groups = 5\n        self.initial_levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _dynamic_levy_flight(self, size, evaluations):\n        levy_alpha = self.initial_levy_alpha * ((self.budget - evaluations) / self.budget)\n        return np.random.standard_cauchy(size) * levy_alpha\n\n    def _mutate(self, target_idx, population, fitness, evaluations):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._dynamic_levy_flight(self.dim, evaluations)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _crossover(self, target, mutant, cr=0.65):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n            elite_size = int(self.initial_elitism_rate * (1 - evaluations / self.budget) * self.population_size)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue  # Preserve elite\n\n                    mutant = self._mutate(i, population, fitness, evaluations)\n                    trial = self._crossover(population[i], mutant)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14029 with standard deviation 0.00620.", "error": "", "parent_ids": ["de0b4e24-c885-4580-9d97-490f22fe712d"], "operator": null, "metadata": {"aucs": [0.14142895241716358, 0.147257546952566, 0.1321910884089863]}}
{"id": "533fdb32-7453-4b0b-80b7-c2e21bdfc951", "fitness": 0.15299960871973137, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce dynamic Lvy flight scaling and adaptive crossover to balance exploration and exploitation, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15300 with standard deviation 0.01017.", "error": "", "parent_ids": ["de0b4e24-c885-4580-9d97-490f22fe712d"], "operator": null, "metadata": {"aucs": [0.1477447364001796, 0.16722691779562926, 0.14402717196338521]}}
{"id": "82fbb25d-a4ef-4dca-a4c0-0e4751348fab", "fitness": 0.13385117256294274, "name": "InertiaMemoryEnhancedOptimizer", "description": "Employ dynamic inertia weight and memory-based mutation to enhance the balance between exploration and exploitation, improving convergence efficiency and robustness.", "code": "import numpy as np\n\nclass InertiaMemoryEnhancedOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.memory_factor = 0.8\n        self.inertia_weight_init = 0.9\n        self.inertia_weight_final = 0.4\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _memory_based_mutation(self, target_idx, population, fitness, scale, memory):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        memory_component = self.memory_factor * (memory[target_idx] - population[a])\n        mutant = population[a] + f * (population[b] - population[c]) + memory_component\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        memory = np.copy(population)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            inertia_weight = self.inertia_weight_init - (self.inertia_weight_init - self.inertia_weight_final) * (evaluations / self.budget)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._memory_based_mutation(i, population, fitness, inertia_weight, memory)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n            memory = combined_pop[best_indices]  # Update memory with the best individuals\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 71, "feedback": "The algorithm InertiaMemoryEnhancedOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13385 with standard deviation 0.01899.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.16069717591418164, 0.12112341540364346, 0.11973292637100308]}}
{"id": "4c079301-8a63-4d27-a85d-afc39501e486", "fitness": 0.1477773832451406, "name": "SwarmEnhancedAdaptiveHybridOptimizer", "description": "Integrate swarm intelligence and dynamic elitism to enhance exploration and convergence by adjusting social influence and elitism based on search progress.", "code": "import numpy as np\n\nclass SwarmEnhancedAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.swarm_influence_rate = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _update_swarm(self, population, best_position):\n        influence = self.swarm_influence_rate * np.random.uniform(0, 1, (self.population_size, self.dim))\n        return population + influence * (best_position - population)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        best_idx = np.argmin(fitness)\n        best_position = population[best_idx]\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            best_idx = np.argmin(fitness)\n            best_position = population[best_idx]\n\n            population = self._update_swarm(population, best_position)\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 72, "feedback": "The algorithm SwarmEnhancedAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14778 with standard deviation 0.01392.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.16049127056854695, 0.15443078295946622, 0.12841009620740862]}}
{"id": "e08b14a2-4eea-47c8-8233-ee3d226b5416", "fitness": 0.13878935979881882, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance convergence by adding stochastic scaling to the adaptive crossover rate.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        stochastic_scale = np.random.uniform(0.9, 1.1)\n        return (cr_base + (cr_max - cr_base) * (evaluations / self.budget)) * stochastic_scale\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13879 with standard deviation 0.00929.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.1481195968375435, 0.14213595251733835, 0.12611253004157463]}}
{"id": "c697377b-12ab-4f17-829d-47e9d13cc66b", "fitness": 0.14525864107852882, "name": "EnhancedChaoticInertiaHybridOptimizer", "description": "Integrate chaotic mapping for initial population diversity and dynamic inertia weights for improved convergence balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedChaoticInertiaHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n\n    def _chaotic_map(self, size):\n        z = np.random.rand(size)\n        return 0.5 * np.sin(np.pi * z) + 0.5\n\n    def _initialize_population(self):\n        chaotic_values = self._chaotic_map(self.population_size * self.dim)\n        chaotic_population = chaotic_values.reshape(self.population_size, self.dim)\n        return self.bounds.lb + chaotic_population * (self.bounds.ub - self.bounds.lb)\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _inertia_weight(self, evaluations):\n        return self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n\n    def _anneal(self, candidate, current, func, temperature, inertia_weight):\n        candidate_fitness = func(candidate)\n        if np.random.rand() < inertia_weight or self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n            inertia_weight = self._inertia_weight(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature, inertia_weight)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedChaoticInertiaHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14526 with standard deviation 0.00320.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.14942845168874153, 0.14468647413995794, 0.14166099740688698]}}
{"id": "2642d233-bbc1-4f0b-b440-356cb480b49c", "fitness": 0.14343760535407013, "name": "RefinedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce a dynamic population resizing mechanism and adaptive mutation strategies based on convergence speed to enhance exploration and exploitation balance, improving convergence efficiency.", "code": "import numpy as np\n\nclass RefinedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self, size):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (size, self.dim))\n\n    def _adaptive_mutation(self, fitness, evals, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        dynamic_factor = 1 - evals / self.budget\n        return f_min + (f_max - f_min) * (1 - norm_fitness) * dynamic_factor\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale, evals):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx], evals)\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population_size = self.initial_population_size\n        population = self._initialize_population(population_size)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale, evaluations)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n            if evaluations < self.budget * 0.5:\n                population_size = min(self.initial_population_size + int((evaluations / self.budget) * 10), len(population))\n            else:\n                population_size = max(self.initial_population_size, len(population))\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 75, "feedback": "The algorithm RefinedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14344 with standard deviation 0.01907.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.15746319840576062, 0.15637923522787067, 0.1164703824285791]}}
{"id": "61b74ffc-36c3-41d5-a78b-fe4ee00e2e28", "fitness": -Infinity, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce adaptive multi-phase learning with dynamic crowding and opposition-based learning to enhance diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.phase_change = 0.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _opposition_based_learning(self, population, fitness):\n        opposites = self.bounds.lb + self.bounds.ub - population\n        opposite_fitness = np.array([func(opp) for opp in opposites])\n        combined_pop = np.vstack((population, opposites))\n        combined_fitness = np.hstack((fitness, opposite_fitness))\n        best_indices = np.argsort(combined_fitness)[:self.population_size]\n        return combined_pop[best_indices], combined_fitness[best_indices]\n\n    def _crowding_distance(self, fitness, epsilon=0.1):\n        sorted_indices = np.argsort(fitness)\n        crowding = np.zeros(self.population_size)\n        crowding[sorted_indices[0]] = crowding[sorted_indices[-1]] = float('inf')\n        for i in range(1, self.population_size - 1):\n            crowding[sorted_indices[i]] = (fitness[sorted_indices[i + 1]] - fitness[sorted_indices[i - 1]]) + epsilon\n        return crowding\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            if evaluations / self.budget < self.phase_change:\n                new_population, new_fitness = self._opposition_based_learning(new_population, new_fitness)\n            else:\n                crowding = self._crowding_distance(new_fitness)\n                for i in np.argsort(crowding):\n                    if evaluations >= self.budget:\n                        break\n                    mutant = self._mutate(i, new_population, new_fitness, scale)\n                    trial = self._crossover(new_population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, new_population[i], func, temperature)\n                    evaluations += 1\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 76, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {}}
{"id": "4da51288-e576-4132-bc1e-977ba011df96", "fitness": -Infinity, "name": "EnhancedQuasirandomDimReductionOptimizer", "description": "Introduce quasirandom initialization and dynamic dimensional reduction to improve search diversity and solution convergence.", "code": "import numpy as np\n\nclass EnhancedQuasirandomDimReductionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        # Quasirandom initialization using Sobol sequence for better diversity\n        from scipy.stats.qmc import Sobol\n        sampler = Sobol(d=self.dim, scramble=True)\n        samples = sampler.random_base2(m=int(np.log2(self.population_size)))\n        return self.bounds.lb + samples * (self.bounds.ub - self.bounds.lb)\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale, active_dims):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(active_dims, scale)\n        return np.clip(mutant, self.bounds.lb[:active_dims], self.bounds.ub[:active_dims])\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr, active_dims):\n        mask = np.random.rand(active_dims) < cr\n        return np.where(mask, mutant, target[:active_dims])\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature, active_dims):\n        full_candidate = np.copy(current)\n        full_candidate[:active_dims] = candidate\n        candidate_fitness = func(full_candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return full_candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            # Dynamic dimensional reduction\n            active_dims = max(1, int(self.dim * (1 - evaluations / self.budget)))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale, active_dims)\n                    trial = self._crossover(population[i], mutant, cr, active_dims)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature, active_dims)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 77, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,) (19,) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,) (19,) ')", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {}}
{"id": "6555f4a8-c01f-4085-b455-dddebb8653ab", "fitness": 0.15130568121621615, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance mutation strategy by adjusting the scaling factor based on fitness variance to improve exploration.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        fitness_variance = np.var(fitness)\n        f = self._adaptive_mutation(fitness[target_idx]) * (1 + fitness_variance)\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15131 with standard deviation 0.00396.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.14569884107871955, 0.15410716566015703, 0.1541110369097719]}}
{"id": "f66462df-0180-4403-bf0c-31255a50345e", "fitness": 0.14126457072778634, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance adaptive mechanisms with multi-agent collaboration to improve exploration efficiency and solution robustness.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.cooperation_factor = 0.1  # New parameter for cooperation\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n        \n        # Multi-agent cooperation for enhanced mutation\n        coop_agent = np.random.choice(self.population_size, replace=False)\n        cooperation = self.cooperation_factor * (population[coop_agent] - population[target_idx])\n        return np.clip(mutant + cooperation, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14126 with standard deviation 0.01409.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.13748865058079307, 0.16009345791117258, 0.1262116036913934]}}
{"id": "f67a779f-6aa6-46d8-aad3-ab2fb4a0495e", "fitness": 0.15299960871973137, "name": "RefinedHierarchicalMemoryOptimizer", "description": "Introduce hierarchical memory-based adaptation with strategic population reinitialization to boost exploration-exploitation trade-off and convergence robustness.", "code": "import numpy as np\n\nclass RefinedHierarchicalMemoryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.memory = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _strategic_reinitialization(self, population, fitness):\n        prob = np.exp(-(fitness - np.min(fitness)) / (np.std(fitness) + 1e-6))\n        reinit_indices = np.where(np.random.rand(self.population_size) < prob)[0]\n        population[reinit_indices] = np.random.uniform(self.bounds.lb, self.bounds.ub, (len(reinit_indices), self.dim))\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            self.memory.append((population.copy(), fitness.copy()))\n            if evaluations % (self.budget // 5) == 0:\n                self._strategic_reinitialization(population, fitness)\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 80, "feedback": "The algorithm RefinedHierarchicalMemoryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15300 with standard deviation 0.01017.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.1477447364001796, 0.16722691779562926, 0.14402717196338521]}}
{"id": "fcb58ce8-89d5-4742-9f7b-648b8d5de4a4", "fitness": -Infinity, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate time-varying chaotic sequences and adaptive Gaussian mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _gaussian_mutation(self, size, scale):\n        return np.random.normal(0, scale, size)  # Added\n\n    def _chaotic_sequence(self, evaluations):  # Added\n        return 0.7 + 0.3 * np.cos(evaluations * np.pi / self.budget)  # Added\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        chaotic_factor = self._chaotic_sequence(evaluations)  # Modified\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale) * chaotic_factor\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutation_type = np.random.rand()  # Added\n                    if mutation_type < 0.5:  # Added\n                        mutant = self._mutate(i, population, fitness, scale)\n                    else:  # Added\n                        mutant = population[i] + self._gaussian_mutation(self.dim, scale * 0.1)  # Added\n\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 81, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {}}
{"id": "9fdd71f6-6c23-4eec-b370-9e29166673d7", "fitness": -Infinity, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce stochastic gradient-based adjustment and adaptive population clustering to enhance local search precision and global diversity.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _gradient_adjustment(self, individual, func):\n        grad_step = np.random.uniform(-0.1, 0.1, self.dim)\n        new_individual = individual + grad_step\n        new_individual = np.clip(new_individual, self.bounds.lb, self.bounds.ub)\n        if func(new_individual) < func(individual):\n            return new_individual\n        return individual\n\n    def _adaptive_clustering(self, population, fitness, cluster_rate=0.1):\n        n_clusters = max(2, int(self.groups * (1 - fitness.std() / fitness.mean())))\n        clusters = np.array_split(np.argsort(fitness), n_clusters)\n        new_population = []\n        for cluster in clusters:\n            cluster_size = max(1, int(cluster_rate * len(cluster)))\n            selected = np.random.choice(cluster, cluster_size, replace=False)\n            new_population.extend(population[selected])\n        return np.array(new_population)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    # Apply stochastic gradient-based adjustment\n                    new_population[i] = self._gradient_adjustment(new_population[i], func)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            # Apply adaptive population clustering\n            population = self._adaptive_clustering(new_population, new_fitness)\n            fitness = np.array([func(ind) for ind in population])\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 82, "feedback": "An exception occurred: IndexError('index 4 is out of bounds for axis 0 with size 3').", "error": "IndexError('index 4 is out of bounds for axis 0 with size 3')", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {}}
{"id": "cf3601ae-8a32-4ba8-bb76-df3b408151c2", "fitness": 0.12994808234482771, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance the mutation strategy by incorporating a novel scaling factor based on the golden ratio to improve convergence precision.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.golden_ratio = 1.61803398875\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale * self.golden_ratio)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12995 with standard deviation 0.01504.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.12753737251773034, 0.14946087635558536, 0.11284599816116747]}}
{"id": "7aaadabf-5d67-461b-ae49-2338f2ef5891", "fitness": 0.1506064185154944, "name": "EnhancedHierarchicalAdaptiveHybridOptimizerV2", "description": "Integrate stochastic parameter adaptation and inverse temperature scaling to dynamically adjust exploration and exploitation balance, improving convergence robustness and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate * (1 - evaluations / self.budget)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15061 with standard deviation 0.01155.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.14489763606279316, 0.1667124085789684, 0.1402092109047216]}}
{"id": "25305772-0f11-4abc-b707-5974a2ec8a2d", "fitness": 0.13394594194207296, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance dynamic Lvy flight scaling and introduce adaptive temperature management to further refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.96  # Changed from 0.98 to 0.96\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.9  # Changed from 1.5 to 1.9\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.6 * np.sin(evaluations / self.budget * np.pi)  # Changed from 0.5 to 0.6\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13395 with standard deviation 0.00354.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.12901750841289084, 0.1356222257646622, 0.1371980916486658]}}
{"id": "70a03643-726f-4982-8cad-bf4d0b15713c", "fitness": 0.12779658469159552, "name": "EnhancedAdaptiveHybridOptimizerV2", "description": "Introduce a dynamic group size adjustment and enhanced exploration through periodic population shuffling to further balance exploration and exploitation, improving convergence consistency and solution robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.shuffle_interval = 100\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            # Dynamically adjust the number of groups\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget) * (1 + np.sin(evaluations/self.budget * np.pi/2))))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            # Periodic population shuffling to enhance exploration\n            if evaluations % self.shuffle_interval == 0:\n                np.random.shuffle(new_population)\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveHybridOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12780 with standard deviation 0.01044.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.120855980179989, 0.14254740004604982, 0.11998637384874777]}}
{"id": "0aafd65d-79d6-447b-8de0-da897cb66a0f", "fitness": 0.13862426897668442, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate self-adaptive dynamic scaling for mutation rates to further enhance convergence velocity and solution precision.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + (f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)) * (1 + 0.1 * np.sin(target_idx))\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13862 with standard deviation 0.01208.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.13134308562410713, 0.15565225348801293, 0.1288774678179332]}}
{"id": "e1e9c55c-36f9-4edc-853a-52e1fcb69186", "fitness": 0.136893718308522, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate dynamically weighted neighborhood search and stochastic tournament selection to enhance adaptability and convergence efficiency in complex landscapes.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.tournament_size = 3\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _tournament_selection(self, population, fitness):\n        selected_indices = np.random.choice(self.population_size, self.tournament_size, replace=False)\n        best_idx = selected_indices[np.argmin(fitness[selected_indices])]\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    parent, parent_fitness = self._tournament_selection(population, fitness)\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(parent, mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, parent, func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13689 with standard deviation 0.00987.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.13534318639814746, 0.1496769987386135, 0.12566096978880503]}}
{"id": "2695b4a5-7865-49d0-b279-75fbd37c50c8", "fitness": 0.1407935374095007, "name": "PheromoneQuorumHybridOptimizer", "description": "Introduce dynamic pheromone-based parameter tuning and quorum sensing for collective decision-making to enhance global search and convergence in black box optimization.", "code": "import numpy as np\n\nclass PheromoneQuorumHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.pheromone_init = 1.0\n        self.pheromone_decay = 0.9\n        self.pheromone_min = 0.1\n        self.pheromone_max = 3.0\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, pheromone, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness) * pheromone\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, pheromones, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx], pheromones[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _update_pheromones(self, pheromones, fitness):\n        best_idx = np.argmin(fitness)\n        pheromones[best_idx] = min(self.pheromone_max, pheromones[best_idx] / self.pheromone_decay)\n        pheromones *= self.pheromone_decay\n        pheromones = np.clip(pheromones, self.pheromone_min, self.pheromone_max)\n        return pheromones\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        pheromones = np.full(self.population_size, self.pheromone_init)\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, pheromones, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            pheromones = self._update_pheromones(pheromones, fitness)\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 89, "feedback": "The algorithm PheromoneQuorumHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14079 with standard deviation 0.01509.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.15554804352086915, 0.1467656666224576, 0.12006690208517534]}}
{"id": "c647f761-07be-46ff-a174-b9a3b0c167f5", "fitness": 0.13284860224468112, "name": "RefinedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate stochastic local search with dynamic parameter adaptation and elite preservation for enhanced exploration and stability.", "code": "import numpy as np\n\nclass RefinedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.97\n        self.bounds = None\n        self.elitism_rate = 0.25\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.local_search_probability = 0.3\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _stochastic_local_search(self, individual, func):\n        perturbation = np.random.normal(scale=0.1, size=self.dim)\n        candidate = np.clip(individual + perturbation, self.bounds.lb, self.bounds.ub)\n        candidate_fitness = func(candidate)\n        return candidate, candidate_fitness\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    if np.random.rand() < self.local_search_probability:\n                        trial, trial_fitness = self._stochastic_local_search(population[i], func)\n                    else:\n                        mutant = self._mutate(i, population, fitness, scale)\n                        trial = self._crossover(population[i], mutant, cr)\n                        trial, trial_fitness = self._anneal(trial, population[i], func, temperature)\n\n                    new_population[i] = trial\n                    new_fitness[i] = trial_fitness\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 90, "feedback": "The algorithm RefinedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13285 with standard deviation 0.01143.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.12213970250470518, 0.14868509713646583, 0.12772100709287237]}}
{"id": "7a81f4c3-18d4-42a0-b20a-277b1d6bdd48", "fitness": -Infinity, "name": "RefinedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce non-linear dynamic scaling factors and probabilistic group-based mutation with stochastic rank-based selection to enhance diversity and convergence reliability.", "code": "import numpy as np\n\nclass RefinedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.1, f_max=0.9):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness**2)\n\n    def _levy_flight(self, size, scale):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v)**(1 / beta)\n        return scale * step * self.levy_alpha\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.5, cr_max=1.0):\n        return cr_base + (cr_max - cr_base) * np.sin(np.pi * evaluations / (2 * self.budget))\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.random.rand() * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = np.random.permutation(range(g, self.population_size, current_groups))\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            ranks = np.argsort(np.argsort(combined_fitness))\n            probabilities = 1 / (ranks + 1)\n            probabilities /= probabilities.sum()\n            selected_indices = np.random.choice(len(combined_pop), self.population_size, p=probabilities)\n            population = combined_pop[selected_indices]\n            fitness = combined_fitness[selected_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 91, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {}}
{"id": "fcfdf34d-fe2a-4411-8f9c-96f688a1ce2d", "fitness": 0.14336812951449074, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Enhance local search by introducing a dynamic scaling factor for Lvy flights and improving temperature cooling schedule for faster convergence.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.995  # Adjusted from 0.98 for slower cooling\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        dynamic_levy_scale = 0.5 + 0.5 * (scale / self.budget)  # Dynamic scaling factor added\n        return np.random.standard_cauchy(size) * self.levy_alpha * dynamic_levy_scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14337 with standard deviation 0.01232.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.14690576085409235, 0.1563769088439415, 0.12682171884543836]}}
{"id": "37b1f6fd-1a1b-41ec-a0f7-9fb31a0fc716", "fitness": 0.09713952145402449, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Incorporate adaptive inertia and a chaotic local search to improve exploration and precision, boosting convergence and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        \n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale, inertia):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = inertia * population[target_idx] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _chaotic_local_search(self, best, func):\n        chaos = np.random.rand(self.dim)\n        chaotic_candidate = np.clip(best + 0.01 * chaos * (self.bounds.ub - self.bounds.lb), self.bounds.lb, self.bounds.ub)\n        chaotic_fitness = func(chaotic_candidate)\n        if chaotic_fitness < func(best):\n            return chaotic_candidate, chaotic_fitness\n        return best, func(best)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale, inertia)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            population[0], fitness[0] = self._chaotic_local_search(population[0], func)\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09714 with standard deviation 0.00424.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.09684597579813614, 0.09210429380162533, 0.102468294762312]}}
{"id": "6eeeb039-36b3-4ca5-8d58-68fb4dc4850d", "fitness": 0.15299960871973137, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate dynamic mutation scaling based on diversity metrics to enhance the balance between exploration and exploitation.  ", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, diversity, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        f_range = f_max - f_min\n        div_factor = 1.0 / (1.0 + np.exp(-diversity))\n        return f_min + f_range * (1 - norm_fitness) * div_factor\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity = np.std(population)  # Calculate population diversity\n        f = self._adaptive_mutation(fitness[target_idx], diversity)\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15300 with standard deviation 0.01017.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.1477447364001796, 0.16722691779562926, 0.14402717196338521]}}
{"id": "d96f7da6-0d7f-4d4e-bf6c-03c4c5d11d24", "fitness": 0.15299960871973137, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce a multi-layer elite preservation strategy and dynamic group adaptation to enhance convergence stability and solution diversity.  ", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.elite_layers = 3  # Number of elite layers for preservation\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n        elite_per_layer = elite_size // self.elite_layers\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15300 with standard deviation 0.01017.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.1477447364001796, 0.16722691779562926, 0.14402717196338521]}}
{"id": "f3aae5e4-e5a3-44e9-985d-644dd866da2d", "fitness": 0.13718266263694043, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce dynamic elitism adaptation and adaptive group scaling to further balance exploration and exploitation, enhancing convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.1  # Changed from 0.2 to 0.1\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - np.cos(evaluations / self.budget * np.pi))))  # Changed\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13718 with standard deviation 0.00918.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.13080761782161365, 0.13057295662842305, 0.15016741346078455]}}
{"id": "bd998449-1530-4817-b317-f03547e0afb7", "fitness": 0.14665631562472078, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate adaptive tabu memory and chaotic maps for diversified search and enhanced convergence precision.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n        self.tabu_memory_size = 5\n        self.tabu_list = []\n        self.chaotic_map_param = 0.7\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def _update_tabu_list(self, solution):\n        if len(self.tabu_list) >= self.tabu_memory_size:\n            self.tabu_list.pop(0)\n        self.tabu_list.append(solution)\n\n    def _is_tabu(self, solution):\n        return any(np.allclose(solution, tabu, atol=1e-6) for tabu in self.tabu_list)\n\n    def _chaotic_map(self, evaluation_step):\n        return (evaluation_step / self.budget) * (1 - evaluation_step / self.budget) * self.chaotic_map_param\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n\n                    if not self._is_tabu(trial):\n                        new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                        self._update_tabu_list(new_population[i])\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate * self._chaotic_map(evaluations)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14666 with standard deviation 0.01301.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.13432646326542852, 0.14098935039797278, 0.16465313321076103]}}
{"id": "0a9596ed-7d4c-4e8d-8ae9-a2b699867875", "fitness": 0.14443668649081468, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Integrate exponential cooling in the simulated annealing process to potentially enhance exploration during later stages of optimization.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= np.exp(-self.cooling_rate)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14444 with standard deviation 0.01720.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.1262336473138329, 0.16751826013254734, 0.1395581520260638]}}
{"id": "cbd3a217-6e1d-4d69-b83f-dca712ba9b1b", "fitness": 0.1506064185154944, "name": "EnhancedHierarchicalAdaptiveHybridOptimizer", "description": "Introduce a dynamic scaling factor in the cooling rate to better adapt to varying evaluation conditions, thereby enhancing convergence.", "code": "import numpy as np\n\nclass EnhancedHierarchicalAdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_temp = 100.0\n        self.cooling_rate = 0.98\n        self.bounds = None\n        self.elitism_rate = 0.2\n        self.groups = 5\n        self.levy_alpha = 1.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.bounds.lb, self.bounds.ub, (self.population_size, self.dim))\n\n    def _adaptive_mutation(self, fitness, f_min=0.3, f_max=0.8):\n        norm_fitness = (fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-6)\n        return f_min + (f_max - f_min) * (1 - norm_fitness)\n\n    def _levy_flight(self, size, scale):\n        return np.random.standard_cauchy(size) * self.levy_alpha * scale\n\n    def _mutate(self, target_idx, population, fitness, scale):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        f = self._adaptive_mutation(fitness[target_idx])\n        mutant = population[a] + f * (population[b] - population[c]) + self._levy_flight(self.dim, scale)\n        return np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n    def _adaptive_crossover(self, evaluations, cr_base=0.65, cr_max=0.9):\n        return cr_base + (cr_max - cr_base) * (evaluations / self.budget)\n\n    def _crossover(self, target, mutant, cr):\n        mask = np.random.rand(self.dim) < cr\n        return np.where(mask, mutant, target)\n\n    def _acceptance_probability(self, current, candidate, t):\n        return 1.0 if candidate < current else np.exp((current - candidate) / t)\n\n    def _anneal(self, candidate, current, func, temperature):\n        candidate_fitness = func(candidate)\n        if self._acceptance_probability(func(current), candidate_fitness, temperature) > np.random.rand():\n            return candidate, candidate_fitness\n        return current, func(current)\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        population = self._initialize_population()\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        temperature = self.initial_temp\n        elite_size = int(self.elitism_rate * self.population_size)\n\n        while evaluations < self.budget:\n            new_population = np.copy(population)\n            new_fitness = np.copy(fitness)\n\n            current_groups = max(2, int(self.groups * (1 - evaluations / self.budget)))\n            scale = 1 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n            cr = self._adaptive_crossover(evaluations)\n\n            for g in range(current_groups):\n                group_indices = range(g, self.population_size, current_groups)\n\n                for i in group_indices:\n                    if i < elite_size:\n                        continue\n\n                    mutant = self._mutate(i, population, fitness, scale)\n                    trial = self._crossover(population[i], mutant, cr)\n                    new_population[i], new_fitness[i] = self._anneal(trial, population[i], func, temperature)\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n            combined_pop = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_pop[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            temperature *= self.cooling_rate * (1 - (evaluations / self.budget))  # Modified line\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHierarchicalAdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15061 with standard deviation 0.01155.", "error": "", "parent_ids": ["533fdb32-7453-4b0b-80b7-c2e21bdfc951"], "operator": null, "metadata": {"aucs": [0.14489763606279316, 0.1667124085789684, 0.1402092109047216]}}
