{"id": "f3c3acc0-7c91-4824-9649-98039cb37d21", "fitness": 0.16368901301543304, "name": "HybridPSOSA", "description": "A hybrid Particle Swarm Optimization and Simulated Annealing algorithm that balances exploration and exploitation for efficient black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.5  # inertia\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.temperature = 1000\n        self.cooling_rate = 0.995\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n            \n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Simulated Annealing component\n                candidate_solution = x[i] + np.random.normal(0, 1, self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < cost or np.random.rand() < np.exp((cost - candidate_cost) / self.temperature):\n                    x[i] = candidate_solution\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n            self.temperature *= self.cooling_rate", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16369 with standard deviation 0.02563.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.13115605247008755, 0.16611683961067536, 0.1937941469655362]}}
{"id": "6d67d39b-956d-437c-b44d-a5bb403e81e4", "fitness": 0.1592659776309561, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA by integrating adaptive velocity and mutation strategy for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_max = 0.9  # increased inertia for exploration\n        self.w_min = 0.4  # decreased inertia for exploitation\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.temperature = 1000\n        self.cooling_rate = 0.995\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n            \n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)  # adaptive inertia weight\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Simulated Annealing component\n                candidate_solution = x[i] + np.random.normal(0, 1, self.dim) * (self.temperature / 1000) # mutation scale\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < cost or np.random.rand() < np.exp((cost - candidate_cost) / self.temperature):\n                    x[i] = candidate_solution\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n            self.temperature *= self.cooling_rate", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15927 with standard deviation 0.02384.", "error": "", "parent_ids": ["f3c3acc0-7c91-4824-9649-98039cb37d21"], "operator": null, "metadata": {"aucs": [0.12918863146688242, 0.16111622917057655, 0.18749307225540934]}}
{"id": "5331a299-3cd8-4ee5-a177-538de4c9c24a", "fitness": 0.09534781472710208, "name": "EnhancedHybridPSOSA", "description": "Introducing Adaptive Inertia and Multi-Swarm Strategy to enhance the exploration-exploitation balance in HybridPSOSA for better convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.initial_w = 0.9\n        self.final_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.temperature = 1000\n        self.cooling_rate = 0.995\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.swarm_division = 5  # Number of sub-swarms\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.full(self.particles, float('inf'))\n        evaluations = 0\n        \n        iteration = 0\n        while evaluations < self.budget:\n            w = (self.initial_w - self.final_w) * (self.budget - evaluations) / self.budget + self.final_w\n            \n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n            \n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                p_best_index = (i // (self.particles // self.swarm_division)) * (self.particles // self.swarm_division)\n                v[i] = (w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (personal_best[p_best_index] - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                candidate_solution = x[i] + np.random.normal(0, 1, self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < cost or np.random.rand() < np.exp((cost - candidate_cost) / self.temperature):\n                    x[i] = candidate_solution\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n            self.temperature *= self.cooling_rate\n            iteration += 1", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09535 with standard deviation 0.00659.", "error": "", "parent_ids": ["f3c3acc0-7c91-4824-9649-98039cb37d21"], "operator": null, "metadata": {"aucs": [0.0876864259515222, 0.09457608980980559, 0.10378092841997844]}}
{"id": "3b528a25-38c0-409b-9d59-60489546bec5", "fitness": 0.14674770555584674, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA by adjusting inertia dynamically for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.5  # inertia\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.temperature = 1000\n        self.cooling_rate = 0.995\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n            \n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.5 + 0.4 * (1 - evaluations / self.budget)  # Dynamically adjusted inertia\n                v[i] = (self.w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Simulated Annealing component\n                candidate_solution = x[i] + np.random.normal(0, 1, self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < cost or np.random.rand() < np.exp((cost - candidate_cost) / self.temperature):\n                    x[i] = candidate_solution\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n            self.temperature *= self.cooling_rate", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14675 with standard deviation 0.01640.", "error": "", "parent_ids": ["f3c3acc0-7c91-4824-9649-98039cb37d21"], "operator": null, "metadata": {"aucs": [0.12362267889336642, 0.1598923555347923, 0.1567280822393815]}}
{"id": "9180e5c1-9763-4988-ac4b-6a9f974ba514", "fitness": 0.14920588163722584, "name": "HybridPSOSA", "description": "Enhanced hybrid PSO and SA algorithm with adaptive inertia weight for better convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.5  # inertia\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.temperature = 1000\n        self.cooling_rate = 0.995\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight update\n            self.w = 0.9 - (0.5 / self.budget) * evaluations\n\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n            \n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Simulated Annealing component\n                candidate_solution = x[i] + np.random.normal(0, 1, self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < cost or np.random.rand() < np.exp((cost - candidate_cost) / self.temperature):\n                    x[i] = candidate_solution\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n            self.temperature *= self.cooling_rate", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14921 with standard deviation 0.02043.", "error": "", "parent_ids": ["f3c3acc0-7c91-4824-9649-98039cb37d21"], "operator": null, "metadata": {"aucs": [0.12148902538720929, 0.15600429309167474, 0.17012432643279352]}}
{"id": "3ef32a00-81fd-4dc5-b130-b860b864793d", "fitness": 0.1710413110506548, "name": "HybridPSOGWO", "description": "HybridPSOGWO - A hybrid Particle Swarm Optimization and Grey Wolf Optimizer that enhances convergence by leveraging swarm intelligence and social hierarchies.", "code": "import numpy as np\n\nclass HybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.5  # inertia\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17104 with standard deviation 0.02282.", "error": "", "parent_ids": ["f3c3acc0-7c91-4824-9649-98039cb37d21"], "operator": null, "metadata": {"aucs": [0.13883432986520639, 0.18534760675396778, 0.1889419965327902]}}
{"id": "ea4b8302-b9a4-4ace-9bec-37da525b5027", "fitness": 0.170274286204119, "name": "HybridPSOGWOv2", "description": "HybridPSOGWOv2 - An enhanced hybrid Particle Swarm Optimization and Grey Wolf Optimizer incorporating adaptive inertia and dynamic social-cognitive coefficients to boost convergence and diversity.", "code": "import numpy as np\n\nclass HybridPSOGWOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_start = 2.5\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.5\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            c1 = self.c1_start - ((self.c1_start - self.c1_end) * evaluations / self.budget)\n            c2 = self.c2_start + ((self.c2_end - self.c2_start) * evaluations / self.budget)\n\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSOGWOv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17027 with standard deviation 0.01153.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.1539890680470618, 0.17766597507102633, 0.17916781549426886]}}
{"id": "be27f98e-863f-4e07-9760-a2ad56eb86ad", "fitness": 0.1709314821456622, "name": "HybridPSOGWO", "description": "Improved HybridPSOGWO by introducing adaptive inertia weight and dynamic particle count to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia weight start\n        self.w_end = 0.4  # adaptive inertia weight end\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            current_w = self.w - ((self.w - self.w_end) * (evaluations / self.budget))  # adaptive inertia\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (current_w * v[i]  # use adaptive inertia weight\n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17093 with standard deviation 0.00965.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.1573655581132578, 0.17905208019929875, 0.17637680812443002]}}
{"id": "216b6bfc-7002-4766-a2fd-69655388318d", "fitness": 0.1709314821456622, "name": "HybridPSOGWO", "description": "Improved HybridPSOGWO - Enhances the hybrid approach by introducing adaptive weight and diversity mechanisms to improve exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # start inertia\n        self.w_min = 0.4  # minimum inertia\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            w_adaptive = self.w_min + (self.w - self.w_min) * (1 - evaluations / self.budget)\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w_adaptive * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17093 with standard deviation 0.00965.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.1573655581132578, 0.17905208019929875, 0.17637680812443002]}}
{"id": "db741ec5-f7e2-49aa-a928-349895f8be9c", "fitness": 0.1611269176917407, "name": "HybridPSOGWOPlus", "description": "HybridPSOGWOPlus - Enhances HybridPSOGWO by incorporating adaptive parameters for improved exploration-exploitation balance and convergence.", "code": "import numpy as np\n\nclass HybridPSOGWOPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 2.0  # social (swarm)\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            \n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component with adaptive coefficients\n                A1, A2, A3 = 2 * (1 - evaluations / self.budget) * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSOGWOPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16113 with standard deviation 0.01609.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.15043022118583416, 0.14908690060661212, 0.18386363128277583]}}
{"id": "981b62ba-5014-4def-84fe-ff0b5dc83c38", "fitness": 0.16353164337998635, "name": "HybridPSOGWO", "description": "Enhanced HybridPSOGWO - Incorporates adaptive inertia and dynamic social factor adjustments to augment convergence efficiency.", "code": "import numpy as np\n\nclass HybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia start\n        self.w_min = 0.4\n        self.c1 = 2.0  # cognitive (particle)\n        self.c2 = 1.5  # dynamic social start\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            # Adaptive inertia and social factor\n            self.w = self.w_min + (0.9 - self.w_min) * (1 - evaluations / self.budget)\n            self.c2 = 2.5 - (2.0 * evaluations / self.budget)\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + self.c1 * r1 * (personal_best[i] - x[i]) \n                        + self.c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16353 with standard deviation 0.02172.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.13411194945732574, 0.17060525891758538, 0.1858777217650479]}}
{"id": "c50febee-232b-4bb5-9c77-b8e2bfa7c4d1", "fitness": 0.1800076967765233, "name": "HybridPSOGWO", "description": "Improved HybridPSOGWO - An enhanced version of HybridPSOGWO that incorporates adaptive parameters to improve convergence through dynamic adjustment of exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.5  # inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                # Adaptive coefficients\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18001 with standard deviation 0.00904.", "error": "", "parent_ids": ["3ef32a00-81fd-4dc5-b130-b860b864793d"], "operator": null, "metadata": {"aucs": [0.19278304354870346, 0.1739515211668985, 0.17328852561396801]}}
{"id": "8945501b-acb7-4e02-a2f8-ff1570c15e24", "fitness": 0.1802906572922179, "name": "EnhancedHybridPSOGWO", "description": "Enhanced HybridPSOGWO with Adaptive Vortex Search - Incorporates a vortex search mechanism and adaptive inertia to improve solution diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                vortex_solution = x[i] + vortex_vector * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18029 with standard deviation 0.00429.", "error": "", "parent_ids": ["c50febee-232b-4bb5-9c77-b8e2bfa7c4d1"], "operator": null, "metadata": {"aucs": [0.18631822499418915, 0.17786574642609998, 0.17668800045636457]}}
{"id": "a380b6bd-bfcb-45ac-84c1-3e0ebb4a51bc", "fitness": 0.17806340146029645, "name": "OptimizedHybridPSOGWO", "description": "OptimizedHybridPSOGWO with Enhanced Adaptive Strategies - Introduces adaptive learning coefficients and an elite re-evaluation mechanism to significantly enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass OptimizedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_init = 0.9\n        self.w_end = 0.4\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            w = self.w_init - (self.w_init - self.w_end) * (evaluations / self.budget)\n            c1 = self.c1_init * (1 - evaluations / self.budget)\n            c2 = self.c2_init * (evaluations / self.budget)\n\n            for i in range(self.particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                vortex_solution = x[i] + vortex_vector * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n            # Elite re-evaluation mechanism to intensify search around best solutions\n            if evaluations < self.budget:\n                elite_re_eval = 0.1 * self.particles\n                for i in range(int(elite_re_eval)):\n                    elite_solution = personal_best[sorted_indices[i]]\n                    elite_cost = func(elite_solution)\n                    evaluations += 1\n                    if elite_cost < self.best_cost:\n                        self.best_cost = elite_cost\n                        self.best_solution = elite_solution.copy()", "configspace": "", "generation": 13, "feedback": "The algorithm OptimizedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17806 with standard deviation 0.00801.", "error": "", "parent_ids": ["8945501b-acb7-4e02-a2f8-ff1570c15e24"], "operator": null, "metadata": {"aucs": [0.18688170405146964, 0.17981919926566603, 0.1674893010637537]}}
{"id": "da28dc25-817d-413f-9f8d-a41889dfab2e", "fitness": 0.1601322852736867, "name": "EnhancedHybridPSOGWOElite", "description": "Enhanced HybridPSOGWO with Adaptive Dynamic Search and Elite Memory - Introduces dynamic exploration and an elite memory mechanism boosting exploration and exploitation balance for superior convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWOElite:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.elite_memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n                    if len(self.elite_memory) < 5:\n                        self.elite_memory.append((self.best_solution.copy(), self.best_cost))\n                    else:\n                        # Replace the worst elite member\n                        worst_elite_index = max(range(len(self.elite_memory)),\n                                                key=lambda j: self.elite_memory[j][1])\n                        if self.best_cost < self.elite_memory[worst_elite_index][1]:\n                            self.elite_memory[worst_elite_index] = (self.best_solution.copy(), self.best_cost)\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Dynamic search enhancement\n                dynamic_vector = np.random.uniform(-1, 1, self.dim)\n                dynamic_solution = x[i] + dynamic_vector * 0.1 * (ub - lb)\n                dynamic_solution = np.clip(dynamic_solution, lb, ub)\n                dynamic_cost = func(dynamic_solution)\n                evaluations += 1\n\n                if dynamic_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = dynamic_cost\n                    personal_best[i] = dynamic_solution.copy()\n                if dynamic_cost < self.best_cost:\n                    self.best_cost = dynamic_cost\n                    self.best_solution = dynamic_solution.copy()\n\n                # Elite memory search\n                if len(self.elite_memory) > 0:\n                    elite_choice = np.random.choice(len(self.elite_memory))\n                    elite_vector = np.random.normal(0, 1, self.dim)\n                    elite_solution = self.elite_memory[elite_choice][0] + elite_vector * 0.05\n                    elite_solution = np.clip(elite_solution, lb, ub)\n                    elite_cost = func(elite_solution)\n                    evaluations += 1\n\n                    if elite_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = elite_cost\n                        personal_best[i] = elite_solution.copy()\n                    if elite_cost < self.best_cost:\n                        self.best_cost = elite_cost\n                        self.best_solution = elite_solution.copy()", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSOGWOElite got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16013 with standard deviation 0.01612.", "error": "", "parent_ids": ["8945501b-acb7-4e02-a2f8-ff1570c15e24"], "operator": null, "metadata": {"aucs": [0.1400426103713167, 0.16085644598650228, 0.17949779946324107]}}
{"id": "7031f742-cd54-4c0b-a31e-909d0487e1be", "fitness": 0.17186361066144773, "name": "EnhancedHybridPSOGWO", "description": "Enhanced Hybrid PSOGWO with Adaptive Hyperparameters - Introduces dynamic adjustment of coefficients and exploration-exploitation balance to enhance performance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.7 + 0.2 * np.cos(np.pi * evaluations / self.budget)  # Adaptive inertia with cosine modulation\n                c1 = self.c1_init * (1 - evaluations / self.budget) * np.random.rand()  # Dynamic adjustment\n                c2 = self.c2_init * (evaluations / self.budget) * np.random.rand()  # Dynamic adjustment\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                vortex_solution = x[i] + vortex_vector * (0.5 * evaluations / self.budget)  # Adjust exploration-exploitation balance\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17186 with standard deviation 0.00810.", "error": "", "parent_ids": ["8945501b-acb7-4e02-a2f8-ff1570c15e24"], "operator": null, "metadata": {"aucs": [0.16209372869208583, 0.18192278923387806, 0.1715743140583793]}}
{"id": "fb0114a4-c066-4805-9929-93857ed6b9e6", "fitness": 0.15386757954297145, "name": "EnhancedHybridPSOGWO", "description": "Enhanced HybridPSOGWO with Adaptive Differential Mutation - Integrates differential mutation strategies for increased exploration and adaptive refinement of solutions.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                vortex_solution = x[i] + vortex_vector * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Mutation addition\n                if evaluations < self.budget - 2:\n                    idxs = np.random.choice(self.particles, 3, replace=False)\n                    F = 0.8  # Differential weight\n                    mutant_vector = personal_best[idxs[0]] + F * (personal_best[idxs[1]] - personal_best[idxs[2]])\n                    mutant_vector = np.clip(mutant_vector, lb, ub)\n                    mutant_cost = func(mutant_vector)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant_vector.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant_vector.copy()", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15387 with standard deviation 0.00728.", "error": "", "parent_ids": ["8945501b-acb7-4e02-a2f8-ff1570c15e24"], "operator": null, "metadata": {"aucs": [0.14362424248063133, 0.15984371735549685, 0.15813477879278615]}}
{"id": "be3d7273-69da-4878-95dd-c79d405d90ac", "fitness": 0.18221700312175085, "name": "EnhancedHybridPSOGWO", "description": "Introduced dynamic adjustment of vortex search intensity based on solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18222 with standard deviation 0.00343.", "error": "", "parent_ids": ["8945501b-acb7-4e02-a2f8-ff1570c15e24"], "operator": null, "metadata": {"aucs": [0.18699651187626154, 0.17913829461765984, 0.1805162028713312]}}
{"id": "967486ed-7c95-4691-a7c0-b0ee592be85a", "fitness": 0.1802392799677125, "name": "EnhancedHybridPSOGWO", "description": "Enhanced dynamic adaptation of swarm and vortex intensities using individual progress metrics to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with refined dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity_factor = np.exp(-personal_best_cost[i] / (self.best_cost + 1e-9))\n                vortex_solution = x[i] + vortex_vector * intensity_factor * (1 - evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18024 with standard deviation 0.00357.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.18524238016176886, 0.17830825024516883, 0.1771672094961998]}}
{"id": "ae14efe8-a043-4a1b-9ab9-c470f3224757", "fitness": 0.1809764248732071, "name": "EnhancedDynamicVortexPSOGWO", "description": "EnhancedDynamicVortexPSOGWO introduces a multi-phase vortex search that dynamically adapts both intensity and direction based on historical performance trends.", "code": "import numpy as np\n\nclass EnhancedDynamicVortexPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n            self.history.append(self.best_cost)\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Multi-phase Vortex search with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                historical_trend = np.std(self.history[-min(len(self.history), 5):]) if len(self.history) > 5 else 1\n                intensity = (personal_best_cost[i] / self.best_cost) * historical_trend if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedDynamicVortexPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18098 with standard deviation 0.00250.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.18419395371060443, 0.17808453237141142, 0.1806507885376054]}}
{"id": "af30df8f-1c7a-43a6-b520-fee29b2029fd", "fitness": 0.18028081423790257, "name": "EnhancedHybridPSOGWO", "description": "Adjusted the vortex search intensity calculation to use a more sensitive scaling factor based on the logarithm of the fitness ratio to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.log1p(personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18028 with standard deviation 0.00401.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.18589682583634692, 0.1781576025748195, 0.17678801430254132]}}
{"id": "bbeef298-74fd-4a8b-9476-34639617a60f", "fitness": 0.18221611241779237, "name": "EnhancedHybridPSOGWO_Improved", "description": "Introduced adaptive learning rates based on convergence speed to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_init = 0.9  # initial inertia\n        self.w_final = 0.4  # final inertia\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                progress = evaluations / self.budget\n                self.w = self.w_init - progress * (self.w_init - self.w_final)\n                c1 = self.c1_init * (1 - progress)\n                c2 = self.c2_init * progress\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * progress\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSOGWO_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18222 with standard deviation 0.00343.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.18699522597978802, 0.17913691567736423, 0.1805161955962249]}}
{"id": "7cd24c1f-384c-43f1-adcc-a8aa6d479c9f", "fitness": 0.17327738880771537, "name": "EnhancedHybridPSOGWO", "description": "Introduced adaptive predator-prey dynamics to enhance exploration and exploitation balance in the search process.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Predator-prey dynamics\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                prey_position = candidate_solution + np.random.normal(0, 1, self.dim) * intensity * (evaluations / self.budget)\n                prey_position = np.clip(prey_position, lb, ub)\n                prey_cost = func(prey_position)\n                evaluations += 1\n\n                if prey_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = prey_cost\n                    personal_best[i] = prey_position.copy()\n                if prey_cost < self.best_cost:\n                    self.best_cost = prey_cost\n                    self.best_solution = prey_position.copy()", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17328 with standard deviation 0.01326.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.15498047822734828, 0.17885804212805634, 0.1859936460677415]}}
{"id": "0af801ab-cc03-433b-be2e-4a8f8d256a80", "fitness": 0.1827045291628254, "name": "EnhancedHybridPSOGWO", "description": "Improved exploration by fine-tuning the inertia weight update strategy for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.6 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18270 with standard deviation 0.00411.", "error": "", "parent_ids": ["be3d7273-69da-4878-95dd-c79d405d90ac"], "operator": null, "metadata": {"aucs": [0.18830698341176488, 0.17856971518676779, 0.1812368888899435]}}
{"id": "257284c0-a1ef-4e7f-aee7-921a5d588c7f", "fitness": 0.17305001296375402, "name": "RefinedHybridPSOGWO", "description": "Introducing dynamic particle interactions and adaptive vortex intensity based on convergence trends to enhance search efficiency and solution quality.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.6 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                convergence_factor = 1 - (self.best_cost / (np.mean(personal_best_cost) + 1e-9))\n                c1 = self.c1_init * (1 - evaluations / self.budget) * convergence_factor\n                c2 = self.c2_init * (evaluations / self.budget) * (2 - convergence_factor)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (1 - convergence_factor) * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17305 with standard deviation 0.00619.", "error": "", "parent_ids": ["0af801ab-cc03-433b-be2e-4a8f8d256a80"], "operator": null, "metadata": {"aucs": [0.16754502600134036, 0.18170210913442353, 0.1699029037554982]}}
{"id": "965f3234-32e2-465b-a341-7a3a11abe116", "fitness": 0.17628732252731596, "name": "EnhancedHybridPSOGWO", "description": "Introduce a slight adaptive change to the Grey Wolf's influence to improve convergence rate.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.6 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                # Slight adaptive change to improve convergence\n                X1 = X1 * (0.9 + 0.1 * (evaluations / self.budget))\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17629 with standard deviation 0.01407.", "error": "", "parent_ids": ["0af801ab-cc03-433b-be2e-4a8f8d256a80"], "operator": null, "metadata": {"aucs": [0.1812750010617905, 0.19047956134091915, 0.15710740517923827]}}
{"id": "7ce44bef-c42e-4b27-82fc-f8cbfb64e418", "fitness": 0.18406273023917, "name": "EnhancedHybridPSOGWO", "description": "Slightly adjusted the inertia weight decrement formula to improve exploitation near the end of the search process.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18406 with standard deviation 0.00505.", "error": "", "parent_ids": ["0af801ab-cc03-433b-be2e-4a8f8d256a80"], "operator": null, "metadata": {"aucs": [0.19094463652495786, 0.18229196192398844, 0.17895159226856372]}}
{"id": "80d84b86-c2d0-4120-b96d-5a5ab09c9141", "fitness": 0.1840627302373139, "name": "EnhancedHybridPSOGWO", "description": "Slightly enhance the vortex search component for more effective exploration by adjusting intensity scaling.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / (self.best_cost + 1e-10)) if self.best_cost != 0 else 1  # Adjusted intensity scaling\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18406 with standard deviation 0.00505.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.19094463652741278, 0.1822919619213924, 0.1789515922631365]}}
{"id": "2713fcfe-7116-455b-bc3c-26ff34d985c8", "fitness": 0.1752391095407186, "name": "EnhancedHierarchyPSOGWO", "description": "Integrate a dynamic hierarchy among particles to enhance exploration and exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHierarchyPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                hierarchy_level = self.particles - sorted_indices[i]  # dynamic hierarchy\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (hierarchy_level / self.particles)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHierarchyPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17524 with standard deviation 0.00456.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.17160843637429501, 0.1816734214797423, 0.1724354707681185]}}
{"id": "5e50d24a-6056-457f-b684-0c7cc4d859ee", "fitness": 0.17710150805816027, "name": "EnhancedDynamicPSOGWO", "description": "Introduce a dynamic particle adjustment strategy and adaptive vortex exploration to enhance convergence rate and exploitation.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                dynamic_factor = 1 - (evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * intensity * dynamic_factor\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17710 with standard deviation 0.00542.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.17222357949964917, 0.18466428835915893, 0.1744166563156727]}}
{"id": "3bcaf7d4-b335-4ca5-9adb-9a7d6d4fb587", "fitness": 0.1722393499109948, "name": "AdaptiveClusteringPSOGWO", "description": "Introduced adaptive dynamic particle clustering and multi-leader selection to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveClusteringPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Adaptive Clustering and Multi-Leader Selection\n                cluster_radius = np.linalg.norm(ub - lb) * (1 - evaluations / self.budget)\n                cluster_center = personal_best[np.random.choice(sorted_indices[:3])]\n                if np.linalg.norm(x[i] - cluster_center) < cluster_radius:\n                    A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                    C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                    \n                    D_alpha = np.abs(C1 * self.alpha - x[i])\n                    D_beta = np.abs(C2 * self.beta - x[i])\n                    D_delta = np.abs(C3 * self.delta - x[i])\n                    \n                    X1 = self.alpha - A1 * D_alpha\n                    X2 = self.beta - A2 * D_beta\n                    X3 = self.delta - A3 * D_delta\n                    \n                    candidate_solution = (X1 + X2 + X3) / 3\n                    candidate_solution = np.clip(candidate_solution, lb, ub)\n                    candidate_cost = func(candidate_solution)\n                    evaluations += 1\n\n                    if candidate_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = candidate_cost\n                        personal_best[i] = candidate_solution.copy()\n                    if candidate_cost < self.best_cost:\n                        self.best_cost = candidate_cost\n                        self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveClusteringPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17224 with standard deviation 0.01264.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.15571345533843617, 0.17460045674896707, 0.18640413764558117]}}
{"id": "47fc6b73-1c66-4449-9bea-d703c1fbb757", "fitness": 0.1840627302206607, "name": "EnhancedHybridPSOGWO", "description": "Fine-tuned the vortex search intensity to enhance convergence towards optimal solutions.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / (self.best_cost + 1e-9)) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18406 with standard deviation 0.00505.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.1909446365496743, 0.18229196189787777, 0.17895159221443002]}}
{"id": "e052a9d3-4d80-4d07-888c-6af733d8f52e", "fitness": 0.16388634020515538, "name": "EnhancedHybridPSOGWO", "description": "Slight modification to the Grey Wolf component to enhance exploration by adjusting the calculation of candidate solutions.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 2.8  # Modified from 3 to 2.8 for better exploration\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16389 with standard deviation 0.00282.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.16008213770810464, 0.16474409620922714, 0.1668327866981344]}}
{"id": "a3f394c4-118c-462c-9ee8-092ecdc16ee6", "fitness": 0.17710150805816027, "name": "EnhancedHybridPSOGWO", "description": "EnhancedHybridPSOGWO with dynamic velocity control and adaptive vortex intensity for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                # Adaptive vortex intensity based on convergence status\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_intensity = intensity * (1 - evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * vortex_intensity\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17710 with standard deviation 0.00542.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.17222357949964917, 0.18466428835915893, 0.1744166563156727]}}
{"id": "1b43abd3-c4c5-45cc-bbb2-23de44075520", "fitness": 0.18338909870188772, "name": "EnhancedHybridPSOGWO", "description": "Slightly refined the vortex search intensity calculation to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) ** 0.5 if self.best_cost != 0 else 1  # Modified line\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18339 with standard deviation 0.00469.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.1895481382880102, 0.18245567818257402, 0.17816347963507895]}}
{"id": "bec63fb0-29aa-4ab8-9d6b-5f64366f7283", "fitness": 0.1771387345882005, "name": "EnhancedHybridPSOGWO", "description": "Introduced adaptive leadership and non-uniform mutation to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component with adaptive leadership\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment and non-uniform mutation\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                mutation_strength = np.power(0.5, evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * intensity * mutation_strength\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17714 with standard deviation 0.00516.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.17217440629955238, 0.1842574962009622, 0.17498430126408693]}}
{"id": "3181516b-5c82-4f0b-aca2-00cce21bac0f", "fitness": 0.18271837261346338, "name": "EnhancedDynamicPSOGWO", "description": "Introduce a novel dynamic learning strategy with adaptive coefficients and phase-based exploration to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # initial inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n        \n        evaluations = 0\n        phase_switch = self.budget // 3\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                if evaluations < phase_switch:\n                    # Exploration phase\n                    self.w = 0.9 - 0.7 * (evaluations / phase_switch)\n                    c1 = self.c1_init * (1 - evaluations / phase_switch)\n                    c2 = self.c2_init * (evaluations / phase_switch)\n                else:\n                    # Exploitation phase\n                    self.w = 0.4 + 0.5 * ((evaluations - phase_switch) / (self.budget - phase_switch))\n                    c1 = self.c1_init * ((self.budget - evaluations) / (self.budget - phase_switch))\n                    c2 = self.c2_init * ((evaluations - phase_switch) / (self.budget - phase_switch))\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with new dynamic adjustment\n                vortex_vector = np.random.randn(self.dim)\n                intensity = np.exp(-evaluations / self.budget) * (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18272 with standard deviation 0.00945.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.19560304886406554, 0.1793577474360204, 0.17319432154030423]}}
{"id": "6d76ba67-7c58-4a09-9546-c0ee90a5ecd4", "fitness": 0.15441335645976453, "name": "EnhancedHybridPSOGWO", "description": "Introduced a dynamic adjustment to the Grey Wolf Optimization component's attraction factor.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                attraction_factor = (1 - evaluations / self.budget)  # New dynamic adjustment                \n                A1, A2, A3 = 2 * attraction_factor * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15441 with standard deviation 0.01446.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.144453054709635, 0.17486321381812453, 0.1439238008515341]}}
{"id": "7195e922-40e1-4599-adbc-69d4a8bec27d", "fitness": 0.18568424889790694, "name": "EnhancedHybridPSOGWO", "description": "Enhanced exploitation accuracy by refining the inertia weight decay function.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18568 with standard deviation 0.00213.", "error": "", "parent_ids": ["7ce44bef-c42e-4b27-82fc-f8cbfb64e418"], "operator": null, "metadata": {"aucs": [0.18797773080011382, 0.18284527476116474, 0.18622974113244228]}}
{"id": "8c2b38b3-ae0a-478f-a9af-152052b3ffd8", "fitness": 0.18574129536477388, "name": "EnhancedHybridPSOGWO", "description": "Enhanced convergence speed by adjusting the personal best update strategy.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n                \n                cost = func(x[i])\n                evaluations += 1\n                \n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])  # Adjusted personal best update strategy\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)  # Adjusted adaptive inertia\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = (personal_best_cost[i] / self.best_cost) if self.best_cost != 0 else 1\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18574 with standard deviation 0.00259.", "error": "", "parent_ids": ["7195e922-40e1-4599-adbc-69d4a8bec27d"], "operator": null, "metadata": {"aucs": [0.18854785799035167, 0.18229598697928506, 0.18638004112468487]}}
{"id": "718118d4-c40c-4b4c-ba06-cc27e1ceac7b", "fitness": 0.18625520994360298, "name": "RefinedHybridPSOGWO", "description": "Introduce dynamic learning rates and stochastic tunneling to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18626 with standard deviation 0.00235.", "error": "", "parent_ids": ["8c2b38b3-ae0a-478f-a9af-152052b3ffd8"], "operator": null, "metadata": {"aucs": [0.18924937138401732, 0.18351125102077115, 0.18600500742602044]}}
{"id": "1d7bf02e-b46c-4799-9462-7d97e1835557", "fitness": 0.1666829185261992, "name": "RefinedHybridPSOGWO", "description": "Introduce adaptive memory with chaotic initialization to diversify search paths and enhance convergence stability.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.memory = np.zeros((self.particles, self.dim))\n\n    def chaotic_initialization(self, lb, ub):\n        # Chaotic initialization using logistic map\n        x0 = np.random.rand(self.dim)\n        chaotic_sequence = np.empty((self.particles, self.dim))\n        for i in range(self.particles):\n            x0 = 4 * x0 * (1 - x0)\n            chaotic_sequence[i] = lb + (ub - lb) * x0\n        return chaotic_sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = self.chaotic_initialization(lb, ub)\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Adaptive memory update\n                self.memory[i] = 0.5 * self.memory[i] + 0.5 * personal_best[i]\n                if np.random.rand() < 0.1:  # occasionally replace with memory-induced diversity\n                    x[i] = np.clip(self.memory[i] + np.random.normal(0, 0.1, self.dim), lb, ub)", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16668 with standard deviation 0.01724.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.171723085142368, 0.18481589228184114, 0.14350977815438848]}}
{"id": "e761bed9-dfcc-4f01-89ed-78ef041590fc", "fitness": 0.1801005795057015, "name": "RefinedHybridPSOGWO", "description": "Enhance the balance of exploration and exploitation by introducing adaptive particle count and dynamic boundary scaling.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = min(30, budget // (2 * dim))  # adaptive particle count\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            boundary_scale = 1 + 0.5 * (1 - evaluations / self.budget)  # dynamic boundary scaling\n            scaled_lb, scaled_ub = lb * boundary_scale, ub * boundary_scale\n\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], scaled_lb, scaled_ub)  # apply dynamic boundary scaling\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, scaled_lb, scaled_ub)  # apply dynamic boundary scaling\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, scaled_lb, scaled_ub)  # apply dynamic boundary scaling\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18010 with standard deviation 0.00577.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.1874565914341506, 0.179470923190585, 0.1733742238923689]}}
{"id": "fa1a157a-bd8b-4fdf-95fa-453096768bd0", "fitness": 0.1830177385932479, "name": "RefinedHybridPSOGWO", "description": "Introduce a small variation in inertia weight calculation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.55 * (evaluations / self.budget)  # Modified line\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 43, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18302 with standard deviation 0.00338.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.1876755828106591, 0.17974624327495947, 0.18163138969412518]}}
{"id": "7cc992c4-661f-4ef2-af4f-f91798b00f7c", "fitness": 0.1861797669032018, "name": "RefinedHybridPSOGWO", "description": "Integrate a dynamic cooling schedule for stochastic tunneling to improve convergence speed.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost) * (1 - evaluations / self.budget)  # Applying dynamic cooling schedule\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 44, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18618 with standard deviation 0.00235.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.18934944961917877, 0.1837411595435261, 0.18544869154690047]}}
{"id": "6e268dba-3cea-4e92-9c0c-a4f3a3970c00", "fitness": 0.18600216315250664, "name": "RefinedHybridPSOGWO", "description": "Introducing adaptive vortex intensity to improve exploration in the optimization process.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with adaptive stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost) * (1 + evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18600 with standard deviation 0.00256.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.18900476195598193, 0.18273980988112182, 0.18626191762041622]}}
{"id": "cfbf0e4e-f00a-480a-8f44-cbf5c47377d2", "fitness": 0.18322656337286547, "name": "RefinedHybridPSOGWO", "description": "Enhance vortex search by scaling vortex_vector intensity using a decay function to improve convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                decay_factor = np.exp(-5 * (evaluations / self.budget))\n                intensity = np.exp(-candidate_cost + self.best_cost) * decay_factor\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 46, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18323 with standard deviation 0.00533.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.18921707311077018, 0.18419287976947518, 0.17626973723835104]}}
{"id": "ecad93bb-156f-4617-84e9-d0aada1b5667", "fitness": 0.15658486996325174, "name": "EnhancedHybridPSOGWO", "description": "Enhance exploration with Levy flights and exploitation with adaptive swarm coherence to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * L\n        v = np.random.normal(0, 1, self.dim)\n        return u / (np.abs(v) ** (1 / self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Levy Flight Integration\n                if np.random.rand() < 0.3:\n                    L = 0.01 # Levy scaling parameter\n                    levy_step = self.levy_flight(L)\n                    lf_solution = x[i] + levy_step\n                    lf_solution = np.clip(lf_solution, lb, ub)\n                    lf_cost = func(lf_solution)\n                    evaluations += 1\n\n                    if lf_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = lf_cost\n                        personal_best[i] = lf_solution.copy()\n                    if lf_cost < self.best_cost:\n                        self.best_cost = lf_cost\n                        self.best_solution = lf_solution.copy()", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15658 with standard deviation 0.01632.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.15914202967286162, 0.13543992211889166, 0.17517265809800198]}}
{"id": "e9fe0fb4-f6e7-4cab-84b5-b75401353e00", "fitness": 0.16898893140028828, "name": "RefinedHybridPSOGWO", "description": "Introduce a non-uniform mutation strategy in vortex search enhancement to prevent premature convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling and non-uniform mutation\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                mutation_strength = np.random.uniform(0.5, 1.5)  # Non-uniform mutation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget) * mutation_strength\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 48, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16899 with standard deviation 0.00276.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.16840334947314872, 0.1659353044217664, 0.17262814030594975]}}
{"id": "7eaeb753-0d7f-4ecc-bd2a-efa3aaa43240", "fitness": 0.15876189477712144, "name": "EnhancedHybridPSOGWO", "description": "Integrate adaptive mutation and chaotic maps to enhance diversity and convergence in hybrid PSOGWO.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n                \n                # Adaptive mutation and chaotic map integration\n                chaos_factor = np.sin(np.pi * evaluations / self.budget)\n                mutation_vector = np.random.normal(0, 1, self.dim) * chaos_factor\n                mutated_solution = candidate_solution + mutation_vector\n                mutated_solution = np.clip(mutated_solution, lb, ub)\n                mutated_cost = func(mutated_solution)\n                evaluations += 1\n\n                if mutated_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = mutated_cost\n                    personal_best[i] = mutated_solution.copy()\n                if mutated_cost < self.best_cost:\n                    self.best_cost = mutated_cost\n                    self.best_solution = mutated_solution.copy()", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15876 with standard deviation 0.00324.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.1568689089374068, 0.15609628380566298, 0.16332049158829454]}}
{"id": "c960d732-8f0b-4ebe-ab5f-37be2b86c694", "fitness": 0.15726445590587187, "name": "EnhancedHybridPSOGWO", "description": "Introduce adaptive mutation and differential evolution to enhance swarm diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution component for mutation\n                if evaluations < self.budget:\n                    idxs = [idx for idx in range(self.particles) if idx != i]\n                    a, b, c = personal_best[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15726 with standard deviation 0.01858.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.13235833709730294, 0.16246159323759302, 0.17697343738271964]}}
{"id": "e7439c1d-7e22-48ad-81bc-07c1ded667ad", "fitness": 0.17571689645474176, "name": "EnhancedHybridPSOGWO", "description": "Integrate levy flights and adaptive mutation to further enhance exploration capabilities and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def levy_flight(self, Lambda):\n        sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                 (np.math.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / Lambda)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Levy flights and adaptive mutation\n                if np.random.rand() < 0.5:\n                    step_size = self.levy_flight(1.5)\n                    levy_solution = x[i] + step_size * (x[i] - personal_best[i])\n                    levy_solution = np.clip(levy_solution, lb, ub)\n                    levy_cost = func(levy_solution)\n                    evaluations += 1\n\n                    if levy_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = levy_cost\n                        personal_best[i] = levy_solution.copy()\n                    if levy_cost < self.best_cost:\n                        self.best_cost = levy_cost\n                        self.best_solution = levy_solution.copy()", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17572 with standard deviation 0.01495.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.15495965096256914, 0.18259583468986862, 0.1895952037117875]}}
{"id": "3cc9f15b-f1f7-4f98-a3b4-f133950809b6", "fitness": 0.16876725421495864, "name": "RefinedHybridPSOGWO", "description": "Enhance diversity by introducing Gaussian perturbations in candidate solutions to improve the exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                # Introduce Gaussian perturbations to candidate solution\n                candidate_solution += np.random.normal(0, 0.1, self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-candidate_cost + self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 52, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16877 with standard deviation 0.00237.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.1716221961270733, 0.16885785891113203, 0.1658217076066706]}}
{"id": "c655db91-1a38-47c9-bbba-db5eb10cd524", "fitness": 0.15567237302480882, "name": "EnhancedHybridPSOGWOVoronoi", "description": "Enhance exploration-exploitation balance using adaptive hybridization of PSO, GWO, and Voronoi decomposition.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWOVoronoi:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = 0.5 * (personal_best[i] + x[i])\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Voronoi Decomposition for exploration\n                voronoi_centers = np.random.uniform(lb, ub, (5, self.dim))\n                for center in voronoi_centers:\n                    voronoi_point = x[i] + np.random.normal(0, 1, self.dim) * (center - x[i])\n                    voronoi_point = np.clip(voronoi_point, lb, ub)\n                    voronoi_cost = func(voronoi_point)\n                    evaluations += 1\n\n                    if voronoi_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = voronoi_cost\n                        personal_best[i] = voronoi_point.copy()\n                    if voronoi_cost < self.best_cost:\n                        self.best_cost = voronoi_cost\n                        self.best_solution = voronoi_point.copy()", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridPSOGWOVoronoi got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15567 with standard deviation 0.01476.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.13740542294285374, 0.173553566362732, 0.1560581297688407]}}
{"id": "a37b2428-70db-4a64-a00c-f1bb952933d5", "fitness": 0.18632134524275054, "name": "RefinedHybridPSOGWO", "description": "Enhance stochastic tunneling by adjusting the intensity factor and modifying personal best update strategy for better convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 54, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18632 with standard deviation 0.00252.", "error": "", "parent_ids": ["718118d4-c40c-4b4c-ba06-cc27e1ceac7b"], "operator": null, "metadata": {"aucs": [0.18963449876725946, 0.18351420436188315, 0.18581533259910898]}}
{"id": "83b1d2a8-1dda-4eec-b5ab-f04bd040688e", "fitness": 0.18505034170125886, "name": "RefinedHybridPSOGWOPlus", "description": "Integrate adaptive particle clustering and phase-shifted vortex intensification to enhance convergence for diverse black box optimization problems.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWOPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive particle clustering and phase-shifted vortex intensification\n                cluster_intensity = np.exp(-2 * np.abs(candidate_cost - np.median(personal_best_cost)))\n                vortex_vector = np.random.normal(0, 1, self.dim) * cluster_intensity\n                vortex_phase_shift = np.sin(2 * np.pi * evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * vortex_phase_shift\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 55, "feedback": "The algorithm RefinedHybridPSOGWOPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18505 with standard deviation 0.00227.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.1880473725262376, 0.18257213992455312, 0.18453151265298584]}}
{"id": "31c70761-328a-4ce2-99b6-a458a4d288dc", "fitness": 0.18630141886395044, "name": "RefinedHybridPSOGWO", "description": "Fine-tune the intensity calculation in the vortex search enhancement for better convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-1.8 * (candidate_cost - self.best_cost))  # Fine-tuned intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 56, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18630 with standard deviation 0.00252.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18960448858303613, 0.1834787466711345, 0.18582102133768064]}}
{"id": "7e2ac155-8d0a-44f6-8f6b-7e061e4f0253", "fitness": 0.1860303471106449, "name": "RefinedHybridPSOGWO", "description": "Adjust the vortex search enhancement to use a dynamic scaling factor for improved exploration.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 57, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18603 with standard deviation 0.00287.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18961000811949535, 0.182584356233491, 0.1858966769789483]}}
{"id": "16422949-7c97-4e93-b465-e6e21b3ab667", "fitness": 0.18629472452760953, "name": "RefinedHybridPSOGWO", "description": "Refine the vortex search enhancement by adjusting the stochastic tunneling's intensity calculation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-1.5 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 58, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18629 with standard deviation 0.00251.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18956932328839704, 0.18347796793910331, 0.18583688235532825]}}
{"id": "cc8b7c5a-6229-4a94-9515-3a6b778ed1bd", "fitness": 0.18620102120743173, "name": "RefinedHybridPSOGWO", "description": "Introduce a dynamic adjustment of the vortex search enhancement intensity factor for improved convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic intensity adjustment\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                dynamic_intensity = np.exp(-2 * (candidate_cost - self.best_cost) * (evaluations / self.budget))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * dynamic_intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 59, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18620 with standard deviation 0.00240.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.1892364003719923, 0.18337071711529085, 0.18599594613501202]}}
{"id": "5b6a2e35-b358-4cf2-ad9e-16dfe154b86d", "fitness": 0.18306237869067113, "name": "RefinedHybridPSOGWO", "description": "Introduce a dynamic adjustment to the vortex vector's intensity to improve the exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - evaluations / self.budget)  # Dynamic intensity adjustment\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18306 with standard deviation 0.00540.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18932421051581516, 0.1837273222066208, 0.17613560334957745]}}
{"id": "70405c3d-64c6-497b-97c2-f879caf1a2b4", "fitness": 0.18615681174692142, "name": "AdaptiveRefinedHybridPSOGWO", "description": "Introduce adaptive population sizing and dynamic parameter tuning to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveRefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_particles = 30\n        self.particles = self.initial_particles\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n            # Adaptive population sizing\n            if evaluations < self.budget * 0.5:\n                self.particles = self.initial_particles\n            else:\n                self.particles = max(10, int(self.initial_particles / 2))\n\n            # Resample individuals if the population size changes\n            if self.particles < len(x):\n                indices = np.argsort(personal_best_cost)\n                x = x[indices[:self.particles]]\n                v = v[indices[:self.particles]]\n                personal_best = personal_best[indices[:self.particles]]\n                personal_best_cost = personal_best_cost[indices[:self.particles]]", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveRefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18616 with standard deviation 0.00183.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18872724842180566, 0.18464971857993218, 0.1850934682390264]}}
{"id": "86d2a93b-c976-4099-887c-3ac3aa9236f5", "fitness": 0.17364252140138536, "name": "EnhancedChaosHybridPSOGWO", "description": "Integrate adaptive leader selection and dynamic parameter control with a chaos-enhanced search mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedChaosHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n        evaluations = 0\n\n        def chaotic_map(value):\n            return 4 * value * (1 - value)\n\n        chaos = np.random.rand()\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))   \n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n            chaos = chaotic_map(chaos)\n            if evaluations < self.budget:\n                chaos_vector = np.random.normal(0, 1, self.dim) * chaos\n                chaos_solution = self.best_solution + chaos_vector\n                chaos_solution = np.clip(chaos_solution, lb, ub)\n                chaos_cost = func(chaos_solution)\n                evaluations += 1\n\n                if chaos_cost < self.best_cost:\n                    self.best_cost = chaos_cost\n                    self.best_solution = chaos_solution.copy()", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedChaosHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17364 with standard deviation 0.00723.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.16959580708324307, 0.16753987667361958, 0.18379188044729344]}}
{"id": "8caef352-d21d-4269-bb6d-1020d0433915", "fitness": 0.18171792899784764, "name": "RefinedHybridPSOGWO", "description": "Slightly refine the vortex search by adjusting the intensity factor to improve convergence speed.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-3 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (1 - evaluations / self.budget)  # Adjusted scaling factor\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 63, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18172 with standard deviation 0.00302.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18142438085716617, 0.18555819836172704, 0.17817120777464968]}}
{"id": "726f2341-4043-4294-8859-487d82b19c1b", "fitness": 0.18448513335208508, "name": "RefinedHybridPSOGWO", "description": "Adjust the vortex vector to enhance exploration capabilities and improve convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 2, self.dim)  # Adjusted vortex vector\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 64, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18449 with standard deviation 0.00275.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18833341645373536, 0.1830252387306044, 0.18209674487191552]}}
{"id": "2d3c5328-b33b-4d53-a788-12c4b78b7e19", "fitness": 0.16385719644557648, "name": "EnhancedRefinedHybridPSOGWO", "description": "Introduce dynamic vortex intensity and adaptive mutation for enhanced exploration and exploitation balance in the optimization process.", "code": "import numpy as np\n\nclass EnhancedRefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic intensity and adaptive mutation\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity_factor = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * intensity_factor\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Introduce adaptive mutation for diversity\n                if np.random.rand() < 0.1:  # Mutation probability\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    mutated_solution = x[i] + mutation_vector\n                    mutated_solution = np.clip(mutated_solution, lb, ub)\n                    mutated_cost = func(mutated_solution)\n                    evaluations += 1\n\n                    if mutated_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutated_cost\n                        personal_best[i] = mutated_solution.copy()\n                    if mutated_cost < self.best_cost:\n                        self.best_cost = mutated_cost\n                        self.best_solution = mutated_solution.copy()", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedRefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16386 with standard deviation 0.00705.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.15485306230426887, 0.16466516858835112, 0.1720533584441094]}}
{"id": "d74bf126-5ee4-4ab2-a4c0-c07cda9b2b3e", "fitness": 0.1832007470777894, "name": "RefinedHybridPSOGWO", "description": "Enhance convergence by modifying inertia weight decay and updating the vortex vector computation.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.75 * (evaluations / self.budget)  # Modified decay\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 0.5, self.dim)  # Modified standard deviation for vortex vector\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 66, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18320 with standard deviation 0.00429.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18921122895680664, 0.1809189926320124, 0.17947201964454917]}}
{"id": "24f62235-8fe0-4aa5-aaa9-6947b7042209", "fitness": 0.1863080273949008, "name": "RefinedHybridPSOGWO", "description": "Tune the vortex search enhancement by modifying the intensity factor calculation for improved convergence.", "code": "import numpy as np\n\nclass RefinedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n                \n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Grey Wolf Optimization component\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n                \n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n                \n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n                \n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-0.5 * (candidate_cost - self.best_cost))  # Adjusted intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 67, "feedback": "The algorithm RefinedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18631 with standard deviation 0.00222.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.18916058305907157, 0.1837453268173862, 0.18601817230824458]}}
{"id": "99c804a2-7cfb-4ee2-b9c2-3abfca765b3e", "fitness": 0.17811324325377023, "name": "EnhancedHybridPSOGWO", "description": "Introduce a dynamic leadership hierarchy and adaptive parameter control in Refined Hybrid PSOGWO for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_init = 0.9\n        self.w_end = 0.4\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.adaptive_factor = 0.5\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                w = self.w_init - (self.w_init - self.w_end) * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * self.adaptive_factor\n                c2 = self.c2_init * (evaluations / self.budget) * self.adaptive_factor\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leadership hierarchy for GWO\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Enhanced vortex search\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - evaluations / self.budget)  # Enhanced intensity calculation\n                vortex_solution = x[i] + vortex_vector * intensity\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17811 with standard deviation 0.00255.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.17451251301759807, 0.179935410059896, 0.17989180668381666]}}
{"id": "f6fdaa90-5f0c-4ce1-a25e-7264f7904f63", "fitness": 0.19385477070637205, "name": "EnhancedDynamicPSOGWO", "description": "Introduce a dynamic leader selection and synergistic exploration-exploitation balance to enhance convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19385 with standard deviation 0.00601.", "error": "", "parent_ids": ["a37b2428-70db-4a64-a00c-f1bb952933d5"], "operator": null, "metadata": {"aucs": [0.1853511962326766, 0.19817056485435125, 0.19804255103208834]}}
{"id": "83eb474c-d3e7-40f4-9540-4ada963aaa83", "fitness": 0.19385477070637205, "name": "EnhancedDynamicPSOGWO", "description": "Introduce a dynamic particle count to adapt exploration-exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = max(30, int(budget / 100))  # dynamic particle count\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19385 with standard deviation 0.00601.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.1853511962326766, 0.19817056485435125, 0.19804255103208834]}}
{"id": "1285b337-6a7a-477f-ad7c-61c1f963e3fe", "fitness": 0.19364971911783724, "name": "EnhancedDynamicPSOGWO", "description": "Introduce a dynamic adjustment of the vortex search intensity based on current evaluation ratio for enhanced search capabilities in black box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with dynamic adjustment of intensity\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - evaluations / self.budget)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19365 with standard deviation 0.00632.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.18471455648087487, 0.198274889476879, 0.19795971139575785]}}
{"id": "59015266-1434-4cc9-aa31-385c662735e2", "fitness": 0.19276432087146703, "name": "EnhancedDynamicPSOGWO", "description": "Implement a minor adaptive adjustment to the social coefficient to enhance late-stage convergence in the optimization process.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget + 0.05)  # Changed line\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19276 with standard deviation 0.00286.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.19515798514675287, 0.1943930197664595, 0.18874195770118873]}}
{"id": "b8dd608e-e7be-40f4-a01b-651807cb6479", "fitness": 0.1900190816724792, "name": "EnhancedVortexDynamicPSOGWO", "description": "Introduce adaptive weighted vortex tunneling and dynamic role adaptation for enhanced exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass EnhancedVortexDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on adaptive roles\n                if evaluations < self.budget / 3:\n                    leader = self.alpha  # exploration phase\n                elif evaluations < 2 * self.budget / 3:\n                    leader = self.beta\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive weighted vortex search enhancement\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-0.1 * (candidate_cost - self.best_cost))\n                adaptive_weight = 1 + evaluations / self.budget\n                vortex_solution = x[i] + vortex_vector * intensity * adaptive_weight\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedVortexDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19002 with standard deviation 0.00461.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.1836624222168306, 0.19446840341938343, 0.19192641938122357]}}
{"id": "972d0516-4628-497e-bb03-46565536621b", "fitness": 0.19332133298622237, "name": "EnhancedDynamicPSOGWO", "description": "Enhance convergence by incorporating adaptive vortex intensity scaling.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with adaptive intensity scaling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost) / self.best_cost)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19332 with standard deviation 0.00595.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.18494906168260727, 0.19822134157890436, 0.1967935956971555]}}
{"id": "98002f3f-db97-4a34-892f-29a02afb3da3", "fitness": 0.1885985496118809, "name": "AdaptiveMemoryPSOGWO", "description": "Integrate adaptive memory-based random walks and dynamic parameter tuning to enhance convergence and exploration in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveMemoryPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_init = 0.9\n        self.w_min = 0.4\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.memory_size = 5\n        self.memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            self.memory.append(self.alpha)\n            if len(self.memory) > self.memory_size:\n                self.memory.pop(0)\n\n            for i in range(self.particles):\n                w = self.w_min + (self.w_init - self.w_min) * (1 - evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                leader = self.best_solution if evaluations >= self.budget / 2 else self.alpha\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                if np.random.rand() < 0.1:\n                    memory_leader = self.memory[np.random.randint(len(self.memory))]\n                    random_walk = np.random.uniform(-1, 1, self.dim)\n                    walk_solution = np.clip(memory_leader + random_walk, lb, ub)\n                    walk_cost = func(walk_solution)\n                    evaluations += 1\n\n                    if walk_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = walk_cost\n                        personal_best[i] = walk_solution.copy()\n                    if walk_cost < self.best_cost:\n                        self.best_cost = walk_cost\n                        self.best_solution = walk_solution.copy()", "configspace": "", "generation": 75, "feedback": "The algorithm AdaptiveMemoryPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18860 with standard deviation 0.00454.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.18329392592368654, 0.18811468251372276, 0.1943870403982334]}}
{"id": "d72d8553-4dd3-412f-b4a4-f374dc3aa284", "fitness": 0.19340825510936185, "name": "RefinedDynamicPSOGWO", "description": "Introduce multi-leader synergy and adaptive learning rates to refine convergence in black box optimization.", "code": "import numpy as np\n\nclass RefinedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.65 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Multi-leader synergy for enhanced guidance\n                leader_ratio = evaluations / self.budget\n                if leader_ratio < 0.33:\n                    leader = self.alpha\n                elif leader_ratio < 0.66:\n                    leader = (self.alpha + self.beta) / 2\n                else:\n                    leader = (self.alpha + self.beta + self.delta) / 3\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 76, "feedback": "The algorithm RefinedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19341 with standard deviation 0.00709.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.18337656689979387, 0.19840299468343148, 0.1984452037448602]}}
{"id": "b5439c89-9542-46ff-90d6-1bbdfcd56183", "fitness": 0.19463728598397326, "name": "EnhancedDynamicPSOGWO", "description": "Enhanced exploration by altering the inertia weight's decay rate for better convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted decay rate\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19464 with standard deviation 0.00523.", "error": "", "parent_ids": ["f6fdaa90-5f0c-4ce1-a25e-7264f7904f63"], "operator": null, "metadata": {"aucs": [0.18724680554254247, 0.1981576092194396, 0.19850744318993774]}}
{"id": "2aa26627-368a-4fe8-b2ab-5246cf1fb042", "fitness": 0.18298285634373967, "name": "EnhancedGeneticDynamicPSOGWO", "description": "Incorporating adaptive crossover and mutation operators inspired by Genetic Algorithms to enhance diversity and convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedGeneticDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                crossover_prob = 0.8 * (1 - evaluations / self.budget)\n                if np.random.rand() < crossover_prob:\n                    random_partner = personal_best[np.random.randint(self.particles)]\n                    crossover_point = np.random.randint(1, self.dim)\n                    new_solution = np.concatenate((x[i][:crossover_point], random_partner[crossover_point:]))\n                    new_solution = np.clip(new_solution, lb, ub)\n                    new_cost = func(new_solution)\n                    evaluations += 1\n\n                    if new_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = new_cost\n                        personal_best[i] = new_solution.copy()\n                    if new_cost < self.best_cost:\n                        self.best_cost = new_cost\n                        self.best_solution = new_solution.copy()\n\n                mutation_prob = 0.1 * (1 - evaluations / self.budget)\n                if np.random.rand() < mutation_prob:\n                    mutation_vector = np.random.normal(0, 1, self.dim)\n                    mutated_solution = x[i] + mutation_vector * (ub - lb) * 0.1\n                    mutated_solution = np.clip(mutated_solution, lb, ub)\n                    mutated_cost = func(mutated_solution)\n                    evaluations += 1\n\n                    if mutated_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutated_cost\n                        personal_best[i] = mutated_solution.copy()\n                    if mutated_cost < self.best_cost:\n                        self.best_cost = mutated_cost\n                        self.best_solution = mutated_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedGeneticDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18298 with standard deviation 0.00784.", "error": "", "parent_ids": ["b5439c89-9542-46ff-90d6-1bbdfcd56183"], "operator": null, "metadata": {"aucs": [0.1740508968097162, 0.18175392837372428, 0.19314374384777855]}}
{"id": "bb4b8e98-edca-441d-9196-607423b9c762", "fitness": 0.18541305976745895, "name": "EnhancedDynamicPSOGWO", "description": "Refined hybrid PSOGWO with adaptive vortex intensity and enhanced leader selection for improved convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted decay rate\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Enhanced dynamic leader selection based on fitness proportion\n                leader = self.alpha if np.random.rand() < 0.5 else self.beta\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive vortex search enhancement with intensity scaling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-3 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (1 - evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18541 with standard deviation 0.00664.", "error": "", "parent_ids": ["b5439c89-9542-46ff-90d6-1bbdfcd56183"], "operator": null, "metadata": {"aucs": [0.19466817240162315, 0.18215010464755, 0.17942090225320373]}}
{"id": "dfe099f8-d7db-4587-b7e9-2a326e974274", "fitness": 0.19839608391953745, "name": "EnhancedDynamicPSOGWO", "description": "Introduced adaptive social and cognitive coefficients based on function evaluations to refine convergence.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)  # Adjusted decay rate\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5  # Change made here for adaptive cognitive coefficient\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Dynamic leader selection based on the current phase\n                if evaluations < self.budget / 2:\n                    leader = self.alpha  # exploration phase\n                else:\n                    leader = self.best_solution  # exploitation phase\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex search enhancement with stochastic tunneling\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedDynamicPSOGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19840 with standard deviation 0.00426.", "error": "", "parent_ids": ["b5439c89-9542-46ff-90d6-1bbdfcd56183"], "operator": null, "metadata": {"aucs": [0.19238917137623357, 0.20180811043825442, 0.20099096994412435]}}
{"id": "6a8013a0-cf62-460b-aace-272be17c250f", "fitness": 0.19897161339895686, "name": "EnhancedDynamicPSOGWODE", "description": "Enhance convergence by integrating a differential evolution-inspired mutation operator with adaptive parameter tuning based on evaluations.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19897 with standard deviation 0.00272.", "error": "", "parent_ids": ["dfe099f8-d7db-4587-b7e9-2a326e974274"], "operator": null, "metadata": {"aucs": [0.19514197146637746, 0.2005867323833268, 0.2011861363471663]}}
{"id": "89e6ac06-dcf7-46e1-9826-2efc8eca0a25", "fitness": 0.18877604350985214, "name": "EnhancedAdaptivePSOGWODE", "description": "Introduce adaptive learning rates and enhanced exploration by dynamically balancing exploration-exploitation trade-offs with self-adapting strategies based on convergence trends.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_init = 0.9\n        self.w_min = 0.4\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            alpha = personal_best[sorted_indices[0]]\n            beta = personal_best[sorted_indices[1]]\n            delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                progress_ratio = evaluations / self.budget\n                self.w = self.w_init - (self.w_init - self.w_min) * progress_ratio\n                c1 = self.c1_init * (1 - progress_ratio)\n                c2 = self.c2_init * progress_ratio\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 3:\n                    leader = alpha\n                elif evaluations < 2 * self.budget / 3:\n                    leader = beta\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * beta - x[i])\n                D_delta = np.abs(C3 * delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = beta - A2 * D_beta\n                X3 = delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * progress_ratio\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * progress_ratio\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptivePSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18878 with standard deviation 0.00730.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.17855853050534443, 0.19262923495213358, 0.19514036507207844]}}
{"id": "1e5a3ba8-1b2f-4742-ac2a-f5e519ab8554", "fitness": -Infinity, "name": "EnhancedDynamicPSOGWODE", "description": "Integrate a chaos-based initialization strategy and enhanced exploration with Levy flights to improve convergence and maintain diversity in solution space.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def chaos_init(self, lb, ub):\n        # Chaos-based initialization with logistic map\n        r = 3.9  # Chaotic parameter\n        x0 = np.random.rand(self.particles, self.dim)\n        x = lb + (ub - lb) * (r * x0 * (1 - x0))\n        return x\n\n    def levy_flight(self, x, lb, ub, beta=1.5):\n        # Levy flight random distribution\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / beta)\n        return np.clip(x + step, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = self.chaos_init(lb, ub)\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Enhanced exploration with Levy flights\n                if np.random.rand() < 0.1:\n                    levy_solution = self.levy_flight(x[i], lb, ub)\n                    levy_cost = func(levy_solution)\n                    evaluations += 1\n\n                    if levy_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = levy_cost\n                        personal_best[i] = levy_solution.copy()\n                    if levy_cost < self.best_cost:\n                        self.best_cost = levy_cost\n                        self.best_solution = levy_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 83, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {}}
{"id": "d93bb069-5f82-4633-9380-3b818b5618a6", "fitness": 0.18953744151945326, "name": "EnhancedDynamicPSOGWODE", "description": "Adjust the mutation scaling factor to amplify diversity and exploration capability.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.8 + 0.5 * (evaluations / self.budget)  # Changed scaling factor from 0.5 to 0.8\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18954 with standard deviation 0.00752.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.17974233332556977, 0.19085871714280078, 0.1980112740899892]}}
{"id": "4154d582-154a-47a0-91e2-c760783e151e", "fitness": 0.1975363841058204, "name": "EnhancedDynamicPSOGWODE", "description": "Slightly tweak the inertia weight calculation for improved convergence stability.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.6 * (evaluations / self.budget)  # Changed from 0.7 to 0.6\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19754 with standard deviation 0.00229.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.1943150785856299, 0.19882740423725986, 0.19946666949457137]}}
{"id": "47eebc65-10e5-4852-bc02-fa85f8931224", "fitness": 0.18882617554710693, "name": "EnhancedDynamicPSOGWODE_v2", "description": "Introduce a dynamic retreat mechanism to adaptively adjust particle exploration based on performance, combined with a layered differential evolution strategy for enhanced global search performance.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n        self.retreat_factor = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget * 0.4:\n                    leader = self.alpha\n                elif evaluations < self.budget * 0.8:\n                    leader = self.beta\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] - self.retreat_factor * vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Layered Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant_a = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant_b = mutant_a + F * (self.best_solution - mutant_a)\n                    mutant = np.clip(mutant_b, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedDynamicPSOGWODE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18883 with standard deviation 0.01175.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.1722518705667102, 0.19610902742912195, 0.19811762864548865]}}
{"id": "6f21b24b-450d-4e6f-8822-c8d97a01b0b1", "fitness": 0.19040028810685036, "name": "RefinedDynamicPSOGWODE", "description": "Integrate an adaptive vortex search mechanism and region-specific mutation strategy to enhance convergence and solution diversity.", "code": "import numpy as np\n\nclass RefinedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-0.5 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (1 - evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Adaptive DE-inspired mutation\n                if np.random.rand() < 0.7:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.3 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 87, "feedback": "The algorithm RefinedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19040 with standard deviation 0.00520.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.18570629036819564, 0.187848665026899, 0.19764590892545641]}}
{"id": "4b425a2b-bc64-4f0b-bf63-b851c7bf2353", "fitness": 0.1873272135084304, "name": "EnhancedDynamicPSOGWODE", "description": "Enhance convergence by incorporating a self-adaptive mutation scale factor in the differential evolution-inspired mutation step.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget) * np.random.rand()  # Changed line\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18733 with standard deviation 0.00907.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.19575570761713323, 0.19148427677233804, 0.17474165613581993]}}
{"id": "69de11d1-eb61-4e5c-943c-51cb1bf2dd68", "fitness": 0.19036525654693828, "name": "EnhancedDynamicPSOGWODEv2", "description": "Introduce a dynamic leader strategy based on fitness ranking and stochastic exploration to enhance convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            alpha = personal_best[sorted_indices[0]]\n            beta = personal_best[sorted_indices[1]]\n            delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if np.random.rand() < 0.5:\n                    leader = alpha\n                else:\n                    # Introduce stochastic exploration around beta and delta\n                    if np.random.rand() < 0.5:\n                        leader = beta\n                    else:\n                        leader = delta\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * beta - x[i])\n                D_delta = np.abs(C3 * delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = beta - A2 * D_beta\n                X3 = delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Introduce vortex strategy with randomness\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * np.random.rand()\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Refined differential evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = np.random.rand() * 0.5 + 0.5\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedDynamicPSOGWODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19037 with standard deviation 0.00392.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.19215923044245853, 0.1849297933988795, 0.19400674579947685]}}
{"id": "4b63bc69-0eff-4202-af19-d742059bfe3f", "fitness": 0.19808838565891942, "name": "EnhancedDynamicPSOGWODE", "description": "Improve convergence by incorporating a decay factor in the differential evolution-inspired mutation operator to adaptively reduce mutation strength.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget) * (1 - evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19809 with standard deviation 0.00400.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.1924257447403035, 0.20092430091210256, 0.20091511132435225]}}
{"id": "1c4b747d-4e1f-48e1-9a33-b4d1cf2c8df6", "fitness": 0.14390394442632803, "name": "LevyDynamicPSO", "description": "Integrate Levy flights and dynamic neighborhood adaptation to enhance exploration and exploitation in a Particle Swarm Optimization framework.", "code": "import numpy as np\n\nclass LevyDynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia weight\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def levy_flight(self, size):\n        # Implementing a simple Levy flight with beta = 1.5\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / (np.abs(v) ** (1 / beta))\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            # Update inertia weight adaptively\n            self.w = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)\n\n            # Determine neighborhood dynamically\n            for i in range(self.particles):\n                # Update coefficients\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i] \n                        + c1 * r1 * (personal_best[i] - x[i]) \n                        + c2 * r2 * (self.best_solution - x[i]))\n                \n                # Levy flight step\n                if np.random.rand() < 0.3:\n                    levy_step = self.levy_flight(self.dim)\n                    x[i] = x[i] + levy_step * (x[i] - self.best_solution)\n                else:\n                    x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                # Evaluate new position\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()", "configspace": "", "generation": 91, "feedback": "The algorithm LevyDynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14390 with standard deviation 0.01652.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.12511038919445128, 0.16531040226508753, 0.1412910418194453]}}
{"id": "c98d76ea-f4d8-4502-ad63-405bfc5c9463", "fitness": 0.16034275248595856, "name": "EnhancedDynamicPSOGWODEV2", "description": "Enhance convergence and exploration by introducing a dynamic inertia weight adjustment and hybrid mutation strategies combining particle swarm dynamics with vortex and differential evolution methods.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODEV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget)\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3) / 3\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Vortex Strategy\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedDynamicPSOGWODEV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16034 with standard deviation 0.00339.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.15661934507506792, 0.1595957616829906, 0.16481315069981717]}}
{"id": "8ba7078f-b6b9-4813-a5b6-0f418e3f790e", "fitness": 0.18923054087919408, "name": "EnhancedDynamicPSOGWODEPlus", "description": "Improve convergence by introducing adaptive swarm size and hybridizing with a crossover mechanism inspired by genetic algorithms.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = max(10, dim * 2)  # adaptive swarm size\n        self.w = 0.9\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = x[i].copy()\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()\n\n                # Genetic Algorithm-inspired crossover\n                if np.random.rand() < 0.3:\n                    idx1, idx2 = np.random.choice(self.particles, 2, replace=False)\n                    crossover_point = np.random.randint(1, self.dim - 1)\n                    offspring1 = np.concatenate((personal_best[idx1][:crossover_point], personal_best[idx2][crossover_point:]))\n                    offspring2 = np.concatenate((personal_best[idx2][:crossover_point], personal_best[idx1][crossover_point:]))\n                    \n                    for offspring in [offspring1, offspring2]:\n                        offspring = np.clip(offspring, lb, ub)\n                        offspring_cost = func(offspring)\n                        evaluations += 1\n\n                        if offspring_cost < self.best_cost:\n                            self.best_cost = offspring_cost\n                            self.best_solution = offspring.copy()", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedDynamicPSOGWODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18923 with standard deviation 0.00321.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.19048501852651267, 0.18482965793721362, 0.19237694617385592]}}
{"id": "aa5f5777-a799-4357-b24b-b3b7214f80da", "fitness": 0.16655818868541936, "name": "AdaptiveDimensionalEnhancedPSOGWODE", "description": "Introduce adaptive dimensional learning by dynamically adjusting particle exploration and exploitation balance based on variance in personal best solutions to enhance convergence and diversity.", "code": "import numpy as np\n\nclass AdaptiveDimensionalEnhancedPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # initial inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                dim_variance = np.var(personal_best, axis=0)\n                dim_weight = 1 / (1 + np.exp(-10 * (dim_variance - np.mean(dim_variance))))\n\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * dim_weight\n                c2 = self.c2_init * (evaluations / self.budget) * dim_weight\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * self.alpha - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = self.alpha - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                if np.random.rand() < 0.5:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 94, "feedback": "The algorithm AdaptiveDimensionalEnhancedPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16656 with standard deviation 0.01323.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.14881592656231113, 0.17028797475996604, 0.18057066473398087]}}
{"id": "1ec78a51-b448-4ead-9bca-f6b93875ce90", "fitness": 0.19935637804936288, "name": "EnhancedDynamicPSOGWODE", "description": "Enhance convergence by adjusting mutation probability based on evaluation progress.", "code": "import numpy as np\n\nclass EnhancedDynamicPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost))\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                # Differential Evolution-inspired mutation\n                mutation_probability = 0.5 + 0.1 * (evaluations / self.budget)\n                if np.random.rand() < mutation_probability:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedDynamicPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19936 with standard deviation 0.00474.", "error": "", "parent_ids": ["6a8013a0-cf62-460b-aace-272be17c250f"], "operator": null, "metadata": {"aucs": [0.19275803818602244, 0.20368008562221096, 0.2016310103398552]}}
{"id": "6caafac1-0c7f-44a6-99e9-b8b38a850ca7", "fitness": 0.19941462846466043, "name": "AdaptiveVortexPSOGWODE", "description": "Introduce an adaptive vortex intensity based on convergence rate to enhance exploration-exploitation balance in PSOGWODE.", "code": "import numpy as np\n\nclass AdaptiveVortexPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        prev_best_cost = float('inf')\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive Vortex Mechanism\n                convergence_rate = np.abs(self.best_cost - prev_best_cost) / (prev_best_cost + np.finfo(float).eps)\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - convergence_rate)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                prev_best_cost = self.best_cost\n\n                # Differential Evolution-inspired mutation\n                mutation_probability = 0.5 + 0.1 * (evaluations / self.budget)\n                if np.random.rand() < mutation_probability:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 96, "feedback": "The algorithm AdaptiveVortexPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19941 with standard deviation 0.00472.", "error": "", "parent_ids": ["1ec78a51-b448-4ead-9bca-f6b93875ce90"], "operator": null, "metadata": {"aucs": [0.19284147819169717, 0.2036903113645988, 0.20171209583768535]}}
{"id": "8996a91f-bacd-4d0b-a79a-cd7d556f61d7", "fitness": 0.19948424059423794, "name": "AdaptiveVortexPSOGWODE", "description": "Introduce a decay factor to the differential evolution-inspired mutation probability to improve exploration-exploitation transition.", "code": "import numpy as np\n\nclass AdaptiveVortexPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        prev_best_cost = float('inf')\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive Vortex Mechanism\n                convergence_rate = np.abs(self.best_cost - prev_best_cost) / (prev_best_cost + np.finfo(float).eps)\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - convergence_rate)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                prev_best_cost = self.best_cost\n\n                # Differential Evolution-inspired mutation\n                mutation_probability = max(0.5 + 0.1 * (evaluations / self.budget) - 0.05 * (evaluations / self.budget)**2, 0)\n                if np.random.rand() < mutation_probability:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveVortexPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19948 with standard deviation 0.00391.", "error": "", "parent_ids": ["6caafac1-0c7f-44a6-99e9-b8b38a850ca7"], "operator": null, "metadata": {"aucs": [0.1939688606556803, 0.202589761603593, 0.2018940995234405]}}
{"id": "f72df23b-b889-441a-8370-a5c35f916f6e", "fitness": 0.18436725532739007, "name": "AdaptiveVortexPSOGWODE", "description": "Enhance adaptive parameters by introducing quadratic decay for the cognitive coefficient and exponential decay for mutation probability to boost dynamic balance.", "code": "import numpy as np\n\nclass AdaptiveVortexPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        prev_best_cost = float('inf')\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - (evaluations / self.budget)**2)  # Quadratic decay\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive Vortex Mechanism\n                convergence_rate = np.abs(self.best_cost - prev_best_cost) / (prev_best_cost + np.finfo(float).eps)\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-2 * (candidate_cost - self.best_cost)) * (1 - convergence_rate)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                prev_best_cost = self.best_cost\n\n                # Differential Evolution-inspired mutation\n                mutation_probability = max(0.5 * np.exp(-(evaluations / self.budget)), 0)  # Exponential decay\n                if np.random.rand() < mutation_probability:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 98, "feedback": "The algorithm AdaptiveVortexPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18437 with standard deviation 0.01170.", "error": "", "parent_ids": ["8996a91f-bacd-4d0b-a79a-cd7d556f61d7"], "operator": null, "metadata": {"aucs": [0.1691722295907555, 0.18630281692409123, 0.19762671946732346]}}
{"id": "265fa778-0f8c-48b5-a811-9ddeefa522ce", "fitness": 0.1995015738649151, "name": "AdaptiveVortexPSOGWODE", "description": "Increase mutation intensity slightly during the early stages to enhance exploration.", "code": "import numpy as np\n\nclass AdaptiveVortexPSOGWODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = 30\n        self.w = 0.9  # adaptive inertia\n        self.c1_init = 2.0  # initial cognitive coefficient\n        self.c2_init = 2.0  # initial social coefficient\n        self.alpha, self.beta, self.delta = None, None, None\n        self.best_cost = float('inf')\n        self.best_solution = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        x = np.random.uniform(lb, ub, (self.particles, self.dim))\n        v = np.random.uniform(-1, 1, (self.particles, self.dim))\n        personal_best = x.copy()\n        personal_best_cost = np.array([float('inf')] * self.particles)\n\n        evaluations = 0\n        prev_best_cost = float('inf')\n\n        while evaluations < self.budget:\n            for i in range(self.particles):\n                if evaluations >= self.budget:\n                    break\n\n                cost = func(x[i])\n                evaluations += 1\n\n                if cost < personal_best_cost[i]:\n                    personal_best_cost[i] = cost\n                    personal_best[i] = (personal_best[i] + x[i]) / 2\n\n                if cost < self.best_cost:\n                    self.best_cost = cost\n                    self.best_solution = x[i].copy()\n\n            sorted_indices = np.argsort(personal_best_cost)\n            self.alpha = personal_best[sorted_indices[0]]\n            self.beta = personal_best[sorted_indices[1]]\n            self.delta = personal_best[sorted_indices[2]]\n\n            for i in range(self.particles):\n                self.w = 0.9 - 0.7 * (evaluations / self.budget)\n                c1 = self.c1_init * (1 - evaluations / self.budget) * 0.5\n                c2 = self.c2_init * (evaluations / self.budget)\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                v[i] = (self.w * v[i]\n                        + c1 * r1 * (personal_best[i] - x[i])\n                        + c2 * r2 * (self.best_solution - x[i]))\n                x[i] = np.clip(x[i] + v[i], lb, ub)\n\n                if evaluations < self.budget / 2:\n                    leader = self.alpha\n                else:\n                    leader = self.best_solution\n\n                A1, A2, A3 = 2 * np.random.rand(3, self.dim) - 1\n                C1, C2, C3 = 2 * np.random.rand(3, self.dim)\n\n                D_leader = np.abs(C1 * leader - x[i])\n                D_beta = np.abs(C2 * self.beta - x[i])\n                D_delta = np.abs(C3 * self.delta - x[i])\n\n                X1 = leader - A1 * D_leader\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                candidate_solution = (X1 + X2 + X3 + x[i]) / 4\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                candidate_cost = func(candidate_solution)\n                evaluations += 1\n\n                if candidate_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = candidate_cost\n                    personal_best[i] = candidate_solution.copy()\n                if candidate_cost < self.best_cost:\n                    self.best_cost = candidate_cost\n                    self.best_solution = candidate_solution.copy()\n\n                # Adaptive Vortex Mechanism\n                convergence_rate = np.abs(self.best_cost - prev_best_cost) / (prev_best_cost + np.finfo(float).eps)\n                vortex_vector = np.random.normal(0, 1, self.dim)\n                intensity = np.exp(-1.8 * (candidate_cost - self.best_cost)) * (1 - convergence_rate)\n                vortex_solution = x[i] + vortex_vector * intensity * (evaluations / self.budget)\n                vortex_solution = np.clip(vortex_solution, lb, ub)\n                vortex_cost = func(vortex_solution)\n                evaluations += 1\n\n                if vortex_cost < personal_best_cost[i]:\n                    personal_best_cost[i] = vortex_cost\n                    personal_best[i] = vortex_solution.copy()\n                if vortex_cost < self.best_cost:\n                    self.best_cost = vortex_cost\n                    self.best_solution = vortex_solution.copy()\n\n                prev_best_cost = self.best_cost\n\n                # Differential Evolution-inspired mutation\n                mutation_probability = max(0.5 + 0.1 * (evaluations / self.budget) - 0.05 * (evaluations / self.budget)**2, 0)\n                if np.random.rand() < mutation_probability:\n                    indices = np.arange(self.particles)\n                    np.random.shuffle(indices)\n                    idx1, idx2, idx3 = indices[:3]\n                    F = 0.5 + 0.5 * (evaluations / self.budget)\n                    mutant = personal_best[idx1] + F * (personal_best[idx2] - personal_best[idx3])\n                    mutant = np.clip(mutant, lb, ub)\n                    mutant_cost = func(mutant)\n                    evaluations += 1\n\n                    if mutant_cost < personal_best_cost[i]:\n                        personal_best_cost[i] = mutant_cost\n                        personal_best[i] = mutant.copy()\n                    if mutant_cost < self.best_cost:\n                        self.best_cost = mutant_cost\n                        self.best_solution = mutant.copy()", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveVortexPSOGWODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19950 with standard deviation 0.00389.", "error": "", "parent_ids": ["8996a91f-bacd-4d0b-a79a-cd7d556f61d7"], "operator": null, "metadata": {"aucs": [0.1940175638110202, 0.20258855784685315, 0.20189859993687198]}}
