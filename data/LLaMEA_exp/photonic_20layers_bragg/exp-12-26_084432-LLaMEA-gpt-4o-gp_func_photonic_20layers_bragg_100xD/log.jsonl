{"id": "23bb7d56-e933-4dcb-be19-9585bd9b16b4", "fitness": 0.09400765379236094, "name": "HybridPSODE", "description": "A hybrid swarm-based algorithm that combines Particle Swarm Optimization (PSO) with Differential Evolution (DE) for enhanced exploration and exploitation in the search space.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Differential Evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.11391999267275721, 0.11391999267275721, 0.11391999267275721, 0.07348216156850529, 0.07348216156850529, 0.07348216156850529, 0.09462080713582033, 0.09462080713582033, 0.09462080713582033]}}
{"id": "edc5e0dd-e388-414f-924d-fe15f37e9013", "fitness": 0.09400816039559723, "name": "HybridPSODE", "description": "A hybrid swarm-based algorithm that enhances particle position updating by modifying the inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.8  # Modified inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Differential Evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["23bb7d56-e933-4dcb-be19-9585bd9b16b4"], "operator": null, "metadata": {"aucs": [0.11392076483363323, 0.11392076483363323, 0.11392076483363323, 0.07348243706300661, 0.07348243706300661, 0.07348243706300661, 0.09462127929015185, 0.09462127929015185, 0.09462127929015185]}}
{"id": "e6e08f6a-2c7d-43df-917b-cd5db597b892", "fitness": 0.09400844465233187, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["edc5e0dd-e388-414f-924d-fe15f37e9013"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "8e1750cd-473d-4bd4-9134-0733d2b9c6f0", "fitness": 0.09400775073187029, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters for enhanced convergence and exploration-exploitation balance, with slightly increased cognitive component for improved individual learning.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.6  # Slightly increased cognitive component\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392014042283338, 0.11392014042283338, 0.11392014042283338, 0.07348221428758528, 0.07348221428758528, 0.07348221428758528, 0.0946208974851922, 0.0946208974851922, 0.0946208974851922]}}
{"id": "b1b4efcf-605c-4278-b7e1-5a3b9a288434", "fitness": 0.09400588538510457, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with enhanced adaptive inertia weight range for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.5  # Minimum inertia weight (changed from 0.4 to 0.5)\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391729735478728, 0.11391729735478728, 0.11391729735478728, 0.0734811998498085, 0.0734811998498085, 0.0734811998498085, 0.09461915895071793, 0.09461915895071793, 0.09461915895071793]}}
{"id": "34b2021f-7ffc-4196-bcb8-1dca28c4b3c6", "fitness": 0.0940041982592719, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm integrating adaptive inertia weight and dynamically adjusted DE parameters with an enhanced mutation strategy for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) * (np.random.rand() + 0.5), lower_bound, upper_bound)  # Enhanced mutation\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391472595443064, 0.11391472595443064, 0.11391472595443064, 0.07348028231478188, 0.07348028231478188, 0.07348028231478188, 0.09461758650860319, 0.09461758650860319, 0.09461758650860319]}}
{"id": "1881ccdf-6046-4be2-af03-6940adb6d8b7", "fitness": 0.09400472092653796, "name": "EnhancedHybridPSODE", "description": "Refined Hybrid PSO-DE with modified inertia weight schedule for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight (modified equation)\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * np.exp(-5 * evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391552254919612, 0.11391552254919612, 0.11391552254919612, 0.07348056657609048, 0.07348056657609048, 0.07348056657609048, 0.09461807365432728, 0.09461807365432728, 0.09461807365432728]}}
{"id": "15ce16d0-c9ba-49a1-a7d4-a92e9a93ce0f", "fitness": 0.09400380267108992, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with a refined adaptive inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.85 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391412299370107, 0.11391412299370107, 0.11391412299370107, 0.0734800671960445, 0.0734800671960445, 0.0734800671960445, 0.09461721782352417, 0.09461721782352417, 0.09461721782352417]}}
{"id": "91a9e09d-513f-4d75-acc3-241260f75661", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with adaptive inertia weight, dynamically adjusted DE parameters, and dynamic crossover probability for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "df791b94-5949-4b30-95d0-4a78b9108312", "fitness": 0.09400629057099912, "name": "AdvancedAdaptivePSODE", "description": "A novel adaptive hybrid PSO-DE algorithm enhancing convergence by introducing a fitness-based dynamic learning rate and rebalancing exploration-exploitation via adaptive DE parameters and adaptive mutation strategy.", "code": "import numpy as np\n\nclass AdvancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f_initial = 0.5\n        self.cr_initial = 0.9\n        self.learning_rate = 0.1  # Additional adaptive learning rate\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            fitness_variance = np.var(personal_best_scores)\n            adaptive_rate = 1 / (1 + np.exp(-fitness_variance))\n            \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * adaptive_rate * r1 * (personal_best_positions - positions) +\n                          self.social_component * adaptive_rate * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = self.f_initial + adaptive_rate * 0.3 * (evaluations / self.budget)\n            self.cr = self.cr_initial - adaptive_rate * 0.1 * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AdvancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392000737163688, 0.11392000737163688, 0.11392000737163688, 0.0734807624455368, 0.0734807624455368, 0.0734807624455368, 0.09461810189582365, 0.09461810189582365, 0.09461810189582365]}}
{"id": "50f62098-2ee1-426d-b8b6-8bec3f94a0b7", "fitness": 0.09400632226322585, "name": "RefinedEnhancedHybridPSODE", "description": "Integration of adaptive parameter control and cooperative search mechanisms to enhance exploration-exploitation balance and convergence speed in a hybrid PSO-DE framework.", "code": "import numpy as np\n\nclass RefinedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f_min = 0.4\n        self.f_max = 0.9\n        self.cr = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = self.f_min + (self.f_max - self.f_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391796327137971, 0.11391796327137971, 0.11391796327137971, 0.07348143740886515, 0.07348143740886515, 0.07348143740886515, 0.09461956610943267, 0.09461956610943267, 0.09461956610943267]}}
{"id": "7fb364c6-47b1-4320-bb93-40e1b83f5658", "fitness": 0.09400844465233187, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm with adaptive inertia weight, dynamically adjusted DE parameters, and improved initial global best estimation for enhanced convergence and exploration-exploitation balance. ", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "3e099a9d-b6f5-4f77-b9db-de36811614de", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "Improved exploration-exploitation balance through adaptive crossover probability adjustment in the DE mutation process.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive crossover rate\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "acb75e69-8106-4803-a1cb-c6657ed90afc", "fitness": 0.09400475612975234, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with an adaptive crossover probability that decreases over iterations for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 * (1 - evaluations / self.budget)  # Update crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391557618698467, 0.11391557618698467, 0.11391557618698467, 0.07348058573121141, 0.07348058573121141, 0.07348058573121141, 0.09461810647106095, 0.09461810647106095, 0.09461810647106095]}}
{"id": "1e2ecc41-b7de-42ea-a3a5-e06f300e3840", "fitness": 0.09400784697700008, "name": "EnhancedHybridPSODE", "description": "Enhancing global exploration by dynamically adjusting DE's crossover probability (cr) based on evaluations.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392028711809787, 0.11392028711809787, 0.11392028711809787, 0.07348226662694524, 0.07348226662694524, 0.07348226662694524, 0.09462098718595713, 0.09462098718595713, 0.09462098718595713]}}
{"id": "b1f5715a-7a38-4866-b7a3-3b45b890dd3d", "fitness": 0.09400652403838956, "name": "EnhancedHybridPSODE", "description": "A refined hybrid swarm algorithm with a modified cognitive component for enhanced local exploration in high-dimensional spaces.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.7  # Adjusted for better local exploration\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391827072906013, 0.11391827072906013, 0.11391827072906013, 0.07348154718847, 0.07348154718847, 0.07348154718847, 0.09461975419763857, 0.09461975419763857, 0.09461975419763857]}}
{"id": "243f1214-601a-4418-992b-5d0c1cfd83fd", "fitness": 0.09400775073187029, "name": "EnhancedHybridPSODE", "description": "A hybrid swarm-type algorithm that integrates adaptive inertia weight and dynamically adjusted DE parameters with a slightly enhanced cognitive component for improved swarm intelligence and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.6  # Slightly increased cognitive component\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392014042283338, 0.11392014042283338, 0.11392014042283338, 0.07348221428758528, 0.07348221428758528, 0.07348221428758528, 0.0946208974851922, 0.0946208974851922, 0.0946208974851922]}}
{"id": "79b77ae8-4733-49e3-b3b1-f2e69b2e7304", "fitness": 0.09400816379729597, "name": "EnhancedHybridPSODE", "description": "Introduced an adaptive crossover probability in the DE phase based on evaluations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392077001138268, 0.11392077001138268, 0.11392077001138268, 0.0734824389172184, 0.0734824389172184, 0.0734824389172184, 0.09462128246328683, 0.09462128246328683, 0.09462128246328683]}}
{"id": "bc3ceee2-e89d-42cd-8a5f-08cc41bffe1c", "fitness": 0.09400726448371104, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive cognitive component for improved personal best updates.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive_component = 1.5 + 0.5 * (evaluations / self.budget)  # Adaptive cognitive component\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.1139193992880887, 0.1139193992880887, 0.1139193992880887, 0.07348194986162593, 0.07348194986162593, 0.07348194986162593, 0.09462044430141847, 0.09462044430141847, 0.09462044430141847]}}
{"id": "602241d4-ea2c-448c-9670-a382fcbe7b23", "fitness": 0.09400844465233187, "name": "ImprovedHybridSwarm", "description": "An improved hybrid swarm algorithm using adaptive learning rates and dynamic population size for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass ImprovedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_population_size = self.population_size\n        self.inertia_weight_max = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Dynamic population size adjustment\n            self.population_size = int(self.initial_population_size * (1 + 0.5 * (evaluations / self.budget)))\n            self.population_size = min(self.population_size, len(scores))  # Ensure it doesn't exceed evaluated count\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm ImprovedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392119807884271, 0.11392119807884271, 0.11392119807884271, 0.07348259165416815, 0.07348259165416815, 0.07348259165416815, 0.09462154422398472, 0.09462154422398472, 0.09462154422398472]}}
{"id": "ab6449b1-a88c-4894-b91e-0b638513ad02", "fitness": 0.0940043927591353, "name": "EnhancedHybridPSODE", "description": "A hybrid algorithm with refined DE scaling factor for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.2 * (evaluations / self.budget)  # Adjusted DE scaling factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391502238701379, 0.11391502238701379, 0.11391502238701379, 0.0734803880990752, 0.0734803880990752, 0.0734803880990752, 0.09461776779131692, 0.09461776779131692, 0.09461776779131692]}}
{"id": "920fb7c4-0475-44ec-a0a3-7868b50fb40a", "fitness": 0.09400670645838909, "name": "EnhancedHybridPSODE", "description": "Improved hybrid swarm-type algorithm with adaptive DE mutation strategy for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9  # Start with a higher inertia weight\n        self.inertia_weight_min = 0.4  # Minimum inertia weight\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Start with a standard DE scaling factor\n        self.cr = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_component * r1 * (personal_best_positions - positions) +\n                          self.social_component * r2 * (global_best_position - positions))\n            positions = positions + velocities\n            positions = np.clip(positions, lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Dynamic DE scaling factor (improved)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11391854878069985, 0.11391854878069985, 0.11391854878069985, 0.07348164638468402, 0.07348164638468402, 0.07348164638468402, 0.09461992420978338, 0.09461992420978338, 0.09461992420978338]}}
{"id": "8d181f5d-f069-4613-b922-c382082db3c9", "fitness": 0.09400906847625667, "name": "AdaptiveMultiSwarmPSODE", "description": "An adaptive hybrid algorithm combining multi-swarm PSO with dynamically tuned DE parameters and local search to enhance convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["e6e08f6a-2c7d-43df-917b-cd5db597b892"], "operator": null, "metadata": {"aucs": [0.11392219306817308, 0.11392219306817308, 0.11392219306817308, 0.07348294392361077, 0.07348294392361077, 0.07348294392361077, 0.09462206843698617, 0.09462206843698617, 0.09462206843698617]}}
{"id": "cc86ed59-b020-4dab-bfe3-b5b040a0ca25", "fitness": 0.09400887796369313, "name": "AdaptiveMultiSwarmPSODE", "description": "Introduced control of DE's crossover rates based on particle diversity and adaptive inertia weight adjustment for enhanced exploration-exploitation trade-off.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with diversity\n            diversity = np.mean(np.std(positions, axis=0))\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget) * diversity\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                diversity_factor = np.mean(np.std(positions, axis=0))\n                self.cr = 0.5 + 0.4 * diversity_factor\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392189285603138, 0.11392189285603138, 0.11392189285603138, 0.07348278320952528, 0.07348278320952528, 0.07348278320952528, 0.09462195782552274, 0.09462195782552274, 0.09462195782552274]}}
{"id": "342732ce-26cd-4b82-ba3f-4b6423994176", "fitness": 0.09400788876437043, "name": "AdaptiveMultiSwarmPSODE", "description": "Enhanced adaptive hybrid algorithm by introducing a non-linear inertia weight decay, improving convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight - changed to non-linear decay\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - (evaluations / self.budget)**2)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392000166158556, 0.11392000166158556, 0.11392000166158556, 0.0734821822101176, 0.0734821822101176, 0.0734821822101176, 0.09462148242140811, 0.09462148242140811, 0.09462148242140811]}}
{"id": "d5f952e0-5ced-48ba-b1e6-b2aec758d565", "fitness": 0.09400823553623205, "name": "AdaptiveMultiSwarmPSODE", "description": "Enhanced exploration and exploitation balance by introducing adaptive cognitive and social components along with self-adaptive DE parameters.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Adaptive cognitive and social components\n            adaptive_cognitive = self.cognitive_component * (1 - evaluations / self.budget)\n            adaptive_social = self.social_component * evaluations / self.budget\n            \n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             adaptive_cognitive * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             adaptive_social * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392008572347079, 0.11392008572347079, 0.11392008572347079, 0.0734827879415828, 0.0734827879415828, 0.0734827879415828, 0.09462183294364257, 0.09462183294364257, 0.09462183294364257]}}
{"id": "2d1c35dd-b389-4b78-800d-cf1b8cb53af2", "fitness": 0.09400872737189048, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Integrating adaptive inertia weight decay and competitive swarm interaction to enhance exploration and convergence in a multi-swarm PSO with DE crossover and local search.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with more aggressive decay\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * ((1 - evaluations / self.budget) ** 2)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Competitive interaction between the swarms\n            if evaluations < self.budget:\n                for k in range(self.num_swarms - 1):\n                    if np.min(scores[k * swarm_size:(k+1) * swarm_size]) < np.min(scores[(k+1) * swarm_size:(k+2) * swarm_size]):\n                        better_swarm = k\n                        worse_swarm = k + 1\n                    else:\n                        better_swarm = k + 1\n                        worse_swarm = k\n                    if np.random.rand() < 0.1:\n                        swap_indices = np.random.choice(range(worse_swarm * swarm_size, (worse_swarm + 1) * swarm_size), 3, replace=False)\n                        for si in swap_indices:\n                            positions[si] = personal_best_positions[np.random.choice(range(better_swarm * swarm_size, (better_swarm + 1) * swarm_size))]\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392164497640533, 0.11392164497640533, 0.11392164497640533, 0.07348267620275395, 0.07348267620275395, 0.07348267620275395, 0.09462186093651215, 0.09462186093651215, 0.09462186093651215]}}
{"id": "ad231fef-6457-4023-a078-40b5aa945734", "fitness": 0.0940088783164228, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduce a self-adaptive strategy for DE's crossover and mutation rates, integrate a diversity preservation mechanism, and employ a restart strategy to enhance convergence and exploration capabilities.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.diversity_threshold = 1e-5\n        self.restart_threshold = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        def initialize_population():\n            positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n            velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                           (self.population_size, self.dim))\n            personal_best_positions = np.copy(positions)\n            personal_best_scores = np.array([func(x) for x in positions])\n            global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n            global_best_score = np.min(personal_best_scores)\n            return positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score\n\n        positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score = initialize_population()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            self.cr = 0.5 + 0.5 * np.exp(-10 * evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n            diversity = np.mean(np.std(positions, axis=0))\n            if diversity < self.diversity_threshold or evaluations / self.budget > self.restart_threshold:\n                positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score = initialize_population()\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392173131967531, 0.11392173131967531, 0.11392173131967531, 0.0734827934936847, 0.0734827934936847, 0.0734827934936847, 0.09462211013590838, 0.09462211013590838, 0.09462211013590838]}}
{"id": "95f75f65-b61f-4ab6-a409-7327fb54e003", "fitness": 0.09400900296516294, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Enhanced hybrid optimization using adaptive multi-swarm PSO with improved DE crossover and elitist strategy for superior convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling and elitism\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            num_elites = max(1, int(self.elite_fraction * self.population_size))\n            elite_indices = np.argsort(scores)[:num_elites]\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                if i in elite_indices:\n                    continue\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392205160858904, 0.11392205160858904, 0.11392205160858904, 0.07348287011260868, 0.07348287011260868, 0.07348287011260868, 0.0946220871742911, 0.0946220871742911, 0.0946220871742911]}}
{"id": "0eb121ad-bf65-4f9b-8be3-faf8e4e17fcc", "fitness": 0.09400884377597245, "name": "AdaptiveMultiSwarmPSODE", "description": "Enhanced AdaptiveMultiSwarmPSODE by introducing a dynamic component adjustment mechanism and improved local search probability calculation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                # Adjust cognitive and social components dynamically\n                self.cognitive_component = 1.5 + 0.5 * (1 - evaluations / self.budget)\n                self.social_component = 1.5 + 0.5 * (evaluations / self.budget)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles with improved probability\n            if evaluations < self.budget and np.random.rand() < 0.3:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392181713528415, 0.11392181713528415, 0.11392181713528415, 0.07348281518775823, 0.07348281518775823, 0.07348281518775823, 0.09462189900487494, 0.09462189900487494, 0.09462189900487494]}}
{"id": "3c51d35d-b21d-48da-a3ea-72a2a67606ec", "fitness": 0.09400906847052322, "name": "AdaptiveMultiSwarmPSODE", "description": "Introduce a dynamic adjustment to the crossover probability in the Differential Evolution step to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                self.cr = 0.9 * (1 - evaluations / self.budget)  # Dynamic adjustment to crossover probability\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392219306817308, 0.11392219306817308, 0.11392219306817308, 0.07348294390641041, 0.07348294390641041, 0.07348294390641041, 0.09462206843698617, 0.09462206843698617, 0.09462206843698617]}}
{"id": "3a76283c-93c0-4d73-8c55-46e198ab3d39", "fitness": 0.094008678479042, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Enhanced AdaptiveMultiSwarmPSODE with dynamic swarm merging and adaptive parameter control to improve convergence and problem-solving versatility.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive parameters and dynamic swarm merging\n            self.inertia_weight = self.inertia_weight_max - \\\n                                  ((self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            if np.random.rand() < 0.3 and self.num_swarms > 1:\n                self.num_swarms = max(1, self.num_swarms - 1)\n                swarm_size = self.population_size // self.num_swarms\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392148594507956, 0.11392148594507956, 0.11392148594507956, 0.07348278471014547, 0.07348278471014547, 0.07348278471014547, 0.09462176478190099, 0.09462176478190099, 0.09462176478190099]}}
{"id": "23ae0e40-9402-48da-b711-9ae4d812798a", "fitness": 0.09400906847625667, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A novel adaptive hybrid algorithm that combines multi-swarm PSO with dynamically tuned DE parameters, local search, and elitism to enhance convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.elitism_rate = 0.1  # Fraction of best solutions to retain\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n\n            # Multi-Swarm PSO update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Elitism: retain a fraction of the best solutions\n            elite_size = int(self.elitism_rate * self.population_size)\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_positions = positions[elite_indices]\n            elite_scores = scores[elite_indices]\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n            # Restore elite solutions\n            positions[:elite_size] = elite_positions\n            scores[:elite_size] = elite_scores\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392219306817308, 0.11392219306817308, 0.11392219306817308, 0.07348294392361077, 0.07348294392361077, 0.07348294392361077, 0.09462206843698617, 0.09462206843698617, 0.09462206843698617]}}
{"id": "c8336051-37c3-4ac7-b05c-8aee67cf6dc6", "fitness": 0.09400910541028855, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A hybrid algorithm leveraging adaptive multi-swarm PSO and DE with chaotic sequences for enhanced exploration, maintaining a fine-tuned balance between diversification and intensification.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        # Initialize a logistic map-based chaotic sequence\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with chaotic influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["8d181f5d-f069-4613-b922-c382082db3c9"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.1139215252972311, 0.11392333896437923, 0.07348267853030754, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "e5b89e0e-e221-4974-9b81-dc7ce5dc2960", "fitness": 0.09400765626383886, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduction of Lvy flights and dynamic swarm size adjustment to enhance exploration and exploitation balance in the EnhancedAdaptiveMultiSwarmPSODE algorithm.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n    \n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with chaotic influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Dynamic swarm size adjustment\n            swarm_size = int(self.population_size * (1 - evaluations / self.budget))\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, min(self.population_size, (k + 1) * swarm_size))\n                r1, r2 = np.random.rand(2, len(swarm_indices), self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] += velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Lvy flights for exploration\n            levy_flight = levy.rvs(size=self.dim)\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                positions[best_idx] += levy_flight\n                positions[best_idx] = np.clip(positions[best_idx], lower_bound, upper_bound)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11391982631585673, 0.11392034936548656, 0.11392006301230728, 0.073482333112464, 0.07348238309860178, 0.07348146078165807, 0.09462141637010235, 0.0946202905906568, 0.09462078372741622]}}
{"id": "a2591da7-a579-4707-823f-a88f49440d10", "fitness": 0.09400843794788316, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduce a dynamic neighborhood radius with Lvy flight-based exploration in adaptive multi-swarm PSO and DE to enhance exploitation and exploration balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.levy_alpha = 1.5\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i - 1] * (1 - chaotic_sequence[i - 1])\n        return chaotic_sequence\n\n    def _levy_flight(self):\n        sigma = (np.math.gamma(1 + self.levy_alpha) * np.sin(np.pi * self.levy_alpha / 2) /\n                 (np.math.gamma((1 + self.levy_alpha) / 2) * self.levy_alpha * 2**((self.levy_alpha - 1) / 2)))**(1 / self.levy_alpha)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        return u / np.abs(v)**(1 / self.levy_alpha)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n                if evaluations < self.budget * 0.8:  # Apply Levy flights in early stages\n                    for i in swarm_indices:\n                        levy_step = self._levy_flight()\n                        positions[i] = np.clip(positions[i] + levy_step, lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392193438769826, 0.11392065470759327, 0.11392000166158556, 0.07348270041242833, 0.07348291037678345, 0.0734821822101176, 0.09462198699242186, 0.0946220883442167, 0.09462148243810342]}}
{"id": "3fc43d66-4a1f-45e5-b872-23cbea78b9cd", "fitness": 0.09400877862102994, "name": "RefinedAdaptiveMultiSwarmPSODE", "description": "A biologically-inspired algorithm that integrates adaptive multi-swarm PSO with DE using chaotic sequences and a sporadic local search, targeting synergistic exploration-exploitation balance for enhanced convergence performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.local_search_prob = 0.1\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget and np.random.rand() < self.local_search_prob:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392192242844923, 0.11392150579580906, 0.11392164854075815, 0.07348289117738072, 0.07348274780628206, 0.07348275176676611, 0.09462198548998069, 0.09462172983552586, 0.0946218247483176]}}
{"id": "583f46bc-254a-46c8-9a67-e283f1e45934", "fitness": 0.09400910541028855, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduce a conditional update in the chaotic sequence to dynamically adjust the PSO inertia weight based on performance, enhancing convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        # Initialize a logistic map-based chaotic sequence\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with chaotic influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            if global_best_score < 0.1:  # Conditional update based on performance\n                chaotic_factor *= 0.5\n            self.inertia_weight += chaotic_factor\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.1139215252972311, 0.11392333896437923, 0.07348267853030754, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "2d8b2ed1-73ad-4a81-8d3a-8adb2f9b8c2f", "fitness": 0.09400879271661916, "name": "RefinedAdaptiveMultiSwarmPSODE", "description": "An enhanced adaptive multi-swarm PSO and DE leveraging chaotic sequences and dynamic learning coefficients to improve exploitation and exploration balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component_max = 2.5\n        self.social_component_max = 2.5\n        self.cognitive_component_min = 1.5\n        self.social_component_min = 1.5\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        # Initialize a logistic map-based chaotic sequence\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with chaotic influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Dynamic learning factors\n            cognitive_component = self.cognitive_component_min + (self.cognitive_component_max - self.cognitive_component_min) * (evaluations / self.budget)\n            social_component = self.social_component_max - (self.social_component_max - self.social_component_min) * (evaluations / self.budget)\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392202416272623, 0.11392180441008803, 0.11392132816336953, 0.07348282497428926, 0.07348284499953239, 0.07348239235790277, 0.09462209715319436, 0.09462191500902606, 0.09462190321944375]}}
{"id": "164fb82b-1da4-4e24-bdc5-2123baedf3c5", "fitness": 0.09400910541028855, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A refined hybrid algorithm using adaptive multi-swarm PSO and DE with chaotic sequences, introducing elite selection and dynamic parameter adjustment for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.elite_fraction = 0.1  # New: Elite fraction\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # New: Elite selection\n            elite_indices = scores.argsort()[:int(self.population_size * self.elite_fraction)]\n            elite_positions = positions[elite_indices]\n            elite_scores = scores[elite_indices]\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.1139215252972311, 0.11392333896437923, 0.07348267853030754, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "9e7eb839-f0a6-4a9f-9d5e-f3da1b6cd435", "fitness": 0.09400910541028855, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "An enhanced hybrid algorithm integrating an adaptive multi-swarm PSO with DE, leveraging chaotic sequences and dynamic scaling to optimize exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.1139215252972311, 0.11392333896437923, 0.07348267853030754, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "153dc931-ba20-450b-880b-410a9c99821e", "fitness": 0.09400910541028855, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "An enhanced algorithm blending adaptive multi-swarm PSO, DE, and chaotic sequences, with a focus on dynamic parameter adjustment and improved local search for superior exploration and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        # Initialize a logistic map-based chaotic sequence\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with chaotic influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles using adaptive L-BFGS\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.1139215252972311, 0.11392333896437923, 0.07348267853030754, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "94c1177e-b0fe-43e5-9399-3f854d6789c4", "fitness": 0.09400645778732065, "name": "RefinedAdaptiveMultiSwarmPSODE", "description": "An improved hybrid algorithm using adaptive multi-swarm PSO and DE with chaotic sequences and increased exploitation through dynamic local search adaptive to convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 4.0  # Increased parameter for chaotic map for more pronounced chaos\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                improvement_threshold = 0.01  # Threshold for triggering local search\n                if np.abs(scores.min() - global_best_score) < improvement_threshold:\n                    best_idx = np.argmin(scores)\n                    res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                    if res.fun < global_best_score:\n                        global_best_score = res.fun\n                        global_best_position = res.x\n                    evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11391243979844423, 0.11392030247457119, 0.1139217605669337, 0.07347946657181492, 0.07348223465800685, 0.07348277315035945, 0.09461618850740205, 0.0946209984598364, 0.09462195589851707]}}
{"id": "b444b530-4fb8-4e96-a0fc-9032d0576979", "fitness": 0.09400880113376665, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Enhanced the exploration phase using an adaptive inertia weight influenced by an exponential decay function for improved convergence and stability.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        # Initialize a logistic map-based chaotic sequence\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Parameter for chaotic map\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        # Initialize particles\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight with exponential decay influence\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * np.exp(-5 * evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Multi-Swarm Particle Swarm Optimization update\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            # Evaluate new positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Differential Evolution mutation and crossover with adaptive scaling\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Local Search for best particles\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392190694395365, 0.11392178453094914, 0.11392164052229747, 0.07348280616653435, 0.07348269577139077, 0.07348281600163453, 0.09462195501419157, 0.0946218019300229, 0.09462180332292547]}}
{"id": "bbcc68a5-d7bd-4bd2-b6c9-2ffdd0045078", "fitness": 0.09400871760137706, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A refined hybrid algorithm leveraging adaptive multi-swarm PSO and DE with chaotic sequences, incorporating elite selection and adaptive parameter tuning for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            elite_indices = np.argsort(scores)[:int(0.2 * self.population_size)]\n            for i in elite_indices:\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392174818633993, 0.11392205299487645, 0.11392127993084866, 0.0734827119166237, 0.0734827766667916, 0.0734823375978303, 0.09462192656522506, 0.09462194012100233, 0.09462168443285557]}}
{"id": "2d2a2a20-e5c1-4766-9aed-2bfa51fbcf5c", "fitness": -Infinity, "name": "EnhancedAdaptiveMultiSwarmPSODEv2", "description": "EnhancedAdaptiveMultiSwarmPSODEv2: Incorporating chaotic Lvy flights for improved global search capability and adaptive neighborhood size adjustments to maintain exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.levy_flight_scale = 0.1\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def _levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v)**(1 / beta)\n        return self.levy_flight_scale * step\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] += velocities[swarm_indices] + self._levy_flight((swarm_size, self.dim))\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {}}
{"id": "5947714b-80ac-4254-896d-f90f1ec7b841", "fitness": 0.09400910551699468, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "An improved hybrid PSO-DE algorithm with dynamic cognitive and social components for better global and personal learning balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["c8336051-37c3-4ac7-b05c-8aee67cf6dc6"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.11392152593181581, 0.11392333896437923, 0.07348267885607807, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "6169fb08-a0b4-4420-a83e-3ddc4bbb5d4d", "fitness": 0.09400850126646387, "name": "EnhancedAdaptiveMultiSwarmPSODE_Refined", "description": "A refined hybrid PSO-DE algorithm introducing adaptive velocity clamping and enhanced differential mutation for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)\n\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                velocity_clamp = 0.1 * (np.subtract(upper_bound, lower_bound))\n                velocities[swarm_indices] = np.clip(velocities[swarm_indices], -velocity_clamp, velocity_clamp)\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                f_adapt = self.f * (1 + np.sin(evaluations / 10))\n                mutant = np.clip(x1 + f_adapt * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392204139614792, 0.11392025461488287, 0.11392025461488287, 0.07348289370199679, 0.0734828627873646, 0.0734828627873646, 0.094622058990121, 0.09462164125270711, 0.09462164125270711]}}
{"id": "e5f3dcc1-71c0-433a-89a7-a67c67b6723f", "fitness": 0.09400910551699468, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "EnhancedAdaptiveMultiSwarmPSODE with adaptive elitism and chaotic sequence diversity control for improved convergence and global search.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            # Introduce adaptive elitism\n            elitism_factor = 0.1 + 0.1 * np.sin(evaluations / self.budget * np.pi)\n            elite_indices = np.argsort(personal_best_scores)[:int(self.population_size * elitism_factor)]\n            elite_positions = personal_best_positions[elite_indices]\n            \n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392165418363864, 0.11392152593181581, 0.11392333896437923, 0.07348267885607807, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "e4e6fe3d-a501-4eff-a487-7cf36444f402", "fitness": 0.09400910545605266, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A refined PSO-DE algorithm with adaptive dimensional search and dynamic inertia weight adjustment using cosine similarity for enhanced convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.1139216541823177, 0.1139215252972311, 0.11392333896437923, 0.07348267844555012, 0.07348280995230405, 0.07348335695385777, 0.0946218690815811, 0.09462186976123366, 0.09462284646601926]}}
{"id": "972fde00-cfc2-44eb-b947-e0441b578b25", "fitness": 0.0940087788744559, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introduced self-adaptive mutation strategies and dynamic inertia adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        # Introduce self-adaptive parameters\n        self.inertia_weight_max = 0.9\n        self.success_rate_threshold = 0.2\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        success_count = 0\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (self.inertia_weight_max - self.inertia_weight_min) * \\\n                                  np.exp(-10 * success_count / evaluations)  # Dynamic inertia adjustment\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n                    success_count += 1\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                f_local = self.f + 0.1 * np.random.rand()  # Adaptive mutation factor\n                mutant = np.clip(x1 + f_local * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    success_count += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392183447189907, 0.11392160979372912, 0.1139216028778014, 0.07348280547596753, 0.07348279289002058, 0.07348277965100147, 0.09462194594730522, 0.09462179487585265, 0.09462184388652606]}}
{"id": "0b924b53-3546-4a45-b15e-462f8f84f312", "fitness": 0.09400910535256482, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Introducing an evolutionary multi-agent communication mechanism to dynamically adjust exploration-exploitation balance in hybrid PSO-DE for enhanced convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.agent_communication_rate = 0.2\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # New agent communication mechanism\n            if evaluations < self.budget and np.random.rand() < self.agent_communication_rate:\n                agent1, agent2 = np.random.choice(self.population_size, 2, replace=False)\n                if personal_best_scores[agent1] < personal_best_scores[agent2]:\n                    positions[agent2] = positions[agent1] + np.random.rand() * (personal_best_positions[agent1] - positions[agent2])\n                else:\n                    positions[agent1] = positions[agent2] + np.random.rand() * (personal_best_positions[agent2] - positions[agent1])\n                positions = np.clip(positions, lower_bound, upper_bound)\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.1139216541823177, 0.11392152583097481, 0.11392333896437923, 0.07348267844944611, 0.0734828099655741, 0.07348335695385777, 0.0946218690815811, 0.09462186827893326, 0.09462284646601926]}}
{"id": "91301a48-28ee-4d9a-80fd-2179b75a33bc", "fitness": 0.09400910538613155, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Enhanced Adaptive Multi-Swarm PSO-DE with chaotic PSO components for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.cos(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.1139216541823177, 0.1139215252972311, 0.11392333896437923, 0.07348267831421562, 0.07348280996543488, 0.07348335695385777, 0.0946218690815811, 0.09462186925014737, 0.09462284646601926]}}
{"id": "bad7ac36-026b-4b8c-9e0f-68fad48807c6", "fitness": 0.09400876838017796, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Adaptive multi-swarm PSO-DE with enhanced chaotic sequence and adaptive crossover for diverse exploration and stable convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += 0.5 * chaotic_factor  # Modified for smoother chaos adaptation\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations * np.pi / self.budget)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            adaptive_cr = 0.8 + 0.1 * np.sin(evaluations * np.pi / self.budget)  # Modified for adaptive crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < adaptive_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392143734092874, 0.11392188991618801, 0.11392185906234353, 0.07348256197468794, 0.07348282550698215, 0.07348284636926183, 0.09462175097441816, 0.09462189559966938, 0.09462184867712187]}}
{"id": "e1775ed5-e1bb-4559-9566-9b85d87993ed", "fitness": 0.09400910545605266, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "Multi-Swarm Dynamic PSO-DE with Adaptive Exploration-Exploitation Balance and Enhanced Local Search for Optimized Performance", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations * np.pi / self.budget)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.1139216541823177, 0.1139215252972311, 0.11392333896437923, 0.07348267844555012, 0.07348280995230405, 0.07348335695385777, 0.0946218690815811, 0.09462186976123366, 0.09462284646601926]}}
{"id": "74a233f2-47e1-4ab7-8727-0f913aef3b7e", "fitness": 0.09400910545605266, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "An enhanced PSO-DE algorithm with adaptive learning rates and chaotic perturbations for maintaining diversity and improving convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations * np.pi / self.budget)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.1139216541823177, 0.1139215252972311, 0.11392333896437923, 0.07348267844555012, 0.07348280995230405, 0.07348335695385777, 0.0946218690815811, 0.09462186976123366, 0.09462284646601926]}}
{"id": "c479be57-866d-4fb4-a335-011c43e9fb1d", "fitness": 0.094008822371659, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "An enhanced hybrid PSO-DE algorithm with adaptive inertia weights and swarm intelligence for improved exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor\n            \n            # Modified strategy: Adaptive swarm intelligence\n            dynamic_social_component = self.social_component * (1 + 0.1 * np.cos(evaluations))\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             dynamic_social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392165602499571, 0.11392160382160732, 0.11392198211316173, 0.07348281759183117, 0.07348278938633168, 0.07348280727386758, 0.09462203542646208, 0.0946217922377478, 0.0946219174689259]}}
{"id": "372bb054-9ad3-4d93-bf13-ad04df6eed8d", "fitness": 0.0940087361467431, "name": "AdaptiveMultimodalSwarm", "description": "Introduced adaptive inertia weight scheduling and multimodal swarm intelligence with random topology reconfiguration for enhanced exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveMultimodalSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.topology_change_rate = 0.1\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_max - \\\n                             (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (self.inertia_weight_max - self.inertia_weight_min)\n            inertia_weight += chaotic_factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                if np.random.rand() < self.topology_change_rate:\n                    np.random.shuffle(swarm_indices)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveMultimodalSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392142267028982, 0.1139220458179585, 0.1139216051397165, 0.0734824965587435, 0.07348281574637949, 0.07348269653053463, 0.09462168468867682, 0.09462206184726973, 0.09462179632111889]}}
{"id": "f75973ec-fc7e-41fe-aa1d-d67082d53a36", "fitness": 0.09400921055430839, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A refined hybrid PSO-DE algorithm with chaotic inertia damping and adaptive mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5  # Modified damping factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)  # Modified adaptive mutation factor\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["5947714b-80ac-4254-896d-f90f1ec7b841"], "operator": null, "metadata": {"aucs": [0.11392220700759503, 0.11392299537348383, 0.11392185847274139, 0.07348268608639885, 0.0734832346851555, 0.07348284636926183, 0.09462262538807398, 0.0946225916752218, 0.09462184993084322]}}
{"id": "5aa98255-4fa1-43a8-b64a-892ed471d03b", "fitness": 0.09400489685202966, "name": "AdvancedMultiStrategyPSODE", "description": "AdvancedMultiStrategyPSODE: A novel PSO-DE algorithm utilizing chaotic sequences, dynamic parameter adjustment, and periodic local search to intensify exploration and exploitation for improved global optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdvancedMultiStrategyPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.num_swarms = 3\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] += velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget and evaluations % (self.population_size * 2) == 0:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedMultiStrategyPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09400 with standard deviation 0.01651.", "error": "", "parent_ids": ["f75973ec-fc7e-41fe-aa1d-d67082d53a36"], "operator": null, "metadata": {"aucs": [0.11391291997711506, 0.11392182904677717, 0.11391262313653261, 0.07347963790837575, 0.07348281678561308, 0.07347953199421298, 0.09461648214007201, 0.0946219300554948, 0.09461630062407345]}}
{"id": "ef6baf2e-6c5b-4465-ad4f-f1baa488a23a", "fitness": 0.09400876344689578, "name": "ImprovedPSO_DESwarmCompactor", "description": "Hybrid PSO-DE with enhanced convergence through dynamic swarm compacting and stochastic tournament selection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedPSO_DESwarmCompactor:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.compact_factor = 0.5\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n            positions = self._stochastic_tournament(positions, scores)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score\n\n    def _stochastic_tournament(self, positions, scores):\n        new_positions = np.copy(positions)\n        for i in range(self.population_size):\n            competitors = np.random.choice(self.population_size, 2, replace=False)\n            winner = competitors[np.argmin(scores[competitors])]\n            loser = competitors[np.argmax(scores[competitors])]\n            new_positions[loser] = new_positions[winner] * self.compact_factor + new_positions[loser] * (1 - self.compact_factor)\n        return new_positions", "configspace": "", "generation": 60, "feedback": "The algorithm ImprovedPSO_DESwarmCompactor got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["f75973ec-fc7e-41fe-aa1d-d67082d53a36"], "operator": null, "metadata": {"aucs": [0.11392115608238829, 0.11392188991618801, 0.11392209618554283, 0.0734826119221107, 0.07348282581015997, 0.07348284103536884, 0.09462158259016962, 0.0946218992948551, 0.09462196818527868]}}
{"id": "fb6340a9-579c-4e5c-a744-d2abe59edea7", "fitness": 0.09400898119557285, "name": "EnhancedAdaptiveMultiSwarmPSODE", "description": "A refined hybrid PSO-DE algorithm with chaotic inertia damping and adaptive mutation, enhanced by dynamically adjusting the crossover rate based on optimization progress to improve exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5  # Modified damping factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)  # Modified for dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)  # Modified adaptive mutation factor\n            self.cr = 0.7 + 0.2 * (1 - evaluations / self.budget)  # Dynamically adjust crossover rate\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["f75973ec-fc7e-41fe-aa1d-d67082d53a36"], "operator": null, "metadata": {"aucs": [0.11392241318115814, 0.11392188991618801, 0.11392185847274139, 0.07348302574791976, 0.07348282247253157, 0.07348284636926183, 0.09462223094939193, 0.09462189540708621, 0.09462184824387687]}}
{"id": "3a2efe34-e39e-4949-893c-b1b46cac7f92", "fitness": 0.0940088272193735, "name": "AdaptiveQuantumPSO", "description": "Introduce an \"Adaptive Quantum PSO\" with quantum-inspired position updates and enhanced diversity through opposition-based learning.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def _opposition_based_learning(self, positions, lower_bound, upper_bound):\n        return lower_bound + upper_bound - positions\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations)\n                \n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n\n                # Quantum-inspired position update\n                phi = np.random.rand(swarm_size, self.dim)\n                positions[swarm_indices] = 0.5 * (personal_best_positions[swarm_indices] + global_best_position) + \\\n                                           phi * np.abs(personal_best_positions[swarm_indices] - global_best_position)\n\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n                # Opposition-based learning\n                opposition_positions = self._opposition_based_learning(positions[swarm_indices], lower_bound, upper_bound)\n                opposition_scores = np.array([func(x) for x in opposition_positions])\n                for i, idx in enumerate(swarm_indices):\n                    if opposition_scores[i] < personal_best_scores[idx]:\n                        personal_best_scores[idx] = opposition_scores[i]\n                        personal_best_positions[idx] = opposition_positions[i]\n                        if opposition_scores[i] < global_best_score:\n                            global_best_score = opposition_scores[i]\n                            global_best_position = opposition_positions[i]\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["f75973ec-fc7e-41fe-aa1d-d67082d53a36"], "operator": null, "metadata": {"aucs": [0.11392174678531453, 0.11392174678531453, 0.11392174678531453, 0.07348281479648822, 0.07348281479648822, 0.07348281479648822, 0.09462192007631776, 0.09462192007631776, 0.09462192007631776]}}
{"id": "bd0ec281-3999-4702-a811-65f60671e2ce", "fitness": 0.09400921128418141, "name": "EnhancedAdaptiveMultiSwarmPSODEv2", "description": "An improved hybrid PSO-DE with adaptive chaotic inertia damping, dynamic learning rates, and cooperative local search for enhanced convergence speed and accuracy.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations / 50)  # More dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["f75973ec-fc7e-41fe-aa1d-d67082d53a36"], "operator": null, "metadata": {"aucs": [0.11392220700759503, 0.11392299537348383, 0.11392185847274139, 0.07348268608639885, 0.07348323461180772, 0.07348284636384095, 0.0946226253322533, 0.0946225986938416, 0.09462184961567]}}
{"id": "b4adf60d-72d1-4f67-8f52-bd4960e0d375", "fitness": 0.0940085576876403, "name": "EnhancedAdaptiveMultiSwarmPSODEv2", "description": "Introduced a stochastic selection of cognitive and social components and enhanced local search by integrating adaptive mutation scaling in EnhancedAdaptiveMultiSwarmPSODEv2.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = np.random.uniform(1.5, 2.5)  # Stochastic selection\n                self.social_component = np.random.uniform(1.5, 2.5)     # Stochastic selection\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n            self.f *= (0.5 + 0.5 * np.random.rand())  # Adaptive mutation scaling\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["bd0ec281-3999-4702-a811-65f60671e2ce"], "operator": null, "metadata": {"aucs": [0.11392000166158556, 0.11392187185533575, 0.11392191822234321, 0.0734821822101176, 0.0734828276765429, 0.07348286612139088, 0.09462148247343127, 0.09462191017040944, 0.09462195879760604]}}
{"id": "89529163-c8e4-4c24-a85e-abbd03522d9a", "fitness": 0.09400877505330268, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "A refined hybrid PSO-DE with improved chaotic inertia damping, adaptive learning rates, and enhanced local search mechanisms for superior convergence and solution quality.  ", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.8\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 1.8\n        self.social_component = 2.2\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.9\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.8 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.8 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.6\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["bd0ec281-3999-4702-a811-65f60671e2ce"], "operator": null, "metadata": {"aucs": [0.11392186569646001, 0.11392190528297841, 0.11392173707525477, 0.0734828022741777, 0.07348284356948798, 0.07348244841006757, 0.09462199911345848, 0.09462155443837894, 0.09462181961946037]}}
{"id": "ae7c4d84-6b35-42c0-b96e-9922cd87b89b", "fitness": 0.09400898003511388, "name": "RefinedMultiSwarmPSODEv2", "description": "A refined hybrid PSO-DE with adaptive chaotic inertia, local diversity preservation, and a novel self-adaptive crossover strategy for improved exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedMultiSwarmPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                self.cognitive_component = 1.5 + 0.5 * np.sin(evaluations / 50)  # More dynamic learning\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n            \n            self.f = 0.5 + 0.3 * np.cos(evaluations / self.budget * np.pi)\n            self.cr = 0.9 - 0.3 * (evaluations / self.budget)  # Decreasing crossover rate\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm RefinedMultiSwarmPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["bd0ec281-3999-4702-a811-65f60671e2ce"], "operator": null, "metadata": {"aucs": [0.11392241324691399, 0.1139218899651907, 0.11392185847274139, 0.07348302574791976, 0.0734828231480168, 0.07348284636926183, 0.0946222180935028, 0.09462189540708621, 0.09462184986539146]}}
{"id": "4596b1ae-4794-41c4-9bea-10073a9d03cb", "fitness": 0.09400924478574621, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "An enhanced PSO-DE with dynamic parameter adaptation, ensemble mutation strategies, and integrated local search for rapid and robust convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["bd0ec281-3999-4702-a811-65f60671e2ce"], "operator": null, "metadata": {"aucs": [0.11392234492316167, 0.11392180319612566, 0.11392312860512577, 0.07348303775882481, 0.07348270494824094, 0.07348324823722607, 0.09462236228613308, 0.09462189030130919, 0.09462268281556874]}}
{"id": "94d7d8cb-3834-48c3-b0a3-9d6b379d0134", "fitness": 0.09354988733510466, "name": "EnhancedAdaptiveMultiSwarmPSODEv4", "description": "Introducing behavior-driven chaotic learning and adaptive dimensionality reduction for enhanced convergence and exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.dim_reduction_factor = max(1, int(dim * 0.1))  # Adaptive dimensionality reduction\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                reduced_dim = min(self.dim, self.dim_reduction_factor)\n                reduced_bounds = [(lower_bound[i], upper_bound[i]) for i in range(reduced_dim)]\n                res = minimize(func, positions[best_idx][:reduced_dim], bounds=reduced_bounds, method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position[:reduced_dim] = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09355 with standard deviation 0.01652.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.1134710636104721, 0.11346917693223346, 0.11346917693223346, 0.07301664870980717, 0.07301597547696614, 0.07301597547696614, 0.09416442545884907, 0.09416327170920724, 0.09416327170920724]}}
{"id": "6650ad5a-4ea9-4637-9fed-26eecd42866f", "fitness": 0.09400886209861131, "name": "RefinedAdaptiveMultiSwarmPSODE", "description": "A refined PSO-DE with adaptive multi-swarm synergy, chaotic sequence-based inertia adjustments, and dynamic differential weight for enhanced global exploration and local exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedAdaptiveMultiSwarmPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for improved diversity\n        self.inertia_weight = 0.7  # Modified for balance\n        self.inertia_weight_min = 0.2\n        self.cognitive_component = 1.5\n        self.social_component = 2.5\n        self.f = 0.5  # Initial differential weight\n        self.cr = 0.9  # Increased crossover probability for exploration\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.9  # Chaotic parameter for randomness\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.7 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.7 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.3 + 0.7 * np.cos(evaluations / self.budget * np.pi)  # Further dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedAdaptiveMultiSwarmPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392263519379231, 0.1139216181485656, 0.1139213220674925, 0.0734831033990544, 0.07348268454151374, 0.073482720911068, 0.09462241918208913, 0.09462186227908564, 0.09462139316484042]}}
{"id": "8932b6b9-10c5-432e-a5c3-9712a4bac12b", "fitness": -Infinity, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "An enhanced PSO-DE with dynamic parameter adaptation, ensemble mutation strategies, and integrated local search for rapid and robust convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0 lines, and the rest of the lines should remain unchanged. This input code has 100 lines, so you can only change 1 lines, the rest 99 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.11392234492316167, 0.11392180319612566, 0.11392312860512577, 0.07348303775882481, 0.07348270494824094, 0.07348324823722607, 0.09462236228613308, 0.09462189030130919, 0.09462268281556874]}}
{"id": "6b121f07-df3a-471f-9c93-036c5cf77fe6", "fitness": 0.09400873622498844, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introduced adaptive chaotic factor adjustment for inertia weight to enhance exploration and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min) * 0.1  # Adjusted chaotic factor scaling\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392152422735302, 0.11392184897073465, 0.11392162911225623, 0.07348267001754116, 0.07348292809223511, 0.07348270498427978, 0.0946215602990661, 0.09462193740076197, 0.0946218229206679]}}
{"id": "c1e02a53-34b4-4bf8-90a2-528b7d09376a", "fitness": 0.09400877830647655, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced Adaptive Multi-Swarm PSO-DE with refined chaotic inertia weight and crossover strategy for better exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.7  # Adjusted chaotic factor contribution\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.15 * (global_best_position - x1), lower_bound, upper_bound)  # Increased global guidance\n                cross_points = np.random.rand(self.dim) < (self.cr + 0.1)  # Adjusted crossover threshold\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392173594211141, 0.11392198129679965, 0.11392167947150211, 0.07348271530860129, 0.07348286905056212, 0.07348253417244788, 0.09462197042917397, 0.09462193838269117, 0.09462158070439941]}}
{"id": "123b0d78-5361-4d45-81a1-5ec426cd768e", "fitness": 0.09400865655438757, "name": "EnhancedAdaptiveMultiSwarmPSODEv4", "description": "An enhanced PSO-DE with adaptive chaotic inertia weights, balanced exploration-exploitation, and hybridized with L-BFGS-B for fine-tuning.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (self.inertia_weight_max - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392161302541981, 0.11392115725221352, 0.11392184182046161, 0.07348263820995415, 0.07348259815339275, 0.07348283395575572, 0.09462179006035631, 0.09462150423272686, 0.09462193227920745]}}
{"id": "58a3fd77-0d55-42d9-bdb8-bdd0ed6eeed3", "fitness": 0.09400924478574621, "name": "HybridChaoticDecompositionPSODE", "description": "A hybrid chaotic-decomposition PSO-DE with adaptive local search using L-BFGS-B and variable swarm interactions for enhanced convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridChaoticDecompositionPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (self.inertia_weight_max - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (self.inertia_weight_max - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm HybridChaoticDecompositionPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392234492316167, 0.11392180319612566, 0.11392312860512577, 0.07348303775882481, 0.07348270494824094, 0.07348324823722607, 0.09462236228613308, 0.09462189030130919, 0.09462268281556874]}}
{"id": "2724e9da-6ab1-47ff-a73a-e2bd5d5f6cf9", "fitness": 0.09400836524557349, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced PSO-DE with refined velocity update using chaotic factor for better exploration-exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]) +\n                                             chaotic_factor)  # More balanced learning with chaotic factor\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392155782795432, 0.11391977147827592, 0.11392166791901026, 0.07348265065054282, 0.07348271189412436, 0.07348276084436034, 0.09462173318210132, 0.09462060193815869, 0.0946218314756333]}}
{"id": "aa0cb32d-49bc-4956-aedc-313cde9780db", "fitness": 0.09400858499683742, "name": "ImprovedHybridPSODEv4", "description": "A novel hybrid PSO-DE algorithm with adaptive chaotic sequences, elite local search, and dynamic learning factors for enhanced exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ImprovedHybridPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Further increased population size for diversity\n        self.inertia_weight = 0.8\n        self.inertia_weight_min = 0.2  # Lowered minimum inertia\n        self.cognitive_component = 2.1\n        self.social_component = 1.9\n        self.f = 0.5  # Adjusted differential weight for diversity\n        self.cr = 0.9  # Increased crossover probability\n        self.num_swarms = 3\n        self.elite_proportion = 0.1  # Proportion of elite solutions for local search\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 4.0  # Adjusted chaotic parameter for more chaos\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.8 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.8 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.3 + 0.6 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.2 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                elite_count = int(self.elite_proportion * self.population_size)\n                elite_indices = np.argsort(scores)[:elite_count]\n                for idx in elite_indices:\n                    res = minimize(func, positions[idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                    if res.fun < global_best_score:\n                        global_best_score = res.fun\n                        global_best_position = res.x\n                    evaluations += res.nfev\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm ImprovedHybridPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.1139215155607034, 0.11392183358616292, 0.1139216625913193, 0.07348249824409481, 0.07348283682896894, 0.07348270712415905, 0.09462037221850483, 0.09462194719098338, 0.09462189162664014]}}
{"id": "a30f3464-0192-4485-959f-45c7727c141e", "fitness": 0.09400845169113352, "name": "EnhancedCCEPSODEv4", "description": "Introduce a cooperative co-evolutionary strategy with adaptive resource allocation and adaptive differential evolution to enhance convergence efficiency and robustness.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedCCEPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better exploration\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4  # Adjusted minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.5\n        self.cr = 0.9  # Increased crossover probability\n        self.num_swarms = 3\n        self.subcomponents = 5  # Number of subcomponents for cooperative co-evolution\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.9  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound, upper_bound = func.bounds.lb, func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n        subcomp_size = self.dim // self.subcomponents\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            # Co-evolutionary Differential Evolution\n            for subcomp in range(self.subcomponents):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = x1 + self.f * (x2 - x3)\n                mutant = np.clip(mutant, lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedCCEPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392021595585211, 0.11392153622354506, 0.11392149200640145, 0.0734824719604078, 0.07348262789574611, 0.07348264156017514, 0.09462131043620803, 0.09462176098327979, 0.09462200819858613]}}
{"id": "a54fdecc-2919-4217-8d08-9934a4ddef4f", "fitness": 0.09400879967266419, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Improved dynamic adaptation with chaotic mutation and optimized inertia oscillation for enhanced convergence performance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (0.5 * (1 + np.sin(2 * np.pi * evaluations / self.budget)))  # 1\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.15 * (global_best_position - x1), lower_bound, upper_bound)  # 2\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.1139208356842164, 0.11392266480241964, 0.11392108574393778, 0.07348282589145194, 0.07348291592610545, 0.07348285296960044, 0.09462196612183149, 0.09462200878214577, 0.0946220411322688]}}
{"id": "be44a5d7-b610-495f-a0bf-ae0f94757fae", "fitness": 0.09400924463746357, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced global guidance by increasing the influence of the global best position during the DE mutation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.2 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392234498721399, 0.1139218032479441, 0.11392312860512577, 0.07348303780173049, 0.07348270498816056, 0.07348324422794039, 0.09462236227636378, 0.09462189030130919, 0.09462268530138385]}}
{"id": "052339e9-8659-4d95-866f-0d392e2d8b8b", "fitness": 0.09400894920641842, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced PSO-DE with improved chaotic dynamics for better exploration.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 4.0  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392187160574474, 0.11392212782660549, 0.11392198612580251, 0.07348286090053702, 0.07348282305582299, 0.07348286078309374, 0.09462196627240016, 0.09462203677951875, 0.0946220095082404]}}
{"id": "03ded9de-38d5-416a-87e5-e358af7f53fd", "fitness": 0.09400828321219563, "name": "RefinedHybridPSODEv4", "description": "A hybrid PSO-DE algorithm with chaos-enhanced parameter adaptation, swarm diversity control, and sporadic local searches for improved exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass RefinedHybridPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Further increased population size for better diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.2  # Further lowered minimum inertia\n        self.cognitive_component = 2.05\n        self.social_component = 2.05\n        self.f = 0.7  # Adjusted differential weight\n        self.cr = 0.9  # Increased crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.local_search_probability = 0.15  # Probability of triggering local search\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.9  # Modified chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             2.05 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             2.05 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget and np.random.rand() < self.local_search_probability:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm RefinedHybridPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392033546625646, 0.11392093603375186, 0.11392176962732237, 0.07348199613984296, 0.0734822955334401, 0.0734828444867407, 0.09462087782579087, 0.09462168093647638, 0.09462181286013904]}}
{"id": "90c6f572-5878-466c-9dce-2970f66b537a", "fitness": 0.09400830095486179, "name": "AdvancedChaoticAdaptivePSODEv4", "description": "A refined PSO-DE algorithm integrating an advanced chaotic sequence and adaptive learning mechanism for enhanced exploration-exploitation balance and convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdvancedChaoticAdaptivePSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for diversity\n        self.inertia_weight = 0.7\n        self.inertia_weight_min = 0.2  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.5\n        self.f = 0.5  # Adjusted differential weight\n        self.cr = 0.9  # Adjusted crossover probability\n        self.num_swarms = 4\n        self.chaotic_sequence = self._init_advanced_chaotic_sequence()\n\n    def _init_advanced_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.999  # Enhanced chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n            if i % 10 == 0:  # Introduce disturbance every 10 iterations\n                chaotic_sequence[i] = (chaotic_sequence[i] + np.random.rand()) % 1\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.8 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.8 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.6\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))  # Enhanced social learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.3 + 0.7 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.2 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm AdvancedChaoticAdaptivePSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392209020407629, 0.1139204033687603, 0.11392039769216922, 0.07348290311165107, 0.07348233467818177, 0.07348264337873989, 0.09462203189818075, 0.09462034749742276, 0.09462155676457407]}}
{"id": "85b37cc9-114a-4a28-b719-d69962c0b38e", "fitness": 0.09400924478574621, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhance dynamic adaptation of parameters using a sinusoidal approach to improve convergence speed and robustness.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            # Sinusoidal adaptation for cognitive component\n            self.cognitive_component = 2.0 + np.sin(2 * np.pi * evaluations / self.budget) * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392234492316167, 0.11392180319612566, 0.11392312860512577, 0.07348303775882481, 0.07348270494824094, 0.07348324823722607, 0.09462236228613308, 0.09462189030130919, 0.09462268281556874]}}
{"id": "54522ebc-861c-4fb0-ab3c-bccd8891f64c", "fitness": 0.09400853199675047, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced particle velocity update with adaptive hyperparameters for improved swarm convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2, r3 = np.random.rand(3, swarm_size, self.dim)  # Changed line: Added a third random component for enhanced exploration\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392234491552367, 0.11391854577858773, 0.1139216044222876, 0.07348303783037091, 0.07348245826196109, 0.07348269634362603, 0.09462236227636378, 0.09462200465458348, 0.09462173348744984]}}
{"id": "edcb7bf0-a346-4bfc-8231-af90526cc925", "fitness": -Infinity, "name": "QuantumAdaptiveMultiSwarmPSO", "description": "Introducing a synergy between adaptive inertia chaos, quantum behaviors, and surrogate local search to enhance convergence and exploration balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass QuantumAdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased for robustness\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4  # Slightly higher minimum for exploration\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.f = 0.5  # Adjusted for exploration-exploitation balance\n        self.cr = 0.9  # Increased crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.kernel = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n        self.gp = GaussianProcessRegressor(kernel=self.kernel, n_restarts_optimizer=10)\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.92  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        surrogate_data = []\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n                \n                surrogate_data.append((positions[i], scores[i]))\n\n            if len(surrogate_data) > self.dim and evaluations < self.budget:\n                X, y = zip(*surrogate_data)\n                self.gp.fit(np.array(X), np.array(y))\n                sampled_point = self.gp.sample_y(np.array([positions[i]]), random_state=42).flatten()\n                res = minimize(func, sampled_point, bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with remapped shapes [original->remapped]: (20,)  and requested shape (1,)').", "error": "ValueError('operands could not be broadcast together with remapped shapes [original->remapped]: (20,)  and requested shape (1,)')", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {}}
{"id": "00e54ef0-4948-4789-b501-12f32610aae4", "fitness": 0.09400859865145353, "name": "HierarchicalAdaptiveSwarmPSO", "description": "Introducing a hierarchical swarm intelligence approach combining adaptive learning rates and hybrid mutation strategies for improved global exploration and local exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HierarchicalAdaptiveSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # More agents for exploration\n        self.inertia_weight = 0.8\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.7  # Enhanced differential weight\n        self.cr = 0.9  # Enhanced crossover probability\n        self.num_swarms = 4\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 4.0  # Adjusted chaotic parameter for more chaos\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.8 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.8 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             2.0 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             2.0 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.15 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm HierarchicalAdaptiveSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.1139215924025122, 0.11392147431267985, 0.11392134555930411, 0.07348271381535576, 0.07348271949012863, 0.07348255990331176, 0.09462178839314084, 0.09462151372035732, 0.09462168026629125]}}
{"id": "13d97511-b9c1-4288-81f3-3accf961df2d", "fitness": 0.09400905229072039, "name": "EnhancedAdaptiveMultiSwarmPSODEv4", "description": "Introduce adaptive inertia weight oscillation and convergence history-guided mutation to enhance robustness and convergence speed.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.oscillation_amplitude = 0.1\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.population_size\n        convergence_history = []\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            oscillation = self.oscillation_amplitude * np.sin(evaluations / self.budget * np.pi)\n            self.inertia_weight += chaotic_factor * 0.5 + oscillation\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            convergence_history.append(np.min(scores))\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            if len(convergence_history) > 1:\n                improvement_rate = (convergence_history[-2] - convergence_history[-1]) / abs(convergence_history[-2])\n                self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi) * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392173473778033, 0.11392322807001698, 0.11392135928546299, 0.07348282109328108, 0.073483329847427, 0.0734828591393134, 0.09462193820071718, 0.0946227823403506, 0.09462141790213396]}}
{"id": "47a4e5ed-fb39-4034-98ff-170ddedbddad", "fitness": 0.09400925721406107, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introducing adaptive mutation scaling and diversity preservation to refine convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["4596b1ae-4794-41c4-9bea-10073a9d03cb"], "operator": null, "metadata": {"aucs": [0.11392254094395182, 0.11392180319907108, 0.11392312872164423, 0.07348301555434344, 0.07348269609417402, 0.07348324404989981, 0.09462231076077221, 0.09462189030130919, 0.09462268530138385]}}
{"id": "4cf16b9f-187c-44a8-89fa-326044e9218b", "fitness": 0.09400868320105384, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Enhanced exploration by slightly increasing inertia weight minimum to maintain balance in particle velocities.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.35  # Slightly increased minimum inertia for better exploration\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392110798665245, 0.11392062522771251, 0.11392223852295424, 0.07348275635260637, 0.07348276436317658, 0.07348285523219533, 0.09462188226337886, 0.09462173823670617, 0.09462218062410199]}}
{"id": "f07d8043-c033-44a3-8d35-9be6a46a6d62", "fitness": 0.09400867435704827, "name": "EnhancedChaoticReinitMultiSwarmPSO", "description": "Introducing chaotic velocity update and periodic reinitialization to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedChaoticReinitMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6\n        self.cr = 0.8\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.reinit_interval = budget // 4  # Periodic reinitialization interval\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound),\n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]) +\n                                             chaotic_factor * np.random.normal(size=(swarm_size, self.dim)))  # Chaotic velocity update\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            if evaluations % self.reinit_interval == 0:  # Periodic reinitialization\n                indices = np.random.choice(self.population_size, self.population_size // 3, replace=False)\n                positions[indices] = np.random.uniform(lower_bound, upper_bound, (len(indices), self.dim))\n                velocities[indices] = np.random.uniform(-abs(upper_bound - lower_bound), \n                                                        abs(upper_bound - lower_bound), (len(indices), self.dim))\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedChaoticReinitMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392057205022033, 0.11392184707407704, 0.11392202996375522, 0.07348270275991775, 0.07348290604193608, 0.07348273062317712, 0.09462169791043384, 0.09462194103653399, 0.09462164175338306]}}
{"id": "5e68379f-a816-4b5b-bb2d-5aae94b6ca20", "fitness": 0.09400858799766636, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Incorporating enhanced global guidance through improved chaotic factors to optimize convergence efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.95  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392165634446771, 0.11392090290002443, 0.11392142915854098, 0.07348279528419355, 0.07348222610162214, 0.07348271173478804, 0.09462190717141894, 0.09462187832029767, 0.09462178496364371]}}
{"id": "c38b6ff9-8db8-413b-9132-aaff9a77cde2", "fitness": 0.09355603087188381, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introducing elite selection strategy with early stopping to enhance convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  \n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  \n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n                \n                # Early stopping if global best doesn't improve\n                if abs(res.fun - global_best_score) < 1e-8:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09356 with standard deviation 0.01652.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11347928395327511, 0.11347854620532982, 0.11347987161429096, 0.07301952654055976, 0.0730191789807495, 0.0730197540825327, 0.09416939755553722, 0.09416897709595673, 0.09416974181872251]}}
{"id": "9c402d09-d7c6-49be-8b11-1254b5788094", "fitness": 0.09400902391475356, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Incorporating adaptive swarm size and enhanced chaotic factor to improve convergence efficiency.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.91  # Adjusted chaotic parameter for better exploration\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.6  # Enhanced chaotic influence\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392298057011241, 0.11392119973520842, 0.11392184139403527, 0.0734832401229224, 0.07348282908661197, 0.0734828126564171, 0.09462266111218631, 0.0946216948181352, 0.09462195573715293]}}
{"id": "42f65cde-3913-478e-adfe-c517a9e71316", "fitness": 0.09400848006182472, "name": "DynamicSwarmAdaptiveLearningPSO", "description": "Introducing dynamic swarm restructuring and adaptive learning to enhance exploitation and exploration balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSwarmAdaptiveLearningPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better exploration\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4  # Adjusted minimum inertia weight\n        self.cognitive_component = 2.5  # Enhanced individual learning factor\n        self.social_component = 1.5  # Reduced social component for more individuality\n        self.f = 0.5  # Initial differential weight\n        self.cr = 0.9  # High crossover probability for diversity\n        self.num_swarms = 5  # More swarms for dynamic restructuring\n        self.chaotic_sequence = self._init_chaotic_sequence()\n        self.exploit_explore_threshold = 0.2  # Threshold to switch between exploration and exploitation\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 4.0  # Adjusted chaotic parameter for more chaos\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            diversity = np.std(positions) / np.mean(np.abs(positions))\n            if diversity < self.exploit_explore_threshold:\n                self.social_component += 0.5  # Emphasize exploration\n            else:\n                self.cognitive_component += 0.5  # Emphasize exploitation\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             self.cognitive_component * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             self.social_component * r2 * (global_best_position - positions[swarm_indices]))\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.3 + 0.7 * np.sin(evaluations / self.budget * np.pi)  # Dynamic F adjustment for diversity\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm DynamicSwarmAdaptiveLearningPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392122768285773, 0.11392147505731787, 0.11392101124004073, 0.07348270594929474, 0.07348261978851767, 0.07348262768927694, 0.09462157710148666, 0.09462165686946644, 0.09462141917816369]}}
{"id": "6e189cfb-9771-4a4d-a485-df5c94408f3e", "fitness": 0.09400924246605169, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introduce a dynamic crossover probability adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            self.cr = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Dynamic CR adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1), lower_bound, upper_bound)  # Added global guidance\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392234491552367, 0.11392180323528434, 0.1139231286875585, 0.07348303787499, 0.07348270494824094, 0.07348324704854858, 0.09462236227636378, 0.09462189030130919, 0.09462266290664623]}}
{"id": "98a7a557-007c-46f6-9e9d-68386b416280", "fitness": 0.09400941316800421, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Implement an adaptive chaotic sequence enhancement to improve exploitation during optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1) + \n                                 chaotic_factor, lower_bound, upper_bound)  # Added global guidance & chaotic factor\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01652.", "error": "", "parent_ids": ["47a4e5ed-fb39-4034-98ff-170ddedbddad"], "operator": null, "metadata": {"aucs": [0.11392320644308307, 0.11392180319612566, 0.11392312873079113, 0.07348328895449163, 0.07348269579330435, 0.07348324901795089, 0.09462278055431084, 0.09462189030130919, 0.09462267552067105]}}
{"id": "1cdc66c8-ec84-406d-a9b6-7d8921001f7a", "fitness": 0.09400873418745531, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introduce an adaptive velocity scaling factor that adjusts based on the global best score improvement rate.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            adaptive_velocity_scaling = 1 + (0.1 * (1 - global_best_score / np.max(personal_best_scores)))  # Line changed\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             1.8 * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             1.8 * r2 * (global_best_position - positions[swarm_indices])) * adaptive_velocity_scaling  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1) + \n                                 chaotic_factor, lower_bound, upper_bound)  # Added global guidance & chaotic factor\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["98a7a557-007c-46f6-9e9d-68386b416280"], "operator": null, "metadata": {"aucs": [0.11392181717112693, 0.11392156410673848, 0.11392208845653629, 0.07348305539845679, 0.0734828084060517, 0.07348327106776187, 0.09462022413259608, 0.09462184898197679, 0.09462192996585284]}}
{"id": "7cbd9d3d-97d9-4dbd-b1ad-5f8e7ee3e8da", "fitness": 0.09400872365076395, "name": "EnhancedAdaptiveMultiSwarmPSODEv3", "description": "Introduce a learning factor to dynamically adjust personal and global best influences in the velocity update.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveMultiSwarmPSODEv3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.3  # Lowered minimum inertia\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.f = 0.6  # Adjusted differential weight\n        self.cr = 0.8  # Adjusted crossover probability\n        self.num_swarms = 3\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.97  # Adjusted chaotic parameter\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n        swarm_size = self.population_size // self.num_swarms\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(upper_bound - lower_bound), abs(upper_bound - lower_bound), \n                                       (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  (0.9 - self.inertia_weight_min) * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * (0.9 - self.inertia_weight_min)\n            self.inertia_weight += chaotic_factor * 0.5\n\n            learning_factor = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Dynamic learning factor\n\n            for k in range(self.num_swarms):\n                swarm_indices = range(k * swarm_size, (k + 1) * swarm_size)\n                r1, r2 = np.random.rand(2, swarm_size, self.dim)\n                velocities[swarm_indices] = (self.inertia_weight * velocities[swarm_indices] +\n                                             learning_factor * r1 * (personal_best_positions[swarm_indices] - positions[swarm_indices]) +\n                                             learning_factor * r2 * (global_best_position - positions[swarm_indices]))  # More balanced learning\n                positions[swarm_indices] = positions[swarm_indices] + velocities[swarm_indices]\n                positions[swarm_indices] = np.clip(positions[swarm_indices], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            self.f = 0.4 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Dynamic F adjustment\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                diversity_factor = np.std(positions) / np.mean(np.abs(positions))  # Adaptive mutation scaling\n                mutant = np.clip(x1 + diversity_factor * self.f * (x2 - x3) + 0.1 * (global_best_position - x1) + \n                                 chaotic_factor, lower_bound, upper_bound)  # Added global guidance & chaotic factor\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, positions[i])\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    positions[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveMultiSwarmPSODEv3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["98a7a557-007c-46f6-9e9d-68386b416280"], "operator": null, "metadata": {"aucs": [0.11392167887741278, 0.11392178851936763, 0.11392145458899394, 0.07348271800540185, 0.07348281449287564, 0.07348272530074973, 0.09462172650306533, 0.09462192278288839, 0.09462168378612024]}}
{"id": "d52aebad-b684-47ca-b93d-bd69eadf000b", "fitness": 0.09400908733663978, "name": "EnhancedDynamicChaoticPSO", "description": "Introduce dynamic population resizing and chaos-enhanced adaptive momentum to improve convergence during optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedDynamicChaoticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30  # Increased initial population size for better exploration\n        self.final_population_size = 10  # Reduced final population size for better exploitation\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4  # Slightly higher minimum inertia for stability\n        self.cognitive_component = 2.0\n        self.social_component = 2.5  # Increased social component for better global search\n        self.cr = 0.7\n        self.chaotic_sequence = self._init_chaotic_sequence()\n\n    def _init_chaotic_sequence(self):\n        chaotic_sequence = np.zeros(self.budget)\n        chaotic_sequence[0] = np.random.rand()\n        r = 3.99  # Slightly increased chaotic parameter for more dynamic search\n        for i in range(1, self.budget):\n            chaotic_sequence[i] = r * chaotic_sequence[i-1] * (1 - chaotic_sequence[i-1])\n        return chaotic_sequence\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lower_bound = func.bounds.lb\n        upper_bound = func.bounds.ub\n\n        positions = np.random.uniform(lower_bound, upper_bound, (self.initial_population_size, self.dim))\n        velocities = np.zeros((self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            inertial_range = self.inertia_weight_max - self.inertia_weight_min\n            self.inertia_weight = self.inertia_weight_min + \\\n                                  inertial_range * (1 - evaluations / self.budget)\n            chaotic_factor = self.chaotic_sequence[evaluations] * 0.5\n\n            population_size = int(self.initial_population_size - \n                                  (self.initial_population_size - self.final_population_size) * \n                                  (evaluations / self.budget))\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(2, self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 chaotic_factor * (global_best_position - positions[i]) +\n                                 self.cognitive_component * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_component * r2 * (global_best_position - positions[i]))\n                positions[i] = positions[i] + velocities[i]\n                positions[i] = np.clip(positions[i], lower_bound, upper_bound)\n\n            scores = np.array([func(x) for x in positions[:population_size]])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = positions[i]\n                    if scores[i] < global_best_score:\n                        global_best_score = scores[i]\n                        global_best_position = positions[i]\n\n            if evaluations < self.budget:\n                best_idx = np.argmin(scores)\n                res = minimize(func, positions[best_idx], bounds=[(lb, ub) for lb, ub in zip(lower_bound, upper_bound)], method='L-BFGS-B')\n                if res.fun < global_best_score:\n                    global_best_score = res.fun\n                    global_best_position = res.x\n                evaluations += res.nfev\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedDynamicChaoticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09401 with standard deviation 0.01651.", "error": "", "parent_ids": ["98a7a557-007c-46f6-9e9d-68386b416280"], "operator": null, "metadata": {"aucs": [0.11392174093036, 0.11392174093036, 0.11392301881588596, 0.07348281269644419, 0.07348281269486345, 0.0734832175884027, 0.09462191648345919, 0.0946219164846328, 0.09462260940534972]}}
