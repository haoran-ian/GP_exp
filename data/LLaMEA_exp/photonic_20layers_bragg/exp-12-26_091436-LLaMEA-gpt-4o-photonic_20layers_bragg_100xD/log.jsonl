{"id": "4f6e3220-f7f3-48e1-93a5-69c5530180bd", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "A dynamically adaptive swarm-based optimization algorithm that leverages local and global search strategies for efficient exploration and exploitation of the search space.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.vel_clamp = 0.1\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_clamp, self.vel_clamp, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 144, in evaluate_gp_func\n    except OverBudgetException:\n  File \"<string>\", line 53, in __call__\n  File \"<string>\", line 30, in update_particles\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n.", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")Traceback (most recent call last):\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 188, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ubuntu/GP_Compare/LLaMEA/llamea/llamea.py\", line 247, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"scripts/5_algorithm_generation.py\", line 144, in evaluate_gp_func\n    except OverBudgetException:\n  File \"<string>\", line 53, in __call__\n  File \"<string>\", line 30, in update_particles\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n", "parent_ids": [], "operator": null, "metadata": {}}
{"id": "e832c244-67af-4c49-a0ae-429e6cb0b520", "fitness": 0.06999160707305425, "name": "AdaptiveSwarmOptimizer", "description": "Enhanced the initialization of global best position to prevent 'NoneType' errors.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.vel_clamp = 0.1\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_clamp, self.vel_clamp, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)  # Initialize global best position\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06999 with standard deviation 0.01011.", "error": "", "parent_ids": ["4f6e3220-f7f3-48e1-93a5-69c5530180bd"], "operator": null, "metadata": {"aucs": [0.055707654344461344, 0.07766729008101592, 0.07659987679368552]}}
{"id": "ecd111a1-aa4a-451e-ad4f-06372595284f", "fitness": 0.07024871473070819, "name": "AdaptiveSwarmOptimizer", "description": "Introducing dynamic adaptation of inertia weight and coefficients based on convergence to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = 0.1\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_clamp, self.vel_clamp, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07025 with standard deviation 0.01003.", "error": "", "parent_ids": ["e832c244-67af-4c49-a0ae-429e6cb0b520"], "operator": null, "metadata": {"aucs": [0.05608369012455505, 0.07793489709727719, 0.07672755697029232]}}
{"id": "2c167362-a1f3-47e8-83b5-e69d4b39651c", "fitness": -Infinity, "name": "SelfAdaptiveSwarmOptimizer", "description": "Introducing self-adaptive population size and velocity update using historical performance to dynamically balance exploration and exploitation in Particle Swarm Optimization.", "code": "import numpy as np\n\nclass SelfAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 30\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = 0.1\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.base_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-self.vel_clamp, self.vel_clamp, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n        \n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n        \n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n        \n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n                \n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        \n        # Adjust population size based on progress\n        self.population_size = int(self.base_population_size + (self.budget // 10) * progress)\n        self.population_size = max(self.population_size, self.base_population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (33,20) (30,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (33,20) (30,20) ')", "parent_ids": ["ecd111a1-aa4a-451e-ad4f-06372595284f"], "operator": null, "metadata": {}}
{"id": "ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb", "fitness": 0.20021487656807171, "name": "AdaptiveSwarmOptimizer", "description": "Introduce velocity clamping based on the dynamic range of each dimension to enhance stability and convergence.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20021 with standard deviation 0.00258.", "error": "", "parent_ids": ["ecd111a1-aa4a-451e-ad4f-06372595284f"], "operator": null, "metadata": {"aucs": [0.19661483003970404, 0.2015089531484845, 0.20252084651602664]}}
{"id": "bc412960-a4cd-43e1-9327-595159609887", "fitness": 0.19906088236535616, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive neighborhood influence for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n        r3 = np.random.rand(self.population_size, self.dim)  # New randomness for neighborhood influence\n        \n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        neighborhood_positions = np.roll(self.population, 1, axis=0)  # New neighborhood influence\n        neighborhood_velocity = 1.5 * r3 * (neighborhood_positions - self.population)  # Added for adaptive influence\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + neighborhood_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19906 with standard deviation 0.00290.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.19646716014149035, 0.1976068636519982, 0.20310862330257995]}}
{"id": "c52e006c-457a-4dea-952c-8f5bcdd016ea", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce an adaptive velocity clamping mechanism based on the standard deviation of particle positions to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        \n        # Adaptive velocity clamping\n        self.vel_clamp = 0.1 * np.std(self.population, axis=0)\n        \n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position[i] = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "7afa84a8-1603-45dd-a0c3-d9ce53538841", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Integrate a dynamic velocity scaling factor to improve exploration during initial iterations and enhance convergence stability.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb) + np.random.rand() * 0.05 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position[i] = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "753c9373-fbe9-4f55-8456-505faaa09d0c", "fitness": 0.1541706229129561, "name": "EnhancedSwarmOptimizer", "description": "Enhance convergence by adapting velocity clamping dynamically based on swarm diversity and using nonlinear inertia weight decay.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n\n        # Dynamically adjust velocity clamping based on swarm diversity\n        swarm_diversity = np.mean(np.std(self.population, axis=0))\n        self.vel_clamp = 0.1 * (swarm_diversity + 1e-5)  # add small value to prevent division by zero\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Nonlinear decay for inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * ((1 - progress) ** 2)\n\n        # Update cognitive and social coefficients\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15417 with standard deviation 0.00526.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.16080937041022814, 0.14795550089370035, 0.1537469974349398]}}
{"id": "8d557f25-6946-4cd8-a210-07c6f409e79a", "fitness": 0.1972549804016818, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive mutation inspired by evolutionary strategies to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.mutation_rate = 0.1  # New mutation rate for exploration\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        # Apply adaptive mutation\n        mutations = np.random.randn(self.population_size, self.dim) * self.mutation_rate\n        self.population += self.velocities + mutations\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n        # Adjust mutation rate based on progress\n        self.mutation_rate = 0.1 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19725 with standard deviation 0.00408.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.19258462601348225, 0.20253108652964547, 0.1966492286619177]}}
{"id": "645b9f50-cb3b-4780-bc37-016c1dcc0c77", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Enhance AdaptiveSwarmOptimizer by introducing a dynamic population size that varies based on convergence progress to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n        # Dynamically adjust population size\n        self.population_size = int(50 + 50 * (1 - progress))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (100,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (100,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "c7c400a7-d31b-43b3-99a2-87cab546e48b", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Integrate adaptive population size adjustment to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.population_size = max(20, int(50 - 30 * progress))  # Adjust population size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "5ceceee8-34d0-4e81-b156-c472fe7371db", "fitness": 0.1600685174787698, "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic velocity clamping and a diversity-driven restart strategy to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        diversity = np.std(self.population, axis=0)\n        self.vel_clamp = 0.1 * (1 + diversity)\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n        if np.std(self.personal_best_scores) < 1e-5:\n            self.initialize_population(func.bounds.lb, func.bounds.ub)\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16007 with standard deviation 0.00907.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.17210239300124353, 0.15022101997421244, 0.1578821394608534]}}
{"id": "f49fe7ac-9594-4411-9096-9753bb37936e", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic population resizing based on convergence progress to balance exploration and exploitation phases more effectively.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.min_population_size = 10\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.population_size = int(self.min_population_size + (self.initial_population_size - self.min_population_size) * (1 - progress))\n        self.population_size = max(self.min_population_size, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "57321f9f-7a50-477d-8f30-4869357f5460", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic population size scaling and adaptive velocity clamping to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 30\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.population_size = int(self.initial_population_size - progress * (self.initial_population_size - self.final_population_size))\n        self.vel_clamp = 0.1 * (func.bounds.ub - func.bounds.lb) * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "679f3905-61f9-4f37-872a-7e3763f61f9f", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic adjustment of population size to enhance exploration and exploitation balance over iterations.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        \n        # Dynamically adjust population size\n        dynamic_population_size = int(self.population_size * (1 + 0.1 * (1 - evaluations / self.budget)))\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.population_size = dynamic_population_size  # Adjust population size\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'evaluations' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'evaluations' referenced before assignment\")", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "6afef0c3-bc3f-46b3-bd27-89cde0e04324", "fitness": 0.19992892091352213, "name": "EnhancedSwarmOptimizer", "description": "Enhance exploration and exploitation phases by introducing an adaptive mutation operator to diversify the search and prevent premature convergence.  ", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.mutation_rate = 0.1\n        self.mutation_factor = 0.05\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def apply_mutation(self):\n        mutation_indices = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n        mutation_values = np.random.normal(0, self.mutation_factor, (self.population_size, self.dim))\n        self.population += mutation_indices * mutation_values\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        self.apply_mutation()\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.mutation_rate = 0.1 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19993 with standard deviation 0.00046.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.19941400551553634, 0.19984753831759916, 0.2005252189074309]}}
{"id": "78ac3043-47cd-45cb-8984-52628eddc299", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity clamping to improve balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.vel_clamp = 0.1 * (1 - evaluations / self.budget) * (ub - lb)\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "7dd0b86a-2b2f-41d5-8de9-29be1f925374", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically updating the population size based on the optimization progress.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.population_size = int(50 * (1 - progress)) + 10  # Dynamically update population size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (60,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (60,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "60614273-b515-4396-9eb2-585e25840cb5", "fitness": 0.18113243010553373, "name": "AdaptiveSwarmOptimizer", "description": "Fine-tune velocity clamping to dynamically adjust and improve convergence stability.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.2 * (ub - lb)  # Increased the velocity clamp factor from 0.1 to 0.2\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18113 with standard deviation 0.00855.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.1919902607032119, 0.17109003615330554, 0.18031699346008379]}}
{"id": "c7a61d83-29a5-45d6-a5b6-db72e11b1975", "fitness": 0.19884711301195235, "name": "AdaptiveSwarmOptimizer", "description": "Integrate adaptive dimensional mutation to improve exploration in high-dimensional spaces.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        \n        # Integrate adaptive dimensional mutation\n        mutation_rate = 0.1 * (1 - (np.linalg.norm(self.velocities.mean(axis=0)) / np.linalg.norm(self.vel_clamp)))\n        mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n        mutation_values = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.population += mutation_mask * mutation_values\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19885 with standard deviation 0.00556.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.20324300071862234, 0.20228887122928063, 0.19100946708795408]}}
{"id": "01085a85-93a7-44dd-9952-643255c34d33", "fitness": 0.1734254929017496, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive learning factors for cognitive and social components based on particle improvement rates to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.last_improvement = np.zeros(self.population_size)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n                self.last_improvement[i] = 0\n            else:\n                self.last_improvement[i] += 1\n\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Dynamic adaptation based on improvement rates\n        improvement_factor = np.clip(1 - self.last_improvement / 10, 0.5, 1.5)  # Adjust factor based on no improvement\n        self.cognitive_coefficient = 2.0 * improvement_factor.mean()\n        self.social_coefficient = 2.0 - self.cognitive_coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17343 with standard deviation 0.00303.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.17289764213551218, 0.17737501365556396, 0.1700038229141727]}}
{"id": "c94d1cf7-5ea5-42b4-866f-5167e0dc71c7", "fitness": 0.19652920316130137, "name": "EnhancedSwarmOptimizer", "description": "Introduce nonlinear inertia weight decay and adaptive cognitive-social balance to improve exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.5\n        self.social_coefficient = 1.5\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (np.cos(np.pi * progress) + 1) / 2\n        self.cognitive_coefficient = 2.5 - 2.0 * progress\n        self.social_coefficient = 0.5 + 2.0 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19653 with standard deviation 0.00252.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.19986481694750136, 0.1937833075544888, 0.19593948498191394]}}
{"id": "e1b12b48-32f4-4909-87ad-67018349d955", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic population size adjustment and adaptive velocity clamping to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        # Adjust population size dynamically\n        self.population_size = max(5, int(50 - 45 * progress))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (48,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (48,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "12ff99ab-ef97-4ed7-a587-344248193321", "fitness": 0.19568758463665648, "name": "AdaptiveNeighborhoodSwarmOptimizer", "description": "Introduce a dynamic neighborhood topology that adapts based on particle performance to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, neighborhood_best_positions):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (neighborhood_best_positions - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        neighborhood_best_positions = np.copy(self.personal_best_positions)\n\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n            # Determine the neighborhood best for this particle\n            neighborhood_indices = np.random.choice(self.population_size, 5, replace=False)\n            best_neighbor = neighborhood_indices[np.argmin(self.personal_best_scores[neighborhood_indices])]\n            neighborhood_best_positions[i] = self.personal_best_positions[best_neighbor]\n\n        return neighborhood_best_positions\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            neighborhood_best_positions = self.evaluate_population(func)\n            self.update_particles(neighborhood_best_positions)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19569 with standard deviation 0.00039.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.1955015379763596, 0.19533684068048396, 0.19622437525312586]}}
{"id": "75964632-f4a2-4356-876a-f118b90d5bf4", "fitness": -Infinity, "name": "EnhancedSwarmOptimizer", "description": "Incorporate adaptive velocity scaling and diversity preservation to improve swarm exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        max_velocity = np.max(np.abs(self.velocities), axis=0)\n        dynamic_velocity_scaling = 1.0 / (1.0 + np.exp(-max_velocity))  # Sigmoid to scale velocities\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities * dynamic_velocity_scaling, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n        # Introduce diversity preservation by re-initializing a portion of the population\n        if progress > 0.5 and np.random.rand() < 0.1:\n            diversity_indices = np.random.choice(self.population_size, size=self.population_size // 5, replace=False)\n            lb, ub = func.bounds.lb, func.bounds.ub\n            self.population[diversity_indices] = np.random.uniform(lb, ub, (len(diversity_indices), self.dim))\n            self.velocities[diversity_indices] = np.random.uniform(-0.1, 0.1, (len(diversity_indices), self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "09e49ada-ff3a-43a3-b413-7fd2756aab6f", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by incorporating a dynamic population size and adaptive velocity clamping based on the current optimization phase.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  \n        self.inertia_min = 0.4  \n        self.cognitive_coefficient = 2.0  \n        self.social_coefficient = 2.0  \n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        phase_factor = (self.global_best_score / np.mean(self.personal_best_scores))\n        self.vel_clamp = 0.1 * (self.vel_clamp * phase_factor)\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n        self.population_size = int(50 - 30 * progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ')", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {}}
{"id": "5d3b279c-d07e-4a13-85fe-1d5440b296f3", "fitness": 0.19398253955072217, "name": "AdaptiveSwarmOptimizer", "description": "Integrate adaptive acceleration and chaotic search mechanism to enhance exploration potential and convergence speed.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.alpha = 0.5  # New parameter for chaotic search\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        # Integrate chaotic search mechanism\n        chaos_term = self.alpha * np.random.rand(self.population_size, self.dim)\n        self.population += self.velocities + chaos_term\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 0.5 + 1.5 * progress\n\n        # Adapt alpha parameter for chaotic search\n        self.alpha = 0.5 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19398 with standard deviation 0.00932.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.2006248231989456, 0.20051900953781665, 0.18080378591540425]}}
{"id": "f2616d07-9b1e-46df-aa72-f26d1c2fe1d7", "fitness": 0.20283495670425078, "name": "AdaptiveSwarmOptimizer", "description": "Adjust social coefficient dynamics to enhance exploitation phase in the latter part of optimization.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9  # Start with a higher inertia\n        self.inertia_min = 0.4  # Minimum inertia weight to ensure convergence\n        self.cognitive_coefficient = 2.0  # Start with higher cognitive coefficient\n        self.social_coefficient = 2.0  # Start with higher social coefficient\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        # Linearly decrease inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n\n        # Update cognitive and social coefficients to focus more on exploration initially and exploitation later\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress  # Adjusted dynamically for better exploitation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20283 with standard deviation 0.00123.", "error": "", "parent_ids": ["ffc1aef5-6adf-44df-aa98-34f1f3fe9fdb"], "operator": null, "metadata": {"aucs": [0.20395332612481354, 0.20342400466096655, 0.20112753932697225]}}
{"id": "c9822882-1025-4cc9-8f00-05e6cf73821a", "fitness": 0.20221033397619104, "name": "EnhancedSwarmOptimizer", "description": "Enhance convergence speed and exploration efficiency by introducing adaptive subgroup dynamics based on fitness diversity and neighborhood bests.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n\n    def adaptive_group_dynamics(self):\n        fitness_variance = np.var(self.personal_best_scores)\n        subgroup_size = self.population_size // 5\n        if fitness_variance > 1e-3:\n            indices = np.argsort(self.personal_best_scores)\n            best_indices = indices[:subgroup_size]\n            for i in range(self.population_size):\n                group_best_position = self.personal_best_positions[best_indices[i % subgroup_size]]\n                self.velocities[i] += 1.0 * (group_best_position - self.population[i])\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.adaptive_group_dynamics()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20221 with standard deviation 0.00547.", "error": "", "parent_ids": ["f2616d07-9b1e-46df-aa72-f26d1c2fe1d7"], "operator": null, "metadata": {"aucs": [0.20466801063582407, 0.20733978062666947, 0.19462321066607957]}}
{"id": "8bdb608e-cf0a-4013-8d24-5a876b3e90aa", "fitness": 0.20304414028834042, "name": "AdaptiveSwarmOptimizer", "description": "Integrate a diversity-maintaining mechanism and adapt velocity clamping for enhanced exploitation and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20304 with standard deviation 0.00165.", "error": "", "parent_ids": ["f2616d07-9b1e-46df-aa72-f26d1c2fe1d7"], "operator": null, "metadata": {"aucs": [0.20516287381389064, 0.2011373942595388, 0.20283215279159184]}}
{"id": "cbbe427a-fb18-44a9-9305-9318919de5ec", "fitness": 0.18951726129109636, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce an adaptive neighborhood topology and dynamically balance exploration-exploitation to enhance global search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.neighborhood_size = 5\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        # Determine local best in neighborhood\n        local_best_positions = np.empty_like(self.personal_best_positions)\n        for i in range(self.population_size):\n            neighbors = self._get_neighborhood(i)\n            best_neighbor_index = min(neighbors, key=lambda idx: self.personal_best_scores[idx])\n            local_best_positions[i] = self.personal_best_positions[best_neighbor_index]\n        \n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (local_best_positions - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        self.population = np.clip(self.population, lb, ub)\n        \n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 1.5 + 0.5 * (1 - progress)\n        self.social_coefficient = 1.5 + 0.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def _get_neighborhood(self, index):\n        neighbors = np.arange(max(0, index - self.neighborhood_size // 2), \n                              min(self.population_size, index + self.neighborhood_size // 2 + 1))\n        return neighbors\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18952 with standard deviation 0.00947.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.17727342746383534, 0.19092517598608016, 0.20035318042337358]}}
{"id": "d6c73bc9-ec19-4086-820d-f2731e2bbf0e", "fitness": 0.18202115489727153, "name": "AdaptiveSwarmOptimizer", "description": "Introduce momentum-based velocity updating to enhance convergence speed in dynamic environments.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = 0.9 * self.velocities + self.inertia_weight * (cognitive_velocity + social_velocity) # Momentum-based velocity update\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18202 with standard deviation 0.01042.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.16898136873903413, 0.1826064971039677, 0.19447559884881271]}}
{"id": "53b2fc20-4243-4d8f-82a5-a2d5ee604cf6", "fitness": 0.20134687196506681, "name": "AdaptiveSwarmOptimizer", "description": "Integrate random reinitialization based on performance indicators to improve adaptive exploration.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles based on performance\n        if np.random.rand() < 0.05:\n            low_performers = self.personal_best_scores > np.median(self.personal_best_scores)\n            random_indices = np.where(low_performers)[0]\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20135 with standard deviation 0.00105.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.2006087758027828, 0.20059968730082578, 0.20283215279159184]}}
{"id": "6e3765e6-e28a-4b34-8048-86ec3a32ed7e", "fitness": 0.20029081389741835, "name": "AdaptiveSwarmOptimizer", "description": "Enhance the AdaptiveSwarmOptimizer by adjusting the probability of diversity maintenance and scaling the velocity range to improve convergence. ", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.15 * (ub - lb)  # Changed from 0.1 to 0.15\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.10:  # Changed from 0.05 to 0.10\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20029 with standard deviation 0.00082.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.19916720302648105, 0.20108130745666986, 0.20062393120910416]}}
{"id": "51beb804-ed05-4da9-a993-b35e72324902", "fitness": 0.20206848439586322, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive learning rates for cognitive and social components based on particle success to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.successful_updates = np.zeros(self.population_size)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n                self.successful_updates[i] += 1\n            else:\n                self.successful_updates[i] = max(0, self.successful_updates[i] - 1)\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        # Adjust learning rates based on individual particle success\n        for i in range(self.population_size):\n            success_factor = 1 + 0.5 * np.tanh(self.successful_updates[i] / 5)\n            self.cognitive_coefficient = 2.0 - 1.5 * progress * success_factor\n            self.social_coefficient = 1.0 + 1.5 * progress * success_factor\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20207 with standard deviation 0.00289.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.20346519590678647, 0.19803957053298948, 0.20470068674781372]}}
{"id": "2650b35e-d879-44eb-bb07-a9da32da4d85", "fitness": 0.20029081389741835, "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration by adjusting inertia weight linearly and reinitializing particles more frequently.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n    \n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly more frequently\n        if np.random.rand() < 0.1:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n    \n    def adapt_parameters(self, progress):\n        # Linearly decrease the inertia weight\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20029 with standard deviation 0.00082.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.19916720302648105, 0.20108130745666986, 0.20062393120910416]}}
{"id": "81a1746a-c50f-4f74-b094-de5720da581c", "fitness": 0.2001863156985614, "name": "MultiPhaseAdaptiveSwarmOptimizer", "description": "Introduce a multi-phase adaptive strategy with phase-specific parameter tuning and differential evolution for enhanced convergence dynamics.", "code": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.phase_threshold = 0.5\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub, progress):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n        \n        if progress < self.phase_threshold:\n            self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n            self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n            self.population += self.velocities\n        else:\n            # Introduce differential evolution strategy in the second phase\n            for i in range(self.population_size):\n                x1, x2, x3 = self.population[np.random.choice(self.population_size, 3, replace=False)]\n                mutant_vector = x1 + 0.5 * (x2 - x3)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                crossover = np.random.rand(self.dim) < 0.9\n                self.population[i] = np.where(crossover, mutant_vector, self.population[i])\n\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub, progress)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm MultiPhaseAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20019 with standard deviation 0.00250.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.2036459898496097, 0.19907832008502224, 0.19783463716105232]}}
{"id": "ee012a61-ab9b-4094-ba05-bd8c061315af", "fitness": 0.20304414028834042, "name": "EnhancedSwarmOptimizer", "description": "Introduce a dynamic diversity-enhancing component and adaptive learning factors to improve convergence and prevent premature stagnation in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Enhance diversity dynamically based on current progress\n        progress = np.mean(self.personal_best_scores) / self.global_best_score\n        diversity_factor = max(0.05, (1 - progress) * 0.1)\n        if np.random.rand() < diversity_factor:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20304 with standard deviation 0.00165.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.20516287381389064, 0.2011373942595388, 0.20283215279159184]}}
{"id": "cb73c960-4d9e-48d7-8f60-419f863609b0", "fitness": 0.19518428142594382, "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence speed by introducing adaptive learning rates for cognitive and social coefficients.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 1.5 + 1.5 * progress  # Updated line 1\n        self.social_coefficient = 1.5 + 1.5 * progress  # Updated line 2\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19518 with standard deviation 0.00076.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.1949921070736791, 0.19619370301494254, 0.19436703418920986]}}
{"id": "a40adc8f-be64-40f8-84b1-c5327f6ba4bf", "fitness": 0.20161992484638058, "name": "AdaptiveSwarmOptimizer", "description": "Enhance the diversity preservation by dynamically adjusting the percentage of particles reinitialized based on optimization progress.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            progress = (self.budget - self.remaining_budget) / self.budget\n            reinit_percent = 0.1 + 0.15 * progress\n            random_indices = np.random.choice(self.population_size, size=int(reinit_percent * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        self.remaining_budget = self.budget\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n            self.remaining_budget -= self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20162 with standard deviation 0.00088.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.20125065771119077, 0.20077696403635914, 0.20283215279159184]}}
{"id": "e2b34dec-56d2-40ad-a1cb-039bdd6f9692", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive reinitialization probability to enhance diversity control.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Adaptive reinitialization for diversity\n        adaptive_reinit_prob = 0.05 + 0.1 * (1 - evaluations / self.budget)\n        if np.random.rand() < adaptive_reinit_prob:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "3af20b00-3fe0-481e-9f61-b62cc99045a3", "fitness": 0.20304414028834042, "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploitation by dynamically adjusting cognitive and social coefficients based on personal best improvement.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                improvement = self.personal_best_scores[i] - score\n                self.cognitive_coefficient *= 1 + 0.01 * improvement  # Change 1\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20304 with standard deviation 0.00165.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.20516287381389064, 0.2011373942595388, 0.20283215279159184]}}
{"id": "98e0f154-6d72-4d8e-b3e8-fbb8574d99f8", "fitness": 0.19432357878916576, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance AdaptiveSwarmOptimizer by introducing a multi-phase strategy for dynamic parameter adjustment and utilizing an elite strategy to safeguard top performers from random reinitialization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.elite_fraction = 0.2  # Fraction of best particles to protect from reinitialization\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity but protect elite particles\n        if np.random.rand() < 0.05:\n            num_protected = int(self.elite_fraction * self.population_size)\n            protected_indices = np.argsort(self.personal_best_scores)[:num_protected]\n            random_indices = np.random.choice(np.setdiff1d(np.arange(self.population_size), protected_indices), size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        phase = int(progress * 3)  # Divide the progress into three phases\n        if phase == 0:  # Exploration phase\n            self.inertia_weight = 0.9\n            self.cognitive_coefficient = 2.5\n            self.social_coefficient = 1.0\n        elif phase == 1:  # Transition phase\n            self.inertia_weight = 0.7\n            self.cognitive_coefficient = 2.0\n            self.social_coefficient = 1.5\n        else:  # Exploitation phase\n            self.inertia_weight = 0.4\n            self.cognitive_coefficient = 1.5\n            self.social_coefficient = 2.5\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19432 with standard deviation 0.00284.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.19087481266519757, 0.1978381257677625, 0.19425779793453724]}}
{"id": "d44722c0-0124-4b63-8cf6-462987415837", "fitness": 0.1987555855309124, "name": "EnhancedSwarmOptimizer", "description": "Enhance swarm exploration with strategic restart and neighborhood learning to improve global search efficiency.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n        # Strategic restart for exploration boost\n        if np.random.rand() < 0.1:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n        \n        # Local learning from neighborhood\n        self.neighborhood_learning(lb, ub)\n\n    def neighborhood_learning(self, lb, ub):\n        for i in range(self.population_size):\n            neighbors = np.random.choice(self.population_size, size=5, replace=False)\n            local_best = min(neighbors, key=lambda idx: self.personal_best_scores[idx])\n            if self.personal_best_scores[local_best] < self.personal_best_scores[i]:\n                direction = self.personal_best_positions[local_best] - self.population[i]\n                self.population[i] += 0.1 * direction\n                self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19876 with standard deviation 0.00354.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.2037057735130563, 0.19560983929437448, 0.19695114378530643]}}
{"id": "cc74ec1c-67a7-4fb5-8b0e-c3c04d34ba21", "fitness": 0.06955420842663902, "name": "EnhancedSwarmOptimizer", "description": "Introduce a dynamic neighborhood strategy and adaptive strategy switching to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.neighborhood_size = 5\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub, progress):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        for i in range(self.population_size):\n            # Determine the neighborhood for dynamic interaction\n            neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n            local_best = neighbors[np.argmin(self.personal_best_scores[neighbors])]\n            neighborhood_best_position = self.personal_best_positions[local_best]\n\n            # Use neighborhood best for social velocity\n            cognitive_velocity = self.cognitive_coefficient * r1[i] * (self.personal_best_positions[i] - self.population[i])\n            social_velocity = self.social_coefficient * r2[i] * (neighborhood_best_position - self.population[i])\n\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n        \n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (self.global_best_position - self.global_best_position)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub, progress)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06955 with standard deviation 0.01038.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.05488578825410739, 0.07729060784148756, 0.07648622918432213]}}
{"id": "f7b57c12-00d3-4ce0-913f-95bf5b5d573e", "fitness": 0.200258533909386, "name": "AdaptiveMultiPopSwarmOptimizer", "description": "Adaptive Multi-Population Swarm Optimizer: Enhance exploration and convergence via a dynamic multi-population strategy and an adaptive diversity mechanism.", "code": "import numpy as np\n\nclass AdaptiveMultiPopSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.sub_population_count = 5\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by introducing sub-populations and perturbations\n        if np.random.rand() < 0.2:\n            for i in range(self.sub_population_count):\n                sub_pop_indices = np.random.choice(self.population_size, size=int(self.population_size / self.sub_population_count), replace=False)\n                self.population[sub_pop_indices] += np.random.uniform(-0.05, 0.05, (len(sub_pop_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveMultiPopSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20026 with standard deviation 0.00210.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.20017756646646268, 0.19772230608834063, 0.20287572917335472]}}
{"id": "b151a879-2b79-4300-b9f0-24e3b68bcd33", "fitness": 0.17814688033456075, "name": "DynamicMultiSwarmOptimizer", "description": "Introduce a dynamic multi-swarm approach with adaptive learning rates and a restart mechanism to enhance convergence efficiency.", "code": "import numpy as np\n\nclass DynamicMultiSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_count = 3\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.swarms = [self.initialize_swarm() for _ in range(self.swarm_count)]\n        self.best_global_position = None\n        self.best_global_score = np.inf\n\n    def initialize_swarm(self):\n        return {\n            'population': None,\n            'velocities': None,\n            'personal_best_positions': None,\n            'personal_best_scores': None,\n            'global_best_position': None,\n            'global_best_score': np.inf\n        }\n    \n    def initialize_population(self, lb, ub, swarm):\n        swarm['population'] = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        swarm['velocities'] = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        swarm['personal_best_positions'] = np.copy(swarm['population'])\n        swarm['personal_best_scores'] = np.full(self.population_size, np.inf)\n        swarm['global_best_position'] = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, swarm, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (swarm['personal_best_positions'] - swarm['population'])\n        social_velocity = self.social_coefficient * r2 * (swarm['global_best_position'] - swarm['population'])\n\n        swarm['velocities'] = self.inertia_weight * swarm['velocities'] + cognitive_velocity + social_velocity\n        swarm['velocities'] = np.clip(swarm['velocities'], -self.vel_clamp, self.vel_clamp)\n\n        swarm['population'] += swarm['velocities']\n        \n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            swarm['population'][random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func, swarm):\n        for i in range(self.population_size):\n            score = func(swarm['population'][i])\n            if score < swarm['personal_best_scores'][i]:\n                swarm['personal_best_scores'][i] = score\n                swarm['personal_best_positions'][i] = swarm['population'][i]\n            if score < swarm['global_best_score']:\n                swarm['global_best_score'] = score\n                swarm['global_best_position'] = swarm['population'][i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        for swarm in self.swarms:\n            self.initialize_population(lb, ub, swarm)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n\n            for swarm in self.swarms:\n                self.update_particles(swarm, lb, ub)\n                self.evaluate_population(func, swarm)\n                \n                if swarm['global_best_score'] < self.best_global_score:\n                    self.best_global_score = swarm['global_best_score']\n                    self.best_global_position = swarm['global_best_position']\n            \n            evaluations += self.swarm_count * self.population_size\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 47, "feedback": "The algorithm DynamicMultiSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17815 with standard deviation 0.00271.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.174867923261375, 0.18150017945828267, 0.17807253828402458]}}
{"id": "4940f9ea-a235-4f8b-adb5-9e02448cf180", "fitness": -Infinity, "name": "AdaptiveDynamicSwarmOptimizer", "description": "Implement a dynamic population resizing and adaptive mutation strategy to balance exploration and exploitation for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation to inject diversity\n        mutation_probability = 0.1 - 0.05 * (self.population_size / self.initial_population_size)\n        if np.random.rand() < mutation_probability:\n            mutation_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[mutation_indices] = np.random.uniform(lb, ub, (len(mutation_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        # Dynamic population resizing\n        self.population_size = int(self.initial_population_size * (1 - 0.5 * progress))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,20) (50,20) ')", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "c486190c-33fc-44ef-af09-815907a801e3", "fitness": -Infinity, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance the adaptive swarm optimizer by incorporating an opposition-based learning mechanism and a self-adaptive velocity coefficient for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Opposition-based learning\n        if np.random.rand() < 0.2:\n            opposition_population = lb + ub - self.population\n            for i in range(self.population_size):\n                opposition_score = func(opposition_population[i])\n                if opposition_score < self.personal_best_scores[i]:\n                    self.population[i] = opposition_population[i]\n        \n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Self-adaptive velocity clamping\n        self.vel_clamp = (0.1 + 0.1 * (1 - progress)) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "9510dd0c-e6bd-4ae7-b363-4afabd74dd09", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic population size mechanism and a learning rate schedule to better adapt exploration and exploitation over generations.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n        \n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        # Introduce dynamic population size and learning rate\n        self.population_size = int(50 + 20 * (1 - progress))\n        self.learning_rate = 0.001 + 0.009 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (70,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (70,20) (50,20) ')", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "e0d477c9-4b30-40bb-8254-3c9c74e72bc3", "fitness": 0.19630036547730803, "name": "CollaborativeAdaptiveSwarmOptimizer", "description": "Introduce multi-swarm collaboration with adaptive inter-swarm communication for enhanced global exploration and local exploitation.", "code": "import numpy as np\n\nclass CollaborativeAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.inter_swarm_communication_rate = 0.05\n        self.num_swarms = 3\n        self.swarms_population = None\n        self.swarms_velocities = None\n        self.swarms_best_positions = None\n        self.swarms_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_swarms(self, lb, ub):\n        self.swarms_population = [np.random.uniform(lb, ub, (self.population_size // self.num_swarms, self.dim))\n                                  for _ in range(self.num_swarms)]\n        self.swarms_velocities = [np.random.uniform(-0.1, 0.1, (self.population_size // self.num_swarms, self.dim))\n                                  for _ in range(self.num_swarms)]\n        self.swarms_best_positions = [np.copy(swarm) for swarm in self.swarms_population]\n        self.swarms_best_scores = [np.full(self.population_size // self.num_swarms, np.inf) for _ in range(self.num_swarms)]\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, swarm_index, lb, ub):\n        r1 = np.random.rand(self.population_size // self.num_swarms, self.dim)\n        r2 = np.random.rand(self.population_size // self.num_swarms, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.swarms_best_positions[swarm_index] - self.swarms_population[swarm_index])\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.swarms_population[swarm_index])\n\n        velocities = self.inertia_weight * self.swarms_velocities[swarm_index] + cognitive_velocity + social_velocity\n        self.swarms_velocities[swarm_index] = np.clip(velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.swarms_population[swarm_index] += self.swarms_velocities[swarm_index]\n        # Occasionally allow inter-swarm communication\n        if np.random.rand() < self.inter_swarm_communication_rate:\n            for i in range(self.num_swarms):\n                if i != swarm_index:\n                    other_swarm_best = self.swarms_best_positions[i][np.argmin(self.swarms_best_scores[i])]\n                    self.swarms_population[swarm_index] = np.where(np.random.rand(self.population_size // self.num_swarms, self.dim) < 0.1,\n                                                                   other_swarm_best,\n                                                                   self.swarms_population[swarm_index])\n\n    def evaluate_population(self, func, swarm_index):\n        for i in range(self.population_size // self.num_swarms):\n            score = func(self.swarms_population[swarm_index][i])\n            if score < self.swarms_best_scores[swarm_index][i]:\n                self.swarms_best_scores[swarm_index][i] = score\n                self.swarms_best_positions[swarm_index][i] = self.swarms_population[swarm_index][i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.swarms_population[swarm_index][i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarms(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n\n            for swarm_index in range(self.num_swarms):\n                self.update_particles(swarm_index, lb, ub)\n                self.evaluate_population(func, swarm_index)\n                evaluations += self.population_size // self.num_swarms\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm CollaborativeAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19630 with standard deviation 0.00551.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.18952670474601796, 0.1963401060680936, 0.20303428561781256]}}
{"id": "b1b15a11-7819-454e-8d7d-1fc66ae28050", "fitness": 0.20295629413494007, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a gradual reduction in the velocity clamping to ensure convergence towards the global best position.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Gradually reduce velocity clamping to ensure convergence\n        self.vel_clamp = (0.1 + 0.05 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20296 with standard deviation 0.00100.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.2042276270435086, 0.20285182688128855, 0.20178942848002301]}}
{"id": "087cfe1d-aa12-48ff-b1be-1b1a8f16b09f", "fitness": -Infinity, "name": "EnhancedSwarmOptimizer", "description": "Introduce a dynamic diversity mechanism based on entropy to enhance particle diversity while incorporating adaptive neighborhood influence for more efficient convergence.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Dynamic diversity mechanism based on entropy\n        if self.calculate_entropy() < 0.7:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def calculate_entropy(self):\n        probabilities, _ = np.histogramdd(self.population, bins=10)\n        probabilities = probabilities / probabilities.sum()\n        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9))  # Add small value to avoid log(0)\n        return entropy\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "An exception occurred: ValueError('invalid dims: array size defined by dims is larger than the maximum possible size.').", "error": "ValueError('invalid dims: array size defined by dims is larger than the maximum possible size.')", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "c3a730ec-54c3-4014-a033-a2c301ecf955", "fitness": -Infinity, "name": "EnhancedSwarmOptimizer", "description": "Combine adaptive particle swarm optimization with a local search mechanism to enhance exploitation and convergence speed.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n        # Apply local search around the best solution occasionally\n        if np.random.rand() < 0.1:\n            perturbation = np.random.normal(0, 0.01, self.dim)\n            candidate = self.global_best_position + perturbation\n            candidate = np.clip(candidate, lb, ub)  # Ensure candidate is within bounds\n            candidate_score = func(candidate)\n            if candidate_score < self.global_best_score:\n                self.global_best_score = candidate_score\n                self.global_best_position = candidate\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {}}
{"id": "46d2cb47-33f4-4db9-bc79-ac0f55f1008d", "fitness": 0.183010332133665, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Implement a learning mechanism that adapts swarm behavior based on particle success to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.success_learning_rate = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n                # Learning mechanism: adapt coefficients based on success\n                self.cognitive_coefficient = max(1.0, self.cognitive_coefficient - self.success_learning_rate)\n                self.social_coefficient = min(3.0, self.social_coefficient + self.success_learning_rate)\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18301 with standard deviation 0.00685.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.17563427059877945, 0.19212977920344765, 0.18126694659876785]}}
{"id": "7e7ae067-1d42-4a88-bf74-8fab30bcd05c", "fitness": 0.20497183245266426, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a neighborhood learning strategy to enhance local exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Introduce neighborhood learning\n        neighborhood_indices = np.random.choice(self.population_size, size=self.population_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (neighborhood_best - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20497 with standard deviation 0.00355.", "error": "", "parent_ids": ["8bdb608e-cf0a-4013-8d24-5a876b3e90aa"], "operator": null, "metadata": {"aucs": [0.2025531206111939, 0.20998554447850926, 0.20237683226828962]}}
{"id": "995c5fdd-f0cc-424a-9bfd-85a6054440dc", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Enhance swarm diversity and convergence by introducing dynamic neighborhood size and hybrid exploration strategies.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Introduce dynamic neighborhood learning\n        neighborhood_size = np.random.randint(1, self.population_size // 4)\n        neighborhood_indices = np.random.choice(self.population_size, size=self.population_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices[:neighborhood_size]]\n        neighborhood_velocity = 0.6 * r1 * (neighborhood_best - self.population[:neighborhood_size])\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.07:  # Slightly increased chance for diversification\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,20) (2,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,20) (2,20) ')", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {}}
{"id": "472d069f-9916-490c-a270-6af2bc412b1d", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic neighborhood size adjustment to enhance local search adaptively.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Introduce neighborhood learning with dynamic size\n        neighborhood_size = max(1, int(self.population_size * 0.05))  # Dynamic neighborhood size\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (neighborhood_best - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (2,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (2,20) (50,20) ')", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {}}
{"id": "f37718b8-95fa-4392-9e3f-c9df7afa0ab6", "fitness": 0.20378620650526438, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Incorporate adaptive learning rates and memory-based diversity to enhance global search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.memory = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        neighborhood_indices = np.random.choice(self.population_size, size=self.population_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (neighborhood_best - self.population)\n\n        memory_velocity = 0\n        if self.memory:\n            memory_best = np.min(self.memory, axis=0)\n            memory_velocity = 0.3 * np.random.rand(self.population_size, self.dim) * (memory_best - self.population)\n\n        self.velocities = (self.inertia_weight * self.velocities + cognitive_velocity + \n                           social_velocity + neighborhood_velocity + memory_velocity)\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n            self.memory.append(self.population[i])\n            if len(self.memory) > 100:\n                self.memory.pop(0)\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20379 with standard deviation 0.00359.", "error": "", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {"aucs": [0.20770799586107758, 0.20462579041838946, 0.19902483323632614]}}
{"id": "5ba5d321-06fe-47ed-a965-28299901d3f1", "fitness": 0.20396227530582392, "name": "AdaptiveSwarmOptimizer", "description": "Introduce an adaptive mutation rate to enhance exploration capabilities of particles.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Introduce neighborhood learning\n        neighborhood_indices = np.random.choice(self.population_size, size=self.population_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (neighborhood_best - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        self.velocities += np.random.normal(0, (0.1 * progress), self.velocities.shape)  # Introduce adaptive mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20396 with standard deviation 0.00734.", "error": "", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {"aucs": [0.2111548324468463, 0.2068452368347523, 0.19388675663587318]}}
{"id": "27678493-0673-4eaf-a7fd-ed1a16b5d5c1", "fitness": 0.15345136966484815, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Implement a dynamic neighborhood learning strategy with adaptive diversity control to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub, progress):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic neighborhood learning\n        neighborhood_size = int(0.1 * self.population_size) + int(0.3 * self.population_size * (1 - progress))\n        neighborhood_indices = np.array([np.random.choice(self.population_size, size=neighborhood_size, replace=False) \n                                         for _ in range(self.population_size)])\n        neighborhood_best = self.personal_best_positions[neighborhood_indices].min(axis=1)\n        neighborhood_velocity = 0.5 * r1 * (neighborhood_best - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n        self.population += self.velocities\n\n        # Adaptive diversity control\n        diversity_threshold = 0.05 + 0.05 * progress\n        if np.random.rand() < diversity_threshold:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub, progress)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15345 with standard deviation 0.01718.", "error": "", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {"aucs": [0.14179779157942296, 0.14081731293105937, 0.1777390044840621]}}
{"id": "ef4b78a3-ee86-42f7-bd3f-470505c42350", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive neighborhood learning by scaling neighborhood influence based on evaluation progress.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Introduce adaptive neighborhood learning\n        neighborhood_indices = np.random.choice(self.population_size, size=self.population_size, replace=True)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = (0.5 * r1 * (neighborhood_best - self.population)) * (1 - evaluations / self.budget)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {}}
{"id": "4a0e8a7e-73d0-4d89-8e4e-ddb623503487", "fitness": 0.20994205865867907, "name": "AdaptiveSwarmOptimizer", "description": "Enhance global exploration via dynamic neighborhood learning to improve the algorithm's convergence behavior.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20994 with standard deviation 0.00311.", "error": "", "parent_ids": ["7e7ae067-1d42-4a88-bf74-8fab30bcd05c"], "operator": null, "metadata": {"aucs": [0.21321705188167428, 0.20576163431690653, 0.21084748977745638]}}
{"id": "cd82e209-ebf0-47e0-81ac-a45f648a739f", "fitness": 0.20852133164246958, "name": "EnhancedSwarmOptimizer", "description": "Integrate adaptive mutation strategies with multi-swarm coordination to bolster exploration and convergence in diverse search landscapes.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.mutation_probability = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic neighborhood and mutation\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation strategy\n        mutation_indices = np.random.rand(self.population_size) < self.mutation_probability\n        for i in np.where(mutation_indices)[0]:\n            self.population[i] += np.random.normal(0, 0.1, self.dim) * (ub - lb)\n\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        self.mutation_probability = 0.1 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20852 with standard deviation 0.00130.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.2067010613572403, 0.20924532169594012, 0.20961761187422834]}}
{"id": "70f5a979-741e-43cb-b1e0-5e6d873b70d3", "fitness": 0.2085124658818237, "name": "AdaptiveSwarmOptimizer", "description": "Improve convergence by introducing adaptive random restarts and enhancing neighborhood learning for diverse exploration.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, max(2, self.population_size // 3))  # Line 1 change\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by more frequent adaptive random restarts\n        if np.random.rand() < 0.1:  # Line 2 change\n            random_indices = np.random.choice(self.population_size, size=int(0.2 * self.population_size), replace=False)  # Line 3 change\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20851 with standard deviation 0.00203.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.20657122074531198, 0.20764752418338472, 0.2113186527167744]}}
{"id": "632a1e8e-f5e7-4154-a3d8-8e1f63286fe6", "fitness": 0.20752364308667406, "name": "MemoryAdaptiveSwarmOptimizer", "description": "Introduce a memory-based adaptive inertia and velocity strategy to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass MemoryAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.previous_best_scores = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n        self.previous_best_scores.append(self.global_best_score)\n\n    def adapt_parameters(self, progress):\n        if len(self.previous_best_scores) > 2:\n            improvement = self.previous_best_scores[-2] - self.previous_best_scores[-1]\n            adapt_factor = max(0, improvement) / (1 + abs(self.previous_best_scores[-2]))\n        else:\n            adapt_factor = 0.1\n\n        self.inertia_weight = max(self.inertia_min, self.inertia_weight - adapt_factor * 0.1)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm MemoryAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20752 with standard deviation 0.00326.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.21101839048542903, 0.20317474015201475, 0.20837779862257844]}}
{"id": "8561308f-17b6-4e46-84e9-08be55f3f561", "fitness": 0.18209238609891024, "name": "MultiSwarmOptimizer", "description": "Utilize an adaptive multi-swarm strategy with dynamic regrouping to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass MultiSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.swarms = 3\n        self.inertia_weight = 0.9\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.populations = [None] * self.swarms\n        self.velocities = [None] * self.swarms\n        self.personal_best_positions = [None] * self.swarms\n        self.personal_best_scores = [None] * self.swarms\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        for swarm in range(self.swarms):\n            self.populations[swarm] = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            self.velocities[swarm] = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n            self.personal_best_positions[swarm] = np.copy(self.populations[swarm])\n            self.personal_best_scores[swarm] = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n    \n    def update_particles(self, swarm):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions[swarm] - self.populations[swarm])\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.populations[swarm])\n\n        # Regroup swarm particles randomly to maintain diversity\n        if np.random.rand() < 0.1:\n            shuffle_indices = np.random.permutation(self.population_size)\n            self.populations[swarm] = self.populations[swarm][shuffle_indices]\n            self.velocities[swarm] = self.velocities[swarm][shuffle_indices]\n\n        self.velocities[swarm] = self.inertia_weight * self.velocities[swarm] + cognitive_velocity + social_velocity\n        self.velocities[swarm] = np.clip(self.velocities[swarm], -self.vel_clamp, self.vel_clamp)\n\n        self.populations[swarm] += self.velocities[swarm]\n        # Randomly reinitialize a fraction of the particles\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.populations[swarm][random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func, swarm):\n        for i in range(self.population_size):\n            score = func(self.populations[swarm][i])\n            if score < self.personal_best_scores[swarm][i]:\n                self.personal_best_scores[swarm][i] = score\n                self.personal_best_positions[swarm][i] = self.populations[swarm][i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.populations[swarm][i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = 0.9 - 0.5 * progress\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Dynamic velocity clamping\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            for swarm in range(self.swarms):\n                self.update_particles(swarm)\n                self.evaluate_population(func, swarm)\n                evaluations += self.population_size\n                if evaluations >= self.budget:\n                    break\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm MultiSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18209 with standard deviation 0.00446.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.18084597040703188, 0.17736662639038636, 0.1880645614993125]}}
{"id": "52c8ce9a-9755-44c7-a683-d372786d450c", "fitness": 0.20316153074335982, "name": "AdaptiveSwarmOptimizerWithMutation", "description": "Introduce a self-adaptive mutation strategy to enhance local exploitation and prevent premature convergence in swarm optimization.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizerWithMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.mutation_prob = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        # Apply mutation strategy\n        mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_prob\n        mutation_effect = np.random.normal(0, 1, (self.population_size, self.dim)) * mutation_mask\n        self.population += self.velocities + mutation_effect\n        self.population = np.clip(self.population, lb, ub)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        self.mutation_prob = 0.1 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm AdaptiveSwarmOptimizerWithMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20316 with standard deviation 0.00787.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.2072253117365601, 0.19215745629433845, 0.2101018241991809]}}
{"id": "68ea007d-78f2-41ca-8f55-c763e53e0b00", "fitness": 0.20602309682853445, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a momentum term in velocity update to improve convergence speed in the AdaptiveSwarmOptimizer.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.momentum = 0.1  # Introduce momentum\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity + self.momentum * self.velocities\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20602 with standard deviation 0.00130.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.20670930661041564, 0.20715911781948215, 0.20420086605570553]}}
{"id": "4aa033de-49ef-4ba3-ad5d-b1d31a6b22e5", "fitness": 0.20680112148619442, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce adaptive learning rates and memory-based resampling to improve exploitation and convergent stability in swarm optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.memory = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Adaptive learning rate based on progress\n        learning_rate = 0.5 + 0.5 * np.random.rand(self.dim)\n\n        # Enhanced neighborhood learning with memory-based resampling\n        if len(self.memory) > 0:\n            memory_velocity = 0.5 * np.random.rand() * (np.mean(self.memory, axis=0) - self.population)\n        else:\n            memory_velocity = np.zeros_like(self.population)\n\n        self.velocities = self.inertia_weight * self.velocities * learning_rate + cognitive_velocity + social_velocity + memory_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        self.population = np.clip(self.population, lb, ub)\n\n        # Maintain diversity by reinitializing based on memory\n        if np.random.rand() < 0.05 and len(self.memory) > 0:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.array(self.memory)[np.random.choice(len(self.memory), size=len(random_indices), replace=True)]\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = np.copy(self.population[i])\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = np.copy(self.population[i])\n        self.memory.append(np.copy(self.global_best_position))\n        if len(self.memory) > 5:  # Limit the memory size\n            self.memory.pop(0)\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20680 with standard deviation 0.00295.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.20774885802122467, 0.20280410023510997, 0.2098504062022486]}}
{"id": "9461ff5c-441a-424f-9c04-7af0ce78f9d0", "fitness": 0.20917351124308028, "name": "AdaptiveSwarmOptimizer", "description": "Integrate adaptive mutation rate to improve exploration in dynamic regions of the search space.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n        # Mutate a randomly chosen individual to enhance exploration\n        if np.random.rand() < 0.1:\n            mutation_index = np.random.randint(self.population_size)\n            self.population[mutation_index] += np.random.normal(0, 0.1, self.dim)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20917 with standard deviation 0.00285.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.205233468142609, 0.21185850712745247, 0.2104285584591794]}}
{"id": "22c620dc-155c-4297-8dc3-0bbbcd3f3c11", "fitness": 0.19885472145722413, "name": "HybridParticleOptimizer", "description": "Hybrid Particle Optimization integrates learning from historical convergence patterns to accelerate exploration and convergence efficiency.", "code": "import numpy as np\nfrom collections import deque\n\nclass HybridParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.convergence_history = deque(maxlen=5)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Historical learning from convergence patterns\n        historical_best = np.mean(self.convergence_history, axis=0) if self.convergence_history else self.global_best_position\n        historical_velocity = 0.3 * np.random.rand(self.population_size, self.dim) * (historical_best - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + historical_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n                self.convergence_history.append(self.global_best_position)\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HybridParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19885 with standard deviation 0.00556.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.2059935763930444, 0.19813429014946538, 0.1924362978291626]}}
{"id": "ee713271-98a2-42ef-b4c4-e166f6786e87", "fitness": 0.20889117175894087, "name": "AdaptiveSwarmOptimizer", "description": "Improve local search capability by introducing a perturbation strategy on individual positions.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n        \n        # Introduce a perturbation strategy on individual positions\n        perturbation = 0.01 * np.random.normal(size=self.population.shape)\n        self.population += perturbation\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20889 with standard deviation 0.00077.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.2080352287363011, 0.20989387615789967, 0.20874441038262181]}}
{"id": "1d3af587-3d21-4ac5-8db4-a68cdfff05bc", "fitness": -Infinity, "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic population size and adaptive neighborhood strategy to enhance convergence by balancing exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.05:\n            random_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n        # Dynamic population adjustment\n        if np.random.rand() < 0.1:\n            self.population_size = max(20, self.population_size + np.random.randint(-5, 5))\n            self.population = np.resize(self.population, (self.population_size, self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,20) (47,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,20) (47,20) ')", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {}}
{"id": "e8e655d2-47e8-48a6-ac82-cc6004ee9a79", "fitness": 0.212378904259538, "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive neighborhood size and diversity mechanism to improve convergence and solution quality.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Maintain diversity by reinitializing some particles randomly\n        if np.random.rand() < 0.1:  # Adjusted reinitialization probability\n            random_indices = np.random.choice(self.population_size, size=int(0.2 * self.population_size), replace=False)  # Adjusted number of particles\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21238 with standard deviation 0.00152.", "error": "", "parent_ids": ["4a0e8a7e-73d0-4d89-8e4e-ddb623503487"], "operator": null, "metadata": {"aucs": [0.2142351081412317, 0.2105014763428643, 0.21240012829451804]}}
{"id": "75f5b72f-17bd-42b2-bb41-4f20b0ceac24", "fitness": -Infinity, "name": "DynamicSwarmOptimizer", "description": "Introduce dynamic population size and adaptive multi-objective balancing for improved exploration-exploitation trade-off in swarm optimization.", "code": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.initial_population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.initial_population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        if np.random.rand() < 0.1:\n            random_indices = np.random.choice(self.population_size, size=int(0.2 * self.population_size), replace=False)\n            self.population[random_indices] = np.random.uniform(lb, ub, (len(random_indices), self.dim))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        # Dynamically adjust population size\n        self.population_size = int(self.initial_population_size * (1.0 + 0.5 * np.sin(np.pi * progress)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (51,20) (50,20) ').", "error": "ValueError('operands could not be broadcast together with shapes (51,20) (50,20) ')", "parent_ids": ["e8e655d2-47e8-48a6-ac82-cc6004ee9a79"], "operator": null, "metadata": {}}
{"id": "fc1c3122-48a8-40d7-a9d7-43833f5896a5", "fitness": 0.2004623292134469, "name": "AdaptiveTurbulenceOptimizer", "description": "Introduce adaptive turbulence and energy mechanism to enhance exploration and exploitation balance and improve convergence rates.", "code": "import numpy as np\n\nclass AdaptiveTurbulenceOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.turbulence_factor = 0.05\n        self.energy_level = np.ones(self.population_size)\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        random_turbulence = self.turbulence_factor * np.random.randn(self.population_size, self.dim) * self.energy_level[:, np.newaxis]\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + random_turbulence\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n        # Update energy levels to maintain diversity dynamically\n        self.energy_level = 1 + 0.5 * np.sin(np.pi * np.linspace(0, 1, self.population_size))\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n        # Scale turbulence factor based on progress\n        self.turbulence_factor = 0.05 + 0.1 * (1 - progress)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveTurbulenceOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20046 with standard deviation 0.00290.", "error": "", "parent_ids": ["e8e655d2-47e8-48a6-ac82-cc6004ee9a79"], "operator": null, "metadata": {"aucs": [0.20175686283429306, 0.19643869354337895, 0.2031914312626687]}}
{"id": "de1e3613-ace9-44b9-b36c-764bbdad5ffa", "fitness": 0.2126708614424939, "name": "AdaptiveSwarmOptimizer", "description": "Strengthen global exploration and dynamic adaptation by introducing an elite-guided strategy and adaptive mutation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Elite-guided mutation for global exploration\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.1\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21267 with standard deviation 0.00157.", "error": "", "parent_ids": ["e8e655d2-47e8-48a6-ac82-cc6004ee9a79"], "operator": null, "metadata": {"aucs": [0.2114640191282149, 0.21165524757722365, 0.2148933176220431]}}
{"id": "36f752be-705a-40d6-be65-a29d5a9dcb23", "fitness": 0.2126708614424939, "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic elite-guided mutation probability to enhance exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Elite-guided mutation for global exploration\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < (0.05 + 0.05):  # Adjusting mutation probability dynamically\n            mutation_strength = np.random.rand() * 0.1\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21267 with standard deviation 0.00157.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.2114640191282149, 0.21165524757722365, 0.2148933176220431]}}
{"id": "3f8a972e-5d9c-4fc4-9c5a-2c817ec8d38f", "fitness": 0.21089182834647371, "name": "AdaptiveSwarmOptimizer", "description": "Introduce stochastic perturbation to enhance diversity in particle exploration.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Elite-guided mutation for global exploration\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.1\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n        # Introduce stochastic perturbation\n        if np.random.rand() < 0.05: \n            perturbation_strength = np.random.randn(self.population_size, self.dim) * 0.01\n            self.population += perturbation_strength\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21089 with standard deviation 0.00202.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.2106839900114741, 0.2134676560398988, 0.20852383898804827]}}
{"id": "e38d8849-b80a-4381-998d-730decebee31", "fitness": -Infinity, "name": "EnhancedSwarmOptimizer", "description": "Introduce a diversity-preserving mechanism with opposition-based learning to enhance convergence speed and solution quality in particle swarm optimization.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Neighborhood learning with dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        # Apply opposition-based learning\n        opposition_positions = lb + ub - self.population\n        for i in range(self.population_size):\n            if np.random.rand() < 0.5:\n                self.population[i] = np.where(func(opposition_positions[i]) < func(self.population[i]), \n                                              opposition_positions[i], self.population[i])\n\n        self.population += self.velocities\n\n        # Elite-guided mutation for global exploration\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.1\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress, lb, ub):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress, lb, ub)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {}}
{"id": "1e208dec-bf4c-4e87-afba-592a28178522", "fitness": 0.2069340077194868, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Introduce a multi-phase exploration-exploitation strategy with adaptive neighborhood influence and elite-guided mutation to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Advanced neighborhood learning with adaptive influence\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_influence = np.random.rand() * 0.5\n        neighborhood_velocity = neighborhood_influence * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Enhanced elite-guided mutation for robust global exploration\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.2  # Increased mutation strength\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Dynamic adaptation of velocity clamping\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20693 with standard deviation 0.00090.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.20732298230543944, 0.20778533960851586, 0.20569370124450514]}}
{"id": "34bf4f10-0f7e-462d-95d0-6909bc011f0a", "fitness": 0.21017646306644341, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance convergence by integrating a dynamic leader selection mechanism and adaptive exploration strategy for improved search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.mutation_probability = 0.1\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic neighborhood-induced velocity\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Dynamic leader selection for enhanced mutation\n        leader_index = np.random.choice(np.argsort(self.personal_best_scores)[:5])\n        leader_position = self.personal_best_positions[leader_index]\n        if np.random.rand() < self.mutation_probability:\n            mutation_strength = np.random.rand() * 0.1\n            self.population += mutation_strength * (leader_position - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21018 with standard deviation 0.00010.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.21023676736102392, 0.2100341306549326, 0.2102584911833737]}}
{"id": "07eae9e6-ed79-402a-a957-6ca0f5d01058", "fitness": 0.1952362735253428, "name": "EnhancedSwarmOptimizer", "description": "Enhance global exploration and exploitation by introducing velocity chaos injection and adaptive elite diversity mechanism.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def chaotic_map(self, x):\n        # Logistic map for chaos injection\n        return 4.0 * x * (1.0 - x)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Enhance neighborhood learning by considering a dynamic neighborhood\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        # Chaotic velocity injection for exploration\n        chaos_factor = np.random.rand(self.population_size, self.dim)\n        chaos_injection = self.chaotic_map(chaos_factor) * (self.vel_clamp / 10)\n        self.velocities += chaos_injection\n\n        self.population += self.velocities\n\n        # Adaptive elite diversity mechanism for exploration and exploitation\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.1\n            elite_mean = np.mean(elite_positions, axis=0)\n            diversity_factor = np.random.rand() * (np.max(elite_positions, axis=0) - np.min(elite_positions, axis=0))\n            self.population += mutation_strength * (elite_mean + diversity_factor - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19524 with standard deviation 0.00132.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.1971035262036288, 0.19422433526202754, 0.19438095911037212]}}
{"id": "a3fc7057-6746-4b36-9de5-222c1f7f9883", "fitness": 0.14021061668636, "name": "AdaptiveSwarmOptimizer", "description": "Refine global exploration by adding adaptive scaling to elite-guided mutation.", "code": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        neighborhood_size = np.random.randint(1, self.population_size // 2)\n        neighborhood_indices = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n        neighborhood_best = self.personal_best_positions[neighborhood_indices]\n        neighborhood_velocity = 0.5 * r1 * (np.mean(neighborhood_best, axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + neighborhood_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        elite_indices = np.argsort(self.personal_best_scores)[:5]\n        elite_positions = self.personal_best_positions[elite_indices]\n        if np.random.rand() < 0.1:\n            mutation_strength = np.random.rand() * 0.1 * (1 - np.mean(self.personal_best_scores) / self.global_best_score)  # Change 1\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)  # Change 2\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14021 with standard deviation 0.09914.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.0, 0.2100735577567805, 0.2105582923022995]}}
{"id": "6a8cba14-2355-4a01-a6ba-fb070c0e96ca", "fitness": 0.21346103373910644, "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhance swarm optimization with a hybrid adaptive mutation strategy and local leader-based learning for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Local leader-based learning\n        local_leaders = np.argsort(self.personal_best_scores)[:self.population_size // 5]\n        local_leader_velocity = r1 * (np.mean(self.personal_best_positions[local_leaders], axis=0) - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity + local_leader_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Hybrid adaptive mutation for global exploration\n        mutation_prob = 0.1 + 0.2 * (1.0 - self.global_best_score / np.min(self.personal_best_scores + 1e-9))\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = np.argsort(self.personal_best_scores)[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21346 with standard deviation 0.00164.", "error": "", "parent_ids": ["de1e3613-ace9-44b9-b36c-764bbdad5ffa"], "operator": null, "metadata": {"aucs": [0.21142444253191306, 0.21352123889039687, 0.2154374197950094]}}
{"id": "e41a6b0b-35fc-4ad9-a7ff-6b60cdbf6f9f", "fitness": 0.09092275544391089, "name": "RefinedAdaptiveSwarmOptimizer", "description": "Enhance swarm optimization with time-varying adaptive coefficients, diversity preservation through clustering, and enhanced mutation for improved convergence and exploration.", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass RefinedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        self.velocities = self.inertia_weight * self.velocities + cognitive_velocity + social_velocity\n        self.velocities = np.clip(self.velocities, -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Enhanced mutation strategy\n        mutation_prob = 0.15\n        if np.random.rand() < mutation_prob:\n            kmeans = KMeans(n_clusters=3, n_init=1)\n            clusters = kmeans.fit_predict(self.population)\n            cluster_centers = kmeans.cluster_centers_\n            for i in range(self.population_size):\n                cluster_center = cluster_centers[clusters[i]]\n                mutation_strength = np.random.rand() * 0.1\n                self.population[i] += mutation_strength * (cluster_center - self.population[i])\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.5 - 1.5 * progress\n        self.social_coefficient = 1.5 + 1.5 * progress\n        # Adapt velocity clamping dynamically\n        self.vel_clamp = (0.1 + 0.1 * progress) * (self.vel_clamp)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm RefinedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09092 with standard deviation 0.01495.", "error": "", "parent_ids": ["6a8cba14-2355-4a01-a6ba-fb070c0e96ca"], "operator": null, "metadata": {"aucs": [0.06977717283746387, 0.10137676658441486, 0.10161432690985395]}}
{"id": "733d1989-80bd-433c-80e7-7a54e35e26bb", "fitness": 0.21487831345630348, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Introduce dynamic local neighborhood learning and adaptive mutation based on convergence speed to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic local neighborhood learning\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation based on convergence speed\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21488 with standard deviation 0.00061.", "error": "", "parent_ids": ["6a8cba14-2355-4a01-a6ba-fb070c0e96ca"], "operator": null, "metadata": {"aucs": [0.21445675119737984, 0.21443646758498924, 0.21574172158654137]}}
{"id": "2287b282-cfab-455d-b319-7b06c53f0a0f", "fitness": 0.21192683842545398, "name": "RefinedDynamicNeighborhoodSwarmOptimizer", "description": "Enhance dynamic neighborhood learning with elite-guided learning and introduce phase-based parameter adaptation to optimize exploration and exploitation phases. ", "code": "import numpy as np\n\nclass RefinedDynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        elite_indices = sorted_indices[:5]  # Top 5 elites\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            elite_guided_velocity = r2[i] * (np.mean(self.personal_best_positions[elite_indices], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] +\n                                  local_leader_velocity + elite_guided_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        if progress < 0.5:\n            self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress * 2)\n            self.cognitive_coefficient = 2.5 - 2.0 * progress\n            self.social_coefficient = 0.5 + 2.0 * progress\n        else:\n            self.inertia_weight = self.inertia_min\n            self.cognitive_coefficient = 1.0 + progress\n            self.social_coefficient = 2.5 - 1.5 * progress\n        self.vel_clamp = (0.1 + 0.2 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm RefinedDynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21193 with standard deviation 0.00263.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.20821629871846203, 0.21398315227057008, 0.2135810642873298]}}
{"id": "e393fa1c-d2b5-49ad-93f0-95c849db31e5", "fitness": -Infinity, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Enhance swarm diversity by introducing leader diversity and adaptive velocity clamping to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic local neighborhood learning\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation based on convergence speed\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n        # Introduce leader diversity\n        if np.random.rand() < 0.1:\n            new_leader = np.random.choice(elite_indices)\n            self.global_best_position = self.personal_best_positions[new_leader]\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        # Adaptive velocity clamping\n        self.vel_clamp = (0.1 + 0.15 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'elite_indices' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'elite_indices' referenced before assignment\")", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {}}
{"id": "686b690e-308d-4d78-bf57-faa1141ce0b4", "fitness": 0.0, "name": "AdaptivePrioritySwarmOptimizer", "description": "Enhance exploration-exploitation balance through adaptive particle prioritization and diversified influence regions based on convergence trends.", "code": "import numpy as np\n\nclass AdaptivePrioritySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.diversification_factor = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, lb, ub):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        for i in range(self.population_size):\n            cognitive_velocity = self.cognitive_coefficient * r1[i] * (self.personal_best_positions[i] - self.population[i])\n            social_velocity = self.social_coefficient * r2[i] * (self.global_best_position - self.population[i])\n\n            # Adaptive priority based on personal best scores\n            priority = (self.personal_best_scores.max() - self.personal_best_scores[i]) / (self.personal_best_scores.max() - self.personal_best_scores.min() + 1e-9)\n            inertia_weighted_velocity = self.inertia_weight * self.velocities[i]\n            self.velocities[i] = inertia_weighted_velocity + priority * (cognitive_velocity + social_velocity)\n\n            # Diversification influence based on convergence trends\n            if np.random.rand() < self.diversification_factor:\n                random_displacement = np.random.uniform(-1, 1, self.dim)\n                self.velocities[i] += 0.2 * np.abs(ub - lb) * random_displacement\n\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n            self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.diversification_factor = 0.05 + 0.45 * progress\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles(lb, ub)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptivePrioritySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.00000 with standard deviation 0.00000.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.0]}}
{"id": "337b4cd7-8442-49b1-a7e4-7b8031a0b69e", "fitness": 0.2127193461888878, "name": "MultiPhaseDynamicSwarmOptimizer", "description": "Integrate a multi-phase dynamic adaptation mechanism to progressively refine the search strategy, enhancing both exploration and convergence precision.", "code": "import numpy as np\n\nclass MultiPhaseDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self, phase):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic local neighborhood learning with phase-based adaptation\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation based on phase\n        if phase == 1:  # Exploration phase\n            mutation_prob = 0.4\n        elif phase == 2:  # Exploitation phase\n            mutation_prob = 0.2\n        else:  # Refinement phase\n            mutation_prob = 0.1\n\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            if progress < 0.33:\n                phase = 1\n            elif progress < 0.67:\n                phase = 2\n            else:\n                phase = 3\n\n            self.adapt_parameters(progress)\n            self.update_particles(phase)\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm MultiPhaseDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21272 with standard deviation 0.00246.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.2155428597569321, 0.2095370678714712, 0.21307811093826012]}}
{"id": "3c13b6e9-8876-424a-9642-aefbe562f2db", "fitness": 0.06969363398991428, "name": "EnhancedDispersalSwarmOptimizer", "description": "Enhance diversity through bio-inspired dispersal patterns and adaptive velocity scaling with dynamic exploration-exploitation trade-off adjustment.", "code": "import numpy as np\n\nclass EnhancedDispersalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Bio-inspired dispersal pattern\n        alpha = 0.1\n        dispersal = alpha * np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        # Adaptive velocity scaling based on population diversity\n        diversity = np.std(self.population, axis=0)\n        velocity_scaling = 1 / (1 + 10 * diversity)\n        \n        for i in range(self.population_size):\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] +\n                                  dispersal[i]) * velocity_scaling\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = 0.9 - 0.5 * progress\n        self.cognitive_coefficient = 2.0 - 1.0 * progress\n        self.social_coefficient = 1.5 + 0.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedDispersalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06969 with standard deviation 0.01041.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.055003774707064856, 0.07794220398635243, 0.07613492327632554]}}
{"id": "537fa55d-2650-4c3c-8806-e6bab0130867", "fitness": 0.16712696610325106, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Enhance convergence by adjusting mutation strength based on population diversity.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic local neighborhood learning\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation based on convergence speed\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.std(self.population) * 0.1 # Adjusted line\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16713 with standard deviation 0.04932.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.21258167546243512, 0.09858707287847757, 0.1902121499688405]}}
{"id": "b520c272-261a-41ed-b9f6-24c3f105187f", "fitness": 0.12615482185319116, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting mutation strength and velocity clamping based on personal best score variance.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        mutation_strength = np.std(self.personal_best_scores) * 0.1  # Changed line\n        if np.random.rand() < mutation_prob:\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (np.std(self.personal_best_scores) + 1e-9)  # Changed line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12615 with standard deviation 0.01589.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.14602537285447303, 0.1253119368042821, 0.10712715590081834]}}
{"id": "6ce964eb-a787-4e38-b31c-0639e943dd23", "fitness": 0.21284748774470894, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Introduce elite position re-evaluation and adaptive inertia weight initialization to enhance convergence speed.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        # Change 1: Adaptive inertia weight initialization\n        self.inertia_weight = np.random.uniform(0.4, 0.9)  \n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            # Change 2: Elite position re-evaluation\n            elite_indices = sorted_indices[:3]  \n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21285 with standard deviation 0.00023.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.21294645508273635, 0.21252891047051592, 0.2130670976808745]}}
{"id": "6ff6fc59-d7d4-4d53-a12c-a377fd0ee7d0", "fitness": 0.21302247758326356, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Introduce a velocity diversity mechanism to maintain diversity and prevent premature convergence.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n            # Introduce velocity diversity mechanism\n            self.velocities[i] += 0.05 * np.random.uniform(-1, 1, self.dim)\n\n        self.population += self.velocities\n\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21302 with standard deviation 0.00031.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.21263489981261163, 0.21338767374184375, 0.21304485919533533]}}
{"id": "b4709db1-8c18-4fc1-b0d9-765b0b2d977a", "fitness": 0.21392673541990592, "name": "EnhancedSwarmOptimizer", "description": "Enhance swarm optimization by incorporating a feedback mechanism for dynamic parameter tuning based on historical performance trends to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.performance_history = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.1 + 0.4 * (1.0 - convergence_speed)\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n        self.performance_history.append(self.global_best_score)\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        historical_improvement = np.mean(self.performance_history[-10:]) if len(self.performance_history) > 10 else 0\n        self.cognitive_coefficient = max(1.5, 2.0 - 0.5 * historical_improvement)\n        self.social_coefficient = 1.0 + 0.5 * historical_improvement\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21393 with standard deviation 0.00223.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.21451210935410403, 0.21095302156465523, 0.2163150753409585]}}
{"id": "ad28e84f-9f7d-4f5f-9770-8c2e710e2bcf", "fitness": 0.21469741400056222, "name": "DynamicNeighborhoodSwarmOptimizer", "description": "Enhance exploration-exploitation with a refined adaptive mutation probability formula.", "code": "import numpy as np\n\nclass DynamicNeighborhoodSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.inertia_min = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.vel_clamp = None\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.population)\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = np.random.uniform(lb, ub, self.dim)\n        self.vel_clamp = 0.1 * (ub - lb)\n\n    def update_particles(self):\n        r1 = np.random.rand(self.population_size, self.dim)\n        r2 = np.random.rand(self.population_size, self.dim)\n\n        cognitive_velocity = self.cognitive_coefficient * r1 * (self.personal_best_positions - self.population)\n        social_velocity = self.social_coefficient * r2 * (self.global_best_position - self.population)\n\n        # Dynamic local neighborhood learning\n        sorted_indices = np.argsort(self.personal_best_scores)\n        for i in range(self.population_size):\n            neighbors = sorted_indices[max(0, i - 2):min(self.population_size, i + 3)]\n            local_leader_velocity = r1[i] * (np.mean(self.personal_best_positions[neighbors], axis=0) - self.population[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity[i] + social_velocity[i] + local_leader_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -self.vel_clamp, self.vel_clamp)\n\n        self.population += self.velocities\n\n        # Adaptive mutation based on convergence speed\n        convergence_speed = np.std(self.personal_best_scores) / (np.mean(self.personal_best_scores) + 1e-9)\n        mutation_prob = 0.2 + 0.3 * (1.0 - convergence_speed)  # Adjusted line\n        if np.random.rand() < mutation_prob:\n            mutation_strength = np.random.rand() * 0.1\n            elite_indices = sorted_indices[:5]\n            elite_positions = self.personal_best_positions[elite_indices]\n            self.population += mutation_strength * (np.mean(elite_positions, axis=0) - self.population)\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            score = func(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i]\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i]\n\n    def adapt_parameters(self, progress):\n        self.inertia_weight = self.inertia_min + (0.9 - self.inertia_min) * (1 - progress)\n        self.cognitive_coefficient = 2.0 - 1.5 * progress\n        self.social_coefficient = 1.0 + 1.5 * progress\n        self.vel_clamp = (0.1 + 0.1 * progress) * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n\n        evaluations = 0\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            self.adapt_parameters(progress)\n            self.update_particles()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm DynamicNeighborhoodSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21470 with standard deviation 0.00065.", "error": "", "parent_ids": ["733d1989-80bd-433c-80e7-7a54e35e26bb"], "operator": null, "metadata": {"aucs": [0.2143551765961048, 0.21412779430759965, 0.21560927109798222]}}
