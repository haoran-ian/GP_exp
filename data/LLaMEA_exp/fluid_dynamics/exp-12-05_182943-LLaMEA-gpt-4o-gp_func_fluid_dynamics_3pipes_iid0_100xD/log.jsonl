{"id": "2d35bf1d-8795-4776-a4d0-b175387f3736", "fitness": 0.06856157430408334, "name": "HybridDE_SA", "description": "A hybrid metaheuristic combining Differential Evolution and Simulated Annealing for diverse exploration and focused exploitation in complex search spaces.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 0, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06469506813233006, 0.06469506813233006, 0.06469506813233006, 0.06355515927695765, 0.06355515927695765, 0.06355515927695765, 0.07743449550296233, 0.07743449550296233, 0.07743449550296233]}}
{"id": "372deb2d-6b61-4535-af32-582c3944042f", "fitness": 0.06016281472673165, "name": "HybridDE_SA_Adaptive", "description": "An enhanced hybrid metaheuristic algorithm combining Differential Evolution, Simulated Annealing, and adaptive cooling for improved convergence in complex search spaces.", "code": "import numpy as np\n\nclass HybridDE_SA_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate\n        self.F = 0.9  # Adjusted scaling factor\n        self.CR = 0.85  # Adjusted crossover probability\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance with adaptive cooling\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                    self.cooling_rate = max(0.9, self.cooling_rate * 1.01)  # Adaptive cooling rate adjustment\n\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 1, "feedback": "The algorithm HybridDE_SA_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["2d35bf1d-8795-4776-a4d0-b175387f3736"], "operator": null, "metadata": {"aucs": [0.06456113234463035, 0.06456113234463035, 0.06456113234463035, 0.05308115297809879, 0.05308115297809879, 0.05308115297809879, 0.0628461588574658, 0.0628461588574658, 0.0628461588574658]}}
{"id": "3b076672-174a-4ec9-91fe-9e7119404bab", "fitness": 0.06766618713679158, "name": "HybridDE_SA_Enhanced", "description": "Enhanced hybrid metaheuristic combining Differential Evolution with adaptive Simulated Annealing for improved convergence.", "code": "import numpy as np\n\nclass HybridDE_SA_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0  # Changed the variable name for clarity\n        self.cooling_rate = 0.95  # Adjusted cooling rate for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Initialize temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate  # Apply cooling\n\n        return best_solution", "configspace": "", "generation": 2, "feedback": "The algorithm HybridDE_SA_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["2d35bf1d-8795-4776-a4d0-b175387f3736"], "operator": null, "metadata": {"aucs": [0.06094470402355101, 0.06094470402355101, 0.06094470402355101, 0.06355515927695765, 0.06355515927695765, 0.06355515927695765, 0.0784986981098661, 0.0784986981098661, 0.0784986981098661]}}
{"id": "a0f6ca99-fbc1-46be-9c90-3ad68177f0de", "fitness": 0.06766618713679158, "name": "HybridDE_SA", "description": "Improved exploration by modifying the cooling rate dynamically based on the best fitness found.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            self.temperature *= (self.cooling_rate + 0.01 * ((best_fitness - fitness.mean()) / (fitness.std() + 1e-9)))\n\n        return best_solution", "configspace": "", "generation": 3, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["2d35bf1d-8795-4776-a4d0-b175387f3736"], "operator": null, "metadata": {"aucs": [0.06094470402355101, 0.06094470402355101, 0.06094470402355101, 0.06355515927695765, 0.06355515927695765, 0.06355515927695765, 0.0784986981098661, 0.0784986981098661, 0.0784986981098661]}}
{"id": "54c1250d-8a75-4c5c-a8fc-10f42e6f920c", "fitness": 0.06856157430408334, "name": "HybridDE_SA", "description": "Refining the acceptance probability in Simulated Annealing to enhance convergence toward optimal solutions.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / (self.temperature + 1e-10)):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            self.temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 4, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["2d35bf1d-8795-4776-a4d0-b175387f3736"], "operator": null, "metadata": {"aucs": [0.06469506813233006, 0.06469506813233006, 0.06469506813233006, 0.06355515927695765, 0.06355515927695765, 0.06355515927695765, 0.07743449550296233, 0.07743449550296233, 0.07743449550296233]}}
{"id": "fbd052b4-af74-4f03-98b6-02e3a428236e", "fitness": 0.09612726234113407, "name": "HybridDE_SA", "description": "Enhanced Hybrid DE-SA with adaptive cooling and strategic population mutation for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)  # Reduced number of distinct individuals\n                c = np.random.choice(idxs)  # Ensure three unique indices\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 5, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["2d35bf1d-8795-4776-a4d0-b175387f3736"], "operator": null, "metadata": {"aucs": [0.09288894588905405, 0.09288894588905405, 0.09288894588905405, 0.08410236715642816, 0.08410236715642816, 0.08410236715642816, 0.11139047397792001, 0.11139047397792001, 0.11139047397792001]}}
{"id": "20fdd572-896a-4ed2-a8cb-76c1a9532df8", "fitness": 0.09612726234113407, "name": "HybridDE_SA", "description": "Small adjustment in the cooling rate for enhanced simulated annealing convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.985  # Slightly adjusted for potentially better convergence\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)  # Reduced number of distinct individuals\n                c = np.random.choice(idxs)  # Ensure three unique indices\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 6, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["fbd052b4-af74-4f03-98b6-02e3a428236e"], "operator": null, "metadata": {"aucs": [0.09288894588905405, 0.09288894588905405, 0.09288894588905405, 0.08410236715642816, 0.08410236715642816, 0.08410236715642816, 0.11139047397792001, 0.11139047397792001, 0.11139047397792001]}}
{"id": "79e87de5-f23f-43c8-9858-03406b4dbf38", "fitness": 0.05915457414149761, "name": "HybridDE_SA", "description": "Fine-tuned Hybrid DE-SA with adjusted mutation strategy for precise exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b = np.random.choice(idxs, 2, replace=False)  # Reduced number of distinct individuals\n                c = np.random.choice(idxs)  # Ensure three unique indices\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)  # Adjusted mutation strategy\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 7, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["fbd052b4-af74-4f03-98b6-02e3a428236e"], "operator": null, "metadata": {"aucs": [0.0609877282332969, 0.0609877282332969, 0.0609877282332969, 0.05262177883528474, 0.05262177883528474, 0.05262177883528474, 0.06385421535591118, 0.06385421535591118, 0.06385421535591118]}}
{"id": "6c875948-3b63-497b-ba83-f871f4d3a151", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Improved mutation strategy and cooling scheme for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 8, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["fbd052b4-af74-4f03-98b6-02e3a428236e"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "9147fc29-4a53-4ac6-95af-b97ac84376c7", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhance exploration via adaptive differential weight strategy.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                adaptive_F = self.F * (1 - evaluations / self.budget)  # Adaptive differential weight\n                mutant = np.clip(a + adaptive_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 9, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "00ab753e-1d27-4656-b56c-a634b75fc706", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration via adaptive crossover probability for improved performance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                # Change: Adapt CR based on temperature\n                adaptive_CR = self.CR * (temperature / self.initial_temperature)\n                trial = np.where(np.random.rand(self.dim) < adaptive_CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 10, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "34691004-e29d-4698-b4a6-67b34f6ffe0e", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Fine-tuned initial temperature for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.5  # Adjusted initial temperature for better exploration\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 11, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "55492eaf-cebf-485e-83f7-9cc2eb87e027", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting the mutation factor for better diversity in population.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.85  # Modified mutation factor for better exploration\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 12, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "9367d501-2cd5-4c88-9322-33df7b394ac8", "fitness": 0.10116676597675785, "name": "HybridDE_SA", "description": "Introduced a dynamic crossover rate to adaptively enhance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                self.CR = 0.8 + 0.2 * (1 - evaluations / self.budget)  # Dynamic CR\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 13, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09722498220168274, 0.09722498220168274, 0.09722498220168274, 0.08754031731070155, 0.08754031731070155, 0.08754031731070155, 0.11873499841788926, 0.11873499841788926, 0.11873499841788926]}}
{"id": "7a082b5d-16ae-4970-9a4f-4e16d52057a9", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Refined mutation strategy by adjusting the differential weight (F) dynamically for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adjusted to dynamically vary F\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 14, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "7987805d-88fc-42a2-adff-b79fe04ef22b", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Fine-tuned control parameter for mutation to enhance convergence speed.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.7  # Adjusted mutation factor for better convergence\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 15, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "4c49fb2a-f40e-43e9-9a7d-0e89da4d2ee9", "fitness": 0.09654375802605923, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting the crossover probability dynamically based on iterations.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                \n                # Adjust crossover probability dynamically\n                self.CR = 0.9 * (1 - evaluations / self.budget)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 16, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09320982697439717, 0.09320982697439717, 0.09320982697439717, 0.08432424493889512, 0.08432424493889512, 0.08432424493889512, 0.11209720216488539, 0.11209720216488539, 0.11209720216488539]}}
{"id": "bd8b164e-5c4a-4ae9-b170-ab23d5f2c331", "fitness": 0.1012312937552033, "name": "HybridDE_SA", "description": "Improved exploration by adjusting the crossover rate dynamically based on fitness diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            fitness_std = np.std(fitness)  # Calculate fitness diversity\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                adaptive_CR = self.CR + (fitness_std / 10)  # Adjust CR based on diversity\n                trial = np.where(np.random.rand(self.dim) < adaptive_CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 17, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0972859573890913, 0.0972859573890913, 0.0972859573890913, 0.08759331601468467, 0.08759331601468467, 0.08759331601468467, 0.11881460786183395, 0.11881460786183395, 0.11881460786183395]}}
{"id": "4e18efe1-585b-4164-b2bd-8751d1cdfa31", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced mutation scaling for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.85  # Modified mutation factor for improved search\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 18, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "176ac40b-4763-457d-a02f-d254af3ef562", "fitness": 0.06766618713679158, "name": "HybridDE_SA", "description": "Enhanced mutation diversity and selection pressure for improved convergence efficiency. ", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)  # Enhanced mutation diversity\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 19, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.06094470402355101, 0.06094470402355101, 0.06094470402355101, 0.06355515927695765, 0.06355515927695765, 0.06355515927695765, 0.0784986981098661, 0.0784986981098661, 0.0784986981098661]}}
{"id": "5c89cebd-79c5-4b91-81a6-718af8ba14d2", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced mutation scaling factor for better diversity and convergence in HybridDE_SA.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.9  # Adjusted for better exploration\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 20, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "de39a552-6360-4686-ab66-ca256bab04f4", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Introduced adaptive cooling rate based on iteration to improve convergence speed while maintaining diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= (self.cooling_rate + 0.02 * evaluations / self.budget)  # Change: adaptive cooling rate\n\n        return best_solution", "configspace": "", "generation": 21, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "9c497e4b-59d8-48c7-b1ac-2b7b445ab71e", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration through adjusted mutation scaling factor.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.9  # Adjusted mutation scaling factor for better exploration\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 22, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "5c66bf48-936a-4786-8e46-b0ce7f3ce9fb", "fitness": 0.09794009077745691, "name": "HybridDE_SA", "description": "Enhanced exploration by dynamically adjusting the mutation factor.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                self.F = 0.5 + 0.3 * np.random.rand()  # Dynamically adjust mutation factor\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 23, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09431117289798252, 0.09431117289798252, 0.09431117289798252, 0.08518237874027978, 0.08518237874027978, 0.08518237874027978, 0.11432672069410843, 0.11432672069410843, 0.11432672069410843]}}
{"id": "7d97b117-930e-45e8-9f08-4dfc9fc7da16", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration and convergence through adjusted mutation factor and adaptive cooling.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.93  # Adjusted for more adaptive cooling\n        self.F = 0.85  # Slightly increased mutation factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 24, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "e89aa1c9-c77c-4b5a-b2ed-a3df89b7677e", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Adjusted mutation factor dynamically based on fitness diversity for improved exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Dynamic adjustment of F based on population fitness diversity\n                self.F = 0.5 + 0.3 * np.std(fitness) / np.mean(fitness)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 25, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "26313a33-eb1a-4d14-b7f4-26b37992d95f", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Fine-tuned mutation factor for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.85  # Adjusted mutation factor for improved performance\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 26, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "e9204dc0-78ec-4472-a795-7cb0b6eb60a5", "fitness": 0.09469956970629496, "name": "HybridDE_SA", "description": "Introduced a dynamic crossover rate adjustment to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9  # Base crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                \n                # Dynamic crossover rate adjustment\n                dynamic_CR = self.CR * (1 - evaluations / self.budget) + 0.1 * (evaluations / self.budget)\n                trial = np.where(np.random.rand(self.dim) < dynamic_CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 27, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0915963065954204, 0.0915963065954204, 0.0915963065954204, 0.08302676882508919, 0.08302676882508919, 0.08302676882508919, 0.10947563369837532, 0.10947563369837532, 0.10947563369837532]}}
{"id": "c0ae3fd0-0e5c-4f4d-a871-30e9f30362fe", "fitness": 0.09506882063698092, "name": "HybridDE_SA", "description": "Introduced a random scaling factor in population initialization for improved exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim)) * np.random.uniform(0.9, 1.1, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 28, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09205765814821187, 0.09205765814821187, 0.09205765814821187, 0.08330526103044933, 0.08330526103044933, 0.08330526103044933, 0.10984354273228158, 0.10984354273228158, 0.10984354273228158]}}
{"id": "e9cd99df-8144-4bb9-a31c-4bc072b86e01", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced mutation scaling and cooling strategy for improved convergence efficiency.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.93  # Adjusted cooling rate for improved convergence\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 29, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "4af73951-7c0a-440d-a113-bfa459fa2cbf", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting mutation factor dynamically based on iterations.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                self.F = 0.5 + 0.3 * (evaluations / self.budget)  # Dynamic adjustment of mutation factor\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 30, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "7c4c60a0-6f8b-4152-98af-f4b3d2fe4abe", "fitness": 0.09794009077745691, "name": "HybridDE_SA", "description": "Enhanced exploration using dynamic scaling factor adjustment in Differential Evolution.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                dynamic_F = self.F * (0.5 + np.random.rand() / 2)  # Dynamic scaling factor adjustment\n                mutant = np.clip(a + dynamic_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 31, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09431117289798252, 0.09431117289798252, 0.09431117289798252, 0.08518237874027978, 0.08518237874027978, 0.08518237874027978, 0.11432672069410843, 0.11432672069410843, 0.11432672069410843]}}
{"id": "b731f994-9c97-4b84-8e42-d9e3e6c37d05", "fitness": 0.1006717635396746, "name": "HybridDE_SA", "description": "Refined cooling scheme and mutation parameters for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.92  # Adjusted cooling rate for better temperature control\n        self.F = 0.9  # Slightly increased mutation factor for better diversity\n        self.CR = 0.85  # Adjusted crossover rate for more robust exploration\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 32, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0967960482215735, 0.0967960482215735, 0.0967960482215735, 0.08719702644676941, 0.08719702644676941, 0.08719702644676941, 0.11802221595068085, 0.11802221595068085, 0.11802221595068085]}}
{"id": "832bdf40-f6bc-4eb5-9332-966315408ece", "fitness": 0.06294193869395959, "name": "HybridDE_SA", "description": "Enhanced hybrid strategy with adaptive population size and mutation scaling for improved performance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = max(5, int(8 * dim))  # Changed population size formula\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.93  # Changed for even slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            new_population_size = max(5, int(self.population_size * (1 - evaluations / self.budget)))  # Adaptive pop size\n            population = population[:new_population_size]\n            fitness = fitness[:new_population_size]\n\n            for i in range(new_population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(new_population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 33, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.06355744906585448, 0.06355744906585448, 0.06355744906585448, 0.05738683465111338, 0.05738683465111338, 0.05738683465111338, 0.0678815323649109, 0.0678815323649109, 0.0678815323649109]}}
{"id": "c04ac1a4-6ae4-45b4-99f6-77b1b9fa82f4", "fitness": 0.1006717635396746, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting crossover probability (CR) for diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.85  # Adjusted crossover probability for diversity\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 34, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0967960482215735, 0.0967960482215735, 0.0967960482215735, 0.08719702644676941, 0.08719702644676941, 0.08719702644676941, 0.11802221595068085, 0.11802221595068085, 0.11802221595068085]}}
{"id": "69a9b6cd-a22a-4168-9397-e1816937a760", "fitness": 0.09469956970629496, "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA with adaptive cooling and mutation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.90  # Adjusted cooling rate for better balance\n        self.F = 0.9  # Increased mutation factor for better exploration\n        self.CR = 0.8  # Slightly reduced crossover rate for diversity\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate * (0.5 + 0.5 * evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution", "configspace": "", "generation": 35, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0915963065954204, 0.0915963065954204, 0.0915963065954204, 0.08302676882508919, 0.08302676882508919, 0.08302676882508919, 0.10947563369837532, 0.10947563369837532, 0.10947563369837532]}}
{"id": "764a6627-eb9e-4b1e-8467-9fcca07a0b4f", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced mutation strategy with self-adaptive control parameters for improved convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution with self-adaptive control parameters\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = 0.5 + 0.3 * np.tanh((evaluations / self.budget - 0.5) * 10)  # Self-adaptive scaling factor\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 36, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "ec00dc21-77a9-492c-9955-3229c684f3a1", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced HybridDE_SA with adaptive mutation factor to improve exploitation and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                self.F = 0.5 + 0.5 * best_fitness / (best_fitness + 1e-9)  # Adaptive mutation factor\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 37, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "6996e1b7-8f67-453a-a137-ce4288912a06", "fitness": 0.1006717635396746, "name": "HybridDE_SA", "description": "Optimized exploration and convergence by adjusting mutation scaling and crossover rates.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.85  # Adjusted mutation scaling factor\n        self.CR = 0.85  # Adjusted crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 38, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0967960482215735, 0.0967960482215735, 0.0967960482215735, 0.08719702644676941, 0.08719702644676941, 0.08719702644676941, 0.11802221595068085, 0.11802221595068085, 0.11802221595068085]}}
{"id": "4568a0f9-b80f-49da-b63d-c4c0bd5d8f5f", "fitness": 0.1001865991444822, "name": "HybridDE_SA", "description": "Enhanced exploitation and adaptivity using dynamic parameters and elitism strategy.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.9  # Adjusted cooling rate for faster cooling\n        self.F = 0.5 + np.random.rand() * 0.3  # Dynamic F\n        self.CR = 0.8 + np.random.rand() * 0.2  # Dynamic CR\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n            # Elitism strategy: Preserve the best solution in the population\n            if np.min(fitness) > best_fitness:\n                worst_idx = np.argmax(fitness)\n                population[worst_idx] = best_solution\n                fitness[worst_idx] = best_fitness\n\n        return best_solution", "configspace": "", "generation": 39, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0972839756879067, 0.0972839756879067, 0.09453584523159841, 0.08759151305374402, 0.08759151305374402, 0.08536832134606454, 0.11881187064167065, 0.11881187064167065, 0.11440050695603421]}}
{"id": "60bd2b29-19ff-42f2-a507-4d0cd3c4695b", "fitness": 0.0919086638494877, "name": "HybridDE_SA", "description": "Adjusted population dynamics and mutation for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased for better diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.9  # Modified for stronger mutation effect\n        self.CR = 0.8  # Lowered for increased trial variation\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 40, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.08904605043031866, 0.08904605043031866, 0.08904605043031866, 0.0809067859942465, 0.0809067859942465, 0.0809067859942465, 0.10577315512389796, 0.10577315512389796, 0.10577315512389796]}}
{"id": "dc050d7a-6df5-4a2e-8705-584310efe135", "fitness": 0.09794009077745691, "name": "HybridDE_SA_Improved", "description": "Adaptive mutation factor and population resizing for improved convergence and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.9  # Slightly increased cooling rate\n        self.F = 0.5  # Adaptive mutation factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                adaptive_F = self.F + (0.5 * np.random.rand())\n                mutant = np.clip(a + adaptive_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            if evaluations % (self.budget // 4) == 0 and self.population_size > 5:\n                self.population_size = max(5, self.population_size // 2)  # Reduce population size over time\n                population = population[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 41, "feedback": "The algorithm HybridDE_SA_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09431117289798252, 0.09431117289798252, 0.09431117289798252, 0.08518237874027978, 0.08518237874027978, 0.08518237874027978, 0.11432672069410843, 0.11432672069410843, 0.11432672069410843]}}
{"id": "428455a9-a10e-4ef8-8a71-89fdcdc3c7c9", "fitness": 0.1006717635396746, "name": "HybridDE_SA", "description": "Refined crossover rate for enhanced exploration and convergence. ", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.85  # Changed crossover rate for better convergence\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 42, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0967960482215735, 0.0967960482215735, 0.0967960482215735, 0.08719702644676941, 0.08719702644676941, 0.08719702644676941, 0.11802221595068085, 0.11802221595068085, 0.11802221595068085]}}
{"id": "11c58938-38b1-46c1-bdd5-74b4ac75f650", "fitness": 0.094773435337324, "name": "HybridDE_SA", "description": "Integrating adaptive parameter control and elitism to enhance convergence and robustness of the hybrid algorithm.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive F parameter\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                    self.CR = 0.6 + 0.3 * np.random.rand()  # Adaptive CR parameter\n\n            temperature *= self.cooling_rate\n            elite_idx = np.argmin(fitness)  # Elitism: ensure the best is retained\n            if fitness[elite_idx] < best_fitness:\n                best_solution = population[elite_idx]\n                best_fitness = fitness[elite_idx]\n\n        return best_solution", "configspace": "", "generation": 43, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0916004555942822, 0.0916004555942822, 0.0916004555942822, 0.08296452430079426, 0.08296452430079426, 0.08296452430079426, 0.10975532611689554, 0.10975532611689554, 0.10975532611689554]}}
{"id": "0b20bde0-e5a2-47df-ae2d-a91706d13552", "fitness": 0.0901760451571018, "name": "HybridDE_SA", "description": "Enhanced local search by adjusting F and CR dynamically based on evaluations.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                self.F = 0.5 + 0.5 * (evaluations / self.budget)  # Dynamic F adjustment\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                self.CR = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic CR adjustment\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 44, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.08756752278606694, 0.08756752278606694, 0.08756752278606694, 0.07973174520470638, 0.07973174520470638, 0.07973174520470638, 0.10322886748053206, 0.10322886748053206, 0.10322886748053206]}}
{"id": "fecfd4d0-929d-47e1-acdf-8d196cb843f8", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting F dynamically and refined cooling strategy for better convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.97  # Adjusted for refined cooling strategy\n        self.F = 0.5  # Changed for better initial exploration\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adjust F over time for balance between exploration and exploitation\n                F_dynamic = self.F + (0.3 * (1 - evaluations / self.budget))  # Dynamic F adjustment\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 45, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "07d3fd82-dafd-4166-888a-ed9b39ff27ae", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Fine-tuning parameter values to balance exploration and exploitation in HybridDE_SA.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.92  # Slightly faster cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 46, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "888c818b-329f-4064-991f-c52a93b4b1b4", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting mutation factor based on fitness diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adjust mutation factor based on fitness diversity\n                self.F = 0.5 + 0.3 * (np.std(fitness) / (np.mean(fitness) + 1e-8))\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 47, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "cbbf6392-b802-46b8-b317-e24a1144c8ac", "fitness": 0.1006717635396746, "name": "HybridDE_SA", "description": "Slightly adjusted differential weight and crossover rate for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.85  # Adjusted for better exploration-exploitation balance\n        self.CR = 0.85  # Adjusted for better exploration-exploitation balance\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 48, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.0967960482215735, 0.0967960482215735, 0.0967960482215735, 0.08719702644676941, 0.08719702644676941, 0.08719702644676941, 0.11802221595068085, 0.11802221595068085, 0.11802221595068085]}}
{"id": "1b54d7bc-2176-4052-b8e2-3e0be22a4804", "fitness": 0.08909680376492361, "name": "HybridDE_SA", "description": "HybridDE_SA with adaptive mutation scaling and elitist selection for improved convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n        self.elite_fraction = 0.1  # New parameter for elitist selection\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution with adaptive scaling\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                adapt_F = self.F * np.random.rand()  # Adaptive mutation scaling\n                mutant = np.clip(a + adapt_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            # Elitist selection\n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]\n            for idx in elite_indices:\n                population[idx] *= 1 + 0.01 * np.random.randn(self.dim)  # Slight perturbation for exploration\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 49, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.08506559903731814, 0.08506559903731814, 0.08506559903731814, 0.08260379370877924, 0.08260379370877924, 0.08260379370877924, 0.09962101854867345, 0.09962101854867345, 0.09962101854867345]}}
{"id": "9d746296-a687-4370-90ec-ae6344b3e48b", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Enhanced exploration and exploitation balance with adaptive population size scaling.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            self.population_size = max(4, int(self.population_size * 0.99))  # Adaptive population size scaling\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 50, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "39946d9e-836c-4674-b5a2-77e42fcc2d24", "fitness": 0.09467907186558218, "name": "HybridDE_SA", "description": "Introduced adaptive control parameters for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Changed for slower cooling\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature  # Corrected to use initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)  # Ensuring unique indices for better diversity\n                F_adaptive = self.F * (1 - evaluations / self.budget)  # Adaptive F\n                mutant = np.clip(a + F_adaptive * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                CR_adaptive = self.CR * (1 - evaluations / self.budget)  # Adaptive CR\n                trial = np.where(np.random.rand(self.dim) < CR_adaptive, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 51, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09157696898714895, 0.09157696898714895, 0.09157696898714895, 0.08301005416735907, 0.08301005416735907, 0.08301005416735907, 0.10945019244223853, 0.10945019244223853, 0.10945019244223853]}}
{"id": "59f839a9-974c-4a4b-af13-701b658991a0", "fitness": 0.09467103143700333, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting the crossover rate dynamically based on population diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            # Calculate diversity for dynamic CR adjustment\n            diversity = np.std(population, axis=0).mean()\n            self.CR = 0.9 - 0.5 * (diversity / (self.upper_bound - self.lower_bound))\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 52, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.09156951731712559, 0.09156951731712559, 0.09156951731712559, 0.083003006796318, 0.083003006796318, 0.083003006796318, 0.10944057019756637, 0.10944057019756637, 0.10944057019756637]}}
{"id": "dd291037-34d1-42ef-befe-9cbcb62460b7", "fitness": 0.10213694563780054, "name": "HybridDE_SA", "description": "Enhanced exploration by increasing population diversity and dynamic scaling factor adjustment.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 53, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["6c875948-3b63-497b-ba83-f871f4d3a151"], "operator": null, "metadata": {"aucs": [0.10706070431952452, 0.10273726359883961, 0.10273726359883961, 0.08338570447098093, 0.07982053532657074, 0.07982053532657074, 0.12597394416218466, 0.11884827996834701, 0.11884827996834701]}}
{"id": "9efaa7d6-3d19-4548-adb9-88e3f30cd2d9", "fitness": 0.09691294548489898, "name": "HybridDE_SA", "description": "Fine-tuning the mutation and crossover strategies in DE by adapting scaling factor dynamics and introducing elitism to enhance convergence speed.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.6 + np.random.rand() * 0.4  # Slightly adjusted scaling factor range\n        self.CR = 0.85  # Decreased crossover rate for diversity\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            population[np.argmax(fitness)] = best_solution  # Elitism: retain the best solution\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 54, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.0915980501478425, 0.09393963361401825, 0.09454427567383139, 0.08306802005825431, 0.08488571002107081, 0.08534778676806665, 0.10997480121725922, 0.1139033986123621, 0.11495483325138567]}}
{"id": "d0b611c2-f7e3-42ee-84f0-6d1e21597346", "fitness": 0.10046869296458578, "name": "HybridDE_SA", "description": "Enhanced exploration by adaptive cooling rate and dynamic mutation strategy for better convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.9  # Changed cooling rate for adaptive cooling\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = self.F * np.tanh(evaluations / self.budget)  # Dynamic mutation strategy\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 55, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10273726359883961, 0.10273726359883961, 0.10273726359883961, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.11884827996834701, 0.11884827996834701, 0.11884827996834701]}}
{"id": "5885f3db-5b3f-414d-81ef-75952dbada29", "fitness": 0.06179454866912753, "name": "HybridDE_SA", "description": "Improved adaptive scaling factor and diversity boost for enhanced convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5\n        self.CR = 0.9\n        self.diversity_factor = 0.1  # New parameter to enhance diversity\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound) # Improved scaling factor\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                    self.F = min(1.0, self.F + self.diversity_factor)  # Adjust scaling dynamically\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 56, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.06778949976412307, 0.058372884232056776, 0.0580228966302484, 0.05800922991087587, 0.05709062899889705, 0.05524835248833748, 0.06949193618386551, 0.0664023817900421, 0.0657231280237015]}}
{"id": "ec5a8278-8606-42f4-b832-4dfae6c8a80a", "fitness": 0.10213694563780054, "name": "HybridDE_SA", "description": "Introduced adaptive cooling rate to improve convergence speed.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate - 0.01  # Adaptive cooling rate\n\n        return best_solution", "configspace": "", "generation": 57, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10706070431952452, 0.10273726359883961, 0.10273726359883961, 0.08338570447098093, 0.07982053532657074, 0.07982053532657074, 0.12597394416218466, 0.11884827996834701, 0.11884827996834701]}}
{"id": "bc2eb96d-b54c-4ece-8164-8098670ab0b1", "fitness": 0.10123729017845522, "name": "HybridDE_SA", "description": "Introduces adaptive population size and adaptive cooling rate for enhanced convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Adaptive population size for better balance\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n            # Adaptive population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5, int(self.population_size * 0.95))\n\n        return best_solution", "configspace": "", "generation": 58, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.09729162078258091, 0.09729162078258091, 0.09729162078258091, 0.08759812066466033, 0.08759812066466033, 0.08759812066466033, 0.1188221290881244, 0.1188221290881244, 0.1188221290881244]}}
{"id": "b8e7091f-adf3-4254-8996-1d78c837c4a5", "fitness": 0.10213694563780054, "name": "HybridDE_SA", "description": "Adaptation of cooling rate and population diversification for enhanced convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98  # Adjusted cooling rate for improved exploration\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 59, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10706070431952452, 0.10273726359883961, 0.10273726359883961, 0.08338570447098093, 0.07982053532657074, 0.07982053532657074, 0.12597394416218466, 0.11884827996834701, 0.11884827996834701]}}
{"id": "ba99ce35-d091-4f2d-85f4-14696db1a415", "fitness": 0.08932677894064851, "name": "HybridDE_SA", "description": "Enhanced balancing between exploration and exploitation through adaptive mutation and crossover rates.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                self.F = 0.4 + 0.6 * np.random.rand()  # Adaptive scaling factor\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                self.CR = 0.8 + 0.2 * (1 - evaluations / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 60, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08675091207172858, 0.08675091207172858, 0.08675091207172858, 0.07895122887845885, 0.07895122887845885, 0.07895122887845885, 0.10227819587175813, 0.10227819587175813, 0.10227819587175813]}}
{"id": "6f04d088-0e21-4691-bc21-faa640f85f1b", "fitness": 0.08661341375832816, "name": "HybridDE_SA", "description": "Enhanced exploration by increasing population diversity and dynamic scaling factor adjustment with adaptive crossover rate.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < (self.CR * (best_fitness / (fitness[i] + 1e-8))), mutant, population[i])  # Adaptive CR\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 61, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.0846780787961845, 0.0846780787961845, 0.0846780787961845, 0.07731073908158537, 0.0786900006602339, 0.07962802208723985, 0.09661924186911364, 0.09661924186911364, 0.09661924186911364]}}
{"id": "f314be41-91bd-47fe-8d96-36f9b6b67126", "fitness": 0.09329763623299303, "name": "HybridDE_SA", "description": "Enhanced exploration by dynamic population resizing and adaptive scaling factor.  ", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n            self.F = 0.2 + 0.8 * (1 - evaluations / self.budget)  # Adaptive scaling factor\n\n        return best_solution", "configspace": "", "generation": 62, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.0901701175931634, 0.0901701175931634, 0.0901701175931634, 0.08170282089488623, 0.08170282089488623, 0.08170282089488623, 0.10801997021092946, 0.10801997021092946, 0.10801997021092946]}}
{"id": "644e1608-e4da-4e98-b515-b9d6b4492863", "fitness": 0.06178269898162953, "name": "HybridDE_SA", "description": "Optimized mutation strategy and adaptive cooling schedule for improved convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.9  # Adjusted cooling rate for faster convergence\n        self.F = 0.6 + np.random.rand() * 0.4  # Optimized dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)  # Fixed mutant generation\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate  # The cooling rate already adjusted above\n\n        return best_solution", "configspace": "", "generation": 63, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.06040094514586003, 0.06254753161861615, 0.06270933260298928, 0.05500570204371835, 0.053969806764962436, 0.05989749361712371, 0.06539361474155414, 0.06398975738100432, 0.07213010691883737]}}
{"id": "cc5b0e5f-6306-461c-bfc0-4bea5c9eed93", "fitness": 0.09065090576814919, "name": "HybridDE_SA", "description": "Introduced adaptive mutation strategy to enhance search efficiency.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mut_factor = self.F * (1 - evaluations / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + mut_factor * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 64, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08784107308226186, 0.0878416736010531, 0.08784107308226186, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.10429090872268454, 0.10429090872268454, 0.10429090872268454]}}
{"id": "68220ad8-6fa7-45c3-b36b-1ee5f0c9209d", "fitness": 0.086927582783849, "name": "HybridDE_SA", "description": "Improved exploration and exploitation by integrating adaptive mutation and crossover rates.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.4 + np.random.rand() * 0.6  # Adjusted dynamic scaling factor\n        self.CR = 0.7 + np.random.rand() * 0.3  # Adaptive crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 65, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.07749075695625596, 0.08390377768488966, 0.09150566660625437, 0.07120735175050885, 0.07639843866284302, 0.08278912879952138, 0.08903709414789618, 0.09982086671447754, 0.11019516373199412]}}
{"id": "da43d345-91c1-4642-98d6-83f59bea846b", "fitness": 0.07360764752842097, "name": "HybridDE_SA", "description": "Improved exploration-exploitation balance by introducing adaptive mutation and recombination rates.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = 0.4 + 0.3 * (best_fitness / (best_fitness + 1))\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                CR_dynamic = 0.8 + 0.2 * (temperature / self.initial_temperature)\n                trial = np.where(np.random.rand(self.dim) < CR_dynamic, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 66, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.0724385299349336, 0.0724385299349336, 0.0724385299349336, 0.06622958023317627, 0.06622958023317627, 0.06622958023317627, 0.08215483241715305, 0.08215483241715305, 0.08215483241715305]}}
{"id": "9da09e28-b876-4353-b993-e7cf1b562640", "fitness": -Infinity, "name": "HybridDE_SA", "description": "Introducing dynamic population size adjustment for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Adjusted initial population size\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            if evaluations > self.budget * 0.5:\n                # Increase population size dynamically\n                new_population_size = min(self.population_size + self.dim, int(self.budget / self.dim))\n                if new_population_size != self.population_size:\n                    additional_population = np.random.uniform(self.lower_bound, self.upper_bound, (new_population_size - self.population_size, self.dim))\n                    population = np.vstack((population, additional_population))\n                    additional_fitness = np.apply_along_axis(func, 1, additional_population)\n                    fitness = np.concatenate((fitness, additional_fitness))\n                    self.population_size = new_population_size\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 67, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {}}
{"id": "0329e7bc-0844-40ab-9c91-c6c62470a86b", "fitness": 0.09235570217345482, "name": "HybridDE_SA", "description": "Enhanced exploration and exploitation with adaptive cooling and dynamic population size.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.9  # Adapted cooling rate\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n            if evaluations >= 0.5 * self.budget:  # Adjust population size dynamically\n                self.population_size = max(5, int(self.population_size * 0.9))\n\n        return best_solution", "configspace": "", "generation": 68, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.09228803324273283, 0.08784107308226186, 0.08784107308226186, 0.08338570447098093, 0.07982053532657074, 0.07982053532657074, 0.11162254758434531, 0.10429090872268454, 0.10429090872268454]}}
{"id": "4a547359-4d15-4075-b3bc-8999f3b04e30", "fitness": 0.10046869296458578, "name": "HybridDE_SA", "description": "Improved exploration by increasing mutation diversity and optimizing cooling performance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.97  # Adjusted cooling rate for better temperature management\n        self.F = 0.6 + np.random.rand() * 0.2  # Adjusted dynamic scaling factor range for better mutation\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 69, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10273726359883961, 0.10273726359883961, 0.10273726359883961, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.11884827996834701, 0.11884827996834701, 0.11884827996834701]}}
{"id": "23e8d325-b3a5-4149-b8f9-3a8d9d7aeea7", "fitness": 0.09457139463604958, "name": "HybridDE_SA", "description": "Enhanced balancing of exploration and exploitation using adaptive cooling and dynamic mutation.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99  # Adjusted cooling rate for slower cooling\n        self.F = 0.5 + np.random.rand() * 0.5\n        self.CR = 0.7  # Reduced crossover rate to improve exploration\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 70, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.09126245735510685, 0.09126245735510685, 0.09126245735510685, 0.08258503107736426, 0.08258503107736426, 0.08258503107736426, 0.10986669547567762, 0.10986669547567762, 0.10986669547567762]}}
{"id": "20d2e05f-a9a8-4ad7-84e7-222cb6b96585", "fitness": 0.0872846838908858, "name": "HybridDE_SA", "description": "Introduce adaptive mutation scaling and dynamic population resizing in HybridDE_SA for improved optimization performance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation scaling\n                F_adaptive = self.F * (1 - evaluations / self.budget)\n                mutant = np.clip(a + F_adaptive * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n            # Dynamic population resizing\n            if evaluations < self.budget // 2:\n                self.population_size = int(0.9 * self.population_size)\n\n        return best_solution", "configspace": "", "generation": 71, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08479977553007723, 0.08480037604886825, 0.08479977553007723, 0.07731283211949258, 0.07731283211949258, 0.07731283211949258, 0.09974124385015726, 0.09974124385015726, 0.09974124385015726]}}
{"id": "6a5c7826-cf05-4d04-8b69-08080c6082cd", "fitness": 0.10213694563780054, "name": "HybridDE_SA", "description": "Enhanced exploration by retaining the best individual's scaling factor to guide diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        best_F = self.F  # Track the best individual's scaling factor\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + best_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)  # Use best_F\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                    best_F = self.F  # Update best_F with current scaling factor\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 72, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10706070431952452, 0.10273726359883961, 0.10273726359883961, 0.08338570447098093, 0.07982053532657074, 0.07982053532657074, 0.12597394416218466, 0.11884827996834701, 0.11884827996834701]}}
{"id": "4d436a27-e9fc-4595-b18b-c0be9c80420f", "fitness": 0.09070782240408415, "name": "HybridDE_SA", "description": "Incorporate adaptive parameter control and elitism to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = 0.5 + 0.5 * (best_fitness - fitness[i]) / (np.ptp(fitness) + 1e-9)  # Adaptive F\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 73, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08801202316299717, 0.08801202316299717, 0.08801202316299717, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.10429090872268454, 0.10429090872268454, 0.10429090872268454]}}
{"id": "8709ecdc-ff5e-4ac6-a7c5-ec8b4e25ab42", "fitness": 0.0907576951549301, "name": "HybridDE_SA", "description": "Improves convergence by introducing adaptive mutation factor and diversity preservation mechanism.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n    \n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                adaptive_F = self.F * (1 + (best_fitness - fitness[i]) / (best_fitness + 1e-9))  # Adaptive mutation factor\n                mutant = np.clip(a + adaptive_F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                else:\n                    population[i] = np.clip(population[i] + np.random.normal(0, 0.1, self.dim), self.lower_bound, self.upper_bound)  # Preserve diversity\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 74, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08880277808208126, 0.08784107308226186, 0.08784107308226186, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.10429090872268454, 0.10429090872268454, 0.10429090872268454]}}
{"id": "31f33d6b-3c0b-45ff-8b51-71fd0d524ed9", "fitness": 0.09110044903745407, "name": "HybridDE_SA", "description": "Enhanced exploration by utilizing a dynamic crossover probability for better diversity management.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                self.CR = 0.8 + 0.2 * np.random.rand()  # Dynamic crossover probability\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 75, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08857843469889681, 0.08857843469889681, 0.08857843469889681, 0.07964711316393669, 0.07964711316393669, 0.07964711316393669, 0.1050757992495287, 0.1050757992495287, 0.1050757992495287]}}
{"id": "c781e780-e914-400f-83fe-0ea2ce150a68", "fitness": 0.0992501031286368, "name": "HybridDE_SA", "description": "Improved population initialization by including random permutations to enhance exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        population = np.apply_along_axis(np.random.permutation, 1, population)  # Improved initialization\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 76, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.09539723197936578, 0.09543324567894318, 0.09540090094380438, 0.08592473799533562, 0.08595666483113484, 0.08592844861763038, 0.11638539152216165, 0.11643339229993022, 0.11639091428942516]}}
{"id": "93ce9697-3669-4af5-b529-659660ca35ca", "fitness": 0.09270328321535086, "name": "HybridDE_SA", "description": "Refined HybridDE_SA with adaptive cooling and jitter mechanism for enhanced exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                jitter = np.random.normal(0, 0.1, self.dim)  # Add jitter for diversity\n                mutant = np.clip(a + self.F * (population[b] - population[c]) + jitter, self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate - 0.01  # Adaptive cooling rate adjustment\n\n        return best_solution", "configspace": "", "generation": 77, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08973667795262374, 0.08973667795262374, 0.08973667795262374, 0.08143473527423617, 0.08143473527423617, 0.08143473527423617, 0.10693843641919265, 0.10693843641919265, 0.10693843641919265]}}
{"id": "48c2a8e4-d28d-4011-b619-8d6628e541ba", "fitness": 0.10046869296458578, "name": "HybridDE_SA", "description": "Enhanced exploration by dynamically adjusting the mutation factor for optimal search efficiency.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95\n        self.F = 0.5 + np.random.rand() * 0.3  # Dynamic scaling factor, smaller range for better control\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 78, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.10273726359883961, 0.10273726359883961, 0.10273726359883961, 0.07982053532657074, 0.07982053532657074, 0.07982053532657074, 0.11884827996834701, 0.11884827996834701, 0.11884827996834701]}}
{"id": "b35e64f7-8b22-460e-b0ab-086f434cc97a", "fitness": 0.20077864443523605, "name": "HybridDE_SA", "description": "Introduced adaptive cooling schedule and mutation strategy to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 79, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.20.", "error": "", "parent_ids": ["dd291037-34d1-42ef-befe-9cbcb62460b7"], "operator": null, "metadata": {"aucs": [0.08784107308226186, 0.08784107308226186, 0.5628872578966866, 0.07982053532657074, 0.07982053532657074, 0.1314722186675138, 0.10429090872268454, 0.10429090872268454, 0.5687432890898896]}}
{"id": "39f12e2c-5f6a-44eb-a7f5-26a90f5f5715", "fitness": 0.09308328532034221, "name": "HybridDE_SA", "description": "Enhanced adaptive cooling and targeted mutation strategy to improve convergence and solution quality.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95 + np.random.rand() * 0.05  # Further adaptive cooling schedule\n        self.F = 0.6 + np.random.rand() * 0.4  # More dynamic scaling factor range\n        self.CR = 0.85  # Slightly adjusted crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive and targeted mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c]) + 0.5 * (best_solution - population[i]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 80, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["b35e64f7-8b22-460e-b0ab-086f434cc97a"], "operator": null, "metadata": {"aucs": [0.08978550988273959, 0.08978550988273959, 0.09063880909012745, 0.08146620840141783, 0.08146620840141783, 0.08215370937000899, 0.1070287509961253, 0.1070287509961253, 0.1083961108623781]}}
{"id": "29c6175e-e37e-4c84-800b-7e22e389f6e6", "fitness": 0.09362375837994913, "name": "HybridDE_SA", "description": "Enhanced exploration by integrating adaptive crossover rate and random reinitialization strategy.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02\n        self.F = 0.5 + np.random.rand() * 0.5\n        self.CR = 0.9 + np.random.rand() * 0.1  # Adaptive crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                elif np.random.rand() < 0.05:  # Random reinitialization strategy\n                    population[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    fitness[i] = func(population[i])\n                    evaluations += 1\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 81, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["b35e64f7-8b22-460e-b0ab-086f434cc97a"], "operator": null, "metadata": {"aucs": [0.0889915844223319, 0.09428303999714838, 0.08798568338983681, 0.0806942483366716, 0.08510148441939258, 0.07983367420032506, 0.10642635993961469, 0.11421734911387016, 0.10508040160035093]}}
{"id": "0fdf0028-be39-460b-9fbf-4339c694bd80", "fitness": 0.09373910365642688, "name": "HybridDE_SA", "description": "Enhanced mutation strategy with random scaling factor to increase diversity and exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim  # Increased population size for diversity\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with a random scaling factor\n                F_dynamic = self.F * np.random.rand()  # Change: introduce variable scaling factor\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 82, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["b35e64f7-8b22-460e-b0ab-086f434cc97a"], "operator": null, "metadata": {"aucs": [0.09155113950735971, 0.09145938389164865, 0.08892872932095419, 0.08289944675808492, 0.08282547641151883, 0.08077824300209513, 0.10983662652044945, 0.10968354272892777, 0.10568934476680325]}}
{"id": "d59e1e5c-f9a8-462f-862b-60a0e723d2af", "fitness": 0.4813655412029104, "name": "HybridDE_SA", "description": "Introduced dynamic population size scaling to enhance adaptability to problem dimension.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 83, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.34.", "error": "", "parent_ids": ["b35e64f7-8b22-460e-b0ab-086f434cc97a"], "operator": null, "metadata": {"aucs": [0.10149302067790378, 0.12668274203849572, 0.907108937258895, 0.4994190146593952, 0.09277812402982566, 0.9062283716924338, 0.5163178911594679, 0.27329587924123355, 0.9089658900685428]}}
{"id": "f3324adb-3579-4b3c-936b-1393c9efc657", "fitness": 0.07495609422647204, "name": "HybridDE_SA", "description": "Enhanced exploration by modifying the mutation strategy for increased diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c] + (population[np.random.choice(idxs)] - population[i])), self.lower_bound, self.upper_bound)  # Modified mutation strategy\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 84, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.06292620626906564, 0.06825776101358927, 0.07752704344513328, 0.0674604465973927, 0.0631969098742059, 0.07226856829379968, 0.0829147826367963, 0.08747032990280268, 0.09258280000546282]}}
{"id": "c75d8831-b476-4584-af52-111de16c1ab7", "fitness": 0.12217592251046004, "name": "HybridDE_SA", "description": "Enhanced diversification by incorporating adaptive crossover rates.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9 + np.random.rand() * 0.1  # Adaptive crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 85, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.06.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.09476657285147394, 0.12668274203849572, 0.10010389563999311, 0.08566870374706015, 0.09277812402982566, 0.09018471829274921, 0.11429819281844789, 0.27329587924123355, 0.12180447393486116]}}
{"id": "249979b6-2df8-4eb9-858c-778cdc5bef1c", "fitness": 0.28957634217793693, "name": "HybridDE_SA", "description": "Enhanced selection strategy with diversity preservation for improved exploration.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with diversity preservation\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[np.random.randint(self.population_size)])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 86, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.10477467297590659, 0.6720875562619644, 0.10149187239144442, 0.12463802531087498, 0.5784498550169598, 0.09130379771638453, 0.12985265584485373, 0.6795319539618907, 0.1240566901211535]}}
{"id": "4d2d94e0-243d-4380-9e8d-8b0113c34feb", "fitness": 0.1097322840896861, "name": "HybridDE_SA", "description": "Enhanced convergence speed and precision by introducing adaptive crossover and mutation strategies.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02\n        self.F = 0.5 + np.random.rand() * 0.5\n        self.CR = 0.8 + np.random.rand() * 0.2  # Adaptive crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = self.F * (0.5 + 0.5 * (self.budget - evaluations) / self.budget)  # Adaptive scaling factor\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 87, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.10203062723199585, 0.10814734574928953, 0.10563939337882755, 0.08993883802399105, 0.09618823783294372, 0.09455533990201725, 0.12136004998226624, 0.13850072399291202, 0.13123000071293167]}}
{"id": "e0cf6624-f67e-40de-8fd8-4bad36cee453", "fitness": 0.3073647932892267, "name": "HybridDE_SA", "description": "Enhanced mutation strategy by incorporating best solution influence to improve convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with enhanced influence of best solution\n                mutant = np.clip(a + self.F * (population[b] - population[c]) + 0.1 * (best_solution - population[i]), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 88, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.19.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.4970583691490613, 0.0920383497449292, 0.17219953509059338, 0.09199462569070516, 0.5427003950760746, 0.10889347233675939, 0.24918522591363246, 0.5542552040290553, 0.45795796257222954]}}
{"id": "92d838cb-0af2-4876-b0e2-c6ae4dd5348b", "fitness": 0.1611534025017045, "name": "HybridDE_SA", "description": "Enhanced exploration by introducing adaptive crossover probabilities and dynamic mutation control.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9 + np.random.rand() * 0.1  # Adaptive crossover probability\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with dynamic control\n                adaptive_F = self.F * (1 - evaluations / self.budget)\n                mutant = np.clip(a + adaptive_F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 89, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.13.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.5158668050126531, 0.11799735279333823, 0.1026850222337733, 0.10601680033839167, 0.10378062347950578, 0.09241989731547995, 0.12824469908893776, 0.15787325598791047, 0.12549616626535043]}}
{"id": "0eaf36b2-21c5-4f32-a8ee-d7ec1061f1d3", "fitness": 0.10965459698999597, "name": "HybridDE_SA", "description": "Enhanced exploration with adaptive multi-strategy mutation and dynamic cooling for improved convergence.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  \n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.99 + np.random.rand() * 0.01  # Slightly adjusted cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  \n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Enhanced Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                \n                if np.random.rand() < 0.5:  # Adaptive multi-strategy mutation\n                    mutant = np.clip(a + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)\n                else:\n                    mutant = np.clip(a + self.F * (best_solution - population[i]), self.lower_bound, self.upper_bound)\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 90, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.01.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.088620106919029, 0.0914679104775743, 0.09618113709421328, 0.12869733622468715, 0.1261237012149955, 0.12510874847434494, 0.10554672733652692, 0.10911452292719925, 0.11603118224139342]}}
{"id": "3839db3d-3ccb-4d14-94d9-1cfeb884d5a3", "fitness": 0.07721415884896357, "name": "HybridDE_SA", "description": "Enhanced hybrid metaheuristic by adjusting mutation vector strategy and improving diversity.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(population[a] + self.F * (population[b] - population[c]), self.lower_bound, self.upper_bound)  # Adjusted mutation strategy\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 91, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.06690133647535756, 0.06965100587749928, 0.07550741258808957, 0.06818522301542085, 0.06559270512555926, 0.08132193572772972, 0.08718688143086739, 0.07822834533996226, 0.10235258406018621]}}
{"id": "6d4a4532-7e76-4b16-9be2-dd77fd509298", "fitness": 0.11260408292079517, "name": "HybridDE_SA", "description": "Enhanced exploration by incorporating dynamic crossover rate and adaptive mutation strategies.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Introduce dynamic CR\n        \n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                F_dynamic = 0.4 + 0.1 * np.random.rand()  # Adaptive F factor\n                mutant = np.clip(a + F_dynamic * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 92, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.10331056796016347, 0.08734902635356145, 0.10267399323345416, 0.10660794691785291, 0.10936580447211564, 0.09124330291525662, 0.14416437035094498, 0.12015223457879876, 0.14856949950500853]}}
{"id": "64250fe3-9227-4330-b965-0fb930f93009", "fitness": 0.2439176575119334, "name": "HybridDE_SA", "description": "Enhanced mutation strategy and dynamic parameters tuning for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95 + np.random.rand() * 0.1  # More adaptive cooling schedule\n        self.F = 0.4 + np.random.rand() * 0.6  # Adjusted dynamic scaling factor for better exploration\n        self.CR = 0.8 + np.random.rand() * 0.2  # Dynamic crossover rate\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                mutant = np.clip(a + self.F * (population[b] - population[c] + 0.5 * (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 93, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.25.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.09939248068471129, 0.15244371290774406, 0.08976134480379538, 0.5997494242040293, 0.09939401594082031, 0.1139606608470084, 0.12063197660734337, 0.8129707711054197, 0.10695453050652881]}}
{"id": "7aea15e2-9446-4478-9765-5ea9d9752c81", "fitness": 0.30856343894852767, "name": "HybridDE_SA", "description": "Introduced temperature perturbation for simulated annealing to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / (temperature + np.random.rand()*0.1)):  # Perturbation added\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 94, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.33.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.0982669057808433, 0.2883398358917927, 0.10115566687036814, 0.913395894202195, 0.913395894202195, 0.09217759339317244, 0.12004572163367322, 0.12450155180787548, 0.12579188675463393]}}
{"id": "8e288d0d-983e-46a4-88f7-3eb6aef01f84", "fitness": 0.3903057925679192, "name": "HybridDE_SA", "description": "Utilize an adaptive mutation strategy and enhanced cooling schedule to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95 + np.random.rand() * 0.05  # Enhanced adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.3  # Adaptive scaling factor with reduced randomness\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with strategy\n                mutant_vector = (population[b] - population[c] + (best_solution - population[i]))\n                mutant = np.clip(a + self.F * mutant_vector, self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 95, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.35.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.23544216659107764, 0.0935342847773577, 0.8766892325969857, 0.10335493279256758, 0.08503485918968146, 0.8748316690057507, 0.2519199856733365, 0.11169379742609853, 0.8802512050584174]}}
{"id": "72a2cd04-b521-4860-a12f-2ac7516ec16d", "fitness": 0.11249922320845308, "name": "HybridDE_SA", "description": "Introduced adaptive crossover rate for increased exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                self.CR = 0.8 + 0.2 * (1 - evaluations / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 96, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.02.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.09819557483187236, 0.10654985737205647, 0.10546224496958723, 0.1161115370119512, 0.09523006920562538, 0.09444139795025264, 0.1323349046120914, 0.13331469521432926, 0.1308527277083117]}}
{"id": "7fb53dff-2b62-43f3-a088-96a9d5189661", "fitness": 0.38087808562770253, "name": "HybridDE_SA", "description": "Enhanced exploration by adjusting population initialization with a wider range.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        # Changed initialization to a wider range [-10.0, 10.0]\n        population = np.random.uniform(-10.0, 10.0, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector\n                mutant = np.clip(a + self.F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 97, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.31.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.1325425582754921, 0.09483749059477342, 0.7317527798242796, 0.11223310345737636, 0.08687361676978722, 0.7294857934857746, 0.6895420819922601, 0.11433387939087492, 0.7363014668587042]}}
{"id": "c0670088-abff-4443-8de2-525b43fcd649", "fitness": 0.5647683804978625, "name": "HybridDE_SA", "description": "Enhanced adaptive mechanisms in mutation factor and dynamic temperature control to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n\n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with dynamic F adjustment\n                dynamic_F = self.F * (1 - evaluations / self.budget) + np.random.rand() * 0.5\n                mutant = np.clip(a + dynamic_F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance with dynamic temperature adjustment\n                dynamic_temperature = temperature * (0.5 + 0.5 * (evaluations / self.budget))\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / dynamic_temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 98, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56 with standard deviation 0.32.", "error": "", "parent_ids": ["d59e1e5c-f9a8-462f-862b-60a0e723d2af"], "operator": null, "metadata": {"aucs": [0.14754464051804317, 0.9487309207375041, 0.6042361497968729, 0.123155640650217, 0.17551824033098085, 0.6013889803155661, 0.9236143343209708, 0.9492921915605899, 0.6094343262500175]}}
{"id": "8b786fad-5c8a-4824-80f4-63c1c9316356", "fitness": 0.38349470683624776, "name": "HybridDE_SA", "description": "Introduced a dynamic crossover rate to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 + 5 * np.log1p(dim))  # Dynamic population size scaling based on dimension\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.98 + np.random.rand() * 0.02  # Adaptive cooling schedule\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n        self.CR = 0.9\n    \n    def __call__(self, func):\n        np.random.seed(0)\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = np.random.choice(idxs, 3, replace=False)\n                # Adaptive mutation vector with dynamic F adjustment\n                dynamic_F = self.F * (1 - evaluations / self.budget) + np.random.rand() * 0.5\n                mutant = np.clip(a + dynamic_F * (population[b] - population[c] + (best_solution - population[i])), self.lower_bound, self.upper_bound)\n                dynamic_CR = self.CR * (1 - evaluations / self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < dynamic_CR, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Simulated Annealing acceptance with dynamic temperature adjustment\n                dynamic_temperature = temperature * (0.5 + 0.5 * (evaluations / self.budget))\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / dynamic_temperature):\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n            temperature *= self.cooling_rate\n\n        return best_solution", "configspace": "", "generation": 99, "feedback": "The algorithm HybridDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.38.", "error": "", "parent_ids": ["c0670088-abff-4443-8de2-525b43fcd649"], "operator": null, "metadata": {"aucs": [0.11047960915568367, 0.1028187804149363, 0.9265331780561745, 0.09822752761947096, 0.09237644171226367, 0.9259607963930174, 0.14117396203725097, 0.12622316103192543, 0.9276589051055071]}}
