{"id": "4dcaddf4-1ebe-4505-92ac-e26cd84c54c5", "fitness": 0.05416960881535086, "name": "HybridPSOSA", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Simulated Annealing (SA) to explore and exploit the search space for robust black box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.054613378095926035, 0.048817601859845405, 0.051863243405988024, 0.053132789724535945, 0.05019863300980909, 0.050543467595979386, 0.061721483386865894, 0.058085890180400224, 0.05854999207880773]}}
{"id": "2e7c7ee8-d5d1-4f48-914e-aa0fb317708e", "fitness": 0.05709814798878648, "name": "HybridPSOSA", "description": "Enhanced PSO-SA hybrid with adaptive inertia weight for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["4dcaddf4-1ebe-4505-92ac-e26cd84c54c5"], "operator": null, "metadata": {"aucs": [0.06859074099687457, 0.052293772879343114, 0.05427543736122131, 0.05983396435699195, 0.04907909785982023, 0.048356802155282486, 0.06909324983780174, 0.056672802861124416, 0.05568746359061849]}}
{"id": "0773a5b9-efba-4629-bb89-8d3229246158", "fitness": 0.05909781526462375, "name": "HybridPSOSA", "description": "Enhanced PSO-SA hybrid with adaptive inertia weight and improved cognitive weight for better convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["2e7c7ee8-d5d1-4f48-914e-aa0fb317708e"], "operator": null, "metadata": {"aucs": [0.06885047443495163, 0.049951534062744996, 0.05394048561585263, 0.06407450363873834, 0.048681421671265546, 0.04975684010699555, 0.08296410304756141, 0.05616396515009703, 0.05749700965340665]}}
{"id": "9ed509c3-f025-4572-95d4-7c45f69a7e43", "fitness": 0.0564415097464929, "name": "HybridPSOSA", "description": "Introduced dynamic social and cognitive weights for varying exploration-exploitation balance in PSO-SA hybrid algorithm.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_initial = 1.7  # Initial cognitive (personal) weight\n        self.c2_initial = 1.5  # Initial social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            # Linearly adjust cognitive and social weights\n            self.c1 = self.c1_initial + ((self.c2_initial - self.c1_initial) * evaluations / self.budget)\n            self.c2 = self.c2_initial - ((self.c2_initial - self.c1_initial) * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["0773a5b9-efba-4629-bb89-8d3229246158"], "operator": null, "metadata": {"aucs": [0.0593095701060653, 0.05999255784637669, 0.052661776808521354, 0.0561258926928323, 0.04939430371303999, 0.049530651227069566, 0.06575690928292666, 0.058303794991526936, 0.05689813105007735]}}
{"id": "2567d44a-9fc8-455b-bd62-e657e39d09ac", "fitness": 0.05750603370341951, "name": "HybridPSOSA", "description": "Incorporate local search with differential evolution to enhance exploitation in PSO-SA hybrid for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n            # Differential Evolution local search\n            if evaluations < self.budget:\n                for j in range(self.population_size):\n                    idxs = [idx for idx in range(self.population_size) if idx != j]\n                    a, b, c = np.random.choice(idxs, 3, replace=False)\n                    mutant = personal_best_positions[a] + 0.8 * (personal_best_positions[b] - personal_best_positions[c])\n                    mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                    trial = np.where(np.random.rand(self.dim) < 0.9, mutant, personal_best_positions[j])\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[j]:\n                        personal_best_scores[j] = trial_score\n                        personal_best_positions[j] = trial\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = trial\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["0773a5b9-efba-4629-bb89-8d3229246158"], "operator": null, "metadata": {"aucs": [0.060059794889102736, 0.054296409795563494, 0.056379668056403154, 0.0562236037233268, 0.05093241453833097, 0.052868461697549995, 0.0659385654657384, 0.059125782944613126, 0.061729602220146895]}}
{"id": "533844b3-8add-4917-bf71-54e435abe07d", "fitness": 0.05970399825634381, "name": "HybridPSOSA", "description": "Introduce dynamic adjustment of social weight to enhance exploration-exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0773a5b9-efba-4629-bb89-8d3229246158"], "operator": null, "metadata": {"aucs": [0.06402839944131056, 0.05845419953752007, 0.052826949646183285, 0.06054409531274041, 0.054724619606046576, 0.051163230868619514, 0.07189134027342958, 0.06425401931968466, 0.05944913030155963]}}
{"id": "e5e40ffb-d3c2-4baa-b4f6-4a629ab635ed", "fitness": 0.05694723431002217, "name": "HybridPSOSA", "description": "Introduce a nonlinear inertia weight decay for improved convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Nonlinear decrease inertia weight\n            self.w = self.w_min + (self.w_max - self.w_min) * ((self.budget - evaluations) / self.budget) ** 2\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.06249348205730698, 0.05252634364876796, 0.05113585965182843, 0.06206650127381619, 0.04893131887500202, 0.04936933939502175, 0.07210007385540917, 0.05690167077841379, 0.05700051925463323]}}
{"id": "390f7673-42c1-48b3-95e5-75ec450bd7a9", "fitness": 0.05828011426611171, "name": "HybridPSOSA", "description": "Refine HybridPSOSA by introducing adaptive cooling rate and improved cognitive weight to enhance convergence performance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Adaptive cooling down the temperature\n            self.temp *= (self.cooling_rate + 0.01 * evaluations / self.budget)\n            self.c1 = 2.0 - evaluations / self.budget  # Improve cognitive weight over iterations\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.07015180780305708, 0.056595554543219406, 0.05439423088904538, 0.06064533178762477, 0.048359635181655536, 0.049949818820548275, 0.07092582264572378, 0.05571487549805454, 0.0577839512260766]}}
{"id": "25b06abe-ffa7-4e37-90c1-e8b455bb86f0", "fitness": 0.05723440729973697, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing a self-adaptive mechanism for dynamically adjusting parameters based on particle performance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  \n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  \n        self.w_min = 0.4  \n        self.c1 = 1.7  \n        self.c2_max = 1.5  \n        self.cooling_rate = 0.99  \n        self.temp = 1.0  \n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) \n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                acceptance_probability = np.exp((global_best_score - score) / self.temp)\n                if score < global_best_score or acceptance_probability > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    \n                # Dynamic parameter adaptation\n                if evaluations % 10 == 0:  # Adjust parameters every 10 evaluations\n                    successful_moves = np.sum(personal_best_scores < global_best_score)\n                    self.c1 += 0.1 * (successful_moves / self.population_size)\n                    self.c2 -= 0.1 * (successful_moves / self.population_size)\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.06395030807212021, 0.04936587636955403, 0.05464099275858325, 0.06250839698986888, 0.047285481521344375, 0.05033750097404155, 0.07230974491365627, 0.05642518628191584, 0.058286177816548324]}}
{"id": "3d4d12d5-2cea-4de7-bcaa-941e7de0537e", "fitness": 0.057763396403904786, "name": "HybridPSOSA", "description": "Introduce dynamic adjustment of cognitive weight to enhance personal best exploration in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_max = 2.5  # Max cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c1 = self.c1_max * (1 - evaluations / self.budget)  # Dynamic adjustment of cognitive weight\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)  # Dynamic adjustment of social weight\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.06714034253697765, 0.05443085163210082, 0.0530008788322438, 0.0597619957894161, 0.05111848059090296, 0.048320650745001026, 0.07109497872196535, 0.05934224451203618, 0.05566014427449917]}}
{"id": "7c0b1835-71b9-4b53-bf2f-3c3b570305a0", "fitness": 0.05420116765244395, "name": "HybridPSOSA", "description": "Adjust velocity clamping dynamically based on the evaluations to enhance convergence control in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            \n            # Dynamically adjust velocity clamp\n            self.velocity_clamp = (self.velocity_clamp[0] * (1 - evaluations / self.budget), \n                                   self.velocity_clamp[1] * (1 - evaluations / self.budget))\n            \n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.05544416558182874, 0.05266676543521631, 0.05209579332790093, 0.05209196932660065, 0.049530936894562894, 0.05024490946208304, 0.06042256820489866, 0.05719879345739165, 0.05811460718151262]}}
{"id": "ec74e0ca-b99b-4b96-a842-903ccd357db1", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Enhance the exploration capability by introducing an adaptive personal weight adjustment in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["533844b3-8add-4917-bf71-54e435abe07d"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "72e7feba-c344-4fbf-ad6e-720c46418b2e", "fitness": 0.05665076717682983, "name": "HybridPSOSA", "description": "Introduce a neighborhood-based search strategy to enhance local search and update velocity with perturbation for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] += 0.01 * np.random.normal(size=self.dim)  # Perturbation\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                # Neighborhood-based local improvement\n                neighborhood = np.clip(particles[i] + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n                neighborhood_score = func(neighborhood)\n                if neighborhood_score < score:\n                    particles[i] = neighborhood\n                    score = neighborhood_score\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.060805049098326514, 0.05359505465357217, 0.04882437660204264, 0.06021128696412159, 0.050372421921169086, 0.049182757791211285, 0.0717159492811773, 0.05824422519131378, 0.05690578308853411]}}
{"id": "38cc9170-c522-42f9-99a8-6c9aa45039fa", "fitness": 0.059597385307037815, "name": "HybridPSOSA", "description": "Enhance convergence by introducing weighted global best influence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Weighting global best for next iteration influence\n            if evaluations < self.budget * 0.5:\n                global_best_position = (global_best_position + np.mean(personal_best_positions, axis=0)) / 2\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06952440082946831, 0.05290229165828986, 0.06331946864564997, 0.06457014115536008, 0.050481622977337826, 0.04933712052294703, 0.07077157887710261, 0.058493285741617274, 0.05697655735556739]}}
{"id": "1182bf03-3bac-4a43-8ccf-cf64221af752", "fitness": 0.056626330824100415, "name": "HybridPSOSA", "description": "Modify the inertia weight update strategy to follow an exponential decay, enhancing exploration capability.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Exponential decay for inertia weight\n            self.w = self.w_min + (self.w_max - self.w_min) * np.exp(-3 * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06044018009070884, 0.049093070857650134, 0.05258765276462163, 0.055049560914948836, 0.05402403461219751, 0.0509086359089137, 0.06427967835366222, 0.06314623956615628, 0.06010792434804457]}}
{"id": "d5bcf8fa-21da-48ec-8cf7-7c15c01e6d1f", "fitness": 0.05569958822215396, "name": "HybridPSOSA", "description": "Introduce a stochastic component by randomly perturbing the global best position to enhance exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i]) + np.random.uniform(-0.1, 0.1, self.dim)  # Stochastic perturbation\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05861909032156698, 0.05302129038644643, 0.05260406892659386, 0.05748633163358163, 0.048451738268248445, 0.0506349199324585, 0.06576504104226366, 0.05580254532754414, 0.05891126816068204]}}
{"id": "48a4ee6f-01dc-4cac-92e9-8b2223b82718", "fitness": 0.05708135247343434, "name": "HybridAdaptiveMemeticPSOSA", "description": "Hybrid Adaptive Memetic PSOSA integrates local search with adaptive PSO and SA for improved convergence.", "code": "import numpy as np\n\nclass HybridAdaptiveMemeticPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n                # Local Search (Memetic Component)\n                if np.random.rand() < 0.1:\n                    local_pos = particles[i] + np.random.normal(0, 0.1, self.dim)\n                    local_pos = np.clip(local_pos, self.lower_bound, self.upper_bound)\n                    local_score = func(local_pos)\n                    evaluations += 1\n                    if local_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_score\n                        personal_best_positions[i] = np.copy(local_pos)\n                        if local_score < global_best_score:\n                            global_best_score = local_score\n                            global_best_position = np.copy(local_pos)\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm HybridAdaptiveMemeticPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05704172425126075, 0.05318704118848916, 0.05728592764554874, 0.05355308585718599, 0.056472336602451434, 0.04980001596619854, 0.062296461706320305, 0.0665528944118653, 0.05754268463158885]}}
{"id": "e8bb9fef-e50d-4d1d-ade7-ce528deecacd", "fitness": 0.05723531632499585, "name": "HybridPSOSA", "description": "Enhance exploration and exploitation by integrating a mutation strategy and adaptive cooling in the HybridPSOSA framework.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.98  # Adapted cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.mutation_prob = 0.1  # Probability for mutation\n        self.mutation_strength = 0.1  # Strength of mutation\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Mutation strategy\n                if np.random.rand() < self.mutation_prob:\n                    mutation = np.random.normal(0, self.mutation_strength, self.dim)\n                    particles[i] = np.clip(particles[i] + mutation, self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.0639555429824954, 0.05608518408357066, 0.050852892738624256, 0.05107724852520035, 0.05300145069298856, 0.05484013314196989, 0.05909366135310534, 0.061860457790378964, 0.06435127561662923]}}
{"id": "d7c1d6a3-380c-4ac5-97a0-c98b624b28a5", "fitness": 0.05672736238324313, "name": "HybridPSOSA", "description": "Introduce adaptive mutation on particles to enhance diversity and escape local optima.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Introduce adaptive mutation\n                if np.random.rand() < 0.1:\n                    particles[i] += np.random.normal(0, 0.1, self.dim)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.0639555429824954, 0.05608518408357066, 0.050852892738624256, 0.05107724852520035, 0.05104858924072164, 0.05484013314196989, 0.05909366135310534, 0.05924173376687136, 0.06435127561662923]}}
{"id": "a2815c5d-278b-497d-bf6b-9753775b468a", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Enhance global best update by incorporating weighted inertia in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Enhanced global best update with weighted inertia\n                if score < global_best_score or (np.exp((global_best_score - score) / self.temp) > np.random.rand() and self.w > 0.5):\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "e8d73421-bce0-4fbc-ba3a-7fb0fe51c2e5", "fitness": 0.05758367069628713, "name": "EnhancedHybridPSOSA", "description": "Introduce a dynamic inertia weight adjustment and mutation strategy in HybridPSOSA to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.98  # Adjusted cooling rate\n        self.temp = 1.0\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = (self.w_max - self.w_min) * np.cos(np.pi * evaluations / (2 * self.budget)) + self.w_min\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n                if np.random.rand() < 0.1:  # Introduce mutation strategy\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06280094020543614, 0.05405601825085815, 0.055801480004295634, 0.05615570383686841, 0.0531050673716329, 0.05037818455597032, 0.06577109990098462, 0.061930496339723806, 0.05825404580081417]}}
{"id": "6edfb742-edc8-4899-b5fd-cba725e53650", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Introduce dynamic cooling rate for Simulated Annealing to enhance convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Dynamic cooling rate adjustment\n            self.cooling_rate = 0.985 + 0.01 * (evaluations / self.budget)\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "04cfec22-d2e1-4df3-8096-bea1b312fe93", "fitness": 0.05695517803007181, "name": "EnhancedHybridPSOSA", "description": "Enhance HybridPSOSA by introducing Levy flights and a time-varying cooling schedule for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.math.gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(L) * sigma\n        v = np.random.randn(L)\n        step = u / np.power(np.abs(v), 1 / beta)\n        return step\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Levy flights for exploration\n                if np.random.rand() > 0.8:\n                    particles[i] += 0.01 * self.levy_flight(self.dim)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Adaptive cooling down of the temperature\n            self.temp = self.cooling_rate ** (evaluations / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.0613208472104394, 0.056181626409555596, 0.05285269874666754, 0.05075077800242156, 0.05408703771855883, 0.05332465674217024, 0.05866232016336381, 0.06324741645548626, 0.06216922082198306]}}
{"id": "54c61df5-0e6a-4ea3-9edb-5204e8e0bce2", "fitness": 0.05568346997218711, "name": "HybridPSOSA", "description": "Introduce a non-linear inertia weight reduction and adaptive velocity clamp to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Non-linear decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget)**2)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # Adaptive velocity clamp\n                velocities[i] = np.clip(velocities[i], \n                                        self.velocity_clamp[0] * (1 - evaluations / self.budget), \n                                        self.velocity_clamp[1] * (1 - evaluations / self.budget))\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06292445125819646, 0.052989289849499466, 0.049298455936893304, 0.056319686196533825, 0.05067310877013709, 0.04838586264824163, 0.06609541078317205, 0.05874142955057193, 0.05572353475643821]}}
{"id": "ee762b3a-52ad-492d-a3dc-1dc9db012a80", "fitness": 0.06057365233917021, "name": "HybridPSOSA", "description": "Improve convergence by slightly increasing the population size to enhance diversity.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 31  # Increased number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.07296210745598974, 0.060399700022935376, 0.0571923557390841, 0.06010728701244672, 0.053390038450626065, 0.05002531591039816, 0.07110343160262189, 0.06211532079966153, 0.05786731405876833]}}
{"id": "072bdb21-47f6-46ff-8079-33bf102d658c", "fitness": 0.05548858744784419, "name": "HybridPSOSA", "description": "Enhance the convergence by introducing a dynamic cooling rate and adaptive velocity clamping in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0] * (1 - evaluations / self.budget), self.velocity_clamp[1] * (1 - evaluations / self.budget))\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate * (1.1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05832205541084645, 0.05312211970459446, 0.04867323499570986, 0.05625199528323743, 0.05200619441876142, 0.048531711522339704, 0.06605430678364466, 0.060473993152187044, 0.055961675759276686]}}
{"id": "170302d2-9f44-464b-98e9-86445d36d284", "fitness": 0.05785880378065173, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA with adaptive velocity scaling based on success history and local search around the global best.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.successful_steps = 0  # Track successful steps\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Introduce adaptive velocity scaling\n                scale_factor = 1 + (0.1 * self.successful_steps / self.population_size)\n                particles[i] += scale_factor * velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n                    self.successful_steps += 1  # Increment successful steps\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Enhance local search around global best\n            local_search = global_best_position + np.random.normal(0, 0.1, self.dim)\n            local_search = np.clip(local_search, self.lower_bound, self.upper_bound)\n            local_score = func(local_search)\n            if local_score < global_best_score:\n                global_best_score = local_score\n                global_best_position = local_search\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.061530822382580674, 0.061596920405409095, 0.05311532869353519, 0.05844529898643169, 0.05056911928462193, 0.050062129972441194, 0.06892498923450996, 0.05855231897427671, 0.05793230609205913]}}
{"id": "9c9d61cf-8fc3-4381-acbd-e5898a613dc2", "fitness": 0.055614215235296416, "name": "HybridPSOSA", "description": "Introduce a dynamic velocity clamp to improve exploration and exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n            dynamic_velocity_clamp = (self.velocity_clamp[0] * (1 - evaluations / self.budget), self.velocity_clamp[1] * (1 - evaluations / self.budget))\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], dynamic_velocity_clamp[0], dynamic_velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05887671266352901, 0.05467663816603563, 0.052236273251787146, 0.05441619563519895, 0.05135849715788299, 0.04912867690479028, 0.06356575781301588, 0.05960854333555754, 0.056660642189870325]}}
{"id": "e56c3c57-092b-4060-b7b2-764f854d1496", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Incremental improvement of HybridPSOSA by adjusting the cooling rate to enhance balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.995  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "a5233515-d1af-46a2-aecd-b58bc6a43b64", "fitness": 0.05600076568410344, "name": "HybridPSOSA", "description": "Introduce a local search phase to refine solutions after simulated annealing in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.local_search_steps = 5  # Local search step count\n\n    def local_search(self, position, func):\n        best_pos = np.copy(position)\n        best_score = func(best_pos)\n        for _ in range(self.local_search_steps):\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            new_pos = np.clip(best_pos + perturbation, self.lower_bound, self.upper_bound)\n            new_score = func(new_pos)\n            if new_score < best_score:\n                best_score = new_score\n                best_pos = new_pos\n        return best_pos, best_score\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            self.temp *= self.cooling_rate\n\n            # Apply local search phase\n            global_best_position, global_best_score = self.local_search(global_best_position, func)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.062026917649085744, 0.05369413123567168, 0.051075782475882514, 0.0564247309850201, 0.05046984274719435, 0.04806510202601966, 0.06847283852385133, 0.05843579898439244, 0.05534174652981316]}}
{"id": "d9700f24-590a-4b42-bfc6-344c9cb87c5f", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Introduce a momentum factor to dynamically adjust the cooling rate, enhancing convergence speed while adhering to the 1.6% change constraint.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature with momentum factor\n            self.temp *= self.cooling_rate + (0.01 * (evaluations / self.budget))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "a1bff0d6-22be-4cc5-9e45-d86b46943ccf", "fitness": 0.05166711271066674, "name": "HybridPSOSA", "description": "Introduce a diversity mechanism in HybridPSOSA by incorporating opposition-based learning to enhance convergence speed.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)  # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n            \n            # Opposition-based learning\n            opposition_particles = self.lower_bound + self.upper_bound - particles\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n                \n                # Update particle position with possible opposition-based position\n                if func(opposition_particles[i]) < func(particles[i]):\n                    particles[i] = opposition_particles[i]\n                else:\n                    particles[i] += velocities[i]\n\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n            \n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05145769920834442, 0.05169160654975358, 0.05162553723986052, 0.04760000991311275, 0.048787063399157504, 0.04786280811811794, 0.054644276613620923, 0.05627575768128712, 0.055059255672745944]}}
{"id": "1052faf4-b74f-4a6f-917b-073b5de48a5d", "fitness": 0.057859336304058054, "name": "HybridPSOSA", "description": "Improve global convergence by introducing a Levy flight mechanism and stochastic dynamic parameter adjustment.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def levy_flight(self, lam=1.5):\n        u = np.random.normal(0, 1, self.dim) * (0.01 ** (1 / lam))\n        v = np.random.normal(0, 1, self.dim)\n        return u / (abs(v) ** (1 / lam))\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i])\n                                 + self.levy_flight())  # Introduce Levy flight\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.060598130011333295, 0.05421060261576571, 0.05547298673531753, 0.0568259366379571, 0.0519117912332534, 0.05212454087502294, 0.06868025355157803, 0.06031737544672611, 0.060592409629568356]}}
{"id": "0fa80755-8f8b-4b8a-a747-d92fa589c120", "fitness": 0.05693620262650055, "name": "HybridPSOSA", "description": "Introduce a novel stochastic mutation operator to improve exploration and prevent premature convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update with mutation\n                mutation = np.random.normal(0, 0.1, self.dim) * (1 - evaluations/self.budget)\n                particles[i] += velocities[i] + mutation\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06022658089157895, 0.0530301459348137, 0.05506765347951614, 0.056442251108332786, 0.05313603168749703, 0.04871037177301751, 0.06761243697615671, 0.0619710124479137, 0.05622933933967844]}}
{"id": "3c61ffb5-238c-408d-92e6-4b8310a6dd39", "fitness": 0.0604873908562743, "name": "HybridPSOSA", "description": "Introduce a dynamic cooling rate based on evaluations to improve convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Dynamic cooling rate adjustment\n            self.temp *= (0.9 + 0.1 * evaluations / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.053098082551428005, 0.06332133328097134, 0.05977707012465938, 0.04979486169009539, 0.0584654980106043, 0.06963119992057021, 0.05757587426603994, 0.0696697254287243]}}
{"id": "8981c2d6-83db-4bf0-ba30-dc5f84559775", "fitness": 0.0570231073017364, "name": "HybridPSOSA", "description": "Incorporate a Lvy flight strategy into HybridPSOSA to enhance global search capabilities and diversify exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.95  # Adjusted cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.alpha_levy = 0.01  # Lvy flight factor\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=size)\n        v = np.random.normal(0, 1, size=size)\n        step = u / np.abs(v)**(1 / beta)\n        return self.alpha_levy * step\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i] + self.levy_flight(self.dim)  # Add Lvy flight\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.058712676781756734, 0.05574797864705572, 0.05148134872927901, 0.05681283570643891, 0.05111195447827699, 0.05229581930602367, 0.06675258382988691, 0.059330372514110885, 0.06096239572279882]}}
{"id": "02a61357-6751-4936-bc0a-7fb5f79040f2", "fitness": 0.05286724178090701, "name": "HybridPSOSA", "description": "Introduce a dynamic velocity scaling factor based on standard deviation to balance exploration and exploitation in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            velocity_scaling = np.std(personal_best_scores) / np.sqrt(self.dim)  # New dynamic scaling factor\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] * velocity_scaling\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05578647174083051, 0.04887085605911867, 0.049832564578212724, 0.05280643010347119, 0.04819493155613863, 0.04796571649001968, 0.06134179377552518, 0.05592875772105077, 0.05507765400379572]}}
{"id": "824fc89c-33fb-461e-a1c4-a6781914a57b", "fitness": 0.057050798812978046, "name": "HybridPSOSA", "description": "Introducing a nonlinear time-varying acceleration coefficient for reduced convergence time.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (np.sin(np.pi * evaluations / self.budget))**2  # Nonlinear time-varying social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05650489306119, 0.05311352803860625, 0.05189754201498786, 0.06260101205523827, 0.05066110186747064, 0.048820949381375045, 0.07488787737131475, 0.058689051279460114, 0.05628123424715947]}}
{"id": "ec5e0064-2822-4f7e-bc28-9bb2e1cd219d", "fitness": 0.055614215235296416, "name": "HybridPSOSA", "description": "Dynamically adjust the velocity clamp to enhance convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            # Adjust velocity clamp based on evaluations\n            dynamic_velocity_clamp = (self.velocity_clamp[0] * (1 - evaluations / self.budget), \n                                      self.velocity_clamp[1] * (1 - evaluations / self.budget))\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], dynamic_velocity_clamp[0], dynamic_velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05887671266352901, 0.05467663816603563, 0.052236273251787146, 0.05441619563519895, 0.05135849715788299, 0.04912867690479028, 0.06356575781301588, 0.05960854333555754, 0.056660642189870325]}}
{"id": "f0f34c36-ee34-4e03-bc84-d6517d1af1b8", "fitness": 0.059509753537540226, "name": "HybridPSOSA", "description": "Implement a sigmoid function to scale the cognitive weight dynamically in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = 1.7 / (1 + np.exp(-10 * (0.5 - evaluations / self.budget)))  # Sigmoid scaling of cognitive weight\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06593801749679051, 0.05786384670382527, 0.05373886304969622, 0.06140203665884292, 0.05403035204618756, 0.049294500712180445, 0.07314935086647989, 0.06325088099076137, 0.05691993331309786]}}
{"id": "c1741824-1fc1-425e-a066-5548d366a264", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Introduce a dynamic particle population size adjustment based on convergence rate in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            if evaluations % 100 == 0:  # Dynamic population size adjustment every 100 evaluations\n                self.population_size = int(self.population_size * 0.98) if evaluations < self.budget / 2 else int(self.population_size * 1.02)\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "0723099a-b62b-41f8-8d46-2ca1a3d308dd", "fitness": -Infinity, "name": "HybridPSOSALevy", "description": "Integrate a Levy flight mechanism into HybridPSOSA to enhance exploration and diversification.", "code": "import numpy as np\n\nclass HybridPSOSALevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i] + self.levy_flight()  # Integrate Levy flight\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {}}
{"id": "4d319e8b-2097-4b38-b2a0-bb30885fe0fc", "fitness": 0.057845160057872116, "name": "HybridPSOSA", "description": "Improve convergence speed by introducing a neighborhood-based local search around the global best position.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Local search around global best\n            neighbor = global_best_position + np.random.uniform(-0.1, 0.1, self.dim)\n            neighbor = np.clip(neighbor, self.lower_bound, self.upper_bound)\n            neighbor_score = func(neighbor)\n            evaluations += 1\n            if neighbor_score < global_best_score:\n                global_best_score = neighbor_score\n                global_best_position = neighbor\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05781112042773717, 0.059628025126938544, 0.05241816816677136, 0.05872017158240428, 0.052903012366397384, 0.04935754791578273, 0.07108569744996673, 0.06166382005142779, 0.05701887743342304]}}
{"id": "e0072fc3-00ba-4bb0-8514-7c2cfedc2831", "fitness": 0.05413817479320869, "name": "HybridPSOSA", "description": "Refine HybridPSOSA by incorporating a dynamic mutation factor to diversify exploration and improve convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n                \n                # Introduce a dynamic mutation factor\n                mutation_factor = np.random.rand() * (1 - evaluations / self.budget)\n                velocities[i] += mutation_factor * (np.random.rand(self.dim) - 0.5)\n                \n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05682498217888543, 0.05375776747237859, 0.05323287041684366, 0.05218592075125972, 0.04742403528523831, 0.05044571515161045, 0.06049856530941344, 0.05448432787739488, 0.05838938869585375]}}
{"id": "3eb09ae7-a147-4894-b69c-c5b1b37370e8", "fitness": 0.05739155995330831, "name": "HybridPSOSA", "description": "Enhance the exploration and exploitation balance in HybridPSOSA by introducing dynamic variation of inertia weight and personal weight adjustment.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.2  # Adjusted minimum inertia weight\n        self.c1 = 2.0  # Adjusted cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06356416336228776, 0.04814954849973718, 0.051769143286439, 0.06506522267654413, 0.04732601471813214, 0.04998009518397406, 0.078484558270283, 0.05438830798744421, 0.05779698559493329]}}
{"id": "a61e56b5-ded8-4c0c-b054-73c0c4780aad", "fitness": 0.05379785030295344, "name": "HybridPSOSA", "description": "Enhance the exploration capability by modifying the velocity update rule with a new random perturbation factor.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.randn(self.dim) # New random perturbation\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i])\n                                 + 0.1 * r3)  # Adding perturbation factor\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.05470086844452837, 0.05277638059500145, 0.05094224331130903, 0.051982584050999536, 0.04847038977081686, 0.050753621762710144, 0.06025942353795721, 0.05590460899013472, 0.05839053226312363]}}
{"id": "0089ce79-ee5f-418b-bbf6-bad4b026b666", "fitness": 0.06171332964585904, "name": "HybridPSOSA", "description": "Introduce a random restart mechanism in HybridPSOSA when the global best score stagnates for a number of iterations.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["ec74e0ca-b99b-4b96-a842-903ccd357db1"], "operator": null, "metadata": {"aucs": [0.06692221371535834, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.07639043157491643, 0.05757587426603994, 0.07047437287209835]}}
{"id": "e6c69586-1f5c-4af0-9a46-7537fa4d05e1", "fitness": 0.05253911331898047, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive learning coefficients and dynamic restart mechanism to boost exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0  # Adjusted initial cognitive weight\n        self.c2_max = 1.7  # Adjusted max social weight\n        self.cooling_rate = 0.95  # Adjusted cooling rate for SA\n        self.temp = 1.5  # Increased initial temperature for SA\n        self.stagnation_limit = 8  # Reduced stagnation limit for quick restart\n        self.restart_threshold = 0.05  # Dynamic restart threshold\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = 1.5 + 0.5 * np.sin(evaluations / 50)  # Adaptive cognitive weight using sine wave\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit or score - global_best_score < self.restart_threshold:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.05722683369608883, 0.05463958440898076, 0.050329189564643384, 0.047391928372360725, 0.05202331514464997, 0.04498066461323247, 0.05437215671867979, 0.060490383905152156, 0.05139796344703618]}}
{"id": "236c5cf1-0360-4881-b806-3782a9f94cfa", "fitness": 0.05686859689322564, "name": "HybridPSOSA", "description": "Introduce an adaptive stagnation limit based on evaluations to enhance the HybridPSOSA's exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n        stagnation_limit = self.budget // 50  # Adjust stagnation limit based on budget\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06319604735259232, 0.052969488805204246, 0.05326513765132812, 0.059038714871141984, 0.04979486169009539, 0.04935084116221, 0.06963119992057021, 0.05757587426603994, 0.05699520631984856]}}
{"id": "157cee28-7339-462d-8454-4c31dfcc59e3", "fitness": 0.05451270965467124, "name": "HybridPSOSA", "description": "Enhance global exploration by adding a mutation mechanism to particles' positions, improving diversity in the search space.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n        self.mutation_rate = 0.1  # Mutation rate for diversity\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply mutation to enhance exploration\n                mutation = np.random.rand(self.dim) < self.mutation_rate\n                particles[i] = np.where(mutation, np.random.uniform(self.lower_bound, self.upper_bound, self.dim), particles[i])\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.05675656776151983, 0.05623279268623682, 0.04993394661509121, 0.05204094182509267, 0.05291152658594778, 0.046873016811149304, 0.060317478694423055, 0.06161569135740941, 0.05393242455517111]}}
{"id": "0f385334-fee6-496a-a579-10c1731853e2", "fitness": 0.05617094304721499, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA with dynamic inertia weight and adaptive personal/social factors for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.0  # Adjusted initial cognitive weight\n        self.c1 = self.c1_initial  # Cognitive weight\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 8  # Adjusted stagnation limit\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget)**0.5)  # Dynamic inertia weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2_max * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.c1 = self.c1_initial * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.059545091573295794, 0.05302637701995039, 0.05435068420145073, 0.05541267886834034, 0.04991172869196592, 0.051291318174588874, 0.0647806068747111, 0.057730598306128034, 0.05948940371450373]}}
{"id": "8ae024cb-fd09-442c-a0f1-d321a82aec83", "fitness": 0.06053237709737807, "name": "HybridPSOSA", "description": "Introduce adaptive mutation to enhance exploration when stagnation is detected.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim) + np.random.normal(0, 0.1, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "1d4ecf0e-fd1c-4e0c-a40a-2de542bfb148", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by incorporating a dynamic velocity clamp and self-adaptive restart mechanism based on population diversity to improve convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.diversity_threshold = 0.1  # New: Diversity threshold for adaptive restart\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            # New: Dynamically adjust velocity clamp based on diversity\n            avg_position = np.mean(particles, axis=0)\n            diversity = np.mean(np.linalg.norm(particles - avg_position, axis=1))\n            if diversity < self.diversity_threshold:\n                self.velocity_clamp = (-0.5, 0.5)\n            else:\n                self.velocity_clamp = (-1.0, 1.0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.population_size:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "f0a3c8ba-cdbc-4e6a-9c7c-c93377aa02f5", "fitness": 0.056312002533093576, "name": "HybridPSOSA", "description": "Introduce adaptive learning factors and a dynamic exploration-exploitation balance by modifying velocity and restart strategies in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1_min = 1.0  # Minimum cognitive weight\n        self.c1_max = 2.5  # Maximum cognitive weight\n        self.c2_min = 1.0  # Minimum social weight\n        self.c2_max = 2.5  # Maximum social weight\n        self.cooling_rate = 0.98  # Adjusted cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 15  # Adjusted stagnation limit for random restart\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            adaptive_factor = (global_best_score - np.mean(personal_best_scores)) / (np.std(personal_best_scores) + 1e-10)\n            self.c1 = self.c1_max - adaptive_factor * (self.c1_max - self.c1_min)\n            self.c2 = self.c2_min + adaptive_factor * (self.c2_max - self.c2_min)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n                    velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.054554485077113135, 0.04872093183583204, 0.06125161458614392, 0.05589732797765967, 0.043780778981658997, 0.056074114289410004, 0.0660366819860253, 0.05340753152730393, 0.0670845565366952]}}
{"id": "1fb46dd6-7871-4c78-8c7a-cbcf012aa97a", "fitness": 0.06053237709737807, "name": "HybridPSOSA", "description": "Introduce a Gaussian perturbation during random restarts to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim) + np.random.normal(0, 0.1, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "3a704966-cce7-4e5d-addc-7f30cabcdc14", "fitness": 0.06171332964585904, "name": "HybridPSOSA", "description": "Introduce a dynamic multi-population strategy to enhance exploration and exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.num_subpopulations = 3  # Added variable for subpopulations\n\n    def __call__(self, func):\n        evaluations = 0\n        global_best_score = float('inf')\n        global_best_position = None\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            for subpop in range(self.num_subpopulations):\n                particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n                velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n                personal_best_positions = np.copy(particles)\n                personal_best_scores = np.array([func(p) for p in particles])\n                subpop_global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n                subpop_global_best_score = np.min(personal_best_scores)\n\n                if subpop_global_best_score < global_best_score:\n                    global_best_score = subpop_global_best_score\n                    global_best_position = subpop_global_best_position\n\n                evaluations += self.population_size\n\n                while evaluations < self.budget:\n                    self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n                    self.c2 = self.c2_max * (1 - evaluations / self.budget)\n                    self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n                    for i in range(self.population_size):\n                        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                        velocities[i] = (self.w * velocities[i]\n                                         + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                         + self.c2 * r2 * (global_best_position - particles[i]))\n                        velocities[i] = np.clip(velocities[i], *self.velocity_clamp)\n\n                        particles[i] += velocities[i]\n                        particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                        score = func(particles[i])\n                        evaluations += 1\n\n                        if score < personal_best_scores[i]:\n                            personal_best_scores[i] = score\n                            personal_best_positions[i] = np.copy(particles[i])\n\n                        if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                            global_best_score = score\n                            global_best_position = np.copy(particles[i])\n                            stagnation_count = 0\n                        else:\n                            stagnation_count += 1\n\n                        if stagnation_count >= self.stagnation_limit:\n                            particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                            velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                            stagnation_count = 0\n\n                    self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06692221371535834, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.07639043157491643, 0.05757587426603994, 0.07047437287209835]}}
{"id": "a12d82b7-ce02-4158-ab30-95207d2ed3f6", "fitness": 0.05493801293291673, "name": "HybridPSOSA", "description": "Enhanced PSOSA with dynamic mutation rate and adaptive velocity bounds for improved global exploration and local exploitation.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                \n                if np.random.rand() < self.mutation_rate:\n                    velocities[i] += np.random.uniform(-0.5, 0.5, self.dim)\n                \n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.mutation_rate *= 0.99\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.056729294646435835, 0.05131714587393632, 0.053858074948869517, 0.0548635378277994, 0.04806609498373382, 0.05072378973946212, 0.06405031552061258, 0.05533165070889634, 0.05950221214650464]}}
{"id": "70e0629a-fbca-4974-a326-6bcc7802da87", "fitness": 0.0580202321907192, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by adjusting the maximum velocity clamp to improve exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-2.0, 2.0)  # Adjusted max velocity clamp for better exploration\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06327051329559819, 0.05116333193288469, 0.054651227534292746, 0.05722322478643693, 0.05238386205464196, 0.05313463790306616, 0.06735448098809338, 0.0611454140676535, 0.06185539715380528]}}
{"id": "0d7a30cb-ea19-48c5-a206-c9f517cae6b8", "fitness": 0.06011219190818078, "name": "HybridPSOSA", "description": "Integrate dynamic neighborhood topology and adaptive inertia weight with a convergence-enhanced mechanism in HybridPSOSA to improve search efficiency.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n        self.neighborhood_size = 5  # Neighborhood size for local topology\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                local_best_position = self._get_local_best(particles, personal_best_scores, i)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (local_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score\n\n    def _get_local_best(self, particles, scores, index):\n        neighborhood_indices = (np.arange(index - self.neighborhood_size, index + self.neighborhood_size + 1)\n                                % self.population_size)\n        local_best_index = neighborhood_indices[np.argmin(scores[neighborhood_indices])]\n        return particles[local_best_index]", "configspace": "", "generation": 58, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.05827425118246099, 0.05717562753835792, 0.05726620676129546, 0.0601506648526019, 0.05507420239436789, 0.055158875647351335, 0.07148165612807367, 0.06170242874084486, 0.06472581392827303]}}
{"id": "1f784d45-bc36-4066-b001-6bf35fbd7bb4", "fitness": 0.056664768533869335, "name": "HybridPSOSA", "description": "Increase the initial temperature for simulated annealing to enhance exploration capabilities.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 5.0  # Initial temperature for SA (increased from 1.0)\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.0609781509312084, 0.05066698813429704, 0.04750421183490161, 0.058840161708694994, 0.0484023853525839, 0.05495972788232362, 0.06944701258008157, 0.05477961065656112, 0.06440466772417175]}}
{"id": "239d6e88-26a6-494d-98f7-703dcda4286e", "fitness": 0.05792754981134941, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by incorporating adaptive velocity scaling and integrating an elite particle preservation mechanism to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n        self.elite_size = 2  # Number of elite particles\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n        elite_indices = np.argsort(personal_best_scores)[:self.elite_size]\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                if i in elite_indices:  # Preserve elite particles\n                    continue\n\n                # PSO velocity update with adaptive velocity scaling\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06731007480720574, 0.05624670232810236, 0.049235183682451944, 0.06048739248148416, 0.05407239291059496, 0.047490680207769476, 0.07209726039663211, 0.05979022065412287, 0.05461804083378108]}}
{"id": "e44a231e-d072-4c9c-b69e-ba10f826c733", "fitness": 0.05798281254828227, "name": "HybridPSOSA", "description": "Introduce a non-linear reduction strategy for inertia weight to enhance exploration and exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Non-linear decrease of inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget) ** 2)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.07066222433935387, 0.053043957005988185, 0.054418230832335546, 0.058433225522499965, 0.052506491493464535, 0.048771139982495715, 0.0667003077993229, 0.06108660002817756, 0.05622313593090211]}}
{"id": "41101464-fe0f-4e1a-9554-07a76878aaff", "fitness": 0.050675419932647826, "name": "HybridPSOSA", "description": "Introduce non-uniform mutation for particles near local minima to enhance exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Non-uniform mutation for exploration\n                if np.abs(func(particles[i]) - global_best_score) < 0.1:\n                    particles[i] += np.random.normal(0, 0.1, self.dim)\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.05532870392122469, 0.04918474219711688, 0.04787585135488581, 0.05203601444956096, 0.04685529053524495, 0.042448930624973014, 0.06028729317677295, 0.053799554425864815, 0.04826239870818638]}}
{"id": "10662e60-77a6-4ee8-a325-c6df7d5242b8", "fitness": -Infinity, "name": "HybridPSOSA", "description": "Introduce a dynamic particle size adjustment strategy based on convergence speed and include an elite particle retention mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n        self.elite_fraction = 0.1  # Fraction of elite particles to retain\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Adjust population size dynamically\n            if evaluations % 10 == 0:  # Adjust size every 10 evaluations\n                self.population_size = max(10, int(self.population_size * 0.95))\n                elite_count = int(self.elite_fraction * self.population_size)\n                elite_indices = np.argsort(personal_best_scores)[:elite_count]\n                new_particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size - elite_count, self.dim))\n                particles[:elite_count] = personal_best_positions[elite_indices]\n                particles[elite_count:] = new_particles\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (26,23) into shape (28,23)').", "error": "ValueError('could not broadcast input array from shape (26,23) into shape (28,23)')", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {}}
{"id": "871bc73f-51f7-4512-b788-dc8f92f3f638", "fitness": 0.06062252429081229, "name": "HybridPSOSA", "description": "Introduce adaptive stagnation limit and velocity scaling based on improvement rate in HybridPSOSA to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            improvement_rate = np.mean(personal_best_scores < global_best_score)  # Calculate improvement rate\n            dynamic_stagnation_limit = int(self.stagnation_limit * (1 + improvement_rate))  # Adaptive stagnation limit\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if adaptive stagnation limit is reached\n                if stagnation_count >= dynamic_stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06305287243337587, 0.052969488805204246, 0.06331946864564997, 0.05977707012465938, 0.04979486169009539, 0.059007509859617224, 0.06963119992057021, 0.05757587426603994, 0.07047437287209835]}}
{"id": "7162e971-386d-47d8-85e1-7a636a6b8aaa", "fitness": 0.05683844553773988, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing adaptive velocity limits, particle diversity boost via Gaussian perturbation, and staggered stagnation restarts for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.99  # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  \n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                # Adaptive velocity clamping\n                velocity_limit = np.exp(-5 * evaluations / self.budget) * np.ptp(self.velocity_clamp)\n                velocities[i] = np.clip(velocities[i], -velocity_limit, velocity_limit)\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  \n                else:\n                    stagnation_count += 1  \n\n                # Introducing a staggered random restart mechanism\n                if stagnation_count % self.stagnation_limit == 0 and stagnation_count > 0:\n                    particles += np.random.normal(0, 0.1, particles.shape)  # Boost diversity\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06350031157821501, 0.051693559755579876, 0.05353570211418335, 0.05939722855264962, 0.0485870677360043, 0.05034897161254026, 0.07024420756392791, 0.05600114500993092, 0.05823781591662769]}}
{"id": "fae87750-45f4-45ea-a91a-4d657afffee4", "fitness": 0.06171332964585904, "name": "HybridPSOSA", "description": "Enhance the cooling schedule of the simulated annealing process to improve global exploration capability.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30  # Number of particles\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.7  # Cognitive (personal) weight\n        self.c2_max = 1.5  # Max social (global) weight\n        self.cooling_rate = 0.999 # Cooling rate for SA\n        self.temp = 1.0  # Initial temperature for SA\n        self.stagnation_limit = 10  # Stagnation limit for random restart\n\n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0  # Initialize stagnation count\n\n        while evaluations < self.budget:\n            # Linearly decrease inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget) # Dynamic adjustment of social weight\n            self.c1 = self.c1 * (1 - evaluations / self.budget)  # Adaptive personal weight adjustment\n\n            for i in range(self.population_size):\n                # PSO velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # PSO position update\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Evaluate new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Simulated annealing acceptance criterion\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    # Update global best\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0  # Reset stagnation count on improvement\n                else:\n                    stagnation_count += 1  # Increment stagnation count if no improvement\n\n                # Randomly restart particles if stagnation limit is reached\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            # Cooling down the temperature\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06692221371535834, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.07639043157491643, 0.05757587426603994, 0.07047437287209835]}}
{"id": "a802d94d-cb12-4550-8e2b-9388805bf608", "fitness": 0.06171332964585904, "name": "HybridPSOSA", "description": "Introduce scale factor adaptation and diversity maintenance to enhance the exploration and exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        \n        # Add scale factor for diversity\n        self.scale_factor = 0.5  # Introduce a scale factor for diversity\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            \n            # Adapt scale factor based on progress\n            diversity = np.std(particles) / (self.upper_bound - self.lower_bound)\n            self.scale_factor = 0.5 + (1.0 - diversity) * 0.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                if stagnation_count >= self.stagnation_limit:\n                    # Use scale factor for particle randomization\n                    particles[i] = self.scale_factor * np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = self.scale_factor * np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.06692221371535834, 0.052969488805204246, 0.06331946864564997, 0.05896574538375143, 0.04979486169009539, 0.059007509859617224, 0.07639043157491643, 0.05757587426603994, 0.07047437287209835]}}
{"id": "30f05600-f2dd-4ff9-baab-b9a6c35b50fe", "fitness": 0.06427086397761222, "name": "HybridPSOSA", "description": "Enhance convergence by integrating adaptive mutation and dynamic neighborhood topology in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["0089ce79-ee5f-418b-bbf6-bad4b026b666"], "operator": null, "metadata": {"aucs": [0.07207663063818814, 0.05532574503710341, 0.05806201285056534, 0.06168550901468384, 0.05918070131515596, 0.05821916121803239, 0.07398243599670917, 0.0706781849362218, 0.06922739479184992]}}
{"id": "35127c7a-ef01-46ea-bf65-e5caf6ea74ef", "fitness": 0.060923986083162344, "name": "HybridPSOSA", "description": "Introduce adaptive mutation scaling based on particles' distance to the global best to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Adaptive mutation scaling based on distance to global best\n                distance_to_global = np.linalg.norm(particles[i] - global_best_position)\n                mutation_scale = 0.1 * (distance_to_global / self.dim)\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, mutation_scale, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["30f05600-f2dd-4ff9-baab-b9a6c35b50fe"], "operator": null, "metadata": {"aucs": [0.05992404611445479, 0.05883456524588937, 0.0562440146668558, 0.06281587106422448, 0.05504020439785695, 0.053181920820276396, 0.07544344825078653, 0.06461847106068974, 0.06221333312742705]}}
{"id": "74b9d767-18a8-4ae7-875f-bc9083adc25e", "fitness": 0.057695599847894505, "name": "HybridPSOSA", "description": "Improve HybridPSOSA convergence by enhancing mutation adaptiveness and introducing a temperature-based mutation threshold.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation based on a temperature threshold\n                if np.random.rand() < self.mutation_rate * (1 - self.temp):  # Line changed\n                    mutation = np.random.normal(0, 0.1 * self.temp, self.dim)  # Line changed\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["30f05600-f2dd-4ff9-baab-b9a6c35b50fe"], "operator": null, "metadata": {"aucs": [0.05842450976706148, 0.05729251640327082, 0.05661246896165051, 0.05428219484397012, 0.053762559175252855, 0.05210119218786069, 0.06336584834369963, 0.06286578378726593, 0.06055332516101852]}}
{"id": "e8c46cdb-caea-42dd-aa47-6029d17b50d5", "fitness": 0.06683169289816746, "name": "HybridPSOSA", "description": "Incorporate an adaptive mutation rate that reduces as evaluations progress to balance exploration and exploitation in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["30f05600-f2dd-4ff9-baab-b9a6c35b50fe"], "operator": null, "metadata": {"aucs": [0.11477145738005923, 0.05793378476814648, 0.05806201285056534, 0.05898489731658185, 0.05753674206880943, 0.05317614927489034, 0.07011163197050463, 0.06825097570998939, 0.06265758474396044]}}
{"id": "a8a270a3-ea96-4a4f-a774-0f41363d3b07", "fitness": 0.05907219993000476, "name": "HybridPSOSA", "description": "Enhance exploration by adjusting velocity range based on evaluations to strike a better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adjust velocity_clamp based on evaluations\n                velocity_range = self.velocity_clamp[1] * (1 - evaluations / self.budget) \n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -velocity_range, velocity_range)\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06750994956813394, 0.05167453493488139, 0.056898921111893874, 0.0628655492239778, 0.05010492587235149, 0.050669479707641796, 0.07533658940925447, 0.057916668191532406, 0.05867318135037569]}}
{"id": "a42bd53c-0aa8-4f9f-9ba5-0384e7b43e6c", "fitness": 0.06465035488840488, "name": "HybridPSOSA", "description": "Introduce a small perturbation in the velocities using a Gaussian distribution to enhance local search capability in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] += np.random.normal(0, 0.01, self.dim)  # Introduce small perturbation\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06591691259194932, 0.06077738469219429, 0.05744805571198153, 0.06908457086662068, 0.05380481851457819, 0.05553759220805232, 0.09113598322646954, 0.06283858436593925, 0.06530929181785883]}}
{"id": "d5e426e1-a977-465c-9c16-ee061a1219e4", "fitness": 0.058396382066830815, "name": "HybridPSOSA", "description": "Implement a dynamic inertia weight adjustment strategy to further balance exploration and exploitation in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget) ** 2)  # Dynamic inertia weight adjustment\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06139580796325639, 0.05800255945418542, 0.05253909119243594, 0.05560197474219364, 0.054332300669153843, 0.05301352375210311, 0.06514454082259691, 0.06371285482849809, 0.06182478517705403]}}
{"id": "f55ccfdb-a7a5-4621-87b2-6aaebf2d7f69", "fitness": 0.06683169289816746, "name": "HybridPSOSA", "description": "Introduce a dynamic inertia weight adjustment based on the global best score improvement rate to enhance convergence speed and precision.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n        last_global_best_score = global_best_score  # Track previous global best score\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.w = self.w_min + (self.w_max - self.w_min) * (last_global_best_score - global_best_score) / np.abs(last_global_best_score)  # Dynamic inertia update\n            last_global_best_score = global_best_score  # Update last global best score\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.11477145738005923, 0.05793378476814648, 0.05806201285056534, 0.05898489731658185, 0.05753674206880943, 0.05317614927489034, 0.07011163197050463, 0.06825097570998939, 0.06265758474396044]}}
{"id": "13fcd699-571f-4f3e-b44e-3bfffb7793e8", "fitness": 0.0574008051951249, "name": "HybridPSOSA", "description": "Enhance exploitation by incorporating a learning component to update the inertia weight based on recent performance rather than a linear decay.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - (global_best_score / np.mean(personal_best_scores)))  # Learn-based inertia weight\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06269519546436841, 0.05416160767650591, 0.05238865688860095, 0.06135126180898287, 0.053173149742337555, 0.04837345303370477, 0.07105185057826813, 0.05846516856482176, 0.054946902998533775]}}
{"id": "4982d66d-bba0-4f08-9f8b-1b7867d191dd", "fitness": 0.061772571646748736, "name": "HybridPSOSA", "description": "Introduce a dynamic inertia weight update mechanism that uses exponential decay to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_min + (self.w_max - self.w_min) * np.exp(-5 * evaluations / self.budget) # Exponential decay for inertia weight\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.0718346430443878, 0.06343782604009074, 0.05392608627937967, 0.06270091670029276, 0.054659505927915575, 0.050653619751819146, 0.07555526798744383, 0.06448606096291332, 0.05869921812649581]}}
{"id": "7aa8742a-02d6-4734-8822-d02e0a3a8e39", "fitness": 0.06263519168070841, "name": "HybridPSOSA", "description": "Integrate a turbulence factor by adding a sinusoidal component to particle velocities for enhanced exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i])\n                                 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Turbulence factor\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.0632589349907422, 0.06268849037294466, 0.05676397999914018, 0.06694498920957881, 0.0533856805750077, 0.053579597754551234, 0.08190995116780997, 0.0624337169316489, 0.06275138412495207]}}
{"id": "0db22fb2-71a7-4e85-986e-2c569ea91da4", "fitness": 0.061058629267196025, "name": "HybridPSOSA", "description": "Introduce a slight increase to the velocity clamp range for enhanced exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.2, 1.2)  # Slightly increase velocity clamp range\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        # Initialize particles\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                # Dynamic neighborhood topology adjustment\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.0606987474991999, 0.059640779219252926, 0.05310741376129113, 0.06081514065645299, 0.05582302851249654, 0.055791009902551814, 0.07215025237107053, 0.06563323862717363, 0.06586805285527475]}}
{"id": "7f13aa80-c7a1-4645-a25e-bdb298f6617f", "fitness": 0.06101463701159829, "name": "HybridPSOSA", "description": "Introduce a decay factor in mutation's standard deviation to refine the adaptive mutation strategy.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_std = 0.1 * (1 - evaluations / self.budget)  # Introduce decay in mutation std deviation\n                    mutation = np.random.normal(0, mutation_std, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06925337299098089, 0.06160719469117315, 0.05708815620273955, 0.058228439307834834, 0.05503705664311864, 0.05290856467427518, 0.0686811126043737, 0.06468114962584526, 0.06164668636404336]}}
{"id": "b623314f-e43d-4353-87f0-7d62fc2b20be", "fitness": 0.06683169289816746, "name": "HybridPSOSA", "description": "Introduce a nonlinear cooling schedule for temperature and enhance neighborhood dynamics in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate ** (1 + 0.01 * evaluations / self.budget)  # Nonlinear cooling\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.11477145738005923, 0.05793378476814648, 0.05806201285056534, 0.05898489731658185, 0.05753674206880943, 0.05317614927489034, 0.07011163197050463, 0.06825097570998939, 0.06265758474396044]}}
{"id": "e511d027-5fa3-47f2-a19f-577ea3b36057", "fitness": 0.06101463701159829, "name": "HybridPSOSA", "description": "Introduce a dynamic mutation standard deviation that decreases over evaluations to fine-tune exploration at later stages.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_std = 0.1 * (1 - evaluations / self.budget)  # Dynamic mutation standard deviation\n                    mutation = np.random.normal(0, mutation_std, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06925337299098089, 0.06160719469117315, 0.05708815620273955, 0.058228439307834834, 0.05503705664311864, 0.05290856467427518, 0.0686811126043737, 0.06468114962584526, 0.06164668636404336]}}
{"id": "d09fa49a-0eb0-4a20-99ae-60b9b0a62946", "fitness": 0.06293062182752385, "name": "HybridPSOSA", "description": "Introduce dynamic velocity clamping to balance exploration and exploitation in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            # Dynamic velocity clamping based on evaluations\n            dynamic_velocity_range = (1.0 - evaluations / self.budget) * 2.0\n            self.velocity_clamp = (-dynamic_velocity_range, dynamic_velocity_range)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06872633436811026, 0.05892168135608278, 0.05863939912490845, 0.06227758944436579, 0.05473989889642061, 0.05715256693795634, 0.07441402396847074, 0.06405035933609116, 0.06745374301530849]}}
{"id": "3799cf5d-c97f-41db-b81f-2348524566ec", "fitness": 0.058176965668257176, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing Lvy flight mutation and a dynamic velocity update rule to improve exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                # Apply adaptive mutation with Lvy flight\n                if np.random.rand() < adaptive_mutation_rate:\n                    levy_step = np.random.normal(0, 0.1, self.dim) * np.random.standard_cauchy(self.dim)\n                    particles[i] += levy_step\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06323578501076632, 0.05536788069567311, 0.05423882857694173, 0.05517876364517271, 0.05471747449558262, 0.05176294820895333, 0.06457368881618519, 0.06422888287196593, 0.060288438693073654]}}
{"id": "e2c10308-4af5-4fef-9d1d-49bed1656797", "fitness": 0.059325921812026755, "name": "HybridPSOSA", "description": "Implement a dynamic neighborhood radius and enhanced mutation for better local and global exploration in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.initial_neighbor_radius = 5  # Dynamic neighborhood radius\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n            neighbor_radius = max(1, int(self.initial_neighbor_radius * (1 - evaluations / self.budget)))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - neighbor_radius), min(self.population_size, i + neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06261178598050687, 0.058553489618765164, 0.05385367572632016, 0.058240396623064794, 0.05418013551866396, 0.052800684680492815, 0.06869800889997812, 0.06349855430968421, 0.06149656495076472]}}
{"id": "fdceb61d-aaea-46ee-bf45-acc01e8d903d", "fitness": 0.05946006846486039, "name": "HybridPSOSA", "description": "Introduce a dynamic exploration-exploitation balance using a sigmoid function for inertia weight and velocity adjustment.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1  # Introduce mutation rate\n        self.neighbor_radius = 5  # Define neighborhood radius\n    \n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            sigmoid = 1 / (1 + np.exp(-10 * (evaluations/self.budget - 0.5)))\n            self.w = self.w_max - (self.w_max - self.w_min) * sigmoid\n            self.c2 = self.c2_max * (1 - sigmoid)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n                    \n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.06454668090108595, 0.0561314787136209, 0.05619048320902886, 0.05682306355926736, 0.05306869653209323, 0.05509136908899592, 0.06668470411124305, 0.06196815882134621, 0.06463598124706205]}}
{"id": "085649aa-eb9c-4c93-9e0f-5e55f56847d6", "fitness": 0.07350248350557491, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing elite sampling and adaptive velocity scaling to improve convergence and solution quality.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.5:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["e8c46cdb-caea-42dd-aa47-6029d17b50d5"], "operator": null, "metadata": {"aucs": [0.09764026759438904, 0.05085699467166982, 0.06628586941582026, 0.08835565497911857, 0.047641127207342815, 0.0624517406528744, 0.11837313546352102, 0.05479435186116155, 0.07512320970427666]}}
{"id": "30bed8d0-5d36-4ef1-b2a0-651146fd164d", "fitness": 0.06405809839467654, "name": "HybridPSOSA", "description": "Introduce a dynamic adaptation strategy with crowding distance to maintain diversity and improve convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5\n        self.elite_scaling_factor = 0.5\n        self.diversity_threshold = 0.1  # New: crowding threshold\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                if np.random.rand() < 0.5:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                # New: Maintain diversity based on crowding distance\n                if np.linalg.norm(particles[i] - global_best_position) < self.diversity_threshold:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["085649aa-eb9c-4c93-9e0f-5e55f56847d6"], "operator": null, "metadata": {"aucs": [0.06641138252758916, 0.05540099291209111, 0.06437177952976159, 0.06195643066418932, 0.052723387116706766, 0.06390523716533059, 0.07370836994455576, 0.06143219466617211, 0.07661311102569246]}}
{"id": "bcfd89e8-b29e-4165-a6a0-ae017c1912c2", "fitness": 0.07088313897409723, "name": "HybridPSOSA", "description": "Enhance convergence by refining elite sampling and adaptive mutation strategies with minimal adjustments.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.6:  # Slight increase in probability\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate * 1.1:  # Slight increase in adaptive mutation rate\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["085649aa-eb9c-4c93-9e0f-5e55f56847d6"], "operator": null, "metadata": {"aucs": [0.08322993219071018, 0.05595348198194572, 0.07030942772862814, 0.07641037465467904, 0.05361968320216748, 0.06320614200036045, 0.09611377828010148, 0.06268345607467996, 0.07642197465360268]}}
{"id": "d98264bf-3dca-4e5d-9663-567656897fd5", "fitness": 0.0669576512549064, "name": "HybridPSOSA", "description": "Optimize exploration by adjusting mutation scaling dynamically based on progress within the budget.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.5:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_scale = 0.1 * (1 - evaluations / self.budget)  # Dynamically scale mutation\n                    mutation = np.random.normal(0, mutation_scale, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["085649aa-eb9c-4c93-9e0f-5e55f56847d6"], "operator": null, "metadata": {"aucs": [0.0809118121560829, 0.05124238156590144, 0.060303516876006436, 0.07401961335232599, 0.04901107944669569, 0.06280289760564983, 0.09186727859737787, 0.05659054597326163, 0.07586973572085576]}}
{"id": "052e18e2-78e3-41cb-bb66-98839c44351b", "fitness": 0.06295990336054982, "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by optimizing elite sampling and mutation strategies for improved convergence and robustness.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5\n        self.elite_scaling_factor = 0.5\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                if np.random.rand() < 0.5:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_direction = np.random.choice([-1, 1], self.dim)\n                    mutation = np.random.normal(0, 0.1, self.dim) * mutation_direction\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["085649aa-eb9c-4c93-9e0f-5e55f56847d6"], "operator": null, "metadata": {"aucs": [0.07802375600249889, 0.046077340861677585, 0.059022059639250446, 0.0724743749231983, 0.043806478302796936, 0.058050063919063755, 0.09061534208853417, 0.04995710019316957, 0.06861261431475874]}}
{"id": "443fe5bc-bf4e-4e39-818f-34365eafabe8", "fitness": 0.07576006391158711, "name": "HybridPSOSA", "description": "Reinforce elite influence and mutation diversity in HybridPSOSA for better exploration.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.6:  # Changed probability from 0.5 to 0.6\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.2, self.dim)  # Changed standard deviation from 0.1 to 0.2\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.03.", "error": "", "parent_ids": ["085649aa-eb9c-4c93-9e0f-5e55f56847d6"], "operator": null, "metadata": {"aucs": [0.07337257165441491, 0.05553318809186669, 0.060107965977749034, 0.06817411913540683, 0.050358756005902894, 0.07477897215327345, 0.0825888586518051, 0.05826853598692627, 0.1586576075469388]}}
{"id": "389bb530-5ac2-4bd8-b5eb-ade22058f3a0", "fitness": 0.06656408164258094, "name": "HybridPSOSA", "description": "Enhance exploration by increasing mutation diversity in HybridPSOSA using dynamic mutation rate.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.6:  # Changed probability from 0.5 to 0.6\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.3, self.dim)  # Changed standard deviation from 0.2 to 0.3\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.0795373132688536, 0.04624180905916331, 0.06033822084020679, 0.07259057679008474, 0.05224755834095396, 0.06168647356808221, 0.09090288398827817, 0.06078484240195481, 0.07474705652565095]}}
{"id": "29e3f768-7d99-498c-811a-541e551801ef", "fitness": 0.062443909499327405, "name": "HybridPSOSA", "description": "Adjust the elite sampling size for improved convergence in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 3  # Changed from 5 to 3\n        self.elite_scaling_factor = 0.5\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                if np.random.rand() < 0.6:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.2, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.06817791939239215, 0.055268525086280995, 0.07091902325000499, 0.06462436988725817, 0.05006528357031659, 0.05375903644442115, 0.07774546643916436, 0.05867219745020058, 0.0627633639739077]}}
{"id": "0e68825f-4e27-4cc0-bd57-fd4d10d23986", "fitness": 0.06557130602764728, "name": "HybridPSOSA", "description": "Slightly increase the exploration capability by adjusting the elite scaling factor.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5\n        self.elite_scaling_factor = 0.6  # Slightly increased from 0.5 for enhanced exploration\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                if np.random.rand() < 0.6:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.2, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.0707146477379812, 0.04430127420029217, 0.0616783978959371, 0.06599051355192964, 0.04185121276382586, 0.07743468683573251, 0.0799324784566019, 0.047531076671846084, 0.10070746613467907]}}
{"id": "896112ed-6b7a-4272-adb7-10a203b2fcd8", "fitness": 0.06920878979808434, "name": "HybridPSOSA", "description": "Reinforce elite influence and mutation diversity in HybridPSOSA for better exploration with fine-tuned mutation rate.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.6:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate * 1.05:  # Increased mutation rate slightly\n                    mutation = np.random.normal(0, 0.2, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.07487059899195203, 0.05959427895991387, 0.060107965977749034, 0.06905737803196543, 0.056187400259860465, 0.06813198421826583, 0.08390448803932427, 0.06630506280100368, 0.08471995090272444]}}
{"id": "40bc9fd0-5c62-443f-b373-be0d27e7126d", "fitness": 0.06738958218038778, "name": "HybridPSOSA", "description": "Enhance velocity scaling and mutation strategy in HybridPSOSA for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5\n        self.elite_scaling_factor = 0.5 \n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.65:  # Increased probability from 0.6 to 0.65\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.25, self.dim)  # Changed standard deviation from 0.2 to 0.25\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.07706428725833003, 0.05436680218478429, 0.055356051084514135, 0.07131510791773821, 0.052324396646213134, 0.06649370915174191, 0.08740539980816231, 0.06090676294027153, 0.08127372263173449]}}
{"id": "f432513b-1ead-45d4-8b92-051a77c657c0", "fitness": 0.06513729544347308, "name": "HybridPSOSA", "description": "Introduce a dynamic velocity scaling factor in HybridPSOSA based on function evaluation ratio for improved adaptability.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  # Introduce elite sampling\n        self.elite_scaling_factor = 0.5  # Scaling for elite positions\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                # Adaptive velocity scaling based on elites\n                if np.random.rand() < 0.6:  # Changed probability from 0.5 to 0.6\n                    velocities[i] += (self.elite_scaling_factor * (1 - evaluations / self.budget)) * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.2, self.dim)  # Changed standard deviation from 0.1 to 0.2\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.07168356777419771, 0.06237056407700248, 0.06014212033876121, 0.06477958006578444, 0.055456009923761984, 0.059018270115521076, 0.07769505937498955, 0.06537637654281747, 0.06971411077842182]}}
{"id": "59be006f-97b2-4b4e-b030-a0babfb09974", "fitness": 0.06402783482690264, "name": "HybridPSOSA", "description": "Fine-tuning elite scaling enhances exploration-exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 30\n        self.velocity_clamp = (-1.0, 1.0)\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.7\n        self.c2_max = 1.5\n        self.cooling_rate = 0.99\n        self.temp = 1.0\n        self.stagnation_limit = 10\n        self.mutation_rate = 0.1\n        self.neighbor_radius = 5\n        self.elite_sample_size = 5  \n        self.elite_scaling_factor = 0.55  # Modified elite scaling factor from 0.5 to 0.55\n\n    def __call__(self, func):\n        particles = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        stagnation_count = 0\n\n        while evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * evaluations / self.budget)\n            self.c2 = self.c2_max * (1 - evaluations / self.budget)\n            self.c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n\n            elite_indices = np.argsort(personal_best_scores)[:self.elite_sample_size]\n            elite_positions = personal_best_positions[elite_indices]\n            elite_center = np.mean(elite_positions, axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + self.c1 * r1 * (personal_best_positions[i] - particles[i])\n                                 + self.c2 * r2 * (global_best_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])\n\n                if np.random.rand() < 0.6:\n                    velocities[i] += self.elite_scaling_factor * (elite_center - particles[i])\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation = np.random.normal(0, 0.2, self.dim)\n                    particles[i] += mutation\n                    particles[i] = np.clip(particles[i], self.lower_bound, self.upper_bound)\n\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                if score < global_best_score or np.exp((global_best_score - score) / self.temp) > np.random.rand():\n                    global_best_score = score\n                    global_best_position = np.copy(particles[i])\n                    stagnation_count = 0\n                else:\n                    stagnation_count += 1\n\n                for neighbor in range(max(0, i - self.neighbor_radius), min(self.population_size, i + self.neighbor_radius)):\n                    if personal_best_scores[neighbor] < personal_best_scores[i]:\n                        personal_best_positions[i] = personal_best_positions[neighbor]\n                        personal_best_scores[i] = personal_best_scores[neighbor]\n\n                if stagnation_count >= self.stagnation_limit:\n                    particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    velocities[i] = np.random.uniform(self.velocity_clamp[0], self.velocity_clamp[1], self.dim)\n                    stagnation_count = 0\n\n            self.temp *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["443fe5bc-bf4e-4e39-818f-34365eafabe8"], "operator": null, "metadata": {"aucs": [0.07953390868895915, 0.052076618731560664, 0.05119883192148944, 0.0732890355224215, 0.04897087757115648, 0.05646250572512834, 0.09167943250965682, 0.05658068316792908, 0.06645861960382227]}}
