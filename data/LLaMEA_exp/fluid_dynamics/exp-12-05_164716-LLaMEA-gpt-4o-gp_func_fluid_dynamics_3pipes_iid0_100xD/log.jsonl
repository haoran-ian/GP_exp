{"id": "7f5615ac-592d-47ed-bcbf-9ee0ff8e2390", "fitness": 0.17957916791783685, "name": "AdaptiveLevyPSO", "description": "Adaptive Particle Swarm Optimization with Lévy Flight for enhanced exploration and exploitation in dynamic search spaces.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.05  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.16.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.1434650779666039, 0.0891203670679106, 0.2721504567363344, 0.09307915387159083, 0.11092685191320517, 0.07833005016730488, 0.1356853978820639, 0.5929762260884751, 0.10047892956704285]}}
{"id": "3ab271d6-f97e-42a2-bd86-290bba5d56aa", "fitness": 0.2446417624797177, "name": "AdaptiveLevyPSO", "description": "Improved the AdaptiveLevyPSO algorithm by reducing inertia weight to enhance convergence speed.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.05  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.16.", "error": "", "parent_ids": ["7f5615ac-592d-47ed-bcbf-9ee0ff8e2390"], "operator": null, "metadata": {"aucs": [0.13811429834327116, 0.4722261736577482, 0.11794467198934644, 0.18465091200628525, 0.10675106765207132, 0.1035335199713302, 0.44964988198105205, 0.4663310668825221, 0.16257426983383227]}}
{"id": "39bc12cd-dd22-422a-8f43-03d8f8e00215", "fitness": 0.26404496374070524, "name": "AdaptiveLevyPSO", "description": "Slightly decreased the social component to balance exploration and exploitation improving convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_ids": ["3ab271d6-f97e-42a2-bd86-290bba5d56aa"], "operator": null, "metadata": {"aucs": [0.11275196833430845, 0.13929898222315495, 0.2515067444153247, 0.0985745241040612, 0.11641395985365421, 0.09974184755237825, 0.37247891881067685, 0.7736712845443103, 0.41196644382847847]}}
{"id": "4f1ef02a-70ea-4a78-98e5-8a6d36668c04", "fitness": 0.08162032240462119, "name": "AdaptiveLevyPSO", "description": "Adjusted the inertia weight dynamically to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                # Change: Dynamically adjust the inertia weight\n                self.w = 0.9 - (self.evaluations / self.budget) * 0.5\n                \n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.08262413471622232, 0.0876814920990504, 0.07862175738316068, 0.07460105025472552, 0.07954224129287235, 0.06084330856595854, 0.09444997939214317, 0.10393856726353912, 0.07228037067391868]}}
{"id": "6afc512d-2baa-40c8-8298-692459be2476", "fitness": 0.07831368121346155, "name": "AdaptiveLevyPSO", "description": "Adjusted inertia weight dynamically based on evaluations to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.4 + 0.6 * (1 - self.evaluations / self.budget)  # Dynamically adjust inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0696557020795383, 0.07147465598274005, 0.08329425315970218, 0.06447797402184396, 0.07286335116311715, 0.0753592736214086, 0.07862380333417607, 0.09343695477747449, 0.09563716278115308]}}
{"id": "19a15460-d602-4a6e-9303-48e6cbe6c34a", "fitness": 0.217759300851655, "name": "AdaptiveLevyPSO", "description": "Introduced adaptive adjustment to inertia weight based on the number of evaluations to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.w = 0.4 + 0.1 * (1 - self.evaluations / self.budget)  # Adaptive adjustment to inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.23.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09044972480844793, 0.09934479358531756, 0.6163342328946103, 0.09070736281079717, 0.08117765926173237, 0.08423405285091123, 0.13183385395365177, 0.10692478985991016, 0.6588272376395166]}}
{"id": "053bb853-b3d6-4b8b-8787-35f0a0dc1233", "fitness": 0.08661049216853373, "name": "AdaptiveLevyPSO", "description": "Introduced adaptive inertia weight to improve convergence balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            self.w = 0.9 - (0.5 * (self.evaluations / self.budget))  # Changed line: adaptive inertia weight\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0891651854915606, 0.07832195458002289, 0.08902500621032039, 0.08221288458421616, 0.06553846059718815, 0.08100040619937787, 0.10864276510721582, 0.0804078135992361, 0.1051799531476656]}}
{"id": "4d332dc3-dc76-418a-a8af-44ef37fdf9ce", "fitness": 0.0870015468208836, "name": "AdaptiveLevyPSO", "description": "Implement a dynamic inertia weight to enhance the balance between exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # Adjusted initial inertia weight for dynamic adjustment\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            # Dynamically adjust inertia weight based on progress\n            self.w = 0.9 - (0.5 * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.0987540179023575, 0.08556027129782628, 0.0781732675693565, 0.07749489290657907, 0.07808832800261312, 0.07225184541873897, 0.10207335877056467, 0.10025473031676546, 0.09036320920315077]}}
{"id": "e856ce25-17a1-4e90-801e-dc964763cc05", "fitness": 0.1271285944620914, "name": "AdaptiveLevyPSO", "description": "Introduced stochastic inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                # Change: Introduce stochastic inertia weight\n                self.velocities[i] = np.random.uniform(0.3, 0.5) * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.04.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.12474756746422444, 0.09785559003546807, 0.09994446814565416, 0.09675820131651824, 0.11254194436791753, 0.08947020820286489, 0.1445038761460845, 0.24099056751809667, 0.13734492696199418]}}
{"id": "31a8c962-7b55-4c4f-8e61-e7655ab53287", "fitness": 0.08162032240462119, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance by introducing adaptive inertia weight and dynamic velocity updates to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.08262413471622232, 0.0876814920990504, 0.07862175738316068, 0.07460105025472552, 0.07954224129287235, 0.06084330856595854, 0.09444997939214317, 0.10393856726353912, 0.07228037067391868]}}
{"id": "b9df43d8-8085-4e0e-a778-029dd55ef0d8", "fitness": 0.18569990848513113, "name": "AdaptiveLevyPSO", "description": "Introduced random restarts every 10% of evaluations to enhance escaping local optima.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            if self.evaluations > 0 and self.evaluations % (self.budget // 10) == 0:  # Change here\n                self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n            \n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.21.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09689079837202985, 0.13929898222315495, 0.10774060781738248, 0.08815101929558611, 0.11641395985365421, 0.09424478983219142, 0.11873925134817886, 0.7736712845443103, 0.13614848307969207]}}
{"id": "6ad91604-17fa-477c-b09b-6519ba4d6a19", "fitness": 0.08517360588612603, "name": "AdaptiveLevyPSO", "description": "Incorporate a dynamic inertia weight and adaptive social component to enhance exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # Increased initial inertia weight for better exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.5  # Decreased social component for better exploration balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Gradually decrease inertia weight to favor exploitation\n            self.w = 0.4 + (0.9 - 0.4) * (1 - self.evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.09382131567802388, 0.06828985107891661, 0.09222416530504907, 0.08296497368492273, 0.06324403096359632, 0.07983004552935102, 0.09852146013597873, 0.07693382338819432, 0.11073278721110158]}}
{"id": "765dc4ff-2540-403e-af73-a9f740342fde", "fitness": 0.22728278811765856, "name": "AdaptiveLevyPSO", "description": "Adjust inertia weight dynamically based on evaluation progress to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                self.w = 0.4 + 0.6 * (self.evaluations / self.budget)  # Dynamically adjust inertia weight\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.10194958731386361, 0.16851160668635612, 0.13599569840063908, 0.09436207338312785, 0.12649138945550342, 0.11593888697567101, 0.1343189100856097, 0.6418879672304542, 0.526088973527702]}}
{"id": "248c24b4-baa1-4b02-91b6-3498def0994e", "fitness": 0.32148675939334886, "name": "AdaptiveLevyPSO", "description": "Improved exploration by increasing the probability of performing a Lévy flight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.24.", "error": "", "parent_ids": ["39bc12cd-dd22-422a-8f43-03d8f8e00215"], "operator": null, "metadata": {"aucs": [0.10315347552682907, 0.10607660088037851, 0.2417008799963991, 0.6565217732010057, 0.10266466719966205, 0.12813549383940837, 0.7358976957095822, 0.29117640917730525, 0.5280538390095693]}}
{"id": "1ef26a40-dd3f-49cc-a415-d3b9cc7a8240", "fitness": 0.08714751836611084, "name": "AdaptiveLevyPSO", "description": "Advanced AdaptiveLevyPSO with dynamic parameter adjustment for improved convergence and exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.7  # increased inertia weight for better exploration initially\n        self.c1 = 1.5  # decreased cognitive component for more global search\n        self.c2 = 2.5  # increased social component for faster convergence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.initial_w = self.w\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for levy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Dynamically adjust the inertia weight for balance between exploration and exploitation\n            self.w = self.initial_w * (1 - self.evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10024457108683271, 0.07393374742796233, 0.07939559628883708, 0.08976690362783424, 0.06940798783543944, 0.06936609168008956, 0.12603745475519335, 0.0889168616590642, 0.08725845093374474]}}
{"id": "1db8d1c5-6d6e-4587-a186-fdf7176da187", "fitness": 0.08527220789381755, "name": "AdaptiveLevyPSO", "description": "Fine-tuned balance between exploration and exploitation by adjusting parameters.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # increased inertia weight from 0.4 to 0.5 for better exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.95  # decreased social component from 2.0 to 1.95 to fine-tune balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09629603623499172, 0.06414256766912252, 0.08859181604796917, 0.08554010914723098, 0.05958696865017765, 0.0807440023256395, 0.116565608330496, 0.0716249752950412, 0.10435778734368917]}}
{"id": "a7b6aa0e-773f-4962-a046-f1068955be41", "fitness": 0.09103529334918654, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration with dynamic population size and adaptive inertia weight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 20 + 10 * (dim // 10)  # Dynamic population size\n        self.init_inertia = 0.9  # Initial inertia weight\n        self.final_inertia = 0.4  # Final inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.05  # Restored original balance of the social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            inertia = self.init_inertia - (self.init_inertia - self.final_inertia) * (self.evaluations / self.budget)  # Adaptive inertia\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = inertia * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # Increased probability of Levy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09100045819508151, 0.08579398204628907, 0.08713920395254227, 0.0885832614604003, 0.07818187695259227, 0.07236350617453413, 0.12158558573322631, 0.10107594621496996, 0.09359381941304312]}}
{"id": "b8468fc0-13aa-42a3-a548-ad9993c73d51", "fitness": 0.1885008395089994, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by slightly adjusting the inertia weight factor for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.45  # inertia weight, changed from 0.4 to improve balance\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.11031947728914804, 0.10354719794182454, 0.09965914394617514, 0.0871835856565304, 0.0875251923733239, 0.10484612938603555, 0.5291191591972952, 0.11854557946732991, 0.45576209032333204]}}
{"id": "79a235ea-5f61-43ab-aee2-2a2cf85abcdd", "fitness": 0.08719964747247698, "name": "AdaptiveLevyPSO", "description": "Introducing a time-varying adaptive strategy for inertia weight and cognitive/social components for enhanced balance and convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1_initial = 2.5\n        self.c2_initial = 1.5\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            c1 = self.c1_initial - (1.5 * (self.evaluations / self.budget))\n            c2 = self.c2_initial + (1.5 * (self.evaluations / self.budget))\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08702446227667937, 0.08344547148922432, 0.08251289452833588, 0.08542129051398262, 0.07147202072579129, 0.07525539770522971, 0.11355334174723253, 0.09066346472638143, 0.09544848353943569]}}
{"id": "130c86a9-8531-43ce-b5ad-28e1625eb2a8", "fitness": 0.09630110262281982, "name": "AdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO with chaotic initialization and dynamic inertia weight adjustment for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = self.chaotic_init(self.num_particles, self.dim)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def chaotic_init(self, num_particles, dim):\n        x = np.random.rand(num_particles, dim)\n        return self.lower_bound + (self.upper_bound - self.lower_bound) * np.sin(np.pi * x)\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09554764300678309, 0.08920584326276881, 0.09079875997432163, 0.08474238832459913, 0.08100889698177072, 0.08804877505696984, 0.11318609081182462, 0.10516893591096066, 0.11900259027537985]}}
{"id": "fcab7124-52f5-44f7-bb55-000906382647", "fitness": 0.0805797285447808, "name": "AdaptiveLevyPSO", "description": "Enhanced Adaptive Levy PSO with dynamic inertia and adaptive mutation rate for improved convergence and diversity.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # Start with high inertia weight for exploration\n        self.w_min = 0.4  # Min inertia weight for exploitation phase\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.mutation_prob = 0.2  # Increased probability for mutation\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = self.w_min + (0.9 - self.w_min) * (self.budget - self.evaluations) / self.budget\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n                if np.random.rand() < self.mutation_prob:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08559613856888693, 0.08233753246968456, 0.08561981083588921, 0.06616633800257143, 0.06776366142659618, 0.07564343704374132, 0.08157014969485954, 0.08355383829667185, 0.09696665056412612]}}
{"id": "4c55a9fc-552f-4625-9eb6-c493d1372cfe", "fitness": 0.0805797285447808, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by dynamically adjusting inertia weight and increased exploration through Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                # Dynamic inertia weight adjustment\n                self.w = 0.9 - (0.5 * self.evaluations / self.budget)\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08559613856888693, 0.08233753246968456, 0.08561981083588921, 0.06616633800257143, 0.06776366142659618, 0.07564343704374132, 0.08157014969485954, 0.08355383829667185, 0.09696665056412612]}}
{"id": "5f3eb0dc-863b-409b-98fe-cdc06b4b2466", "fitness": 0.09029034883607957, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration by adjusting inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # dynamic inertia weight\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08779390320357694, 0.07766331064281728, 0.09762916622797313, 0.0779593686824438, 0.07474021471909276, 0.09701788421561108, 0.10107915275498369, 0.09633155856336861, 0.10239858051484885]}}
{"id": "9a50377f-a588-4c1e-95ed-f9c8c38d37c0", "fitness": 0.08335228480978625, "name": "EnhancedAdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO with dynamic adjustment of parameters and diversity maintenance for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # inertia weight, dynamically adjusted between 0.9 and 0.4\n        self.c1 = 1.5 + np.random.rand() * 1.5  # cognitive component, randomized for diversity\n        self.c2 = 1.5 + np.random.rand() * 1.5  # social component, randomized for diversity\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.4 + (0.9 - 0.4) * (self.budget - self.evaluations) / self.budget  # dynamic inertia weight\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.0840481296437694, 0.08409286070167465, 0.08135798842717756, 0.07043646101355117, 0.0668043418823786, 0.07681190178110231, 0.08841130350566284, 0.09940872082883245, 0.09879885550392731]}}
{"id": "91f16c94-6dc8-4813-a26f-63df861e01b4", "fitness": 0.16161601602771955, "name": "EnhancedAdaptiveLevyPSO", "description": "Enhanced exploration and exploitation via adaptive swarm intelligence with dynamic parameter adjustment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevyPSO:  # Changed class name\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 50  # Increased particle count\n        self.w = 0.5  # Increased inertia weight for enhanced exploratory behavior\n        self.c1_start, self.c1_end = 2.5, 1.5  # Dynamic cognitive component\n        self.c2_start, self.c2_end = 1.5, 2.5  # Dynamic social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        def update_parameters(eval_ratio):\n            self.c1 = self.c1_start * (1 - eval_ratio) + self.c1_end * eval_ratio\n            self.c2 = self.c2_start * eval_ratio + self.c2_end * (1 - eval_ratio)\n        \n        while self.evaluations < self.budget:\n            eval_ratio = self.evaluations / self.budget  # Calculate evaluation ratio\n            update_parameters(eval_ratio)\n\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # Increased probability for Levy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.18.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09651162508168887, 0.09757756630164871, 0.09739955727338834, 0.13414291030457215, 0.07206318650748433, 0.0876510780691836, 0.6585806131866491, 0.09090947556327122, 0.11970813196158958]}}
{"id": "ea84840b-500a-474c-b57c-0ec72c95eaf5", "fitness": 0.11812211279078794, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by reducing the inertia weight to 0.35 for better exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.35  # inertia weight, reduced from 0.4 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.03.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.12454340092463034, 0.09868944792551271, 0.08454157201086099, 0.10807647312378088, 0.0918242849907196, 0.08474056567413613, 0.19016400065889127, 0.16412456463477576, 0.1163947051737837]}}
{"id": "a47f5ece-9878-49c7-88d3-0dd14c3998b7", "fitness": 0.09950703556526325, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration in particle swarm optimization by dynamically adjusting inertia and introducing Cauchy mutation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_min = 0.1  # Minimum inertia weight\n        self.w_max = 0.5  # Maximum inertia weight\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def cauchy_mutation(self, L):\n        step = np.random.standard_cauchy(size=L)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                elif np.random.rand() < 0.1:\n                    self.positions[i] += self.cauchy_mutation(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09345853135177151, 0.10551319584149044, 0.09097929255337434, 0.08465505196920609, 0.09350381472747082, 0.07599865433567021, 0.1120917044977997, 0.13916988406917397, 0.10019319074141209]}}
{"id": "b1d88c2d-e452-4f6f-bd3c-fd5dc6668716", "fitness": 0.08722523169013117, "name": "AdaptiveLevyPSO", "description": "Enhanced particle swarm optimization with adaptive Lévy flight for improved exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.18:  # changed from 0.15 to 0.18\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09296242679146638, 0.07020774273110819, 0.0906973381046543, 0.075552875535282, 0.06488063488390705, 0.08965968716432327, 0.09770662084323878, 0.07958046806802066, 0.12377929108917995]}}
{"id": "54f91824-3f27-477e-852c-0c03b1608864", "fitness": 0.09078495260767297, "name": "AdaptiveLevyPSO", "description": "Improved exploration by increasing the probability of performing a Lévy flight to enhance convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n                \n                if np.random.rand() < 0.17:  # changed from 0.15 to 0.17\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09087970589566874, 0.07503195613630909, 0.09898579858979484, 0.08226300327724223, 0.06886425379456618, 0.0896606809766124, 0.102536748481174, 0.08677698878509155, 0.12206543753259769]}}
{"id": "836e59d0-2c3a-4789-8f8c-f04b6bf8418f", "fitness": 0.09306894579481098, "name": "AdaptiveLevyPSO", "description": "Enhanced velocity update and adaptive inertia weight for balanced exploration and exploitation in Particle Swarm Optimization.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # adaptive inertia weight, starting high for exploration\n        self.c1 = 2.05\n        self.c2 = 2.05  # slightly increased for better convergence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                # Adaptive inertia weight update\n                self.w = 0.9 - 0.5 * (self.evaluations / self.budget)\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15: \n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08450368587991586, 0.13343615718645951, 0.0849456357448104, 0.07429822999819091, 0.0788954426003795, 0.08036295005469962, 0.0951053014014912, 0.1015042354266944, 0.10456887386065739]}}
{"id": "9b06030f-1ad2-4ac8-98c6-f45a94f8287c", "fitness": 0.07096091150898819, "name": "AdaptiveLevyPSO", "description": "Improved global search efficiency by incorporating dynamic inertia adjustment and chaotic Lévy flight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.0  # decreased from 2.05 to improve balance\n        self.c2 = 2.5  # increased to enhance social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        beta = 1.5  # chaotic factor\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        step *= np.power(np.random.rand(), beta)  # add chaotic behavior\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            self.w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08728991296363076, 0.06226362360100879, 0.058605796101364405, 0.07860446717717506, 0.057854883991696804, 0.05593919866080732, 0.10215577696168343, 0.06925463951141031, 0.06667990461211681]}}
{"id": "71fd4c57-6b88-4260-850c-2d733c0756ad", "fitness": 0.16747180522993066, "name": "AdaptiveLevyPSO", "description": "Enhanced adaptive exploration by adjusting inertia weight during Lévy flights.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += 0.5 * self.velocities[i]  # Adjusted inertia weight for better control\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.15.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10053985356742523, 0.10553610877598618, 0.09799096791086193, 0.1264702443368112, 0.0788944887343711, 0.08984095298752559, 0.5885920471388374, 0.10194173162455822, 0.2174398519929991]}}
{"id": "76950da4-3277-4547-a21c-a2092b4655ef", "fitness": 0.15395730453758324, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance using adaptive inertia weight and differential mutation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # adaptive inertia weight, start with a higher value\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1 = 2.0  # slightly reduced cognitive component\n        self.c2 = 2.0  # social component remains unchanged\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def differential_mutation(self, target_idx):\n        indices = list(range(self.num_particles))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F = 0.5  # mutation factor\n        mutant_vector = self.positions[a] + F * (self.positions[b] - self.positions[c])\n        return np.clip(mutant_vector, self.lower_bound, self.upper_bound)\n\n    def adapt_inertia(self):\n        self.w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.adapt_inertia()  # adapt inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                elif np.random.rand() < 0.2:  # additional differential mutation\n                    self.positions[i] = self.differential_mutation(i)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.21.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07738172479466143, 0.7510127815492875, 0.07026788381618787, 0.07124833457367519, 0.07340319710864862, 0.07098839712547256, 0.08868962068614916, 0.09388836194002403, 0.08873543924414284]}}
{"id": "6acc34e4-f537-4fec-ba1d-eb2a6ceb0ca2", "fitness": 0.08375127794075798, "name": "AdaptiveLevyPSO", "description": "Enhance global exploration by increasing the probability of Lévy flight and adjusting the social component for better balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.95  # social component, decreased from 2.0 for better balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.20:  # increased from 0.15 to 0.20\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07452749586169372, 0.07638373252221442, 0.09247987606369845, 0.06870006341702062, 0.07776092386649491, 0.08262962296527798, 0.08498524094762439, 0.08734891761559438, 0.108945628207203]}}
{"id": "1f9f0497-7512-433e-a401-1cdc1162112b", "fitness": 0.08761634527829106, "name": "AdaptiveLevyPSO", "description": "Enhanced global exploration by adjusting social component and levy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.1  # social component, increased from 2.0 to enhance exploration\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # changed from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09971051332954117, 0.08214282630956149, 0.07799752679843763, 0.08425956487127129, 0.07499721223160938, 0.07176679485511905, 0.11168565254625773, 0.09646264370074953, 0.08952437286207227]}}
{"id": "489fcdb9-f1dd-4692-b681-687cf70b2957", "fitness": 0.20535568381631794, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration by incorporating dynamic c1 and c2 coefficients in PSO.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * (1 - self.evaluations/self.budget) * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * (self.evaluations/self.budget) * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.11156569984405251, 0.09336951885467382, 0.08762970140232962, 0.09491828203374197, 0.5293651357308231, 0.07503388595067029, 0.15761630952303018, 0.600706491362424, 0.09799612964511617]}}
{"id": "0b7b557e-875f-45dc-bd1c-64b88dffaa75", "fitness": 0.1073989566396358, "name": "AdaptiveLevyPSO", "description": "Enhanced adaptive particle control and dynamic parameter tuning for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight, increase to improve exploration\n        self.c1 = 1.5  # cognitive component, decreased for better social influence\n        self.c2 = 2.5  # social component, increased for stronger social influence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.init_levy_prob = 0.15  # initial probability for Levy flight\n        self.dynamic_levy_prob = 0.05  # dynamic adjustment for levy flight probability\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.dynamic_levy_prob = self.init_levy_prob * (1 - (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < self.dynamic_levy_prob:  # dynamically adjusted probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.04.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.17311627825232334, 0.0967249444255065, 0.09214752317131847, 0.09886183152487615, 0.06031001414090531, 0.08319444717266022, 0.17685464845807664, 0.0730072459769816, 0.11237367663407405]}}
{"id": "f3cf1e8e-9476-4871-bacf-085ea62c682e", "fitness": 0.0952025486966977, "name": "AdaptiveLevyPSO", "description": "Enhanced adaptive exploration by tweaking velocity update and Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight, increased from 0.4 to balance exploration and exploitation\n        self.c1 = 1.95  # cognitive component, slightly decreased for finer personal exploration\n        self.c2 = 2.1  # social component, slightly increased for deeper global exploration\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2 for more frequent exploratory jumps\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09005302769787749, 0.09267553416481522, 0.08102364132086404, 0.08408770972664137, 0.08344763572642577, 0.08623995334425949, 0.10925437535437432, 0.11280824014006685, 0.11723282079495467]}}
{"id": "eb052664-334f-40d9-b2e5-8bb2a7e589b5", "fitness": 0.0793908652889427, "name": "AdaptiveLevyPSO", "description": "Enhanced local search by adjusting the inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # Initial inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                # Update inertia weight dynamically\n                self.w = 0.4 + 0.6 * (1 - self.evaluations / self.budget)\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08756154022925033, 0.07451147119342438, 0.07364060658320792, 0.07738840114675405, 0.06773706507316724, 0.06723738977908145, 0.09977596276414324, 0.08359969013596558, 0.08306566069549004]}}
{"id": "f707d602-b972-4722-b53e-82a3fa7e5ce0", "fitness": 0.08065038147385974, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration by integrating dynamic inertia weight and adaptive mutation based on fitness variance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.initial_w = 0.9  # dynamic inertia starts high\n        self.final_w = 0.4  # dynamic inertia ends low\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def adaptive_mutation(self, diversity):\n        return np.random.normal(0, diversity, self.dim)\n\n    def update_inertia_weight(self):\n        return self.final_w + (self.initial_w - self.final_w) * ((self.budget - self.evaluations) / self.budget)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            scores = np.zeros(self.num_particles)  # to store particle scores\n            for i in range(self.num_particles):\n                scores[i] = func(self.positions[i])\n                self.evaluations += 1\n                \n                if scores[i] < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = scores[i]\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if scores[i] < self.global_best_score:\n                    self.global_best_score = scores[i]\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            diversity = np.std(scores) + 1e-8  # ensure no division by zero\n            self.w = self.update_inertia_weight()\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:  # reduced probability of levy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                elif np.random.rand() < 0.05:  # additional mutation based on diversity\n                    self.positions[i] += self.adaptive_mutation(diversity)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09196053185092812, 0.08137315943349277, 0.06514193220476916, 0.08156031908509231, 0.06897460630976693, 0.06314218801009153, 0.10925838645119768, 0.08673509927504497, 0.07770721064435415]}}
{"id": "e172baaf-de08-4b63-98f7-bc40bf2f00ff", "fitness": 0.08503485797608021, "name": "AdaptiveLevyPSO", "description": "Enhanced balance between exploration and exploitation by adjusting inertia weight dynamically and varied particle count.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30 + dim // 5  # Adjust number of particles based on dimensionality\n        self.w = 0.9  # Initial inertia weight, will adjust dynamically\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.4 + 0.5 * (1 - (self.evaluations / self.budget))  # Dynamically adjust inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09960263142995618, 0.06687573325576479, 0.08644106848808342, 0.08106404674434586, 0.06288899465483633, 0.07882054100492086, 0.11059484705711864, 0.0772699043834989, 0.10175595476619692]}}
{"id": "de87e9e7-324d-4c87-80fd-92ed7579b5f9", "fitness": 0.09249524793179238, "name": "AdaptiveLevyPSO", "description": "Enhanced global search by increasing the probability of performing a Lévy flight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # changed from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10081173843181912, 0.10355084175500073, 0.07926148849102066, 0.0902128034056151, 0.07444721134864485, 0.07139759523076483, 0.12630406472256261, 0.0939407112026518, 0.09253077679805177]}}
{"id": "787d5afc-7ae1-4653-b50d-bb0ca336988f", "fitness": 0.09597404926023938, "name": "AdaptiveLevyPSO", "description": "Enhance exploration by balancing the Lévy flight and velocity update frequency.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # changed from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += 0.9 * self.velocities[i]  # changed velocity scaling from 1 to 0.9\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08504583369813468, 0.09884358579113406, 0.08677802288948577, 0.07778057955306494, 0.08944289372265979, 0.08281808265265389, 0.09939914578179454, 0.12712281244189239, 0.1165354868113343]}}
{"id": "05e05b22-9e46-4a32-b38f-bc38351e1ea8", "fitness": 0.09954394050482064, "name": "AdaptiveLevyPSO", "description": "Enhanced global search by modifying inertia weight dynamically.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  \n        self.c1 = 2.05  \n        self.c2 = 2.0  \n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                self.w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # dynamic adjustment of inertia weight\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  \n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08300963921416793, 0.08674169121205388, 0.11408388245411694, 0.07967377749992166, 0.08355223837111836, 0.09623655112759477, 0.10325636047897602, 0.11240523886140985, 0.13693608532402635]}}
{"id": "d2d35ba9-5a48-427b-abfc-8e0919b9ed75", "fitness": 0.08962427236126211, "name": "EnhancedAdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO with dynamic inertia weight and mutation for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.05\n        self.c2 = 1.5\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for Levy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                if np.random.rand() < 0.1:  # mutation chance\n                    mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                    self.positions[i] += mutation\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09111070501967355, 0.08256781213898923, 0.0850995913446152, 0.08681272436091647, 0.07448019795416372, 0.08443444057188432, 0.11026279499982994, 0.079162289296825, 0.11268789556446157]}}
{"id": "816eb226-ef7d-4ba0-a602-b654d49e77e1", "fitness": 0.0981367262393546, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by slightly increasing the inertia weight for better exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.42  # inertia weight, increased from 0.4 to slightly improve exploitation\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.03.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10533345419987872, 0.08090412419480952, 0.073297126357454, 0.1431687087666984, 0.08499825324653343, 0.06767143235310968, 0.13184554559622563, 0.11278293660422944, 0.0832289548352525]}}
{"id": "2a5ace0a-b974-4eee-ac0b-f383bede7d1b", "fitness": 0.09365844537512485, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance using Non-Uniform Mutation and adaptive inertia weight adjustment.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # adaptive inertia weight (initial value)\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 1.5  # reduced social component for better exploration\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def non_uniform_mutation(self, position, t, t_max, b=5):\n        delta = (1 - np.power(t / t_max, b)) * np.random.uniform(-1, 1, size=position.shape)\n        return position + delta\n\n    def __call__(self, func):\n        t_max = self.budget / self.num_particles\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    t = self.evaluations // self.num_particles\n                    self.positions[i] = self.non_uniform_mutation(self.positions[i] + self.velocities[i], t, t_max)\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Adaptive inertia weight update\n            self.w = 0.4 + 0.5 * (1 - self.evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.1398829734423893, 0.1021912485543105, 0.0774545464796359, 0.08164534421155012, 0.07791737967763168, 0.06912342468746135, 0.10756161542781462, 0.10117735679278272, 0.08597211910254754]}}
{"id": "1d2d5e38-c0aa-4345-a4a3-b92c7db65e6a", "fitness": 0.07370955339373947, "name": "AdaptiveLevyPSO", "description": "Enhanced particle swarm optimization by slightly increasing the influence of both cognitive and social components for better convergence balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.1  # cognitive component, increased from 2.05\n        self.c2 = 2.1  # social component, increased from 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07615690889082027, 0.06825457548258052, 0.07118718592517803, 0.07180285107574591, 0.06323330611537092, 0.06585633110849953, 0.08953354822410342, 0.07683161846465603, 0.08052965525670064]}}
{"id": "7924cc8b-7bba-47c0-afc8-07c5975237cf", "fitness": 0.08026191170350588, "name": "AdaptiveLevyPSO", "description": "Enhanced the balance between exploration and exploitation using dynamic inertia weight and adaptive Lévy probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.abs(v) ** (1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)  # Dynamic inertia\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < (0.1 + 0.2 * (self.global_best_score - self.personal_best_scores[i]) / self.global_best_score):  # Adaptive probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08202553594742723, 0.07465250969494897, 0.08093577394385154, 0.07451578246518675, 0.06920119460320029, 0.07006136182056455, 0.1083300554933937, 0.07704616488383775, 0.08558882647914223]}}
{"id": "47000c04-c75c-42a4-afd7-13619e98dc8f", "fitness": 0.1710179535611317, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration by adjusting the inertia weight dynamically and increasing the Lévy flight probability slightly.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # dynamically adjust inertia weight, modified from 0.4\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.18:  # slightly increased from 0.15 to 0.18\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n                \n                self.w *= 0.99  # dynamically decrease inertia weight\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.1140950456272054, 0.7083766380539742, 0.07825800027766949, 0.0940341253264596, 0.09325320835029827, 0.0719890020655104, 0.15359837775653706, 0.13568025368203662, 0.08987693091049431]}}
{"id": "24421580-2d6b-4ff1-937a-ce20e530567a", "fitness": 0.15678163645086074, "name": "AdaptiveLevyPSO", "description": "Enhanced particle diversity by slightly increasing cognitive and social components.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.10  # cognitive component, increased from 2.05 to enhance diversity\n        self.c2 = 2.05  # social component, increased from 2.0 to enhance global search potential\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.10.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.3615813720938271, 0.08807299163516691, 0.2946045533965874, 0.08575671770140891, 0.08092732193231356, 0.0852164146024682, 0.11605610766191365, 0.18535410295759336, 0.11346514607646752]}}
{"id": "ac599f22-7205-46a8-b52c-b62d529575cf", "fitness": 0.0951179477460356, "name": "AdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO with chaotic inertia weight and dynamic particle count for improved exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = int(20 + 10 * np.random.rand())  # dynamic particle count\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.0  # cognitive component, decreased to improve balance\n        self.c2 = 2.1  # social component, slightly increased\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def chaotic_inertia_weight(self, t):\n        beta = 0.5  # logistic map parameter\n        return self.w_min + (self.w_max - self.w_min) * np.sin(beta * np.pi * t)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.chaotic_inertia_weight(self.evaluations / self.budget)  # dynamic inertia weight\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.18:  # changed from 0.15 to 0.18\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07859804143146054, 0.09101005132137174, 0.09148509842158037, 0.08915569198869633, 0.08940096281703436, 0.07711236702153257, 0.12179674559562415, 0.11824084453261374, 0.09926172658440657]}}
{"id": "790c9c4c-15cc-40d4-acde-f01c74722bd4", "fitness": 0.08407002792102575, "name": "AdaptiveLevyPSO", "description": "Enhanced Particle Swarm Optimization with Adaptive Lévy Flights and Dynamic Inertia Weight for Improved Exploration and Convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.1  # increased cognitive component for better exploration\n        self.c2 = 1.9  # decreased social component slightly for balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)  # dynamic inertia weight\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for Levy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08679123203370698, 0.0888894633518944, 0.07576815241154988, 0.07363046232396264, 0.07411905295518018, 0.07450610286441905, 0.09285872109462656, 0.09430340860837627, 0.0957636556455157]}}
{"id": "ef6584d3-d434-4135-843c-c869e8fe1bcf", "fitness": 0.08761634527829106, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by increasing the social component and adjusting the Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.1  # social component, increased from 2.0 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # changed from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09971051332954117, 0.08214282630956149, 0.07799752679843763, 0.08425956487127129, 0.07499721223160938, 0.07176679485511905, 0.11168565254625773, 0.09646264370074953, 0.08952437286207227]}}
{"id": "73b296ab-476a-4022-888a-99ac71e80bae", "fitness": 0.1118883727250097, "name": "AdaptiveLevyPSO", "description": "Improved balance between exploration and exploitation by adjusting inertia weight and Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight, increased to improve exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.12:  # decreased from 0.15 to 0.12\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.07.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09392866879987949, 0.0714718940712008, 0.09146831607823869, 0.08805126347638381, 0.07042450227658081, 0.08876064847386378, 0.2933080293211593, 0.0882485456076404, 0.12133348642014041]}}
{"id": "346b32b7-95b8-47df-bd98-9c353beb0ec5", "fitness": 0.09856800108645826, "name": "AdaptiveLevyPSO", "description": "Enhanced local search by periodically resetting velocities to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                if self.evaluations % 50 == 0:  # Reset velocities every 50 evaluations\n                    self.velocities[i] = np.random.uniform(-1, 1, self.dim)\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10083952352481074, 0.08047756420702878, 0.10285946041361982, 0.08733132957452472, 0.078219654301381, 0.09407122685080649, 0.11754895256228193, 0.10259863686477844, 0.12316566147889241]}}
{"id": "9e144c19-0c14-4ab6-a633-64f650454053", "fitness": 0.08570598898671516, "name": "AdaptiveLevyPSO", "description": "Enhance exploration using adaptive inertia weights and hybrid Lévy-PSO mechanisms.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight for better exploration\n        self.w_min = 0.4  # minimum inertia weight for better exploitation\n        self.c1 = 2.05  \n        self.c2 = 2.0  \n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased to 0.2 for more frequent Lévy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08746938008423233, 0.07557958135302645, 0.08740278110988409, 0.08040553696316755, 0.06785620241162538, 0.07960301767778455, 0.10329923452122491, 0.08496996490781383, 0.10476820185167746]}}
{"id": "6b2bd44d-2381-4661-83cb-709d0d032bfa", "fitness": 0.09205863363007895, "name": "AdaptiveLevyPSO", "description": "Enhanced balance between exploration and exploitation by adjusting the probability of Lévy flights and inertia weight dynamically.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < (0.1 + 0.1 * (self.budget - self.evaluations) / self.budget):  # dynamic probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09550030935028053, 0.08333897466307527, 0.09640150300409633, 0.08630835657115654, 0.07625329891556132, 0.07654572982326258, 0.11525318162451348, 0.09743314537202952, 0.10149320334673495]}}
{"id": "273ce232-930f-4315-8967-c0e9aa906c91", "fitness": 0.10114320515804502, "name": "AdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO by adjusting the probability of Lévy flight dynamically based on exploration necessity and incorporating random restarts.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < (0.1 + 0.05 * (self.evaluations / self.budget)):  # dynamic Lévy probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                if np.random.rand() < 0.01:  # random restart\n                    self.positions[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.1018615244440948, 0.09360383106674541, 0.10908858160723234, 0.08508078791006624, 0.07949578856810069, 0.08525996384578671, 0.13798505091348012, 0.10431303403433578, 0.11360028403256306]}}
{"id": "368e1a5a-1cb8-4dfd-9944-6d8672513f78", "fitness": 0.09029034883607957, "name": "AdaptiveLevyPSO", "description": "Enhanced inertia weight adaptation based on evaluations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.4 + (0.9 - 0.4) * (1 - (self.evaluations / self.budget))  # Adaptive inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08779390320357694, 0.07766331064281728, 0.09762916622797313, 0.0779593686824438, 0.07474021471909276, 0.09701788421561108, 0.10107915275498369, 0.09633155856336861, 0.10239858051484885]}}
{"id": "e8155bb3-4e27-42ca-8c5e-094313648440", "fitness": 0.09382175903890098, "name": "AdaptiveLevyPSO_DE", "description": "Enhanced convergence by hybridizing Lévy flight with adaptive differential evolution.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # increased inertia weight\n        self.c1 = 2.05\n        self.c2 = 1.75  # decreased social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.F = 0.5  # differential weight\n        self.CR = 0.7  # crossover probability\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def differential_evolution(self, idx, dim):\n        idxs = [i for i in range(self.num_particles) if i != idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.positions[a] + self.F * (self.positions[b] - self.positions[c])\n        trial = np.copy(self.positions[idx])\n        for j in range(dim):\n            if np.random.rand() < self.CR:\n                trial[j] = mutant[j]\n        return np.clip(trial, self.lower_bound, self.upper_bound)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                if np.random.rand() < 0.1:\n                    self.positions[i] = self.differential_evolution(i, self.dim)\n                else:\n                    self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n                    if np.random.rand() < 0.2:  # increased probability\n                        self.positions[i] += self.levy_flight(self.dim)\n                    else:\n                        self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveLevyPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08191207415239321, 0.10103297131164535, 0.08250091819929528, 0.0909034038827311, 0.0883891318193224, 0.06599126338872185, 0.12683542692515182, 0.12814545884390338, 0.07868518282694448]}}
{"id": "c09631ff-d563-43c0-95d7-1c36b2aabf7a", "fitness": 0.0891454833029009, "name": "AdaptiveLevyPSO", "description": "Fine-tuned the social component coefficient to enhance global exploration balance while adhering to the modification constraint.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.1  # social component, adjusted from 2.0 to fine-tune exploration\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09695387695206814, 0.07953636355153382, 0.07118718592517803, 0.09014412030582442, 0.08395064470075364, 0.06585633110849953, 0.11778101339471037, 0.1151140151710276, 0.08178579861651247]}}
{"id": "65666cd3-466b-4a7f-8d04-04053a42cfd8", "fitness": 0.08475322180843008, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration with dynamic Lévy flight adaptation and adaptive velocity scaling.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4\n        self.c1 = 1.7  # decreased to boost social influence\n        self.c2 = 2.3  # increased to enhance social influence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.levy_prob = 0.2  # adjusted from 0.15 to 0.2 for more frequent flights\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            inertia_decay = 0.95 + (0.5 / self.budget) * self.evaluations\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = inertia_decay * (self.w * self.velocities[i]) + cognitive_velocity + social_velocity\n\n                if np.random.rand() < self.levy_prob:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i] * (self.evaluations / self.budget)  # adaptive velocity scaling\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08189155825857952, 0.07146550087758696, 0.07720588013402963, 0.07098627252314704, 0.07207330863774275, 0.08288640848587026, 0.09617604439771243, 0.09155110436096292, 0.11854291860023913]}}
{"id": "54d93ffc-776a-4767-ac48-7562b5aa4520", "fitness": 0.13703828285062686, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by adjusting inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # initial inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                # Update inertia weight dynamically\n                self.w = 0.4 * (1 - self.evaluations / self.budget) + 0.2\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.11.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07851716355512928, 0.10402310823760041, 0.11463219637291988, 0.07188154136294034, 0.07591332541201412, 0.15101750603422937, 0.08993706478785679, 0.10160269103395103, 0.44581994885900056]}}
{"id": "4555a42c-1425-41d0-b3ac-6b4fce173e19", "fitness": 0.09598648848239646, "name": "AdaptiveLevyPSO", "description": "AdaptiveLevyPSO with dynamic inertia and crossover-based exploration for enhanced convergence speed and diversity.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # dynamic inertia weight\n        self.w_min = 0.1\n        self.c1 = 1.49  # reduced cognitive component\n        self.c2 = 1.49  # reduced social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * self.evaluations / self.budget)\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                if np.random.rand() < 0.1:  # new crossover probability\n                    j = np.random.randint(self.num_particles)\n                    self.positions[i] = 0.5 * (self.positions[i] + self.positions[j])\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.10492666241359494, 0.10006674022069761, 0.07842223666227865, 0.07539544019344879, 0.09504310622513323, 0.09134125190756803, 0.10057210573681186, 0.11020189786346679, 0.10790895511856824]}}
{"id": "debe7d28-ab4c-4c08-b371-43748d4b9630", "fitness": 0.09154956883977876, "name": "AdaptiveLevyPSO", "description": "Enhance particle diversity by introducing adaptive velocity scaling and dynamic social component.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = (self.c2 + 0.1 * (self.budget - self.evaluations) / self.budget) * r2 * (self.global_best_position - self.positions[i])\n                \n                self.velocities[i] = (self.w + 0.2 * (self.evaluations / self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09039411617082826, 0.1037235073904027, 0.0755128915073443, 0.08779139527119106, 0.07959582191736303, 0.07332927580708315, 0.1170378655008868, 0.10390760486906025, 0.09265364112384922]}}
{"id": "f3a7a8e5-4723-4fb3-9be1-6ef222d6fabc", "fitness": 0.08515445809441208, "name": "EnhancedLevyPSO", "description": "Enhanced exploration and convergence by incorporating dynamic coefficients and inertia weight scheduling.", "code": "import numpy as np\n\nclass EnhancedLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.min_w = 0.2\n        self.max_w = 0.9\n        self.c1_min = 1.5\n        self.c1_max = 2.5\n        self.c2_min = 1.5\n        self.c2_max = 2.5\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def update_parameters(self):\n        # Dynamically adjust the inertia weight and coefficients\n        progress = self.evaluations / self.budget\n        self.w = self.max_w - progress * (self.max_w - self.min_w)\n        self.c1 = self.c1_max - progress * (self.c1_max - self.c1_min)\n        self.c2 = self.c2_min + progress * (self.c2_max - self.c2_min)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.update_parameters()\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08894217437738938, 0.06673648207434657, 0.08125995287462595, 0.0807919262404373, 0.06180319752892005, 0.07856134122546576, 0.106400229440332, 0.07501088476421103, 0.1268839343239806]}}
{"id": "b7d2a9f2-de25-4117-b136-ef0160a050c7", "fitness": 0.10863599636144688, "name": "AdaptiveLevyPSO", "description": "Enhanced exploitation by adjusting inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.w = 0.9 - (self.evaluations / self.budget) * 0.5  # dynamically adjust inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.04.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09160912954049782, 0.06953528873826087, 0.08793190037023701, 0.0871507752179721, 0.07387367584521187, 0.09814894153316123, 0.1666279787957965, 0.09364279790439978, 0.20920347930748484]}}
{"id": "c6adf811-cd86-45e7-8750-cd588a972d33", "fitness": 0.07925682874473594, "name": "EnhancedAdaptiveLevyPSO", "description": "Enhanced adaptive strategy using dynamic parameter tuning and chaos-inspired initialization for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.7  # increased inertia weight for better exploration\n        self.c1 = 1.5  # decreased cognitive component for improved social learning\n        self.c2 = 2.5  # increased social component for stronger convergence\n        self.positions = self.initialize_positions()  # use chaos-inspired initialization\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def initialize_positions(self):\n        # Chaos inspired initialization using logistic map\n        positions = np.zeros((self.num_particles, self.dim))\n        x = 0.7  # Initial condition for logistic map\n        for i in range(self.num_particles):\n            for j in range(self.dim):\n                x = 3.9 * x * (1 - x)  # Logistic map equation\n                positions[i, j] = self.lower_bound + (self.upper_bound - self.lower_bound) * x\n        return positions\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for Levy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07371642624936747, 0.08023686460197732, 0.0611355231916656, 0.06832348344877015, 0.07935072595995318, 0.0715820804926206, 0.08475459272105246, 0.10366561227215698, 0.0905461497650597]}}
{"id": "efeafa76-5fc4-4f30-b663-b1fcdf47bc8c", "fitness": 0.15366765281247993, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by adjusting inertia weight dynamically based on progress.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                \n                # Changed line: Dynamic inertia weight\n                self.w = 0.4 + 0.1 * (1 - self.evaluations / self.budget)\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.18.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07896958407563626, 0.0925175487823815, 0.0863700779183888, 0.0774548998108966, 0.1078156883999497, 0.08222353706826335, 0.08963137569053703, 0.6584742302278013, 0.1095519333384648]}}
{"id": "e44f8059-d5c2-4a86-82da-835ce82fa2b0", "fitness": 0.08109140171990488, "name": "EnhancedDynamicAdaptivePSO", "description": "Enhanced Dynamic Adaptive PSO with Lévy flights and adaptive inertia weight for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 40  # increased from 30 for better diversity\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 1.5  # reduced cognitive component\n        self.c2 = 2.5  # increased social component for better global search\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.dynamic_w = self.w_max\n    \n    def update_inertia_weight(self):\n        self.dynamic_w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.update_inertia_weight()\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.dynamic_w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # adjusted probability for Lévy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedDynamicAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07261298059731203, 0.07470911567203842, 0.0953757062939764, 0.07278801549377967, 0.06969407185005383, 0.07289661112515222, 0.09247210243949722, 0.08745598616230654, 0.09181802584502763]}}
{"id": "9524f624-3c96-48e1-a23f-0c1129cf4147", "fitness": 0.09078495260767297, "name": "AdaptiveLevyPSO", "description": "Enhanced particle movement by increasing probability of Lévy flight to improve exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.17:  # changed from 0.15 to 0.17\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09087970589566874, 0.07503195613630909, 0.09898579858979484, 0.08226300327724223, 0.06886425379456618, 0.0896606809766124, 0.102536748481174, 0.08677698878509155, 0.12206543753259769]}}
{"id": "cf22ae1c-2002-4c58-8326-40af215e2027", "fitness": 0.10448508323450807, "name": "AdaptiveLevyPSO", "description": "Incorporating adaptive inertia weight and dynamic population size adjustment for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        \n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))  # Adaptive inertia weight\n            if self.evaluations % 100 == 0 and self.num_particles > 10:\n                self.num_particles -= 1  # Dynamic population size adjustment\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.04.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09348016694641803, 0.07643810185299371, 0.09435460819161778, 0.08438453262182877, 0.07782048689634291, 0.08147170983232821, 0.11451393980084401, 0.1001865086258763, 0.21771569434232296]}}
{"id": "de4ead12-100d-40a9-b223-9a9974317333", "fitness": 0.07939086528903222, "name": "AdaptiveLevyPSO", "description": "Enhancing convergence by adjusting inertia weight dynamically based on evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.w = 0.4 + 0.6 * ((self.budget - self.evaluations) / self.budget)  # dynamically update w\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n                \n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08756154022925033, 0.07451147119342572, 0.07364060658320792, 0.07738840114703871, 0.06773706507316724, 0.06723738977908145, 0.09977596276466294, 0.08359969013596558, 0.08306566069549004]}}
{"id": "ad723fc5-22ea-42db-9172-1af689fd8187", "fitness": 0.1035618629123746, "name": "HybridDynamicLevyPSO", "description": "A hybrid algorithm combining Lévy flights and dynamic adaptive components for enhanced global exploration and convergence balance.", "code": "import numpy as np\n\nclass HybridDynamicLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 40  # increased from 30 to enhance exploration\n        self.w = 0.5  # adjusted for improved balance between exploration and exploitation\n        self.c1 = 2.2  # slightly increased for more cognitive influence\n        self.c2 = 1.8  # slightly decreased for balanced social influence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n        self.adaptive_factor = 0.1  # new adaptive component\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                adaptive_velocity = self.adaptive_factor * np.random.randn(self.dim)\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + adaptive_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for Lévy flight\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm HybridDynamicLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.04.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08744589069228148, 0.0904726567241545, 0.09048110681901267, 0.07964746018062852, 0.07540919491162579, 0.10574710533370602, 0.10306889094886684, 0.09689448519404087, 0.20288997540705467]}}
{"id": "a22bb9ac-4269-40f5-bdac-b16ea0249b91", "fitness": 0.09689418210989602, "name": "AdaptiveLevyPSO", "description": "Enhanced velocity update by adding a small perturbation to improve local search capability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + 0.01 * np.random.randn(self.dim)\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.11170449265386162, 0.08406116318242574, 0.07230982464655744, 0.09907795676537301, 0.07671238542241654, 0.07901583678557533, 0.14628247727463117, 0.09857440138821683, 0.10430910087000644]}}
{"id": "dd735f23-3930-4160-9318-dcab9eb712ff", "fitness": 0.10276973281350393, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by fine-tuning the inertia weight dynamically.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                self.w = 0.4 + 0.2 * (1 - self.evaluations / self.budget)  # Dynamic inertia weight adjustment\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08799958778635797, 0.08475470703825227, 0.11412552250038255, 0.0902843559845603, 0.07585884517304076, 0.09627419292623551, 0.13894242293956105, 0.09970129031879127, 0.13698667065435377]}}
{"id": "46f5d196-3415-4d33-b5c6-b24aa06fdb46", "fitness": 0.08815343576557687, "name": "AdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO with dynamic parameter adjustment and individual particle adaptation to improve convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.9 - 0.5 * (self.evaluations / self.budget) # dynamic inertia weight\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability of Levy flight\n                    self.positions[i] += self.levy_flight(self.dim, alpha=1.3)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08162906349661725, 0.07433823725952471, 0.08988755067098497, 0.07400724672986514, 0.07292328196295017, 0.08866051069800718, 0.09367179238268009, 0.0920353026761207, 0.12622793601344162]}}
{"id": "0893b35b-1b9c-4590-88cc-fb0c75f26df6", "fitness": 0.10048558615497344, "name": "AdaptiveLevyPSO", "description": "Enhanced global exploration by dynamically adjusting Lévy flight probability based on the number of evaluations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                levy_prob = 0.1 + 0.1 * (self.evaluations / self.budget)  # dynamically adjusted Lévy probability\n                if np.random.rand() < levy_prob:  # dynamically adjusted probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.03.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.1067448134224328, 0.07183296786856042, 0.11373720190767378, 0.09518691579813587, 0.060197391805856926, 0.10060599462766795, 0.13530398610488326, 0.07252109822941744, 0.14823990563013245]}}
{"id": "8fbec58c-1df2-425b-b2f8-b5b8ff89ede7", "fitness": 0.08570598898671516, "name": "AdaptiveLevyPSO", "description": "Improved the exploration phase by adjusting the inertia weight dynamically and modifying the probability of performing a Lévy flight.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_init = 0.9  # initial inertia weight\n        self.w_end = 0.4  # final inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_init - (self.w_init - self.w_end) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # Adjusted from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08746938008423233, 0.07557958135302645, 0.08740278110988409, 0.08040553696316755, 0.06785620241162538, 0.07960301767778455, 0.10329923452122491, 0.08496996490781383, 0.10476820185167746]}}
{"id": "1e16b4c4-b4c7-4fee-bcef-60d631a8618f", "fitness": 0.09456457243108608, "name": "AdaptiveLevyPSO", "description": "Enhanced diversity by adjusting cognitive and social parameters based on performance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 1.9  # cognitive component, adjusted from 2.05 to 1.9\n        self.c2 = 2.1  # social component, adjusted from 2.0 to 2.1\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.03.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.11947297374222776, 0.09359066662033555, 0.07118718592517803, 0.10080469506185474, 0.06784299302327323, 0.06585633110849953, 0.16810368783305674, 0.0836929633086485, 0.08052965525670064]}}
{"id": "dd7791d5-30c5-4571-93e1-8ca4461a3298", "fitness": 0.09098707970533321, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance using adaptive inertia weight and improved Lévy flight integration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_min = 0.2  # adaptive inertia weight minimum\n        self.w_max = 0.7  # adaptive inertia weight maximum\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step * 0.5  # scaled down the step for better fine-tuning\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))  # adaptive inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability of Lévy flight for exploration\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08382128987771009, 0.08157186966413377, 0.08055678517015408, 0.09135518223486583, 0.07473904035694667, 0.07385482850224412, 0.1450645121589177, 0.09470373969228008, 0.09321646969074648]}}
{"id": "7a5bf505-f32c-46c3-87b5-498a8983afda", "fitness": 0.10242207181056388, "name": "AdaptiveLevyPSO", "description": "Slightly adjust cognitive and social components to fine-tune particles' balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.1  # cognitive component, increased from 2.05 for better exploration\n        self.c2 = 1.95  # social component, decreased from 2.0 for better exploitation\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09114270043120143, 0.09437309478998768, 0.1375007648262906, 0.086221632620049, 0.0844885236336963, 0.07801434537382268, 0.11535519151897733, 0.12635555818624944, 0.10834683491480046]}}
{"id": "6344a496-28e3-42ff-a86e-d9b54e50c689", "fitness": 0.05570512942684805, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation balance by dynamically adjusting parameters based on diversity.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_init = 0.9  # initial inertia weight, increased for better exploration\n        self.w_end = 0.4   # final inertia weight, retained for convergence\n        self.c1_init = 2.5  # initial cognitive component, increased for better exploration\n        self.c2_init = 1.5  # initial social component, decreased to favor exploration\n        self.c1_end = 1.5\n        self.c2_end = 2.5\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def diversity(self):\n        return np.mean(np.std(self.positions, axis=0))\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n                # Dynamically adjust weights\n                div = self.diversity()\n                self.w = self.w_end + (self.w_init - self.w_end) * (1 - div)\n                self.c1 = self.c1_end + (self.c1_init - self.c1_end) * div\n                self.c2 = self.c2_end + (self.c2_init - self.c2_end) * div\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased to 0.2 for more frequent Levy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.059338728585772826, 0.04612898402027832, 0.05957896834322329, 0.05529471468997693, 0.043189300939812214, 0.05566176993941241, 0.06574197014271699, 0.05008435328472627, 0.06632737489571316]}}
{"id": "65990221-c078-4222-8c34-563c751615aa", "fitness": 0.10612740589817299, "name": "AdaptiveLevyPSO", "description": "Improved exploration by dynamically adjusting the Lévy flight probability based on iterations.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            lev_prob = 0.15 + 0.1 * (self.evaluations / self.budget)  # dynamically adjust probability\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < lev_prob:  # use dynamically adjusted probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.03.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09322099375841075, 0.09493730618945728, 0.0874393546214588, 0.07993228939930341, 0.08720391274756112, 0.1152165489310194, 0.10347344080754617, 0.1178149366690342, 0.17590786995976582]}}
{"id": "c9473eb8-96b4-4ce9-8e34-30a7fd36685e", "fitness": 0.08109447602369323, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration through dynamic inertia adjustment and adaptive Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # increased initial inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.05\n        self.c2 = 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                inertia_weight = self.w - (self.w - self.w_min) * (self.evaluations / self.budget)\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                levy_probability = 0.1 + 0.1 * (self.evaluations / self.budget)  # dynamic probability\n                if np.random.rand() < levy_probability:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08268279598082784, 0.08699751005854173, 0.08880805021150007, 0.07041133695152435, 0.07903740731654596, 0.05999499304182043, 0.08818671766240715, 0.1028003700247817, 0.07093110296528982]}}
{"id": "372534ab-e3f5-4fbd-bdfe-a226b528d97f", "fitness": 0.09029034883607957, "name": "AdaptiveLevyPSO", "description": "Enhanced global exploration by adjusting the inertia weight adaptively based on evaluations.  ", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # base inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            # Adjust inertia weight adaptively\n            self.w = 0.9 - (0.5 * self.evaluations / self.budget)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08779390320357694, 0.07766331064281728, 0.09762916622797313, 0.0779593686824438, 0.07474021471909276, 0.09701788421561108, 0.10107915275498369, 0.09633155856336861, 0.10239858051484885]}}
{"id": "79998cd4-cd5b-480b-b517-69245f4f9343", "fitness": 0.23104503942111007, "name": "AdaptiveLevyPSO", "description": "Improved AdaptiveLevyPSO with dynamic parameters and enhanced Lévy flight for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight, made adaptive\n        self.c1 = 2.5  # cognitive component, made dynamic\n        self.c2 = 1.5  # social component, made dynamic\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step * 0.1  # reduce step size for finer exploration\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.w = 0.9 - (0.5 * self.evaluations / self.budget)  # adaptive inertia weight\n            self.c1 = 2.5 - (1.5 * self.evaluations / self.budget)  # dynamic cognitive\n            self.c2 = 0.5 + (1.5 * self.evaluations / self.budget)  # dynamic social\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased Lévy flight probability\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09825492879503639, 0.5108440000197667, 0.141085805681744, 0.08779677630349869, 0.09342367392068551, 0.11451233270804417, 0.12388650559335979, 0.20978287291187048, 0.6998184588559846]}}
{"id": "151c0bb7-73d6-499d-b1cf-96e3ca362309", "fitness": 0.09029034883607957, "name": "AdaptiveLevyPSO", "description": "Enhanced balance in exploration by varying the inertia weight dynamically during optimization.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.9  # inertia weight, start high\n        self.w_min = 0.4  # minimum inertia weight\n        self.w_max = 0.9  # maximum inertia weight\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                self.w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)  # update inertia weight dynamically\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08779390320357694, 0.07766331064281728, 0.09762916622797313, 0.0779593686824438, 0.07474021471909276, 0.09701788421561108, 0.10107915275498369, 0.09633155856336861, 0.10239858051484885]}}
{"id": "222fe5c6-6d41-47d1-bf69-60aa2f4466a1", "fitness": 0.08546909649737061, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration and exploitation using adaptive inertia weight and hybridized Lévy flight with Gaussian mutation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 2.0  # cognitive component, slightly modified\n        self.c2 = 2.0  # social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))  # adaptive inertia weight\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for alternative exploration\n                    self.positions[i] += self.levy_flight(self.dim) + np.random.normal(0, 0.1, self.dim)  # hybrid exploration\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08162141643241783, 0.07053776478776996, 0.09730605374230639, 0.07465370249962278, 0.065160981504094, 0.08821169380897986, 0.09409535557805615, 0.08023356276029658, 0.11740133736279201]}}
{"id": "dee697aa-4147-4558-ac01-947b9bfb9dab", "fitness": 0.08570598898671516, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration with dynamic inertia and increased Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            inertia_weight = 0.9 - (0.5 * self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08746938008423233, 0.07557958135302645, 0.08740278110988409, 0.08040553696316755, 0.06785620241162538, 0.07960301767778455, 0.10329923452122491, 0.08496996490781383, 0.10476820185167746]}}
{"id": "76bfa5ce-8cd2-4a0c-8fc0-c102441dcfe6", "fitness": 0.09356024326276992, "name": "AdaptiveLevyPSO", "description": "Enhanced convergence by increasing the inertia weight and Lévy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # inertia weight, increased from 0.4 to improve exploration\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.08503109330211311, 0.08455260628250594, 0.08327801163380633, 0.08885777768544423, 0.07722797487461563, 0.08100763870676042, 0.13591388505249946, 0.09918593852338331, 0.10698726330380082]}}
{"id": "eeafb2a8-9d09-4425-a01b-cfaff2d09edf", "fitness": 0.10242207181056388, "name": "AdaptiveLevyPSO", "description": "Enhanced global exploration by adjusting social and cognitive components dynamically.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.1  # cognitive component, increased from 2.05\n        self.c2 = 1.95  # social component, decreased from 2.0\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09114270043120143, 0.09437309478998768, 0.1375007648262906, 0.086221632620049, 0.0844885236336963, 0.07801434537382268, 0.11535519151897733, 0.12635555818624944, 0.10834683491480046]}}
{"id": "807b5ebf-b4cf-4762-9e10-661671bc7c3a", "fitness": 0.07614678248983267, "name": "EnhancedAdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO via dynamic parameter tuning and adaptive mutation strategy for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.5  # Adjusted inertia weight for dynamic adaptation\n        self.c1 = 1.5  # Reduced cognitive component for better exploration\n        self.c2 = 2.5  # Increased social component for improved convergence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        initial_budget = self.budget\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n                # Dynamic inertia weight adjustment\n                self.w = 0.9 - self.evaluations / (2.0 * initial_budget)\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Adaptive mutation strategy\n                mutation_prob = 0.2 + 0.3 * (1 - self.evaluations / initial_budget)\n                if np.random.rand() < mutation_prob:\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07602923321293653, 0.06238272179257842, 0.08492764770542716, 0.06906958804111185, 0.05799181880752946, 0.07670390703596752, 0.08863482686459179, 0.069717678888363, 0.09986362005998828]}}
{"id": "89c936d0-6cb1-450f-b4c0-bac273db005e", "fitness": 0.08761634527829106, "name": "AdaptiveLevyPSO", "description": "Enhanced social influence and random initialization for improved exploration.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.1  # social component, increased from 2.0 for stronger social influence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # changed from 0.15 to 0.2\n                    self.positions[i] += self.levy_flight(self.dim)  # alternative random initialization\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09971051332954117, 0.08214282630956149, 0.07799752679843763, 0.08425956487127129, 0.07499721223160938, 0.07176679485511905, 0.11168565254625773, 0.09646264370074953, 0.08952437286207227]}}
{"id": "70590ad9-86c4-43cb-8197-4073880d293c", "fitness": 0.08722523169013117, "name": "AdaptiveLevyPSO", "description": "Enhanced global convergence through a slightly increased levy flight probability.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.18:  # changed from 0.15 to 0.18\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09296242679146638, 0.07020774273110819, 0.0906973381046543, 0.075552875535282, 0.06488063488390705, 0.08965968716432327, 0.09770662084323878, 0.07958046806802066, 0.12377929108917995]}}
{"id": "90a2906c-4e0f-4c5b-8162-7ebc36ad503d", "fitness": 0.09841492860625672, "name": "AdaptiveLevyPSO", "description": "Enhanced exploration by adding a small random disturbance to particle positions.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i] + np.random.normal(0, 0.01, size=self.dim), self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09045785468928247, 0.10999415535050094, 0.08810545581190976, 0.08222825387483723, 0.09156231078707511, 0.08025665375883051, 0.10805343887263363, 0.13105495156492197, 0.10402128274631883]}}
{"id": "b3574e59-798f-4768-9220-377883a0c807", "fitness": 0.0891454833029009, "name": "AdaptiveLevyPSO", "description": "Enhance global convergence by slightly increasing the social component to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.4  # inertia weight, reduced from 0.5 to improve convergence speed\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.1  # social component, increased from 2.0 to enhance global convergence\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.15:  # changed from 0.1 to 0.15\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.09695387695206814, 0.07953636355153382, 0.07118718592517803, 0.09014412030582442, 0.08395064470075364, 0.06585633110849953, 0.11778101339471037, 0.1151140151710276, 0.08178579861651247]}}
{"id": "8eb825ea-33f2-47e5-b1f0-acd551ffef23", "fitness": 0.07237949326775325, "name": "ImprovedLevyPSO", "description": "Enhanced exploration and exploitation balance using adaptive inertia weight and hybrid mutation strategies.", "code": "import numpy as np\n\nclass ImprovedLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w_max = 0.9  # maximum inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 1.5  # reduced cognitive component\n        self.c2 = 2.5  # increased social component\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)  # adaptive inertia weight\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased probability for more frequent Levy flights\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm ImprovedLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.01.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.07319764768319381, 0.06774226711653053, 0.07836895185158299, 0.06470972365621863, 0.06062354803399128, 0.07569689117947509, 0.0790637391676815, 0.07339854857467443, 0.07861412214643104]}}
{"id": "15da0c83-01f4-4c1d-ada2-1f8f1d958f9a", "fitness": 0.09572269609858386, "name": "AdaptiveLevyPSO", "description": "Enhanced AdaptiveLevyPSO by fine-tuning exploration probability and inertia weight for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveLevyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.w = 0.45  # inertia weight, increased from 0.4 to improve convergence stability\n        self.c1 = 2.05  # cognitive component\n        self.c2 = 2.0  # social component, decreased from 2.05 to improve balance\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_scores = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.evaluations = 0\n\n    def levy_flight(self, L, alpha=1.5):\n        sigma1 = np.power((np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2)) /\n                          (np.math.gamma((1 + alpha) / 2) * alpha * np.power(2, (alpha - 1) / 2)), 1 / alpha)\n        sigma2 = 1\n        u = np.random.normal(0, sigma1, size=L)\n        v = np.random.normal(0, sigma2, size=L)\n        step = u / np.power(np.abs(v), 1 / alpha)\n        return step\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i]\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                if np.random.rand() < 0.2:  # increased from 0.15 to 0.2 to enhance exploration\n                    self.positions[i] += self.levy_flight(self.dim)\n                else:\n                    self.positions[i] += self.velocities[i]\n\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveLevyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.02.", "error": "", "parent_ids": ["248c24b4-baa1-4b02-91b6-3498def0994e"], "operator": null, "metadata": {"aucs": [0.0874749385593192, 0.09101682823000568, 0.07202382076037994, 0.08045316891038645, 0.0960725490835741, 0.07887409513962373, 0.10258978859251167, 0.1483435798847016, 0.10465549572675237]}}
