{"id": "3f4a81a0-17c8-48cb-babf-ad92956c5939", "fitness": 0.056343232218820684, "name": "HPSO_ADE", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) to dynamically balance exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 0, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.0488352308244111, 0.057513772447530864, 0.05567290710452988, 0.04599656270889585, 0.054029669325498686, 0.06507312163836942, 0.05277196554982855, 0.0631830075771298]}}
{"id": "31582ab0-87f3-4c6f-a721-e741264e1efb", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE+) using adaptive inertia weight and crossover probability to improve convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for eval_num in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia = 0.9 - 0.5 * (eval_num / self.budget)  # Adaptive inertia\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                self.cr = 0.9 - 0.4 * (eval_num / self.budget)  # Adaptive crossover probability\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 1, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "560549d9-8ae1-4722-a816-221b453bc1ce", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with dynamic inertia factor adjustment for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Initial inertia\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Dynamic inertia adjustment\n            self.inertia = 0.4 + 0.5 * (1 - iteration / self.budget)\n            \n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 2, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "399a188b-c946-463b-9e49-b01ae2428f2e", "fitness": 0.05461134231191797, "name": "HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) by improving inertia and adaptive social parameters for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Adjusted inertia\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 3, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05842309746484908, 0.046939214179209765, 0.057083254157677565, 0.05457514916734851, 0.0442629262224814, 0.05353849959763368, 0.06364876192877444, 0.05054438459840094, 0.06248679349088637]}}
{"id": "1e93200d-8952-4989-acf7-7993906a087d", "fitness": 0.05613331147682093, "name": "HPSO_ADE", "description": "Improved HPSO-ADE by adjusting inertia and introducing a mutation factor for enhanced dynamic adaptation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Adjusted inertia for improved exploration\n        self.cognitive = 1.5\n        self.social = 1.5\n        self.mutation_factor = 0.1  # New mutation factor for dynamic adaptation\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i]) + self.mutation_factor * np.random.normal(size=self.dim)\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 4, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.056685665315999056, 0.04723082202751372, 0.06309800999020032, 0.052764725370454735, 0.044542147085145256, 0.05894555180649064, 0.06125173847612975, 0.05086838536717031, 0.06981275785228458]}}
{"id": "5f28430e-852d-49c4-832c-13781ac04f18", "fitness": 0.053416680516596905, "name": "HPSO_ADE", "description": "Refined HPSO-ADE with adaptive inertia and dynamic crossover to enhance exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Changed from 0.7 to 0.9\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):  # Changed _ to iteration\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Adjusting inertia dynamically\n            self.inertia = 0.9 - 0.5 * (iteration / self.budget)  # Changed inertia adjustment\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Adaptive crossover probability\n            self.cr = 0.5 + 0.4 * np.sin(np.pi * iteration / self.budget)  # Changed crossover adjustment\n\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 5, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.055004719637982036, 0.05122049487154334, 0.05451186357896087, 0.05184381882219713, 0.045470280356106896, 0.05119236563065743, 0.06004996151626962, 0.052048033415279193, 0.05940858682037564]}}
{"id": "1c635124-ce3d-4409-a499-d806978f559b", "fitness": 0.055601150310699135, "name": "HPSO_ADE", "description": "Improved Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) using adaptive learning factors for enhanced convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.7\n        self.cognitive = 2.0  # Changed from 1.5 \n        self.social = 2.5  # Changed from 1.5\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 6, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.0605229498453731, 0.05085384887041422, 0.054295138769217655, 0.05668398694614407, 0.047132919177861, 0.05103201577631655, 0.06645009209017139, 0.05413525030201771, 0.05930415101877651]}}
{"id": "8c9033df-d9af-4ad3-91d9-8bff8f2369ef", "fitness": 0.05633285416929986, "name": "HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) by dynamically adjusting cognitive and social coefficients for improved black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Dynamically adjust cognitive and social coefficients\n            self.cognitive *= 0.99\n            self.social *= 1.01\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 7, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.06076386178572646, 0.049885480729613185, 0.05668716140627683, 0.056638346707371556, 0.0469125846343017, 0.05328966711235672, 0.06679005519975412, 0.05385956629353683, 0.06216896365476132]}}
{"id": "b8543b49-0e93-48b0-a804-3210d089c1e3", "fitness": 0.055401851664938224, "name": "HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution (Enhanced HPSO-ADE) using dynamic parameter adjustment for better convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Dynamic adjustment of parameters based on iteration\n            self.inertia = 0.9 - 0.4 * (_ / self.budget)  # Change 1\n            self.cognitive = 2.5 - 1.5 * (_ / self.budget)  # Change 2\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 8, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05595911811147769, 0.05136113693519129, 0.05725263734091168, 0.0532732792330074, 0.04826841115281788, 0.05298152929143085, 0.061910559232397855, 0.05587676968578337, 0.061733224001426]}}
{"id": "172134ad-18ba-4050-b446-53ac9546c11a", "fitness": 0.05447104194371382, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with adaptive parameters for inertia and cognitive weights to improve convergence speed.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia_initial = 0.9\n        self.inertia_final = 0.4\n        self.cognitive_initial = 2.0\n        self.cognitive_final = 1.0\n        self.social = 1.5\n\n    def __call__(self, func):\n        for t in range(self.budget):\n            inertia = self.inertia_initial - t * (self.inertia_initial - self.inertia_final) / self.budget\n            cognitive = self.cognitive_initial - t * (self.cognitive_initial - self.cognitive_final) / self.budget\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (inertia * self.velocities +\n                               cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 9, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05676708918261786, 0.0475578680907941, 0.05646862400456909, 0.05324516009437441, 0.044830001978138134, 0.05446643745639668, 0.061873262299146914, 0.0512623853688331, 0.06376854901855411]}}
{"id": "36cc4555-1472-4000-bf43-5b4746792f10", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with adaptive inertia and tailored mutation to improve convergence in black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Adaptive inertia\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for i in range(self.budget):\n            scores = np.array([func(ind) for ind in self.population])\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n            \n            self.inertia = 0.9 - 0.5 * (i / self.budget)  # Adaptive inertia adjustment\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 10, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "2429504a-dc14-48e4-af7e-82655b2165b9", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with adaptive inertia weight and dynamic selection for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Adaptive inertia weight\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for t in range(self.budget):\n            # Adaptive inertia weight\n            self.inertia = 0.9 - (0.5 * (t / self.budget))  \n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 11, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "40c8ed0b-b0ac-47e5-a25b-85f0350d111c", "fitness": 0.05509477754765768, "name": "HPSO_ADE", "description": "Improved HPSO_ADE by adjusting adaptive parameters and introducing dynamic weights for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Changed inertia to 0.9\n        self.cognitive = 1.7  # Changed cognitive parameter to 1.7\n        self.social = 1.3  # Changed social parameter to 1.3\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 12, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.06002380129297158, 0.050146536624075644, 0.05352355007505616, 0.0562385494098655, 0.04723280228005888, 0.05032353686407087, 0.06583232532093464, 0.05425117979807459, 0.05828071626381126]}}
{"id": "cad07924-c4b3-4cd3-a0ef-f8e83689be5b", "fitness": 0.05509477754765768, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE with dynamic parameter tuning to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Updated Inertia\n        self.cognitive = 1.7  # Updated cognitive\n        self.social = 1.3  # Updated social\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 13, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.06002380129297158, 0.050146536624075644, 0.05352355007505616, 0.0562385494098655, 0.04723280228005888, 0.05032353686407087, 0.06583232532093464, 0.05425117979807459, 0.05828071626381126]}}
{"id": "9a2f5051-a451-4c1d-b4d2-4b08ca00032c", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with adaptive inertia weight to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9  # Initial inertia\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for t in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Adaptive inertia weight\n            self.inertia = 0.9 - 0.5 * (t / self.budget)\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 14, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "1689c1c7-567e-42c3-bf30-cb4f86d1b905", "fitness": 0.05478263985221156, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with dynamic adjustment of inertia weight to improve convergence performance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia_initial = 0.9\n        self.inertia_final = 0.4\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for i in range(self.budget):\n            # Dynamic inertia adjustment\n            self.inertia = self.inertia_initial - i * (self.inertia_initial - self.inertia_final) / self.budget\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 15, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.05958037423250029, 0.047010074436151905, 0.05708179881213826, 0.05464669414316292, 0.044327607340603814, 0.053537105419457554, 0.06374661127061543, 0.05062824378809572, 0.06248524922717813]}}
{"id": "5cec2848-ddca-4bf8-9cfb-a68590cd3136", "fitness": 0.054981654486239234, "name": "HPSO_ADE", "description": "Enhanced HPSO-ADE with dynamic parameters to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.inertia = 0.9 - 0.5 * (budget / 1000)  # Dynamic inertia\n        self.cognitive = 2.0 - 0.5 * (budget / 1000)  # Dynamic cognitive\n        self.social = 1.5 + 0.5 * (budget / 1000)  # Dynamic social\n\n    def __call__(self, func):\n        for _ in range(self.budget):\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 16, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.057742275122840914, 0.04992754752762796, 0.05803445860227219, 0.054191877984239745, 0.043932769396892724, 0.05417554700251914, 0.06311806037217571, 0.05024940222847918, 0.06346295213910558]}}
{"id": "193e9aed-6d77-49a3-8a2a-9b3a53745f73", "fitness": 0.056505594691074745, "name": "HPSO_ADE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution using dynamic parameter tuning to improve convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 17, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3f4a81a0-17c8-48cb-babf-ad92956c5939"], "operator": null, "metadata": {"aucs": [0.06590605361638302, 0.04890119497493639, 0.057229707064067714, 0.05567290710452988, 0.04605516972138557, 0.05388162760600146, 0.06507312163836942, 0.05285112606735276, 0.06297944442664649]}}
{"id": "b1836ec7-14ec-4ebd-9101-f5017c87f081", "fitness": 0.05499380952848625, "name": "HPSO_ADE", "description": "A refined HPSO_ADE algorithm with dynamic parameter adjustment and elitism to enhance convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.9 - 0.7 * (iteration / self.budget)  # Adjusted dynamic inertia\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n            \n            elite_index = np.argmin(self.pbest_scores)  # Elitism: retain the best individual\n            self.population[0] = self.pbest_positions[elite_index]\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 18, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["193e9aed-6d77-49a3-8a2a-9b3a53745f73"], "operator": null, "metadata": {"aucs": [0.06040963073904204, 0.04702944890514382, 0.05708355528794806, 0.0546857191977026, 0.04434535597537648, 0.05445133290769544, 0.06380068957619944, 0.05065099987019683, 0.06248755329707156]}}
{"id": "f8433207-f47c-42fc-9b05-f484a5550320", "fitness": 0.05473459378628071, "name": "HPSO_ADE", "description": "Refined HPSO-ADE with adaptive mutation factor and exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.5\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.8 - 0.6 * (iteration / self.budget)\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                self.f = 0.4 + 0.3 * np.random.rand()  # Adaptive mutation factor\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 19, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["193e9aed-6d77-49a3-8a2a-9b3a53745f73"], "operator": null, "metadata": {"aucs": [0.057378449858803804, 0.049502810152012744, 0.05575888981936494, 0.053839149117346885, 0.046623623289719474, 0.05237962613062541, 0.0626900279132977, 0.05354254500719102, 0.06089622278816442]}}
{"id": "8635937d-ec6c-4e89-b151-6f259bfb1f4b", "fitness": 0.0565600052639539, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE with adjusted cognitive and social coefficients for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 20, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["193e9aed-6d77-49a3-8a2a-9b3a53745f73"], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.04826617105922559, 0.05890691124663239, 0.05567290710452988, 0.04548174748211087, 0.05498509346657121, 0.06507312163836942, 0.05209953740586881, 0.06454170517908486]}}
{"id": "e5cb8bf4-3b41-4d04-8bc9-a707ddc44f91", "fitness": 0.056544727749015325, "name": "HPSO_ADE", "description": "Improve exploration by adjusting the variation of PSO velocity factors dynamically with each iteration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 - 0.3 * (iteration / self.budget)  # Dynamic cognitive adjustment\n            self.social = 1.5 + 0.3 * (iteration / self.budget)     # Dynamic social adjustment\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 21, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["8635937d-ec6c-4e89-b151-6f259bfb1f4b"], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.04824656147983808, 0.05883282714846749, 0.05567290710452988, 0.04546389707311782, 0.05498398490622869, 0.06507312163836942, 0.05207628357721361, 0.0645401140201809]}}
{"id": "e0b210a8-91af-4594-830f-76797bc111ed", "fitness": 0.0565600052639539, "name": "HPSO_ADE", "description": "Introduced adaptive parameters for DE crossover rate and inertia to enhance optimization adaptability.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)  # Adapt DE crossover rate\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 22, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["8635937d-ec6c-4e89-b151-6f259bfb1f4b"], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.04826617105922559, 0.05890691124663239, 0.05567290710452988, 0.04548174748211087, 0.05498509346657121, 0.06507312163836942, 0.05209953740586881, 0.06454170517908486]}}
{"id": "2ce7ca75-96e4-4fcf-b3b8-e3eac7e42f05", "fitness": 0.05356478244032809, "name": "HPSO_ADE", "description": "Improved exploration by introducing random perturbations for global best updates.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best with perturbation\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx] + np.random.uniform(-0.1, 0.1, self.dim)\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 23, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["8635937d-ec6c-4e89-b151-6f259bfb1f4b"], "operator": null, "metadata": {"aucs": [0.05736447766210617, 0.049659160556424164, 0.0527741602704106, 0.053831441068618924, 0.0467654727287663, 0.04891868022378287, 0.06269151975639198, 0.053682911158226765, 0.056395218538225045]}}
{"id": "5e7eb35a-31eb-4ef7-8ef9-0e8628710090", "fitness": 0.05658555618912765, "name": "HPSO_ADE", "description": "Improved HPSO_ADE by dynamically adapting the social coefficient for enhanced convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 24, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["8635937d-ec6c-4e89-b151-6f259bfb1f4b"], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.04827463892098682, 0.05897269491362478, 0.05567290710452988, 0.04548945852057107, 0.05504171539369063, 0.06507312163836942, 0.05210958160630763, 0.06462303481087661]}}
{"id": "1b987370-8d86-4c79-8640-b1704cdee028", "fitness": 0.05552755770781173, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE by incorporating adaptive mutation factor and elite retention for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        elite_size = 5  # Added for elite retention\n        for iteration in range(self.budget):\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n            scores = np.array([func(ind) for ind in self.population])\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n            self.f = 0.5 + 0.2 * (iteration / self.budget)  # Adaptive mutation factor\n            for i in range(self.population_size):\n                if i < elite_size:  # Preserve elite individuals\n                    continue\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 25, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["5e7eb35a-31eb-4ef7-8ef9-0e8628710090"], "operator": null, "metadata": {"aucs": [0.055724005895678386, 0.054907975762022554, 0.05439219579079424, 0.05235362948700695, 0.05146632290946207, 0.05108036063920607, 0.060706849332056056, 0.05988574553895709, 0.05923093401512214]}}
{"id": "7367ba59-adf8-4841-9988-a8a71afa151c", "fitness": 0.05320656135337368, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE by incorporating adaptive cognitive coefficient and damping factor in velocities for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        damping_factor = 0.99  # New damping factor for velocities\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive cognitive coefficient\n            self.cognitive = 1.5 + 0.2 * np.sin(iteration / self.budget * np.pi) \n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = damping_factor * (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 26, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_ids": ["5e7eb35a-31eb-4ef7-8ef9-0e8628710090"], "operator": null, "metadata": {"aucs": [0.056462394399469096, 0.04907362754151956, 0.05377792129979486, 0.05301398092521725, 0.04547146994228779, 0.04979987124366214, 0.06156653161786074, 0.05208421298217136, 0.05760904222838026]}}
{"id": "ec3c1ff4-6883-4c9d-8f39-972eca69b69a", "fitness": 0.05604079995772401, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE by adjusting the DE mutation factor and introducing a diversity measure to maintain exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.8  # Adjusted DE mutation factor\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                diversity = np.mean(np.std(self.population, axis=0))  # Diversity measure\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 27, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["5e7eb35a-31eb-4ef7-8ef9-0e8628710090"], "operator": null, "metadata": {"aucs": [0.05780453608506009, 0.051646409884330224, 0.05636056932800526, 0.05424724592755781, 0.048299518996925306, 0.05394434833930839, 0.06319754191487204, 0.055741763974033964, 0.06312526516942307]}}
{"id": "6e5a9355-eafd-4dc9-8788-b9d129615d10", "fitness": 0.056658928059111845, "name": "HPSO_ADE", "description": "Refinement of HPSO_ADE by incorporating adaptive mutation factor and crossover rate to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                indices = [index for index in range(self.population_size) if index != i]\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                trial_score = func(trial_vector)\n                if trial_score < self.pbest_scores[i]:\n                    self.population[i] = trial_vector\n                    self.pbest_scores[i] = trial_score\n                    if trial_score < self.gbest_score:\n                        self.gbest_score = trial_score\n                        self.gbest_position = trial_vector\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 28, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["5e7eb35a-31eb-4ef7-8ef9-0e8628710090"], "operator": null, "metadata": {"aucs": [0.06401285279319202, 0.04824948462374068, 0.05923357503005788, 0.05567290710452988, 0.045466555083844895, 0.055237194390613586, 0.06507312163836942, 0.05207974097745183, 0.06490492089020639]}}
{"id": "12e8c842-ba81-4946-8e4b-e992f64bfeac", "fitness": 0.05892321244592907, "name": "HPSO_ADE", "description": "Enhancement of HPSO_ADE by integrating an elite preservation strategy and adjusted velocity update to refine global exploration and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        elite_size = 3  # Preserving top 3 elites\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 29, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["6e5a9355-eafd-4dc9-8788-b9d129615d10"], "operator": null, "metadata": {"aucs": [0.06064735931736431, 0.05449928747539534, 0.05965732216115094, 0.05682288069797936, 0.051212120613718826, 0.05586486430664239, 0.06663483201814469, 0.059419602810754535, 0.06555064261221122]}}
{"id": "1cefa673-1718-49b9-800e-5c18325bde14", "fitness": 0.058862083517949824, "name": "HPSO_ADE", "description": "Enhancing HPSO_ADE by fine-tuning the cognitive coefficient to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.9  # Adjusted cognitive coefficient (Change made here)\n        self.social = 1.5\n\n    def __call__(self, func):\n        elite_size = 3  # Preserving top 3 elites\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 30, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["12e8c842-ba81-4946-8e4b-e992f64bfeac"], "operator": null, "metadata": {"aucs": [0.06046994298403485, 0.05449928747539534, 0.05965732216115094, 0.05666578268646172, 0.051212120613718826, 0.05586486430664239, 0.06641918601117858, 0.059419602810754535, 0.06555064261221122]}}
{"id": "8a1765e7-f09b-4aea-9fe2-56425784e2fb", "fitness": 0.05924819457308486, "name": "HPSO_ADE", "description": "Enhancement of HPSO_ADE by refining the elite preservation strategy to dynamically adjust elite size based on convergence progress.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia\n            self.inertia = 0.7 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 31, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["12e8c842-ba81-4946-8e4b-e992f64bfeac"], "operator": null, "metadata": {"aucs": [0.060511240127436694, 0.05402231799507207, 0.06252732845888354, 0.05669979226378974, 0.0507637720057289, 0.05669076751140989, 0.06646040194577807, 0.058869796318544054, 0.06668833453112077]}}
{"id": "a695d0a5-593a-449d-908e-7551f2a388e6", "fitness": 0.059730385433120085, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE by slightly refining the adaptive inertia weight strategy for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 32, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["8a1765e7-f09b-4aea-9fe2-56425784e2fb"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05279545091041504, 0.06352374841168973, 0.057426659374170796, 0.049649804186770785, 0.05931241207245097, 0.06746341600997463, 0.05736957426039091, 0.07030747820199057]}}
{"id": "8fbcfd97-7800-4f18-9418-0c02ad413789", "fitness": 0.057707868773590985, "name": "HPSO_ADE", "description": "Improved the algorithm by adjusting the inertia weight to enhance exploration in early iterations.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.9 - 0.6 * (iteration / self.budget)  # Changed from previous 0.8 and 0.5\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 33, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.0600863443409283, 0.052883785531801175, 0.057572185802194475, 0.0563162868998105, 0.049717993518485715, 0.05498275779927597, 0.06594846735612325, 0.05750380420526091, 0.06435919350843855]}}
{"id": "793d00d1-1d2a-4923-99a5-3057df32e832", "fitness": 0.05591474757708242, "name": "HPSO_ADE", "description": "Enhanced exploration phase by introducing a small random noise to the velocities to diversify search paths.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population) +\n                               0.01 * np.random.randn(self.population_size, self.dim))  # Added random noise\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 34, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.058694243804020885, 0.051590053496425536, 0.05025354699670159, 0.054072606245702426, 0.04854262416245725, 0.05566922939702379, 0.06295203551979289, 0.05594818460958906, 0.06551020396202833]}}
{"id": "d54263bf-a63a-4890-8d5e-958a91bdd8c6", "fitness": 0.05742515293395177, "name": "HPSO_ADE_Refined", "description": "Further refines adaptive strategies and introduces chaotic map for enhancing convergence and diversity.", "code": "import numpy as np\n\nclass HPSO_ADE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n        self.chaos = np.random.rand()  # Introduce chaotic variable\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.9 - 0.6 * (iteration / self.budget)  # Change 1: Slightly refined adaptive inertia\n            self.social = 1.6 + 0.4 * (iteration / self.budget)    # Change 2: Slightly refined adaptive social factor\n            self.f = 0.6 + 0.2 * np.sin(0.6 * np.pi * iteration / self.budget)  # Change 3\n            self.cr = 0.85 - 0.35 * (iteration / self.budget)  # Change 4\n\n            scores = np.array([func(ind) for ind in self.population])\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n            self.chaos = 4 * self.chaos * (1 - self.chaos)  # Change 5: Chaotic map for enhancing diversity\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 35, "feedback": "The algorithm HPSO_ADE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.06345006595559244, 0.04991877777526743, 0.05623325892547981, 0.0580221602703308, 0.047019106891939444, 0.05435172044796499, 0.0682856882210201, 0.05397384354029855, 0.06557175437767238]}}
{"id": "e85460da-b3ce-4da9-8f65-3b32758e80e2", "fitness": 0.05964068252353748, "name": "HPSO_ADE", "description": "Enhanced HPSO_ADE by dynamically adjusting the cognitive coefficient for improved exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of cognitive coefficient\n            self.cognitive = 1.7 + 0.3 * (iteration / self.budget)\n\n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 36, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05278334038625976, 0.06352374841168973, 0.057103274913794855, 0.049638784262307944, 0.05931241207245097, 0.06701698995193783, 0.05735518904117831, 0.07030747820199057]}}
{"id": "6f084e86-09a6-4689-9fb0-eb33a8dc74eb", "fitness": 0.05972028206872065, "name": "HPSO_ADE", "description": "Enhanced the cognitive coefficient adjustment to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(0.5 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               (self.cognitive + 0.1 * (iteration / self.budget)) * r1 * (self.pbest_positions - self.population) +  # <--- Changed line\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 37, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05279146264444379, 0.06352374841168973, 0.057393715683783486, 0.04964617517791248, 0.05931241207245097, 0.06741778430202194, 0.05736483665396552, 0.07030747820199057]}}
{"id": "a9d34747-6d3d-4ec8-8cee-f3de46dde7c9", "fitness": 0.059785392965352555, "name": "HPSO_ADE", "description": "Improved exploration by adjusting the mutation factor's periodicity in the adaptive strategy.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 38, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a695d0a5-593a-449d-908e-7551f2a388e6"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.052808153334347296, 0.06352374841168973, 0.05761747401229089, 0.04966132677857382, 0.05931241207245097, 0.06772842836348969, 0.05738459004311269, 0.07030747820199057]}}
{"id": "5536f230-3638-4dac-9c4d-10189e2c7970", "fitness": 0.057697754049833204, "name": "HPSO_ADE", "description": "Enhanced exploration by modifying the inertia weight decay to improve convergence rate.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.9 - 0.6 * (iteration / self.budget)  # Modified inertia decay\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 39, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["a9d34747-6d3d-4ec8-8cee-f3de46dde7c9"], "operator": null, "metadata": {"aucs": [0.0600863443409283, 0.05289011307791769, 0.05746539165116227, 0.0563162868998105, 0.04972195626295539, 0.05498275779927597, 0.06594846735612325, 0.057509275551886896, 0.06435919350843855]}}
{"id": "7b4a6f04-aafa-4b6b-a902-b70153ec9bb8", "fitness": 0.05920676031232291, "name": "HPSO_ADE", "description": "Introduced a dynamic cognitive coefficient for improved exploration and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Dynamic adjustment of cognitive coefficient\n            self.cognitive = 1.7 + 0.3 * np.cos(np.pi * iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 40, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a9d34747-6d3d-4ec8-8cee-f3de46dde7c9"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.052365933770684436, 0.06352374841168973, 0.0559924476771001, 0.0492611496840798, 0.05931241207245097, 0.06550771639510777, 0.05686503112757546, 0.07030747820199057]}}
{"id": "394ee0bc-12d6-4003-9962-22eda56690fb", "fitness": 0.055454216364873896, "name": "HPSO_ADE", "description": "Enhancing the adaptive strategy by refining the mutation factor's adjustment formula for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.cos(np.pi * iteration / self.budget)  # Refined periodicity adjustment\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 41, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_ids": ["a9d34747-6d3d-4ec8-8cee-f3de46dde7c9"], "operator": null, "metadata": {"aucs": [0.06050839600863467, 0.055153396068697624, 0.05120076600069934, 0.05275286680710889, 0.05179699313642927, 0.0493194896229282, 0.06122577937070495, 0.06017881423864746, 0.056951446030014674]}}
{"id": "becc8ff7-4ca7-4b1c-975c-24002471bc3a", "fitness": 0.059731583938698915, "name": "HPSO_ADE", "description": "Improved exploitation by refining the inertia scaling for better local search capability.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.3 * (iteration / self.budget)  # More gradual scaling\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            self.population += self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 42, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["a9d34747-6d3d-4ec8-8cee-f3de46dde7c9"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05283634550040017, 0.06352374841168973, 0.05738765585390715, 0.04968696432489783, 0.05930295918946371, 0.0674093879764216, 0.057418093905594825, 0.0702941748156879]}}
{"id": "3707c02d-209e-493a-9a66-2e779f5da468", "fitness": 0.0869863464980606, "name": "HPSO_ADE", "description": "Enhanced diversity by introducing an adaptive velocity scaling factor in the PSO component.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # New line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 43, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["a9d34747-6d3d-4ec8-8cee-f3de46dde7c9"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05253547877622844, 0.06289738512713383, 0.1016137058355161, 0.049409180670619945, 0.05873867278469325, 0.21344683153537647, 0.05706383207471877, 0.06957937658388635]}}
{"id": "91217692-8d42-4d76-9ce4-a9cba994b3ed", "fitness": 0.05980843968930533, "name": "HPSO_ADE", "description": "Improved exploration by modifying the velocity scaling factor to enhance dynamic adaptations.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.cos(2 * np.pi * iteration / self.budget)  # Adjusted line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 44, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3707c02d-209e-493a-9a66-2e779f5da468"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05280765531374998, 0.06352374841168973, 0.05770322645686343, 0.0496608733886148, 0.05931395645589421, 0.06784791822368008, 0.057383997437468914, 0.0703096560455595]}}
{"id": "6afb93fb-024f-428f-a2e4-d0183b2de6cb", "fitness": 0.08698612401803273, "name": "HPSO_ADE", "description": "Enhanced diversity by introducing adaptive inertia and velocity scaling adjustments in the PSO component.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.2 * np.sin(2 * np.pi * iteration / self.budget)  # Modified scaling\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 45, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["3707c02d-209e-493a-9a66-2e779f5da468"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05253484228434102, 0.06289738512713383, 0.1016137058355161, 0.04940859397870001, 0.05873867278469325, 0.21344683153537647, 0.057063052938275294, 0.06957937658388635]}}
{"id": "91552344-3c1c-4397-8f6a-5188f92b85f6", "fitness": 0.08698612424260693, "name": "HPSO_ADE", "description": "Enhanced exploration by adjusting the velocity scaling factor's periodicity in PSO.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(4 * np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 46, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["3707c02d-209e-493a-9a66-2e779f5da468"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052534842929479186, 0.06289738512713383, 0.1016137058355161, 0.04940859457180746, 0.05873867278469325, 0.21344683153537647, 0.057063053721197465, 0.06957937658388635]}}
{"id": "07851b58-cd8e-461f-87f9-c621a7ff3555", "fitness": 0.05769025767070051, "name": "HPSO_ADE", "description": "Enhanced exploration via adaptive mutation scale factor in DE component.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.6 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # New line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 47, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["3707c02d-209e-493a-9a66-2e779f5da468"], "operator": null, "metadata": {"aucs": [0.06405466651339675, 0.05227617344503854, 0.05490220036331417, 0.059872523122611265, 0.04917828806047686, 0.05152203809595557, 0.0708245918282927, 0.05676256040895211, 0.05981927719826663]}}
{"id": "5264d31d-8586-40d9-aab7-70b75faff573", "fitness": 0.08698640913177902, "name": "HPSO_ADE", "description": "Introduced a non-linear scaling factor in the velocity update for enhanced exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (slightly refined)\n            self.inertia = 0.8 - 0.5 * (iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 48, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["3707c02d-209e-493a-9a66-2e779f5da468"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.0525356517340535, 0.06289738512713383, 0.1016137058355161, 0.049409342527508504, 0.05873867278469325, 0.21344683153537647, 0.05706406096347094, 0.06957937658388635]}}
{"id": "875700c8-bb52-40c0-a1cc-2ee2437e8db8", "fitness": 0.08702111090603902, "name": "HPSO_ADE", "description": "Introduced non-linear dynamic scaling to adjust the inertia weight for improved convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 49, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["5264d31d-8586-40d9-aab7-70b75faff573"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052636423566794543, 0.06289738512713383, 0.1016137058355161, 0.049500880535277014, 0.05873867278469325, 0.21344683153537647, 0.057184067091301416, 0.06957937658388635]}}
{"id": "c8c911a0-e2bd-4dde-b32d-01c23c93c5ca", "fitness": 0.08702111090603902, "name": "HPSO_ADE", "description": "Introduced a non-linear adjustment to the cognitive coefficient to enhance exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 50, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["875700c8-bb52-40c0-a1cc-2ee2437e8db8"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052636423566794543, 0.06289738512713383, 0.1016137058355161, 0.049500880535277014, 0.05873867278469325, 0.21344683153537647, 0.057184067091301416, 0.06957937658388635]}}
{"id": "336a47cf-a32f-455e-9ca8-e69c20967947", "fitness": 0.08695970525201431, "name": "HPSO_ADE", "description": "Introduced adaptive cognitive scaling to enhance exploitation capabilities.  ", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               (self.cognitive + 0.3 * np.cos(np.pi * iteration / self.budget)) * r1 * (self.pbest_positions - self.population) +  # Modified line\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 51, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["875700c8-bb52-40c0-a1cc-2ee2437e8db8"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052460251083357834, 0.06289738512713383, 0.1016137058355161, 0.04933843726130671, 0.05873867278469325, 0.21344683153537647, 0.05697003196248607, 0.06957937658388635]}}
{"id": "8c09bf41-08a2-4ef7-ab23-bc47c10cd9f0", "fitness": 0.08705563839543465, "name": "HPSO_ADE", "description": "Introduced a non-linear dynamic scaling to adjust the cognitive coefficient for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 52, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["875700c8-bb52-40c0-a1cc-2ee2437e8db8"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05273669759871635, 0.06289738512713383, 0.1016137058355161, 0.04959185429715962, 0.05873867278469325, 0.21344683153537647, 0.05730356670205761, 0.06957937658388635]}}
{"id": "6467a7da-5b43-438f-9f58-e22a83ff334a", "fitness": 0.08704423306131949, "name": "HPSO_ADE", "description": "Introduced a sinusoidal variation in the social coefficient to better balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Changed line\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 53, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["8c09bf41-08a2-4ef7-ab23-bc47c10cd9f0"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052703556009524255, 0.06289738512713383, 0.1016137058355161, 0.049561832113583115, 0.05873867278469325, 0.21344683153537647, 0.0572640824677898, 0.06957937658388635]}}
{"id": "8f9a1c7a-b318-494b-9f6a-e3f491255753", "fitness": 0.08705563839543465, "name": "HPSO_ADE", "description": "Introduced a refined adaptive mutation strategy to improve convergence in HPSO_ADE.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (iteration / self.budget)\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 54, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["8c09bf41-08a2-4ef7-ab23-bc47c10cd9f0"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05273669759871635, 0.06289738512713383, 0.1016137058355161, 0.04959185429715962, 0.05873867278469325, 0.21344683153537647, 0.05730356670205761, 0.06957937658388635]}}
{"id": "e19d412d-ea63-4f11-86cc-18b64195ff6e", "fitness": 0.0870579241371538, "name": "HPSO_ADE", "description": "Introduced a quadratic dynamic variation for the social coefficient to improve convergence speed and enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 55, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["8c09bf41-08a2-4ef7-ab23-bc47c10cd9f0"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05274333826780586, 0.06289738512713383, 0.1016137058355161, 0.04959786964123092, 0.05873867278469325, 0.21344683153537647, 0.057311482364369115, 0.06957937658388635]}}
{"id": "732db5d8-33f6-4ff8-a826-3e2e2eaa6a8c", "fitness": 0.05423927843464625, "name": "HPSO_ADE", "description": "Improved exploration by introducing a cosine dynamic adjustment for the social coefficient.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * (np.cos(np.pi * iteration / self.budget))  # Cosine adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 56, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.05881866349025122, 0.05264590186203888, 0.04948379794314761, 0.05503690099617353, 0.04950184668827362, 0.0471268581364499, 0.06423136989684985, 0.057184476842294996, 0.05412369005633666]}}
{"id": "135a64ee-3552-4897-9781-ba238538ea12", "fitness": 0.08699241442394502, "name": "HPSO_ADE", "description": "Enhanced local search by introducing a small random exploration component to improve diversity and avoid premature convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites with random exploration\n            self.population[elite_indices] = elite_population + np.random.uniform(-0.1, 0.1, elite_population.shape)  # Changed line\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 57, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05233622601386301, 0.0630863829145033, 0.1016137058355161, 0.049298368602308074, 0.05887035777157057, 0.21344683153537647, 0.0569217910775669, 0.06976541097042854]}}
{"id": "d8948b45-6d6d-4d30-84fa-b83d04d3056c", "fitness": 0.07180692218741724, "name": "HPSO_ADE", "description": "Enhanced convergence by refining elite preservation strategy through precise dynamic elite size adjustment.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(3 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 58, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.02.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.09602577914259613, 0.05057024754780981, 0.06289738512713383, 0.0865532423022467, 0.047600402280194354, 0.05873867278469325, 0.11880688897394975, 0.055490304944245006, 0.06957937658388635]}}
{"id": "b3d3dc9b-2540-4243-ac49-a3555c88952a", "fitness": 0.08705295889903736, "name": "HPSO_ADE", "description": "Introduced a decaying mutation factor to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 * (1 - iteration / self.budget) + 0.3 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 59, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05272891434252491, 0.06289738512713383, 0.1016137058355161, 0.04958481172047202, 0.05873867278469325, 0.21344683153537647, 0.05729427706736112, 0.06957937658388635]}}
{"id": "a13735c4-8825-45f4-afbd-3fcf4d7285de", "fitness": 0.0870579241371538, "name": "HPSO_ADE", "description": "Enhanced elite preservation by adding diversity control to prevent premature convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size and diversity control\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n            if np.std(scores) < 0.01:  # Diversity control\n                elite_population += np.random.uniform(-0.1, 0.1, elite_population.shape)\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 60, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05274333826780586, 0.06289738512713383, 0.1016137058355161, 0.04959786964123092, 0.05873867278469325, 0.21344683153537647, 0.057311482364369115, 0.06957937658388635]}}
{"id": "bbcf050e-6042-4313-84da-350e86830997", "fitness": 0.08711906732731751, "name": "HPSO_ADE", "description": "Enhanced adaptive inertia strategy by introducing new periodicity to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 61, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["e19d412d-ea63-4f11-86cc-18b64195ff6e"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052920748604374124, 0.06289738512713383, 0.1016137058355161, 0.04975872384293978, 0.05873867278469325, 0.21344683153537647, 0.05752350653756555, 0.06957937658388635]}}
{"id": "d3121b4c-3abd-4057-b48b-b891b3ea8fc3", "fitness": 0.08711186535820664, "name": "HPSO_ADE", "description": "Introduced a sigmoid function to modulate the periodicity of the adaptive mutation factor for better balance in exploration-exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Apply sigmoid modulation to mutation factor\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget) / (1 + np.exp(-0.04 * iteration))  # Modified line\n            \n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 62, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbcf050e-6042-4313-84da-350e86830997"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.0528998494486822, 0.06289738512713383, 0.1016137058355161, 0.04973981840435604, 0.05873867278469325, 0.21344683153537647, 0.057498493409843365, 0.06957937658388635]}}
{"id": "4d8bff17-bcd7-402d-99d5-be6fbf171144", "fitness": 0.05878575616966222, "name": "HPSO_ADE", "description": "Introduce a small adaptive scaling factor to the velocity update for enhanced exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            scaling_factor = 0.9 + 0.1 * np.sin(np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               scaling_factor * (self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population)))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 63, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbcf050e-6042-4313-84da-350e86830997"], "operator": null, "metadata": {"aucs": [0.06178778756842329, 0.05251222683669843, 0.06615449193106959, 0.05784665711152992, 0.04938881973919895, 0.05366728272702537, 0.06800204471214655, 0.057038887324301624, 0.06267360757656626]}}
{"id": "8ddd3036-6cfd-4c00-8447-a665f03d6316", "fitness": 0.05943807482617853, "name": "HPSO_ADE", "description": "Introduced a non-linear velocity scaling factor to enhance adaptive performance in dynamic environments.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.3 * np.sin(np.pi * iteration / self.budget)  # Adjusted periodicity\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.cos(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 64, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbcf050e-6042-4313-84da-350e86830997"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05295608779655803, 0.06352374841168973, 0.05611463349134638, 0.04979597478780684, 0.05930295918946371, 0.06566937726182498, 0.057560792211001854, 0.0702941748156879]}}
{"id": "224565fd-fbca-4a07-bad8-65758c93fd17", "fitness": 0.08712972187707803, "name": "HPSO_ADE", "description": "Introduce periodic fluctuation in mutation factor to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(np.pi * iteration / self.budget)  # Note: changed 0.3 to 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 65, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbcf050e-6042-4313-84da-350e86830997"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.052951656885317, 0.06289738512713383, 0.1016137058355161, 0.04978666704681389, 0.05873867278469325, 0.21344683153537647, 0.05756054600059313, 0.06957937658388635]}}
{"id": "aeeb7fd6-ebb2-44a0-8d11-8a01e0b87f16", "fitness": 0.05948407595635839, "name": "HPSO_ADE", "description": "Enhance exploration by amplifying velocity scaling, improving adaptation to search space dynamics.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.5 * np.sin(np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  \n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 1.0 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 66, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["224565fd-fbca-4a07-bad8-65758c93fd17"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05299811783952946, 0.06352374841168973, 0.05623576751577963, 0.049834127847683596, 0.05930295918946371, 0.06583210387344796, 0.05761075864371623, 0.0702941748156879]}}
{"id": "c23d3b9f-a57c-4bca-a026-73070cd0bf85", "fitness": 0.08758838334306915, "name": "HPSO_ADE", "description": "Enhance mutation strategy with a dynamic mutation factor curve modification for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 67, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["224565fd-fbca-4a07-bad8-65758c93fd17"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053069228119934864, 0.06289738512713383, 0.1016137058355161, 0.049892928584989504, 0.06028097659089604, 0.21344683153537647, 0.05770167798631132, 0.07180006121309201]}}
{"id": "363b26f3-5995-447f-838a-f8ae0c857041", "fitness": 0.08724636505529242, "name": "HPSO_ADE", "description": "Strengthen the exploration phase by modifying the periodic impact on the mutation factor.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.6 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line, stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 68, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05316209058209842, 0.06289738512713383, 0.1016137058355161, 0.04997690005080835, 0.05890321950204702, 0.21344683153537647, 0.05781314693270223, 0.06981135083757706]}}
{"id": "10c2f5fd-58be-46f1-a55d-076dc3bcb040", "fitness": 0.08747250038111345, "name": "HPSO_ADE", "description": "Introducing a dynamic cognitive coefficient adjustment to improve the exploration-exploitation balance of the HPSO_ADE.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.5 * np.cos(2 * np.pi * iteration / self.budget)  # Updated line\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 69, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05394332692541315, 0.06289738512713383, 0.1016137058355161, 0.0506882811701882, 0.05873867278469325, 0.21344683153537647, 0.058752268373441496, 0.06957937658388635]}}
{"id": "a6855117-b1c0-4690-bfff-481c74cd16a7", "fitness": 0.08758838334306915, "name": "HPSO_ADE", "description": "Introduced a periodic adjustment to the cognitive coefficient for enhanced diversity in exploration.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 70, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053069228119934864, 0.06289738512713383, 0.1016137058355161, 0.049892928584989504, 0.06028097659089604, 0.21344683153537647, 0.05770167798631132, 0.07180006121309201]}}
{"id": "fb9fe0ee-238e-4508-93fd-b2e40d7c1587", "fitness": 0.08758838334306915, "name": "HPSO_ADE", "description": "Incorporate non-linear dynamic adjustment of crossover rate for better exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * np.sin(iteration / self.budget)  # Non-linear adjustment of crossover rate\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 71, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053069228119934864, 0.06289738512713383, 0.1016137058355161, 0.049892928584989504, 0.06028097659089604, 0.21344683153537647, 0.05770167798631132, 0.07180006121309201]}}
{"id": "65dbe957-99df-4ad5-8fb3-a852834dcc40", "fitness": 0.08716721858231374, "name": "HPSO_ADE", "description": "Fine-tune cognitive coefficient adjustment to enhance adaptability in dynamic environments.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 72, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05285942857248016, 0.06289738512713383, 0.1016137058355161, 0.04970303077954574, 0.058997564359915655, 0.21344683153537647, 0.05745027572567596, 0.06994409021080761]}}
{"id": "e3a0dcb8-442f-49cd-8929-a5cf2b6987c7", "fitness": 0.08749915093771692, "name": "HPSO_ADE", "description": "Introduce a small nonlinear adjustment to the cognitive coefficient in the velocity update for enhanced adaptability.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               (self.cognitive + 0.1 * np.sin(2 * np.pi * iteration / self.budget)) * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 73, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05336454838109195, 0.06289738512713383, 0.1016137058355161, 0.05015952526678891, 0.05958132753227974, 0.21344683153537647, 0.05805696687001971, 0.07077941279687328]}}
{"id": "855f1303-1a22-45f3-aa4b-0ae82335400a", "fitness": 0.08758838334306915, "name": "HPSO_ADE", "description": "Introduce a sinusoidal variation to the crossover rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration**2 / self.budget**2)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    self.cr = 0.9 - 0.4 * np.sin(2 * np.pi * iteration / self.budget)  # Introduced sinusoidal variation\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 74, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053069228119934864, 0.06289738512713383, 0.1016137058355161, 0.049892928584989504, 0.06028097659089604, 0.21344683153537647, 0.05770167798631132, 0.07180006121309201]}}
{"id": "bbd1606b-e869-4289-a64f-9a20bf908e69", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Introduce periodic velocity scaling to enhance exploration and exploitation balance throughout the optimization process.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 75, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["c23d3b9f-a57c-4bca-a026-73070cd0bf85"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "2f83d7d0-581b-4bb3-ab59-bdbae2354d9a", "fitness": 0.06062962862077665, "name": "HPSO_ADE", "description": "Introduce slight variation to the velocity scaling factor for improved convergence efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.88 + 0.12 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 76, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.06528250318971973, 0.056049121651182365, 0.05820069920900328, 0.06098140307082789, 0.05260320478275471, 0.05478713546965608, 0.07233783989612474, 0.06126108875491054, 0.0641636615628105]}}
{"id": "d5c46381-8801-4cf3-8a04-a2f87f7aab06", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Introduce a dynamic inertia weight adjustment to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 77, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "a9eb8720-53ac-4f06-9dc4-55224babbae6", "fitness": 0.05766621462101492, "name": "HPSO_ADE", "description": "Introduce stochastic velocity scaling for enhanced adaptability and improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + np.random.rand() * 0.1  # Modified line to incorporate stochastic scaling\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 78, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.06726408343526735, 0.05263432027233372, 0.05088104483507905, 0.06273664104534893, 0.04950240154742647, 0.048283790452580466, 0.07481581912717261, 0.05718395212312699, 0.055693878750798675]}}
{"id": "d6774357-a581-42ed-9680-cd6cf7b458b0", "fitness": 0.08702571825893568, "name": "HPSO_ADE", "description": "Introduce a slight bias towards best particles by amplifying cognitive influence periodically to enhance convergence speed.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget) + 0.05  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 79, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.0526505774952577, 0.06289738512713383, 0.1016137058355161, 0.049512668462736276, 0.05873867278469325, 0.21344683153537647, 0.057199591411448925, 0.06957937658388635]}}
{"id": "0b8c2119-43cc-4e20-a9bd-ac390518fe28", "fitness": 0.08741224974469514, "name": "HPSO_ADE", "description": "Introduce sinusoidal scaling to the cognitive coefficient for enhanced adaptability and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n\n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n\n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(4 * np.pi * iteration / self.budget)  # Changed line\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 80, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05338169961006567, 0.06289738512713383, 0.1016137058355161, 0.05017527093217389, 0.059238169192561974, 0.21344683153537647, 0.05807749137378837, 0.07028703900126776]}}
{"id": "3f013d85-34c2-46ba-ad4d-42bc67c73314", "fitness": 0.05966410036905704, "name": "HPSO_ADE", "description": "Adjust the velocity scaling to include a dynamic factor for enhancing convergence speed.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = (0.9 + 0.1 * np.cos(np.pi * iteration / self.budget))  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 81, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.05972492547022734, 0.05321357770429769, 0.06352374841168973, 0.0566361411182269, 0.05002961351082902, 0.05930295918946371, 0.06638419312034649, 0.057867569980744604, 0.0702941748156879]}}
{"id": "83c4a64a-6b92-4609-af33-6956c9a24614", "fitness": 0.081640100901883, "name": "HPSO_ADE", "description": "Introduce a minor adjustment to the DE crossover rate to further refine exploration and exploitation balance.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.8 - 0.4 * (iteration / self.budget)  # Adjusted line\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 82, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.04.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11417199580526427, 0.05073802313459208, 0.06287969475983479, 0.09939876206734355, 0.04718602927159432, 0.05872222121755166, 0.1779038226827181, 0.05420119034408988, 0.0695591688339584]}}
{"id": "f74449cc-a6ba-495f-9956-1dee972c0166", "fitness": 0.060634976814969495, "name": "HPSO_ADE", "description": "Fine-tune the velocity scaling factor to enhance convergence precision while maintaining exploration ability.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.95 + 0.05 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 83, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.06814185982545329, 0.052634727841009976, 0.058469459326723205, 0.06349219972600584, 0.04949360357999477, 0.05537646331080759, 0.07599194942247622, 0.057209348754779454, 0.0649051795474751]}}
{"id": "d873f5b7-462c-4cc7-93e9-901cb99757b1", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Introduce dynamic scaling of mutation factor, increasing diversity in challenging search spaces.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 84, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "633cb5b5-7d26-4e84-9e33-e341f0192e34", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Enhance convergence by introducing adaptive mutation probability based on iteration number.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 85, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "68d665e3-3cb4-44e4-9337-383417ba9c56", "fitness": 0.0873800573495698, "name": "HPSO_ADE", "description": "Introduce adaptive velocity scaling based on iteration percentage to improve convergence and balance exploration-exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * (iteration / self.budget)  # Changed this line for adaptive scaling\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 86, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05306602742247979, 0.06289738512713383, 0.1016137058355161, 0.04989002623628647, 0.05952205118407661, 0.21344683153537647, 0.057697845894352895, 0.0706939878165338]}}
{"id": "5f28b72a-3d1b-4d92-a90b-8937fb52a18c", "fitness": 0.08744544471207275, "name": "HPSO_ADE", "description": "Introduce a dynamic elite preservation strategy by modifying the elite size formula to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(np.ceil(5 * (1 - np.sin(iteration / self.budget * np.pi)))))  # Modified line\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 87, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05178642792298016, 0.06289738512713383, 0.1016137058355161, 0.048778207254142614, 0.06130819945232169, 0.21344683153537647, 0.05624311031655782, 0.07334247987025377]}}
{"id": "7aa6d2e3-d2bc-4946-aa5c-78adc8aa0b64", "fitness": 0.08786833307799757, "name": "HPSO_ADE_Refined", "description": "Implement a dynamic adjustment of the cognitive, social coefficients, and mutation factor to enhance the exploration-exploitation balance adaptively.", "code": "import numpy as np\n\nclass HPSO_ADE_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 88, "feedback": "The algorithm HPSO_ADE_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "988437e1-8517-4923-a8a0-8f4f011fe0b1", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Introduce adaptive personal best selection based on population diversity to improve convergence efficiency.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # New line added\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 89, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "3c7ea2ef-d2c3-485a-9b61-1dea1e7b6c53", "fitness": 0.08733363557107293, "name": "HPSO_ADE", "description": "Adjust the cognitive coefficient to enhance convergence speed and precision.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7  # Adjusted cognitive coefficient\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)  # Quadratic adjustment\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)  # Note: changed 0.5 for stronger periodic impact\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))  # Adjust elite size dynamically\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.8 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)  # Adjusted line\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:  # Skip elites during mutation\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 90, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05354358651834257, 0.06289738512713383, 0.1016137058355161, 0.050319825003620866, 0.05873867278469325, 0.21344683153537647, 0.058270681656714673, 0.06957937658388635]}}
{"id": "08059329-2b69-4f2e-802c-d156277f5fe4", "fitness": 0.08786850659698572, "name": "HPSO_ADE", "description": "Introduce temperature-based scaling for velocities to better control exploration and exploitation phases.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 91, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["bbd1606b-e869-4289-a64f-9a20bf908e69"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053053161905684765, 0.06289738512713383, 0.1016137058355161, 0.04987825025474368, 0.061308816146949496, 0.21344683153537647, 0.057682329690702305, 0.07334342378239267]}}
{"id": "cab4e648-73f3-47fe-b58e-a5f5788e7934", "fitness": 0.08786833307799757, "name": "HPSO_ADE", "description": "Introduce an adaptive scaling factor for updating velocities based on the sine function to balance exploration and exploitation phases.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 92, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["08059329-2b69-4f2e-802c-d156277f5fe4"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305316156340423, 0.06289738512713383, 0.1016137058355161, 0.04987824994456447, 0.06130819945232169, 0.21344683153537647, 0.05768232927903538, 0.07334247987025377]}}
{"id": "b9abf421-c155-40f5-862c-da0b104988b0", "fitness": 0.06482436995297436, "name": "HPSO_ADE", "description": "Introduce velocity decay factor to improve convergence stability over iterations.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        velocity_decay = 0.99  # New line added for introducing velocity decay\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (velocity_decay * self.inertia * self.velocities +  # Modified line\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 93, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["08059329-2b69-4f2e-802c-d156277f5fe4"], "operator": null, "metadata": {"aucs": [0.07298826032054118, 0.053150669691696906, 0.06553447969763093, 0.0677326656442292, 0.049967713235035016, 0.06107101006865823, 0.08227591469168172, 0.0577960446133754, 0.07290257161392066]}}
{"id": "84ccf750-dfb3-452d-99fe-926cf0efef84", "fitness": 0.05642270439833563, "name": "HPSO_ADE", "description": "Integrate a cosine-based modulation to adjust crossover rate in DE dynamically for balanced diversity and convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (np.cos(2 * np.pi * iteration / self.budget))  # Modified line\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 94, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["08059329-2b69-4f2e-802c-d156277f5fe4"], "operator": null, "metadata": {"aucs": [0.0678915438694595, 0.04514364762167533, 0.053298471250942225, 0.06325704528621778, 0.04263886614689205, 0.05153751163518139, 0.07566967440251648, 0.048519974693845835, 0.05984760467829009]}}
{"id": "0d5be10f-dd3f-497f-8432-6e47171bad29", "fitness": 0.08786850659698572, "name": "HPSO_ADE", "description": "Fine-tune adaptive parameters to improve dynamic balance between exploration and exploitation.  ", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))  # Modified line\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 95, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["08059329-2b69-4f2e-802c-d156277f5fe4"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.053053161905684765, 0.06289738512713383, 0.1016137058355161, 0.04987825025474368, 0.061308816146949496, 0.21344683153537647, 0.057682329690702305, 0.07334342378239267]}}
{"id": "877441d0-e724-464b-bebb-1f8035b35cb7", "fitness": 0.0879260334706781, "name": "HPSO_ADE", "description": "Enhance exploration by modifying the velocity scaling factor to incorporate a sinusoidal adjustment with respect to the elite population size.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            # Modified line\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget) * elite_size / 5)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 96, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["08059329-2b69-4f2e-802c-d156277f5fe4"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05305402404602988, 0.06289738512713383, 0.1016137058355161, 0.049879131275996524, 0.061511785739026714, 0.21344683153537647, 0.057683491558244704, 0.07365529102440638]}}
{"id": "063c7176-f5b3-4047-97c8-211ac66bb0e4", "fitness": 0.05744049846170239, "name": "HPSO_ADE", "description": "Refine velocity update by introducing a multiplicative noise factor to enhance exploration and avoid local optima.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            # Dynamic adjustment of inertia (non-linear adjustment)\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            \n            # Dynamic adjustment of social coefficient\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            \n            # Adaptive mutation factor and crossover rate\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            # Evaluate the current population\n            scores = np.array([func(ind) for ind in self.population])\n\n            # Update personal bests\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            # Elite preservation with dynamic elite size\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            # Update velocities and positions (PSO)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            # Introducing multiplicative noise factor\n            noise_factor = 1 + 0.1 * np.random.randn(self.population_size, self.dim)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population)) * noise_factor\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget) * elite_size / 5)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            # Apply Differential Evolution (DE) crossover and mutation\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            # Reinstate elites\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 97, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["877441d0-e724-464b-bebb-1f8035b35cb7"], "operator": null, "metadata": {"aucs": [0.06102641588381941, 0.04918522511939638, 0.06273698092359448, 0.05715608994815291, 0.04670157282837928, 0.05502457897769042, 0.06706359777175974, 0.053618310458126706, 0.06445171424440221]}}
{"id": "a56a206b-0a4a-4213-a5c3-6ab86c425cb8", "fitness": 0.08728430696916434, "name": "HPSO_ADE", "description": "Introduce an exponential decay factor for velocity scaling and adapt the differential evolution strategy to improve convergence.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            # Modified lines\n            decay_factor = np.exp(-iteration / self.budget)\n            velocity_scaling = 0.9 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget) * elite_size / 5) * decay_factor\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    # Modified line\n                    mutant_vector = np.clip(a + self.f * (b - c) * decay_factor, -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 98, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.05.", "error": "", "parent_ids": ["877441d0-e724-464b-bebb-1f8035b35cb7"], "operator": null, "metadata": {"aucs": [0.11759265509437222, 0.05300947590955962, 0.06289738512713383, 0.1016137058355161, 0.04983888107497669, 0.05924041562705118, 0.21344683153537647, 0.05762995531153747, 0.07028945720695545]}}
{"id": "c12859ff-1093-44b3-b19c-dab6f8d9eaf2", "fitness": 0.059903869752387075, "name": "HPSO_ADE", "description": "Slightly adjusted the velocity scaling factor to enhance the balance between exploration and exploitation phases.", "code": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.population = np.random.uniform(-5, 5, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim))\n        self.pbest_positions = np.copy(self.population)\n        self.pbest_scores = np.full(self.population_size, np.inf)\n        self.gbest_position = None\n        self.gbest_score = np.inf\n        self.f = 0.5\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.cognitive = 1.7\n        self.social = 1.5\n\n    def __call__(self, func):\n        for iteration in range(self.budget):\n            self.inertia = 0.8 - 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.social = 1.5 + 0.5 * ((iteration / self.budget) ** 2)\n            self.f = 0.5 + 0.5 * np.sin(2 * np.pi * iteration / self.budget)\n            self.cr = 0.9 - 0.4 * (iteration / self.budget)\n\n            scores = np.array([func(ind) for ind in self.population])\n\n            better_indices = scores < self.pbest_scores\n            self.pbest_positions[better_indices] = self.population[better_indices]\n            self.pbest_scores[better_indices] = scores[better_indices]\n\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.gbest_score:\n                self.gbest_score = scores[min_score_idx]\n                self.gbest_position = self.population[min_score_idx]\n\n            elite_size = max(1, int(5 * (1 - iteration / self.budget)))\n            elite_indices = np.argsort(scores)[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.cognitive = 1.7 + 0.3 * np.sin(2 * np.pi * iteration / self.budget)\n            self.velocities = (self.inertia * self.velocities +\n                               self.cognitive * r1 * (self.pbest_positions - self.population) +\n                               self.social * r2 * (self.gbest_position - self.population))\n            # Modified line\n            velocity_scaling = 0.92 + 0.1 * np.sin(2 * np.pi * iteration / self.budget) * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget) * elite_size / 5)\n            self.population += velocity_scaling * self.velocities\n            self.population = np.clip(self.population, -5, 5)\n\n            for i in range(self.population_size):\n                if i not in elite_indices:\n                    indices = [index for index in range(self.population_size) if index != i]\n                    a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.f * (b - c), -5, 5)\n                    trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.population[i])\n                    trial_score = func(trial_vector)\n                    if trial_score < self.pbest_scores[i]:\n                        self.population[i] = trial_vector\n                        self.pbest_scores[i] = trial_score\n                        if trial_score < self.gbest_score:\n                            self.gbest_score = trial_score\n                            self.gbest_position = trial_vector\n\n            self.population[elite_indices] = elite_population\n\n        return self.gbest_position, self.gbest_score", "configspace": "", "generation": 99, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_ids": ["877441d0-e724-464b-bebb-1f8035b35cb7"], "operator": null, "metadata": {"aucs": [0.06654665834116724, 0.05261906366823721, 0.05862605926384501, 0.062039852674976026, 0.0491006760355418, 0.055025201004979984, 0.07406139061810668, 0.05665944801485345, 0.06445647814977629]}}
