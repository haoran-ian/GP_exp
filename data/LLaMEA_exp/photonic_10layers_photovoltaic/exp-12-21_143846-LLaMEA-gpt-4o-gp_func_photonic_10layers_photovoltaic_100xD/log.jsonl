{"id": "bcccba65-9580-4507-b28f-5483c555e922", "fitness": 0.05058460506962876, "name": "AdaptiveCulturalSwarmOptimizer", "description": "Adaptive Cultural Swarm Optimizer leveraging dynamic belief space updates for diverse exploration and convergence in black box optimization.", "code": "import numpy as np\n\nclass AdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update belief space normative knowledge\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n                \n            # Update particles\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                # Enforce normative belief space boundaries and update position\n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05058 with standard deviation 0.00287.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05242929493422943, 0.05602915902849659, 0.05334605285835625, 0.04842551014890817, 0.05174512056578362, 0.049265043331851, 0.04666979941621452, 0.049873726769472326, 0.04747773857334692]}}
{"id": "7cbb479b-3288-4216-ab54-b94658be3c8e", "fitness": 0.05169102039321397, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Enhanced Adaptive Cultural Swarm Optimizer incorporating adaptive inertia weight and diversity preservation for improved balance between exploration and exploitation in black box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(self.population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update belief space normative knowledge\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n                \n            # Update particles\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                # Add random noise for diversity preservation\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05169 with standard deviation 0.00284.", "error": "", "parent_ids": ["bcccba65-9580-4507-b28f-5483c555e922"], "operator": null, "metadata": {"aucs": [0.05318592075984474, 0.05602915902849659, 0.05613840925932645, 0.049123231124413747, 0.05174512056578362, 0.05183042926047032, 0.047343206604556154, 0.049873726769472326, 0.049949980166561825]}}
{"id": "8398857b-dbf4-4a65-9ed5-af998dbd766f", "fitness": 0.05058326840190636, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Enhanced Adaptive Cultural Swarm Optimizer with a dynamic population size that adapts based on exploration and exploitation needs.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            # Dynamic update of population size\n            self.population_size = min(100, max(20, int(50 * (1 - eval_count / self.budget))))\n            \n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(self.population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update belief space normative knowledge\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n                \n            # Update particles\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                # Add random noise for diversity preservation\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05058 with standard deviation 0.00308.", "error": "", "parent_ids": ["7cbb479b-3288-4216-ab54-b94658be3c8e"], "operator": null, "metadata": {"aucs": [0.05220882952351158, 0.05665197161520985, 0.05294078587634388, 0.04821829256462695, 0.05231685176930878, 0.04889622382014658, 0.04646823043662107, 0.050424509205570955, 0.047123720805817615]}}
{"id": "10d24141-662c-498d-a059-9da3218fa49a", "fitness": 0.05186376158300383, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Introduced a dynamic population size strategy to improve the balance between exploration and exploitation over iterations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05186 with standard deviation 0.00309.", "error": "", "parent_ids": ["7cbb479b-3288-4216-ab54-b94658be3c8e"], "operator": null, "metadata": {"aucs": [0.0527452192304827, 0.05602915902849659, 0.057130718383188284, 0.048716495236572066, 0.05174512056578362, 0.05274730112776549, 0.04695050664856293, 0.049873726769472326, 0.050835607256710436]}}
{"id": "e23c0ced-8ec7-4e91-9f8f-e3f16e20ff54", "fitness": -Infinity, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Introduced adaptive mutation and elite preservation to enhance exploitation while maintaining diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.mutation_prob_initial = 0.3\n        self.mutation_prob_final = 0.1\n        self.elite_ratio = 0.1  # Preserve top 10% solutions\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            mutation_prob = ((self.budget - eval_count) / self.budget) * (self.mutation_prob_initial - self.mutation_prob_final) + self.mutation_prob_final\n            \n            scores = np.array([func(ind) for ind in pop[:current_population_size]])\n            eval_count += current_population_size\n            for i, score in enumerate(scores):\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n            elite_count = int(self.elite_ratio * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            pop = np.array([pop[i] for i in elite_indices])\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                if np.random.rand() < mutation_prob:\n                    mutation = np.random.uniform(-1, 1, self.dim)\n                    velocities[i] += mutation\n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {}}
{"id": "e408bbcc-d826-4112-a199-b6b707362143", "fitness": 0.04827728019495273, "name": "MultiPhaseAdaptiveCulturalSwarmOptimizer", "description": "Introduced a multi-phase velocity update strategy using adaptive memory to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass MultiPhaseAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.history_memory_size = 10\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        history_memory = [np.copy(personal_best_positions) for _ in range(self.history_memory_size)]\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            # Update belief space\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            # Update velocities and positions using adaptive memory\n            history_memory.pop(0)\n            history_memory.append(np.copy(personal_best_positions))\n            historical_best = np.min([np.min(mem, axis=0) for mem in history_memory], axis=0)\n\n            for i in range(current_population_size):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                historical_component = self.social_coeff * r3 * (historical_best - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component + historical_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm MultiPhaseAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04828 with standard deviation 0.00385.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.04945127983226538, 0.05602915902849659, 0.04895936394902256, 0.04566668945621, 0.05174512056578362, 0.045209209636772885, 0.04400203571336925, 0.049873726769472326, 0.04355893680318201]}}
{"id": "6ce637e7-33ea-4888-89bc-fbd432ea4b02", "fitness": 0.050635941949438164, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Enhanced convergence speed by incorporating a self-adaptive mutation mechanism based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.mutation_rate = 0.1  # Added mutation rate\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            diversity = np.std(pop, axis=0)  # Calculate diversity\n            mutation_strength = self.mutation_rate * diversity  # Calculate mutation strength\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, mutation_strength, self.dim)  # Adjust noise by mutation strength\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05064 with standard deviation 0.00305.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.05178340968418049, 0.05639099728112351, 0.05379514921574324, 0.04782624710891481, 0.0520776530153354, 0.04968308462318083, 0.04608994983943948, 0.05019422161434073, 0.04788276516268497]}}
{"id": "5988fcd5-f171-458a-8c6f-45d1b2d0d8cc", "fitness": 0.050816722882165516, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Enhanced adaptive strategy with a multi-swarm approach and improved convergence by incorporating local search refinements.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.num_swarms = 3  # New parameter: number of swarms\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = [np.full(self.initial_population_size, np.inf) for _ in range(self.num_swarms)]\n        pops = [np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.initial_population_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(pops[i]) for i in range(self.num_swarms)]\n\n        while eval_count < self.budget:\n            for swarm in range(self.num_swarms):\n                current_population_size = int(\n                    self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                    (self.initial_population_size - self.final_population_size)\n                )\n                inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n                \n                for i in range(current_population_size):\n                    score = func(pops[swarm][i])\n                    eval_count += 1\n                    if score < personal_best_scores[swarm][i]:\n                        personal_best_scores[swarm][i] = score\n                        personal_best_positions[swarm][i] = pops[swarm][i].copy()\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = pops[swarm][i].copy()\n                        self.belief_space['situational'] = global_best_position\n                    \n                    if eval_count >= self.budget:\n                        return global_best_position, global_best_score\n\n                for d in range(self.dim):\n                    self.belief_space['normative'][0, d] = np.min([np.min(personal_best_positions[swarm][:, d]) for swarm in range(self.num_swarms)])\n                    self.belief_space['normative'][1, d] = np.max([np.max(personal_best_positions[swarm][:, d]) for swarm in range(self.num_swarms)])\n\n                for i in range(current_population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[swarm][i] - pops[swarm][i])\n                    social_component = self.social_coeff * r2 * (global_best_position - pops[swarm][i])\n                    velocities[swarm][i] = (inertia_weight * velocities[swarm][i] + cognitive_component + social_component)\n                    new_position = pops[swarm][i] + velocities[swarm][i]\n                    pops[swarm][i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05082 with standard deviation 0.00374.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.05652055868318906, 0.05602915902849659, 0.05000595945999564, 0.052195467207320045, 0.05174512056578362, 0.046177905924699614, 0.05030729058911554, 0.049873726769472326, 0.04449531771141724]}}
{"id": "6c9ac486-e782-43ea-8793-d24938408916", "fitness": 0.05047861955972082, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Introduced an adaptive mutation mechanism with Gaussian perturbations to enhance exploration in early iterations and intensified exploitation later.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                # Adaptive Gaussian mutation\n                mutation_strength = ((self.budget - eval_count) / self.budget) * 0.1\n                noise = np.random.normal(0, mutation_strength, self.dim)\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05048 with standard deviation 0.00289.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.05251291938434954, 0.05605855663951853, 0.05289158650597703, 0.04850088873209657, 0.051772140987099036, 0.04885046325138298, 0.04674185563202127, 0.04989977054734074, 0.0470793943577017]}}
{"id": "04bee8cd-c5b3-431d-b14b-5bedfb07d0ef", "fitness": -Infinity, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Introduced a hybrid mutation strategy leveraging LÃ©vy flights to enhance exploration capabilities and avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def levy_flight(self, size, beta=1.5):\n        sigma_u = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return step\n    \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                levy_mutation = self.levy_flight(self.dim) * (pop[i] - global_best_position)\n                new_position = pop[i] + velocities[i] + levy_mutation\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {}}
{"id": "aef9c4ff-da85-4efc-81f3-c88ed665cef9", "fitness": 0.050422624981113794, "name": "EnhancedStochasticNeighborhoodOptimizer", "description": "Introduced a stochastic neighborhood influence model and adaptive mutation rate to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedStochasticNeighborhoodOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.mutation_rate = 0.1\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                neighbor_indices = np.random.choice(current_population_size, 2, replace=False)\n                neighbor_best_position = personal_best_positions[neighbor_indices[0]] if personal_best_scores[neighbor_indices[0]] < personal_best_scores[neighbor_indices[1]] else personal_best_positions[neighbor_indices[1]]\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                neighborhood_component = self.social_coeff * r3 * (neighbor_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component + neighborhood_component)\n                mutation = self.mutation_rate * np.random.normal(0, 1, self.dim)\n                new_position = pop[i] + velocities[i] + mutation\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedStochasticNeighborhoodOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05042 with standard deviation 0.00358.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.049892993695485166, 0.05602915902849659, 0.05536938230358013, 0.04607673319410277, 0.05174512056578362, 0.0511343372998061, 0.044398884316477316, 0.049873726769472326, 0.04928328765682011]}}
{"id": "d208e3dc-7d48-47c1-95aa-ab362c67513f", "fitness": 0.05186376158300383, "name": "RefinedCulturalSwarmOptimizer", "description": "Introduced a multi-layer cultural belief update mechanism for improved situational and normative adaptation.", "code": "import numpy as np\n\nclass RefinedCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = ((self.budget - eval_count) / self.budget) * (self.inertia_weight_initial - self.inertia_weight_final) + self.inertia_weight_final\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            self.update_belief_space(current_population_size, personal_best_positions)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score\n    \n    def update_belief_space(self, population_size, personal_best_positions):\n        # Multi-layer belief update: consider multiple layers of best solutions for richer belief adaptation\n        top_individuals = int(0.2 * population_size)  # Top 20% individuals for belief update\n        sorted_indices = np.argsort(personal_best_positions[:population_size], axis=0)\n        for d in range(self.dim):\n            self.belief_space['normative'][0, d] = np.min(personal_best_positions[sorted_indices[:top_individuals], d])\n            self.belief_space['normative'][1, d] = np.max(personal_best_positions[sorted_indices[:top_individuals], d])", "configspace": "", "generation": 11, "feedback": "The algorithm RefinedCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05186 with standard deviation 0.00309.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.0527452192304827, 0.05602915902849659, 0.057130718383188284, 0.048716495236572066, 0.05174512056578362, 0.05274730112776549, 0.04695050664856293, 0.049873726769472326, 0.050835607256710436]}}
{"id": "7e8424b0-ba19-495d-953f-401223ec4e2b", "fitness": 0.05235877909640471, "name": "EnhancedAdaptiveCulturalSwarmOptimizer", "description": "Introduced adaptive inertia and an elite mechanism for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1  # Introduced elite fraction\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),  # [0] for min, [1] for max\n            'situational': np.full(dim, np.inf)  # Best solution found\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                if i not in elite_indices:\n                    pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05236 with standard deviation 0.00344.", "error": "", "parent_ids": ["10d24141-662c-498d-a059-9da3218fa49a"], "operator": null, "metadata": {"aucs": [0.0527452192304827, 0.05602915902849659, 0.058736408005995, 0.048716495236572066, 0.05174512056578362, 0.05420239748858857, 0.04695050664856293, 0.049873726769472326, 0.05222997889368863]}}
{"id": "6abaf91c-ee12-4fe8-89eb-eec385585efa", "fitness": 0.053781272234417914, "name": "RefinedAdaptiveCulturalSwarmOptimizer", "description": "Enhanced interaction between elite and non-elite particles with adaptive velocity control for improved convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveCulturalSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence  # Enhanced interaction with elite positions\n                    velocities[i] = np.clip(velocities[i], -1, 1)  # Adaptive velocity control\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm RefinedAdaptiveCulturalSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05378 with standard deviation 0.00369.", "error": "", "parent_ids": ["7e8424b0-ba19-495d-953f-401223ec4e2b"], "operator": null, "metadata": {"aucs": [0.05520801775448647, 0.06123932823944689, 0.05562569061639244, 0.050986030174690056, 0.05650345185493033, 0.05136998612946109, 0.049140355122610946, 0.054448140014867974, 0.049510450202875034]}}
{"id": "b0cffb29-079a-4494-87e3-9b4aa9701dca", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Hybrid Cultural and Differential Evolution Optimizer that combines adaptive velocity control with differential mutation and crossover for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["6abaf91c-ee12-4fe8-89eb-eec385585efa"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "04ab0540-403d-4171-a456-648280d9b89b", "fitness": 0.05373048700940222, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced elite influence by increasing its impact on velocity updates for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.3 * elite_influence  # Increased elite influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05373 with standard deviation 0.00269.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05739043779265984, 0.05655488246967, 0.057945353386627985, 0.05299209699228291, 0.05222823361783446, 0.05349464699831141, 0.05107399636525034, 0.050339338863328975, 0.051555396598654046]}}
{"id": "32fc68e5-82f1-4365-8cdf-8ef8638a5bdd", "fitness": 0.055846233154449004, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic strategy adaptation using feedback from belief space for improved convergence speed and accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff_initial = 1.5\n        self.cognitive_coeff_final = 2.0\n        self.social_coeff_initial = 2.5\n        self.social_coeff_final = 1.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            cognitive_coeff = self.cognitive_coeff_final + (self.cognitive_coeff_initial - self.cognitive_coeff_final) * (1 - eval_count / self.budget)\n            social_coeff = self.social_coeff_final + (self.social_coeff_initial - self.social_coeff_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_component + social_component\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05585 with standard deviation 0.00299.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.058547371078745525, 0.06131103042397912, 0.058840043133637665, 0.05405005004278807, 0.056579945513499985, 0.05431915180741409, 0.05209157900976713, 0.054525970380288835, 0.05235095699992065]}}
{"id": "6468e2d8-4523-4e25-9092-ac57a4b42883", "fitness": 0.055392439070057815, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with increased cognitive coefficient for improved personal exploration.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.7  # Changed from 1.5 to 1.7 for better personal exploration\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05539 with standard deviation 0.00311.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05682724924041427, 0.06042970057256236, 0.05998151580222644, 0.0524782217901798, 0.05577665926229369, 0.05535707709570348, 0.05058017099963197, 0.05375437021913421, 0.05334698664837412]}}
{"id": "bb778bd4-3873-42a9-aa61-4e6161dda2c7", "fitness": 0.05602331251016184, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "An Enhanced Hybrid Cultural and Differential Evolution Optimizer that integrates adaptive learning factors and self-adaptive mutation mechanisms for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff_initial = 1.5\n        self.social_coeff_initial = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_learning_rate = 0.05\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            cognitive_coeff = self.cognitive_coeff_initial + self.adaptive_learning_rate * (1 - eval_count / self.budget)\n            social_coeff = self.social_coeff_initial + self.adaptive_learning_rate * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_initial * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05602 with standard deviation 0.00395.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06309398509412856, 0.06042970057256236, 0.05576945657286214, 0.05818536728152701, 0.05577665926229369, 0.05150207699265219, 0.05606044796290666, 0.05375437021913421, 0.04963774863338977]}}
{"id": "256feb9c-7d8d-46f4-ab62-908c70d26f7b", "fitness": 0.054825227221073795, "name": "EnhancedAdaptiveCulturalDEOptimizer", "description": "Enhanced Adaptive Cultural Differential Evolution Optimizer that integrates multi-swarm coordination and adaptive learning to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 10\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.2\n        self.mutation_factor = 0.85\n        self.crossover_rate = 0.95\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        sub_swarm_count = 3\n        \n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n\n                # Multi-swarm coordination\n                if np.random.rand() < 0.05:\n                    sub_swarm_indices = np.random.choice(current_population_size, sub_swarm_count, replace=False)\n                    sub_swarm_best = np.min(personal_best_scores[sub_swarm_indices])\n                    if sub_swarm_best < personal_best_scores[i]:\n                        velocities[i] += 0.1 * (personal_best_positions[sub_swarm_indices[0]] - pop[i])\n                \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveCulturalDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05483 with standard deviation 0.00299.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.057449964086488836, 0.06043074968282003, 0.05752874495588267, 0.0530486339031937, 0.05577573133083513, 0.05311734376101118, 0.05112919737256527, 0.05375273750470233, 0.051193942392165015]}}
{"id": "63d9d56d-c6c3-4022-8e35-3b926cb8b73e", "fitness": 0.055213906981541355, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer that introduces adaptive mutation and crossover strategies and incorporates a diversity preservation mechanism for improved solution quality and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 60\n        self.final_population_size = 25\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.inertia_weight_initial = 0.8\n        self.inertia_weight_final = 0.3\n        self.elite_fraction = 0.15\n        self.mutation_factor_initial = 0.5\n        self.mutation_factor_final = 1.2\n        self.crossover_rate_initial = 0.7\n        self.crossover_rate_final = 0.95\n        self.diversity_threshold = 0.2\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            diversity_measure = np.mean(np.std(pop, axis=0))\n            if diversity_measure < self.diversity_threshold:\n                random_positions = np.random.uniform(func.bounds.lb, func.bounds.ub, (current_population_size, self.dim))\n                pop = np.concatenate((pop, random_positions), axis=0)\n                current_population_size *= 2\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05521 with standard deviation 0.00316.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06131280434345132, 0.05735451082380516, 0.05800821392927358, 0.05656592828906937, 0.052961845367947125, 0.053554999216789634, 0.05450636878123738, 0.0510458992579399, 0.05161459282435876]}}
{"id": "15151b8c-e30d-4b2e-ae80-792d56088bc6", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDEOptimizer", "description": "An Enhanced Hybrid Cultural and Differential Evolution Optimizer improving exploration and exploitation balance by incorporating adaptive learning and self-adaptive parameters for velocity and mutation.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.3\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) *\n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n\n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Differential Evolution Mutation and Crossover with self-adaptive mutation factor\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedHybridCulturalDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "5298d815-d0cb-4097-be4d-8e5dab82f6ad", "fitness": 0.05424021442178781, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced hybrid optimizer leveraging adaptive learning mechanisms in both belief space and parameter adjustments for improved convergence speed and quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover with Adaptive Mutation Factor\n                if np.random.rand() < 0.5:\n                    self.mutation_factor = np.random.uniform(0.5, 1.0)  # Adaptive mutation factor\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05424 with standard deviation 0.00295.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05932445191855107, 0.0581432561462365, 0.056076264071000304, 0.05475501904805502, 0.053684632900544815, 0.05177372446744166, 0.05276739055989821, 0.05174170375195175, 0.04989548693241097]}}
{"id": "3c8d09ec-2e92-44dc-97c7-d6c7c1d722c9", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer with adaptive learning rates and dynamic population scaling for improved convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.1\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n            \n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, self.learning_rate, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "43767423-39b1-4290-aa29-d2aa3004f334", "fitness": 0.05593406029098675, "name": "EnhancedHybridOptimizer", "description": "Enhanced Hybrid Optimizer using Self-Adaptive Learning and Multi-Modal Search to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.learning_rate = 0.1\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        success_rates = np.zeros(self.initial_population_size)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                    success_rates[i] += 1\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            success_rates /= np.sum(success_rates) + 1e-9  # Normalize success rates\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_component + social_component\n                velocities[i] *= (1 + self.learning_rate * (success_rates[i] - 0.5))  # Adaptive learning\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05593 with standard deviation 0.00303.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06078611090955177, 0.06042970057256236, 0.0577958333034132, 0.056080939947389274, 0.05577665926229369, 0.053341966655524375, 0.05403865872520375, 0.05375437021913421, 0.051402303023808105]}}
{"id": "64a60cb1-9a0d-4839-b994-ec60968b1798", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer by introducing a dynamic mutation factor for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8  # Changed\n        self.mutation_factor_final = 0.3    # New\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)  # New dynamic mutation factor\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "db1775a9-5859-435a-ab20-6ef4a10de99d", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Incorporate a dynamic mutation factor adjustment based on current progress to enhance convergence efficiency.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.mutation_factor = 0.8 * (1 - eval_count / self.budget) # Dynamic mutation factor\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "1298ca8d-671c-4062-9ee4-464a71f90e0c", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced strategy by fine-tuning the elite influence factor for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence  # Slight adjustment to elite influence factor.\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "40e3b410-f182-457e-a809-843340e3af1d", "fitness": 0.05289022552934982, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive elite influence and a dynamic mutation strategy to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.3\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += np.clip(0.1 * elite_influence, -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05289 with standard deviation 0.00314.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05887763307067451, 0.05602915902849659, 0.054296948941466416, 0.054342452831545596, 0.05174512056578362, 0.05014700194294419, 0.05236899435939424, 0.049873726769472326, 0.048330992254370875]}}
{"id": "73143c83-0482-453e-8572-c9d20298189d", "fitness": 0.055037326096596756, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive multi-population strategy to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 60\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.9\n        self.mutation_factor_final = 0.5\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.6\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05504 with standard deviation 0.00275.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05837997300235631, 0.05834571842711189, 0.05936965287828111, 0.05390046286551453, 0.05386768111687923, 0.05479759386279015, 0.05194906028865853, 0.05191694566060412, 0.0528088467671749]}}
{"id": "5b00d590-d766-415d-9a4e-b30ac564fb81", "fitness": 0.05254309697448705, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic mutation-crossover balancing and adaptive elite influence for superior convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_init = 0.8\n        self.crossover_rate_init = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_init * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_init * (eval_count / self.budget)\n            elite_factor = 0.1 + 0.9 * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += elite_factor * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Dynamic Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05254 with standard deviation 0.00280.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.054429891646150086, 0.0571639214959172, 0.05648489318012684, 0.050270026037985804, 0.05278543983932227, 0.05215845989231749, 0.04844991795126019, 0.050875387518367954, 0.050269935208935634]}}
{"id": "e4ac62b1-2e7f-46c6-bb74-7ab2cf0547f6", "fitness": 0.05347334242830377, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive elite influence and dynamic dimensional adjustments for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_elite_influence_factor = 0.5\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            adaptive_elite_influence = self.adaptive_elite_influence_factor * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    adaptive_elite_influence = self.adaptive_elite_influence_factor * (1 - eval_count / self.budget)\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += adaptive_elite_influence * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05347 with standard deviation 0.00288.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05819010383534706, 0.057591987284621005, 0.05528133615101749, 0.05372785823208093, 0.05317818179157063, 0.05105120636889948, 0.051783450937595066, 0.051253654162071394, 0.04920230309153084]}}
{"id": "3d04ea06-2cce-4379-8cdc-a9e51326ce92", "fitness": 0.05397359726293286, "name": "EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Adaptive Cultural Differential Evolution Optimizer with dynamic population sizing and oscillatory mutation rates to improve convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 60\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 2.3\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.3\n        self.elite_fraction = 0.1\n        self.mutation_factor_min = 0.5\n        self.mutation_factor_max = 0.9\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_min + (self.mutation_factor_max - self.mutation_factor_min) * np.sin(2 * np.pi * eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05397 with standard deviation 0.00319.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.0549601816780283, 0.05836894518808622, 0.05936965287828111, 0.05075167688225157, 0.053874998120272743, 0.05479759386279015, 0.04891188062915741, 0.05191859936035337, 0.0528088467671749]}}
{"id": "f3a9c829-2f3c-46d3-bdb9-4f112dbc06da", "fitness": 0.05403997634593981, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer incorporates adaptive velocity scaling and dynamic mutation to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_min = 0.5\n        self.mutation_factor_max = 1.0\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                # Dynamic Mutation Factor\n                mutation_factor = self.mutation_factor_min + (self.mutation_factor_max - self.mutation_factor_min) * (1 - eval_count / self.budget)\n                \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                # Adaptive Velocity Scaling\n                adaptive_scaling = np.random.normal(0, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] * adaptive_scaling\n                \n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05404 with standard deviation 0.00287.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05854070464998451, 0.058348025029446804, 0.055996721900188784, 0.05404241469621407, 0.0538711903785557, 0.05171358180774288, 0.05208362149818491, 0.05192086892569425, 0.04984265822744638]}}
{"id": "0e03096d-5515-4f7d-b98f-eb9e85b735a4", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Improved Hybrid Cultural and Differential Evolution Optimizer using adaptive learning rates and diversity preservation for enhanced convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.learning_rate_adaptation = 0.01\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Learning Rate for Mutation\n                learning_factor = 1.0 + self.learning_rate_adaptation * eval_count / self.budget\n                adaptive_mutation_factor = self.mutation_factor * learning_factor\n                \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + adaptive_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "990db3f0-1f08-498d-a455-d9bd42eba000", "fitness": 0.05471187259803546, "name": "EnhancedCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Cultural Differential Evolution Optimizer with Adaptive Elite Influence and Noise Control for Improved Exploration and Convergence.", "code": "import numpy as np\n\nclass EnhancedCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.noise_decay_factor = 0.995  # Decay factor for noise reduction\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        noise_std = 0.1  # Initial noise standard deviation\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n\n                # Adaptive noise control\n                noise = np.random.normal(0, noise_std, self.dim)\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n            # Decay noise over time\n            noise_std *= self.noise_decay_factor\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05471 with standard deviation 0.00417.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05949560663197884, 0.06184435981993497, 0.05375030643032508, 0.05488908274955295, 0.0570619119575726, 0.04964431015936088, 0.05288759242086716, 0.054987305420256094, 0.047846377792470585]}}
{"id": "5203856f-6cc6-430a-9e1e-37031bd854b4", "fitness": 0.05637238967565453, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic adaptation of cognitive and social coefficients, and improved diversity maintenance through adaptive mutation strategies.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff_initial = 1.0\n        self.cognitive_coeff_final = 2.0\n        self.social_coeff_initial = 2.0\n        self.social_coeff_final = 3.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.5\n        self.mutation_factor_final = 1.0\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            cognitive_coeff = self.cognitive_coeff_final + (self.cognitive_coeff_initial - self.cognitive_coeff_final) * (eval_count / self.budget)\n            social_coeff = self.social_coeff_final + (self.social_coeff_initial - self.social_coeff_final) * (eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Enhanced Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05637 with standard deviation 0.00303.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05844999750016355, 0.06042970057256236, 0.06153901462369604, 0.05396270368594902, 0.05577665926229369, 0.05675267653429594, 0.0520082288113789, 0.05375437021913421, 0.054678155871417]}}
{"id": "d93881de-eb2d-40d4-87bb-7502a85cf2b1", "fitness": 0.05438492361594043, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic elite influence and adaptive mutation for better convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.2\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.2 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05438 with standard deviation 0.00288.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05690581750703294, 0.057521533216893905, 0.059572648055772226, 0.052549993530392025, 0.05311564812374403, 0.05497669823776863, 0.050649174419132637, 0.05119425560015156, 0.05297854385257594]}}
{"id": "bb1ffab4-2ac3-4145-85af-320af61e39ab", "fitness": 0.05480766036719934, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Slightly enhanced exploration by introducing a small stochastic perturbation in the trial vector generation.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector + np.random.normal(0, 0.01, self.dim), pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05481 with standard deviation 0.00287.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.059931240175070344, 0.05774747229325916, 0.05768402132334849, 0.055301595713324825, 0.05332181744208664, 0.05326387058843107, 0.05328985809826903, 0.0513923819910137, 0.051336685679990834]}}
{"id": "c59101b7-06ae-4c54-a3a5-d5895e7c3de3", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer incorporating dynamic adaptive mutation and crossover rates for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.4\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.5\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "ff106d2d-59d9-414b-b39e-53b12cbd7a14", "fitness": 0.0578250423667048, "name": "AdaptiveSwarmCulturalDifferentialOptimizer", "description": "Adaptive Swarm Cultural-Differential Optimizer that integrates dynamic elite influence and adaptive mutation strategies for diverse and efficient search.", "code": "import numpy as np\n\nclass AdaptiveSwarmCulturalDifferentialOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.4\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveSwarmCulturalDifferentialOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "761dd57e-29b1-4110-bf3e-994e5f0309fb", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Introduced a dynamic mutation factor that linearly decreases over time to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.initial_mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.initial_mutation_factor * (1 - eval_count / self.budget)  # Dynamic mutation factor\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "84317434-9aa0-4483-b226-71186fe15cb3", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Introduced adaptive crossover rate based on iteration progress to balance exploration and exploitation.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.5\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "6a518869-988b-4c00-988f-52ea7d6536e7", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced exploration by adjusting the mutation factor dynamically based on progress.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8  # Adjusted dynamically later\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.mutation_factor = 0.8 + (0.2 * (1 - eval_count / self.budget))  # Dynamically adjusting mutation factor\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "137cbdd4-a1bc-4a97-a069-9db1d5b30988", "fitness": 0.0559724038228518, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced velocity update to improve convergence by reducing randomness in velocity updates.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.uniform(0.5, 1.5, self.dim)  # Reduced randomness\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05597 with standard deviation 0.00316.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05743324391300164, 0.06042970057256236, 0.06126031531735876, 0.05303089819563267, 0.05577665926229369, 0.05650820296952208, 0.05111118388890956, 0.05375437021913421, 0.054447060067251196]}}
{"id": "b722da72-815f-4c20-833f-5117de0fc418", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Hybrid Cultural and Differential Evolution Optimizer with enhanced elite influence for improved exploitation.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence  # Slightly increase elite influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "b0410c30-10bb-4c34-a5c5-4c29108077f1", "fitness": 0.0558386818631703, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer with self-adaptive parameters to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.adaptive_rate = 0.05  # New adaptive rate parameter\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            # Self-adaptive parameter adjustment\n            self.mutation_factor = np.clip(self.mutation_factor + np.random.uniform(-self.adaptive_rate, self.adaptive_rate), 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + np.random.uniform(-self.adaptive_rate, self.adaptive_rate), 0.7, 1.0)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05584 with standard deviation 0.00281.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.059091701408923725, 0.05919271625128819, 0.06038853472396932, 0.054550116548354954, 0.054645245144974264, 0.055731862208397764, 0.05257346609196367, 0.05266602795527664, 0.05370846643538418]}}
{"id": "7d8ff866-7825-430c-a966-88e1b279e7b4", "fitness": 0.055926460109469875, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer integrates adaptive learning rates and dynamic neighborhood selection for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_learning_rate = 0.01\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        \n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += self.adaptive_learning_rate * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                # Differential Evolution Mutation and Crossover with Dynamic Neighborhood Selection\n                neighborhood_size = np.random.randint(1, current_population_size//2 + 1)\n                indices = np.random.choice(current_population_size, neighborhood_size + 2, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05593 with standard deviation 0.00312.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.061746943089626916, 0.05921919720614277, 0.05801237231056655, 0.05696428989575386, 0.05466417800792678, 0.05355109718393958, 0.05489014353991439, 0.05268216463398101, 0.05160775511737703]}}
{"id": "988b2c6d-5685-4a2f-84b0-7062e8da3871", "fitness": 0.052867685596099806, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer by integrating adaptive mutation and diversity preservation strategies for improved exploration and convergence. ", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.2\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.4\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                diversity_preserve = np.random.uniform(-0.1, 0.1, self.dim)\n                new_position = pop[i] + velocities[i] + noise + diversity_preserve\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05287 with standard deviation 0.00313.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05821623120469921, 0.05708678952913049, 0.05383005786111539, 0.0537399177900485, 0.05271519678138037, 0.04971255551938514, 0.05179035098395268, 0.050807939639670674, 0.04791013105551578]}}
{"id": "16342f42-d649-4972-82d3-de519b045655", "fitness": 0.05432096255066462, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive elite influence and self-adaptive parameters for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_component + social_component\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    adaptive_influence = 0.1 + 0.1 * np.exp(-0.1 * eval_count / self.budget)\n                    velocities[i] += adaptive_influence * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05432 with standard deviation 0.00280.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05675579328926328, 0.05899063178337838, 0.058040496239368466, 0.05241265888332336, 0.054461672711014764, 0.053581528736995176, 0.05051702321687401, 0.05248994276108354, 0.05163891533468057]}}
{"id": "37d1470c-427a-442e-bcf9-2ae662f3b165", "fitness": 0.055121714396775094, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer by refining the inertia weight dynamic to improve convergence speed.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - (eval_count / self.budget) ** 2)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05512 with standard deviation 0.00305.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.056802875833679045, 0.06042970057256236, 0.05912977986209689, 0.052455873952925614, 0.05577665926229369, 0.05458308920143118, 0.05055865249113556, 0.05375437021913421, 0.05260442817571731]}}
{"id": "699e2a13-26bd-4b0f-a65e-e9edf0c488a7", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with Adaptive Mutation and Crossover Rates for Improved Convergence and Robustness.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.crossover_rate_initial = 0.9\n        self.mutation_factor_final = 0.3\n        self.crossover_rate_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n\n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Differential Evolution Mutation and Crossover with adaptive rates\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "f6f3ac0e-5142-4aa2-b4ab-6f23d4a75f91", "fitness": 0.05332139020953514, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive mutation factor adjustment for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Updated mutation factor\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05332 with standard deviation 0.00342.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05518771225951802, 0.060193598591277375, 0.055207439807887004, 0.05096218236672867, 0.055558500081723805, 0.05098498472171187, 0.049115313355713286, 0.05354364949099011, 0.04913913121026614]}}
{"id": "9c6c2ef8-5d79-42e4-80ef-ea6c1a8aea8d", "fitness": 0.051996605282813614, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive mutation and improved elite influence mechanisms for better convergence and diversity.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                adaptive_noise = np.random.normal(0, 0.1 * (1 - eval_count / self.budget), self.dim)\n\n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                adaptive_mutation_factor = self.mutation_factor * (1 + np.random.randn() * 0.1)\n                mutant_vector = a + adaptive_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n\n                new_position = pop[i] + velocities[i] + adaptive_noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05200 with standard deviation 0.00280.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.053716326061599595, 0.056539907750257745, 0.056070780886762095, 0.04961171067503933, 0.05221447553690761, 0.051775640734461614, 0.04781442298951755, 0.050326080320799216, 0.04990010258997779]}}
{"id": "262e5e66-4469-4b1c-9403-03fcc93d5abd", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic adaptation of mutation factor and crossover rate for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8  # renamed for clarity\n        self.crossover_rate_initial = 0.9  # renamed for clarity\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_initial - 0.5 * (eval_count / self.budget)  # dynamic adaptation\n            crossover_rate = self.crossover_rate_initial - 0.3 * (eval_count / self.budget)  # dynamic adaptation\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "18381579-6679-4117-b139-bb528238c1af", "fitness": 0.05445768965748153, "name": "AdaptiveMemeticHybridOptimizer", "description": "Adaptive Memetic Hybrid Optimizer integrates local search and adaptive memory strategies into the cultural and differential evolution framework for improved convergence and exploration.", "code": "import numpy as np\n\nclass AdaptiveMemeticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.local_search_prob = 0.1  # Probability to apply local search\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_component + social_component\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                # Adaptive local search\n                if np.random.rand() < self.local_search_prob:\n                    trial_vector = self.local_search(trial_vector, func)\n                \n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score\n\n    def local_search(self, position, func):\n        step_size = 0.1 * (func.bounds.ub - func.bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_position = position + perturbation\n        new_position = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        return new_position if func(new_position) < func(position) else position", "configspace": "", "generation": 55, "feedback": "The algorithm AdaptiveMemeticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05446 with standard deviation 0.00363.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05538265272601939, 0.06163765532319587, 0.05725118119085082, 0.05115007115917025, 0.056837659744941926, 0.05285872970239669, 0.049299877140207005, 0.054758087178888304, 0.05094329275166354]}}
{"id": "332bd685-30e1-4836-8ab4-0790515ab146", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with dynamic diversity control and adaptive adjustment of exploration-exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.diversity_control_factor = 0.5\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            population_diversity = np.std(pop, axis=0).mean()\n            exploration_exploitation_factor = max(0.1, min(1.0, population_diversity * self.diversity_control_factor))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component) * exploration_exploitation_factor\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "644ee679-c5a2-4b49-b896-13003ad25a39", "fitness": 0.05438492361594043, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with improved elite influence for better convergence. ", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.2 * elite_influence  # Increased the elite influence factor from 0.1 to 0.2\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05438 with standard deviation 0.00288.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05690581750703294, 0.057521533216893905, 0.059572648055772226, 0.052549993530392025, 0.05311564812374403, 0.05497669823776863, 0.050649174419132637, 0.05119425560015156, 0.05297854385257594]}}
{"id": "5b3b9b23-34d6-4efd-8dda-5fda4f1794e2", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Introduce a small dynamic adjustment to the mutation factor to enhance diversity and convergence balance.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                # Adjust mutation factor dynamically\n                dynamic_mutation_factor = self.mutation_factor * (1 - eval_count / self.budget)\n                mutant_vector = a + dynamic_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "ec89ca1e-2735-44f5-9ea8-7447758b4513", "fitness": 0.054959726859785465, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer using adaptive population rescaling and covariance matrix adaptation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.min_population_size = 10\n        self.max_population_size = 100\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = self.min_population_size + int(\n                np.ceil(np.log(eval_count + 1) / np.log(self.budget + 1) * (self.max_population_size - self.min_population_size))\n            )\n            current_population_size = min(current_population_size, self.initial_population_size)\n            inertia_weight = self.inertia_weight_final + \\\n                (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n\n                # Differential Evolution Mutation and Crossover using Covariance Matrix\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                cov_matrix = np.cov(np.array([a, b, c]), rowvar=False)\n                mutant_vector = np.random.multivariate_normal(a + self.mutation_factor * (b - c), cov_matrix)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n\n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05496 with standard deviation 0.00278.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.057861500654449616, 0.059468255778022505, 0.05852696169499971, 0.0534157186411689, 0.05488745945541218, 0.05403091298915286, 0.051478587594891545, 0.05289517417518119, 0.05207297075479067]}}
{"id": "7aeedcc9-73b7-49ce-a1af-d2ac8cbf7079", "fitness": 0.047324772829950706, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Improved adaptive inertia weight update strategy in the hybrid optimization algorithm for better convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (global_best_score / np.max(personal_best_scores))\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04732 with standard deviation 0.00385.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.048499918186044044, 0.05508451612227705, 0.04800749252857317, 0.044711530032826685, 0.05079617106098322, 0.04425357658903284, 0.04304520603201456, 0.04892289634070357, 0.04260164857710125]}}
{"id": "436c8adf-9ad3-4b10-a880-060bcf9d0336", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced the mutation mechanism by adjusting the mutation factor dynamically based on convergence, improving exploration and exploitation balance in the search process.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.mutation_factor = 0.8 - 0.6 * (eval_count / self.budget)  # Change: Dynamic mutation factor adjustment\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "0f0b9314-abcf-459d-be92-8edc3dbd8e07", "fitness": 0.05445761193330451, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Slightly adjusted the inertia weight calculation for better convergence handling.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (0.5 * (1 - eval_count / self.budget))\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05446 with standard deviation 0.00321.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05733726330801536, 0.06066605581189144, 0.0562274049107484, 0.05294578046440901, 0.05599225568481747, 0.051919355878559004, 0.0510303511080521, 0.05396152899915385, 0.050038511234093974]}}
{"id": "89e5033f-635c-4548-88c0-584804e68cf6", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced adaptive elite influence to boost local exploitation and improve convergence speed.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence  # Changed from 0.1 to 0.15\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "238c0a00-e62e-441f-a84c-35098cee9297", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer integrating dynamic inertia weight adjustment and adaptive mutation control for heightened convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.4\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover with adaptive mutation factor\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "c9704c21-f93f-4b39-8402-788f3dc1b677", "fitness": 0.0578250423667048, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced exploration-exploitation balance by adjusting mutation factor dynamically based on evaluation count.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                # Adjust mutation factor dynamically\n                dynamic_mutation_factor = self.mutation_factor * (1 - eval_count / self.budget)\n                mutant_vector = a + dynamic_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "9ff8719a-3161-4097-a3fe-9753780f00c6", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with diversity preservation through dynamic boundary shrinkage and adaptive inertia for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.diversity_preservation_factor = 0.05  # New parameter for boundary shrinkage\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            # Dynamic boundary shrinkage for diversity preservation\n            shrinkage_factor = 1 - (eval_count / self.budget) * self.diversity_preservation_factor\n            self.belief_space['normative'][0] = func.bounds.lb + shrinkage_factor * (self.belief_space['normative'][0] - func.bounds.lb)\n            self.belief_space['normative'][1] = func.bounds.ub - shrinkage_factor * (func.bounds.ub - self.belief_space['normative'][1])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "f3224ecc-1a12-43a4-a5f1-052cde9797a9", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with Adaptive Mutation Scaling and Dynamic Elite Strategy for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "137858f1-3c5a-4be7-b387-6735858e3444", "fitness": 0.049626184014862434, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive population resizing and elite-guided mutation for improved exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 10\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.2\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = trial_vector + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04963 with standard deviation 0.00320.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.051542289418237575, 0.05602915902849659, 0.051168830083223815, 0.04760406155834407, 0.05174512056578362, 0.04725715903721617, 0.045875571372371526, 0.049873726769472326, 0.045539738300616195]}}
{"id": "350a4ca8-2886-4489-8a72-3ac442313534", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive population resizing and dynamic belief space adjustment for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "ecd92b3d-4e70-4e1a-8afc-f5be5ee3045e", "fitness": 0.05336967622650673, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive population size and elite-guided mutation strategies to boost convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.2 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Elite-guided Differential Evolution Mutation and Crossover\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(elite_size, 2, replace=False)\n                    a, b = elite_positions[indices[0]], elite_positions[indices[1]]\n                    c = pop[np.random.choice(current_population_size)]\n                else:\n                    indices = np.random.choice(current_population_size, 3, replace=False)\n                    a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                \n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05337 with standard deviation 0.00309.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.059295537700085554, 0.05628486693156687, 0.055170174191985, 0.05472938575354391, 0.05198007118004322, 0.05093672983337605, 0.05274306016473529, 0.050100153578788165, 0.0490871067044365]}}
{"id": "555e8a3d-f4ac-4b15-ba07-b0d22dd8eebd", "fitness": 0.05438492361594043, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive elite influence for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.2 * elite_influence  # Adjusted elite influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05438 with standard deviation 0.00288.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05690581750703294, 0.057521533216893905, 0.059572648055772226, 0.052549993530392025, 0.05311564812374403, 0.05497669823776863, 0.050649174419132637, 0.05119425560015156, 0.05297854385257594]}}
{"id": "12fb0046-b26e-4809-bfef-e4d28c723a27", "fitness": 0.056048377362812235, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "The enhanced optimizer incorporates adaptive learning to dynamically adjust cognitive and social coefficients based on performance trends, improving convergence speed and precision.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n\n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.cognitive_coeff = 1.5 + np.tanh((global_best_score - personal_best_scores[i]) / 10)  # Adaptive learning adjustment\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05605 with standard deviation 0.00284.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06007712489212502, 0.06042970057256236, 0.058840043133637665, 0.05544951599634196, 0.05577665926229369, 0.05431915180741409, 0.05343787338188044, 0.05375437021913421, 0.05235095699992065]}}
{"id": "0754ac2e-f7eb-448c-92e7-f348fe02d264", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer with dynamic parameter adaptation and elite-guided mutation for improved convergence and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.6\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover with dynamic parameters\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "752acfaa-68bb-48d3-9058-5b323ed65ed6", "fitness": 0.05582341155135495, "name": "EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Adaptive Cultural Differential Evolution Optimizer that incorporates dynamic elitism, adaptive crossover rates, and stochastic learning to improve convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction_initial = 0.1\n        self.elite_fraction_final = 0.05\n        self.mutation_factor = 0.8\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.6\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            elite_fraction = self.elite_fraction_final + (self.elite_fraction_initial - self.elite_fraction_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05582 with standard deviation 0.00299.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05777068522462803, 0.06042970057256236, 0.06042966703509289, 0.05334327658166038, 0.05577665926229369, 0.05576056484322889, 0.051413133381812415, 0.05375437021913421, 0.053732646841781695]}}
{"id": "995b9839-75e2-4f9d-bd84-94b596dddd2d", "fitness": 0.05398872935437013, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Improved balance between exploration and exploitation by adjusting the cognitive and social coefficients dynamically based on progress.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adjust cognitive and social coefficients dynamically\n                dynamic_cognitive_coeff = self.cognitive_coeff * (1 - eval_count / self.budget)\n                dynamic_social_coeff = self.social_coeff * (eval_count / self.budget)\n                cognitive_component = dynamic_cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = dynamic_social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05399 with standard deviation 0.00273.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05768349932880468, 0.05836299007157475, 0.05667828399571617, 0.05325692246978775, 0.05388216073043817, 0.05233596692147502, 0.051327446472077765, 0.05193035999748996, 0.050440934201966936]}}
{"id": "ea2896a5-5863-4c7d-ae9c-ac3ed9a56841", "fitness": 0.0578250423667048, "name": "EnhancedCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Evolutionary Cultural Algorithm that incorporates adaptive mutation strategies and elite exploration to balance diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                adaptive_mutation_factor = self.mutation_factor + 0.2 * (1 - eval_count / self.budget)\n                mutant_vector = a + adaptive_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "44ec70bc-ef6a-46b9-bcc2-39c9b4bea1c8", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced strategic balance between exploration and exploitation by slightly increasing the elite influence on velocities.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence  # Changed from 0.1 to 0.15\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "2cdda479-6f89-4c95-a27a-1d7db7f4e2c2", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "\"Enhanced Hybrid Cultural Differential Evolution Optimizer with Adaptive Elite Crossover and Dynamic Mutation for Improved Convergence and Exploration.\"", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "cda0ac9e-fd7b-423c-a961-5b6b0168f60d", "fitness": 0.050804669453586714, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer using adaptive learning rates and self-adaptive mutation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.01\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        adaptive_mutation = np.full(self.initial_population_size, self.mutation_factor)\n        \n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Self-adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                adaptive_mutation[i] *= (1 + self.learning_rate * (np.random.rand() - 0.5))\n                mutant_vector = a + adaptive_mutation[i] * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                # Update position with velocity and noise\n                new_position = trial_vector + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05080 with standard deviation 0.00318.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05525946225659706, 0.05602915902849659, 0.051234570436507476, 0.05101617834879357, 0.05174512056578362, 0.04731996624586077, 0.0491626029321971, 0.049873726769472326, 0.045601238498571894]}}
{"id": "805b9c15-f966-4cc7-b046-75efcec06d80", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer with adaptive population dynamics and crossover strategy for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.9\n        self.mutation_factor_final = 0.5\n        self.crossover_rate_initial = 0.95\n        self.crossover_rate_final = 0.7\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_initial + (self.mutation_factor_final - self.mutation_factor_initial) * (eval_count / self.budget)\n            crossover_rate = self.crossover_rate_initial + (self.crossover_rate_final - self.crossover_rate_initial) * (eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "1122761e-aeee-4ed5-9812-7a786c3c9646", "fitness": 0.0552334745901076, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive elite influence adjustment and dynamic mutation for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += (0.1 * elite_influence * (1 - eval_count / self.budget))\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05523 with standard deviation 0.00315.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05684331036653856, 0.06103938368247108, 0.058840043133637665, 0.052492998323412476, 0.056332570393821446, 0.05431915180741409, 0.05059441900236539, 0.05428843760138702, 0.05235095699992065]}}
{"id": "e2245455-4b59-4262-94a0-e20701628883", "fitness": 0.05537242879384238, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Slightly enhance exploration by reducing inertia weight more aggressively in the Hybrid Cultural and Differential Evolution Optimizer.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.2  # Changed from 0.4 to 0.2\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05537 with standard deviation 0.00319.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05675579328926328, 0.06108267064986095, 0.059332738553263153, 0.05241265888332336, 0.05637200268393172, 0.05476912730273664, 0.05051702321687401, 0.05432630606209354, 0.052783538503234806]}}
{"id": "81c951ad-6ade-491c-8bf9-cf346437f40c", "fitness": 0.05438492361594043, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced a component of the Hybrid Cultural and Differential Evolution Optimizer to improve exploration by increasing the elite influence in the velocity update.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.2 * elite_influence  # Increased elite influence from 0.1 to 0.2\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05438 with standard deviation 0.00288.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05690581750703294, 0.057521533216893905, 0.059572648055772226, 0.052549993530392025, 0.05311564812374403, 0.05497669823776863, 0.050649174419132637, 0.05119425560015156, 0.05297854385257594]}}
{"id": "c29e579b-c34a-4400-bf7e-27306ab13ef1", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive mutation and dynamic crossover for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.3\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.6\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n\n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "d2ccf5b5-90ff-439f-8a52-cbbdaeef9e4b", "fitness": 0.05776616614827495, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced velocity update by introducing elite influence into all particles for better convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                # Apply elite influence to all particles\n                elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                velocities[i] += 0.1 * elite_influence\n                velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05777 with standard deviation 0.00357.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.061957481446686, 0.05870108589450085, 0.059243429196117914, 0.057165542194466346, 0.05418368453398248, 0.0570723335923643, 0.05508707053295869, 0.052217339825853304]}}
{"id": "a8d7afa0-d2ad-4002-b446-8aeb013b0c43", "fitness": 0.05530249145703489, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Refined Hybrid Cultural and Differential Evolution Optimizer with modified elite influence weight for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.05 * elite_influence  # Modified elite influence weight\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05530 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05675579328926328, 0.06042970057256236, 0.05975974651388538, 0.05241265888332336, 0.05577665926229369, 0.05515864880415666, 0.05051702321687401, 0.05375437021913421, 0.053157822351821093]}}
{"id": "be00e5e7-2c32-40d7-bc3f-daaace2264d4", "fitness": 0.05284517816001845, "name": "AdaptiveHybridCulturalDifferentialEvolutionOptimizer", "description": "Adaptive Hybrid Cultural Differential Evolution with Chaos Optimization to Improve Exploration and Exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.chaos_factor = 0.5  # Introduce chaos factor\n\n    def chaos_map(self, x):\n        return self.chaos_factor * x * (1 - x)\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        chaos_values = np.random.rand(self.initial_population_size)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise + self.chaos_map(chaos_values[i])\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n                chaos_values[i] = self.chaos_map(chaos_values[i])\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm AdaptiveHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05285 with standard deviation 0.00318.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05429122540398379, 0.05900904012004249, 0.05575117803024121, 0.05014109135194367, 0.054477018240987274, 0.05148572443764532, 0.04832504678012228, 0.052504117535609685, 0.049622161539590315]}}
{"id": "7d1c3b30-8989-4e7d-ae7c-e6edaae584c2", "fitness": 0.054407515292163984, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive learning rates and elite-guided search for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.2\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate_decay = 0.995\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        \n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover with learning rate decay\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise * self.learning_rate_decay\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05441 with standard deviation 0.00373.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05798595742295709, 0.06144639695831766, 0.05464581740782848, 0.05353753856703647, 0.05670363106110354, 0.05046626816468602, 0.05159896631395555, 0.05464489635070946, 0.04863816538288157]}}
{"id": "8b412d34-d6b6-441c-a6c1-ff4b6661c4c7", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer utilizing adaptive mutation factor and dynamic crossover rates for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.9\n        self.mutation_factor_final = 0.6\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.4\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            crossover_rate = self.crossover_rate_final + (self.crossover_rate_initial - self.crossover_rate_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "523ff461-c8d5-417c-ac25-72105169008c", "fitness": 0.05567778654370857, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced exploration by introducing Gaussian noise to perturb velocities for improved solution diversity.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i] + np.random.normal(0, 0.05, self.dim), -1, 1)  # (Modified Line)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05568 with standard deviation 0.00326.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05997477377957172, 0.056836328447004925, 0.06135322102066065, 0.05535321504164881, 0.052486794403933446, 0.05661066099845502, 0.05334415566423234, 0.050588504010880775, 0.05455242552698947]}}
{"id": "fad4b5d6-10f1-4c81-8634-03972724d655", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer with adaptive mutation factor and elite influence for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 1.2\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            mutation_factor = self.mutation_factor_final + (self.mutation_factor_initial - self.mutation_factor_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "86ce54da-2e49-4812-8280-b3a426de70b5", "fitness": 0.05495273623695626, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced elite influence by adjusting the factor to improve convergence speed.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.15 * elite_influence  # Increased elite influence factor\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00310.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05752174661528442, 0.060907236133900144, 0.05739603633395418, 0.053113760815908906, 0.05621212092094752, 0.052990106841342755, 0.051191638104254866, 0.054172737836003626, 0.05106924253100997]}}
{"id": "bb9541bf-1a40-4ded-b066-13b4955de884", "fitness": 0.056269684927530164, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "An enhanced Hybrid Cultural and Differential Evolution Optimizer that incorporates adaptive learning rates and a dynamic elite strategy to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        self.adaptive_learning_rate = 0.1\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            self.cognitive_coeff = max(0.5, self.cognitive_coeff - self.adaptive_learning_rate * len(elite_positions)/self.initial_population_size)\n            self.social_coeff = min(3.0, self.social_coeff + self.adaptive_learning_rate * len(elite_positions)/self.initial_population_size)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05627 with standard deviation 0.00283.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06041967386403224, 0.06042970057256236, 0.059232207379092516, 0.055751792390839605, 0.05577665926229369, 0.054662797970635335, 0.0537243627204973, 0.05375437021913421, 0.052675599968684206]}}
{"id": "966be9e6-08c8-4806-a076-54e4790f33f7", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural and Differential Evolution Optimizer utilizing adaptive parameter tuning and elite-guided mutation for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            adaptive_mutation_factor = self.mutation_factor * (1 - eval_count / self.budget)\n            adaptive_crossover_rate = self.crossover_rate * (1 + eval_count / (2 * self.budget))\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + adaptive_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < adaptive_crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "327ed2fc-c284-49e5-94b1-c7d26264a604", "fitness": 0.0578250423667048, "name": "EnhancedHybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Hybrid Cultural Differential Evolution Optimizer incorporating adaptive mutation and crossover strategies for improved convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.base_mutation_factor = 0.8\n        self.base_crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Adaptive Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutation_factor = self.base_mutation_factor * (1 - eval_count / self.budget)\n                crossover_rate = self.base_crossover_rate + (1 - self.base_crossover_rate) * (eval_count / self.budget)\n                mutant_vector = a + mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05783 with standard deviation 0.00354.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.06426752811754466, 0.06199998238396631, 0.058840043133637665, 0.059243429196117914, 0.05720572743195973, 0.05431915180741409, 0.0570723335923643, 0.055126228637417896, 0.05235095699992065]}}
{"id": "6fd38de9-4936-40c7-8c94-b60333ac6a04", "fitness": 0.05532375596827867, "name": "EnhancedHybridEvolutionaryOptimizer", "description": "Enhanced Hybrid Evolutionary Optimizer with Adaptive Elite Influence and Dynamic Mutation for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedHybridEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_elite_influence = 0.2  # New parameter for adaptive influence\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    adaptive_influence = self.adaptive_elite_influence * (1 - eval_count / self.budget)\n                    velocities[i] += adaptive_influence * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution with Dynamic Mutation Factor\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                dynamic_mutation_factor = self.mutation_factor * (1 - eval_count / self.budget)\n                mutant_vector = a + dynamic_mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedHybridEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05532 with standard deviation 0.00353.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.056769212705886196, 0.062335876931319256, 0.05791890582851145, 0.052424970988565134, 0.05751281617421089, 0.05347002690691072, 0.05052888155009394, 0.055421568176098335, 0.05153154445291208]}}
{"id": "2f8c6847-b9cf-4762-82e1-59254f5cc364", "fitness": 0.05477121844765419, "name": "HybridCulturalDifferentialEvolutionOptimizer", "description": "Enhanced global exploration by adjusting cognitive and social coefficients for improved convergence.", "code": "import numpy as np\n\nclass HybridCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 2.0  # Modified from 1.5 to 2.0\n        self.social_coeff = 2.5\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                noise = np.random.normal(0, 0.1, self.dim)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i] + noise\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm HybridCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05477 with standard deviation 0.00328.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05675579328926328, 0.06121606785218192, 0.0572684626275316, 0.05241265888332336, 0.0564934899527757, 0.05287515985507407, 0.05051702321687401, 0.054442963244638265, 0.050959347107225494]}}
{"id": "725a1376-7c8e-463e-9067-b281fe5ccaab", "fitness": 0.052202182283046995, "name": "EnhancedCulturalDifferentialEvolutionOptimizer", "description": "Enhanced Cultural and Differential Evolution Optimizer with adaptive belief space and dynamic learning for improved exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedCulturalDifferentialEvolutionOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n        \n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = 0.4 + 0.5 * np.cos(np.pi * eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Differential Evolution Mutation and Crossover\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedCulturalDifferentialEvolutionOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05220 with standard deviation 0.00278.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05560238601551515, 0.057102126707352374, 0.054274715088702075, 0.05135201820659974, 0.052730454365379376, 0.05012760354888146, 0.04949451910410407, 0.050823102518434915, 0.04831271499245382]}}
{"id": "7d280729-5299-46cb-b65d-a7e919a94c00", "fitness": 0.052665760466380086, "name": "EnhancedHybridCulturalDifferentialEvolution", "description": "Enhanced Hybrid Cultural Differential Evolution with Adaptive Elite Influence and Non-Uniform Mutation for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridCulturalDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 60\n        self.final_population_size = 20\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.elite_fraction = 0.15\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.belief_space = {\n            'normative': np.zeros((2, dim)),\n            'situational': np.full(dim, np.inf)\n        }\n\n    def __call__(self, func):\n        eval_count = 0\n        global_best_position = np.full(self.dim, np.inf)\n        global_best_score = np.inf\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n\n        while eval_count < self.budget:\n            current_population_size = int(\n                self.final_population_size + ((self.budget - eval_count) / self.budget) * \n                (self.initial_population_size - self.final_population_size)\n            )\n            inertia_weight = self.inertia_weight_final + (self.inertia_weight_initial - self.inertia_weight_final) * (1 - eval_count / self.budget)\n            \n            for i in range(current_population_size):\n                score = func(pop[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = pop[i].copy()\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = pop[i].copy()\n                    self.belief_space['situational'] = global_best_position\n                \n                if eval_count >= self.budget:\n                    break\n\n            elite_size = int(self.elite_fraction * current_population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n\n            for d in range(self.dim):\n                self.belief_space['normative'][0, d] = np.min(personal_best_positions[:, d])\n                self.belief_space['normative'][1, d] = np.max(personal_best_positions[:, d])\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions[i] - pop[i])\n                social_component = self.social_coeff * r2 * (global_best_position - pop[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                if i not in elite_indices:\n                    elite_influence = np.mean(elite_positions - pop[i], axis=0)\n                    velocities[i] += 0.1 * elite_influence * np.random.rand()\n                    velocities[i] = np.clip(velocities[i], -1, 1)\n                    \n                # Enhanced Differential Evolution Mutation and Crossover with Non-Uniform Mutation\n                indices = np.random.choice(current_population_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant_vector = a + self.mutation_factor * (b - c) * (1 - eval_count / self.budget)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, pop[i])\n                \n                new_position = pop[i] + velocities[i]\n                pop[i] = np.clip(new_position, func.bounds.lb, func.bounds.ub)\n        \n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHybridCulturalDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05267 with standard deviation 0.00273.", "error": "", "parent_ids": ["b0cffb29-079a-4494-87e3-9b4aa9701dca"], "operator": null, "metadata": {"aucs": [0.05539486227572887, 0.05746237903518581, 0.05561216286019177, 0.05116122105383991, 0.05306097320455738, 0.051354243891845175, 0.04931059529907178, 0.05114143831697027, 0.04949396826002983]}}
