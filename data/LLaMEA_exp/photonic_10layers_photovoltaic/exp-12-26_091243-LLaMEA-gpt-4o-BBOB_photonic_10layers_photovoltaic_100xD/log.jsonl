{"id": "41eedf4b-276c-44b1-afe1-7bb7b4ffa794", "fitness": 0.0997303614338809, "name": "HybridPSODE", "description": "A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.047206887032450906, 0.0783940266160007, 0.05038764946739149, 0.16102416007719478, 0.16610614381970956, 0.14110658982313506, 0.0875501129791234, 0.08359028717676364, 0.08220739591315862]}}
{"id": "c15ee751-ffd7-4f33-a06b-8a6fa24cf8e4", "fitness": 0.09934568590684914, "name": "HybridPSODE", "description": "A hybrid particle swarm algorithm integrating adaptive velocity control and dynamic differential evolution to enhance convergence speed and precision in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9 # Maximum inertia weight\n        self.w_min = 0.4 # Minimum inertia weight\n        self.w = self.w_max\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.evals = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals += self.population_size\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        \n        while self.evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (self.evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F * (1 - (self.evals / self.budget))  # Dynamic scaling factor\n                mutant = x0 + F_dynamic * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                self.evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09935 with standard deviation 0.04176.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.05454504831393747, 0.08590632687284516, 0.06069570897748966, 0.15478908136955594, 0.16610614381970956, 0.14858979733784428, 0.08594193586186327, 0.0711158972474003, 0.06642123336099659]}}
{"id": "6430f733-46bf-462e-9536-43d77f4db825", "fitness": 0.09288467256575716, "name": "HybridPSODE", "description": "Enhanced HybridPSODE by leveraging adaptive inertia weight for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_min = 0.4   # Minimum inertia weight\n        self.w_max = 0.9   # Maximum inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.evals = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        self.evals = self.population_size\n        \n        while self.evals < self.budget:\n            # Adaptive Inertia Weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (self.evals / self.budget)\n\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                self.evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09288 with standard deviation 0.04696.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.03418078043640993, 0.05913433621798403, 0.05314823231036525, 0.1511471530500179, 0.16610614381970956, 0.15236357987249738, 0.08594193586186327, 0.06758974405451301, 0.06635014746845413]}}
{"id": "5afad87e-4a9d-48bd-89df-ffcbe2983c79", "fitness": 0.09288467256575716, "name": "HybridPSODE", "description": "A refined hybrid particle swarm algorithm with adaptive inertia weight for improved exploration-exploitation trade-off in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 3, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09288 with standard deviation 0.04696.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.03418078043640993, 0.05913433621798403, 0.05314823231036525, 0.1511471530500179, 0.16610614381970956, 0.15236357987249738, 0.08594193586186327, 0.06758974405451301, 0.06635014746845413]}}
{"id": "202d17e9-6aa4-47c3-a588-911b9adecdf8", "fitness": 0.09288467256575716, "name": "HybridPSODE", "description": "Improved the hybrid optimization strategy by introducing a dynamic inertia weight for better convergence.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F = 0.8  # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Update inertia weight dynamically\n            self.w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09288 with standard deviation 0.04696.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.03418078043640993, 0.05913433621798403, 0.05314823231036525, 0.1511471530500179, 0.16610614381970956, 0.15236357987249738, 0.08594193586186327, 0.06758974405451301, 0.06635014746845413]}}
{"id": "58f6c936-9133-4985-80ce-a9fe99f023fb", "fitness": 0.09288467256575716, "name": "HybridPSODE", "description": "A hybrid particle swarm algorithm with adaptive parameters for enhanced exploration and exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09288 with standard deviation 0.04696.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.03418078043640993, 0.05913433621798403, 0.05314823231036525, 0.1511471530500179, 0.16610614381970956, 0.15236357987249738, 0.08594193586186327, 0.06758974405451301, 0.06635014746845413]}}
{"id": "ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0", "fitness": 0.1102580504789819, "name": "EnhancedHybridPSODE", "description": "A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.", "error": "", "parent_ids": ["41eedf4b-276c-44b1-afe1-7bb7b4ffa794"], "operator": null, "metadata": {"aucs": [0.06660734588650419, 0.12017469269824188, 0.07464873271541417, 0.1724232729490902, 0.16610614381970956, 0.15976577165781425, 0.08594193586186327, 0.07702330409623992, 0.06963125462595976]}}
{"id": "5b0adc4b-c904-4881-a357-f4a7846d7d58", "fitness": 0.11015271769842283, "name": "EnhancedHybridPSODE", "description": "Enhanced hybrid PSO-DE with dynamic mutation factor scaling for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + ((0.2 + 0.1 * (generation / (self.budget / self.population_size))) * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11015 with standard deviation 0.04150.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.07763384780649107, 0.1196324879669387, 0.05202867751321405, 0.17322007664771277, 0.16610614381970956, 0.151240226844078, 0.08594193586186327, 0.07606067645294767, 0.08951038637285036]}}
{"id": "814b4a42-39d1-4f72-b860-478b4b2ab099", "fitness": 0.10784735045870816, "name": "QuantumEnhancedHybridPSODE", "description": "Quantum-inspired Enhanced Hybrid PSODE integrates quantum superposition and collapse mechanisms into the existing particle swarm and differential evolution framework for improved exploration and convergence in black box optimization.", "code": "import numpy as np\n\nclass QuantumEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                \n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Quantum-inspired step: Superposition and collapse\n            if generation % 5 == 0:\n                quantum_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                quantum_fitness = np.array([func(x) for x in quantum_population])\n                evals += self.population_size\n                for i in range(self.population_size):\n                    if quantum_fitness[i] < fitness[i]:\n                        population[i], fitness[i] = quantum_population[i], quantum_fitness[i]\n                        pbest[i] = population[i]\n                        pbest_fitness[i] = fitness[i]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 8, "feedback": "The algorithm QuantumEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10785 with standard deviation 0.04175.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.0722756345450205, 0.1133184934775825, 0.05915426890828701, 0.1724232729490902, 0.16610614381970956, 0.1500504092089111, 0.09020382187055309, 0.07622674079914471, 0.0708673685500748]}}
{"id": "16fc8c3d-c39f-413e-95f8-1517df5dc25c", "fitness": 0.10697281838810314, "name": "EnhancedHybridPSODE", "description": "An improved hybrid particle swarm algorithm that enhances global best influence for better convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + (self.c2 + 0.1) * r2 * (gbest - population)  # Modified line\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10697 with standard deviation 0.03660.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.07518883031321744, 0.10594548922699465, 0.06958063601219866, 0.15549522092966583, 0.16610614381970956, 0.1481366571810777, 0.08594193586186327, 0.07772838110743285, 0.0786320710407683]}}
{"id": "0b0c7500-eaeb-4e9e-a6ba-ee1785d84aa6", "fitness": 0.10791469360713245, "name": "EnhancedHybridPSODE", "description": "A refined hybrid PSO-DE algorithm with strategic non-uniform mutation and dynamic parameter adjustment for enhanced robustness in optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.5, 2)  # Adjusted lower bound of F\n            CR = np.clip(CR, 0.1, 1)  # Adjusted lower bound of CR\n            \n            # Differential Evolution Step with strategic mutation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + F[i] * (x1 - x2), lb, ub)  # Ensure mutant is within bounds\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10791 with standard deviation 0.04017.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.08511657269060702, 0.11550417240730537, 0.05143080599850902, 0.1528911697694968, 0.16610614381970956, 0.1507118603359835, 0.11600911685208948, 0.06149934592948991, 0.07196305466100139]}}
{"id": "25423d06-faa4-4226-84ab-dab0c19c652b", "fitness": 0.10037331921661426, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid particle swarm and differential evolution algorithm utilizing dynamically adjusted learning rates based on population diversity to improve convergence and exploration in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0))\n            adapt_factor = 1 + (diversity / np.mean(ub - lb))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size)) * adapt_factor\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size)) * adapt_factor\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10037 with standard deviation 0.04461.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.06373289828468365, 0.08233057584265335, 0.04342901597448079, 0.1619078979109032, 0.16610614381970956, 0.15577024878548174, 0.08594193586186327, 0.07495035452530496, 0.06919080194444782]}}
{"id": "991ff44c-b3e9-4b1c-9473-b5e96f280d93", "fitness": 0.09643361018427685, "name": "EnhancedHybridPSODE", "description": "Introducing a dynamic mutation factor adjustment based on diversity metrics to improve convergence in the hybrid particle swarm and differential evolution algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic mutation factor based on diversity\n            diversity = np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n            F = self.F_base + 0.5 * (diversity / (ub - lb).max())\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09643 with standard deviation 0.04813.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.029311553927233835, 0.07944179575273969, 0.034163253581716124, 0.15451334857186338, 0.1693006451304776, 0.1509625357582811, 0.08594193586186327, 0.08176951053468884, 0.0824979125396278]}}
{"id": "e33bc464-1398-41d6-94f4-6a7c27da57c4", "fitness": 0.09823195282452132, "name": "EnhancedHybridPSODEv2", "description": "An enhanced hybrid particle swarm and differential evolution algorithm using dynamic parameters and Gaussian mutation for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Dynamic inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step with Gaussian Mutation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 4, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 4, replace=False)\n                x0, x1, x2, x3 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2) + np.random.normal(0, 0.001, self.dim)  # Gaussian mutation\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09823 with standard deviation 0.04749.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.035509268231287305, 0.07932409946334107, 0.06230710040111098, 0.15362703398711308, 0.16955938025656692, 0.16429951788416797, 0.08650746069453896, 0.06202067134966971, 0.07093304315289595]}}
{"id": "bd10fa59-f1c8-41d3-b193-f2c13d02b819", "fitness": 0.10791469360713245, "name": "EnhancedHybridPSODE", "description": "An advanced hybrid particle swarm optimizer with a refined adaptive differential evolution for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.5, 2)  # Increased lower bound for mutation factor F\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10791 with standard deviation 0.04017.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.08511657269060702, 0.11550417240730537, 0.05143080599850902, 0.1528911697694968, 0.16610614381970956, 0.1507118603359835, 0.11600911685208948, 0.06149934592948991, 0.07196305466100139]}}
{"id": "ec3753c6-dfc8-46a4-9fcc-a060e8d51de2", "fitness": 0.09515127641523882, "name": "EnhancedHybridPSODEPlus", "description": "An enhanced hybrid particle swarm algorithm with dynamic parameter adaptation and elite selection to improve convergence and solution diversity in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_min, self.c1_max = 1.0, 2.5  # Adaptive cognitive parameter\n        self.c2_min, self.c2_max = 1.0, 2.5  # Adaptive social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.elite_fraction = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            self.c1 = self.c1_max - ((self.c1_max - self.c1_min) * (evals / self.budget))\n            self.c2 = self.c2_min + ((self.c2_max - self.c2_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]\n            elite_population = population[elite_indices]\n            \n            for i in range(self.population_size):\n                if i in elite_indices:\n                    continue\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices or any(index in elite_indices for index in indices):\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09515 with standard deviation 0.04576.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.0427087173008327, 0.06358858511267451, 0.0592182408691474, 0.14727890950047107, 0.16610614381970956, 0.15997938661845534, 0.08594193586186327, 0.07046646238949106, 0.06107310626450446]}}
{"id": "7fc7c715-026c-48d2-9aa9-e7df507fd6d4", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid particle swarm and differential evolution algorithm using dynamic population resizing and local search to improve convergence and exploration efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.local_search_prob = 0.1  # Probability threshold for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            # Differential Evolution Step\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Local Search Enhancement\n            if np.random.rand() < self.local_search_prob:\n                local_candidate = gbest + np.random.randn(self.dim) * 0.1 * (ub - lb)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_fitness = func(local_candidate)\n                evals += 1\n                if local_fitness < gbest_fitness:\n                    gbest, gbest_fitness = local_candidate, local_fitness\n\n            # Dynamic Population Resizing\n            population_size = max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n        return gbest", "configspace": "", "generation": 16, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (18,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (18,10) (20,10) ')", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {}}
{"id": "e926bfdc-b0c2-434c-8b44-33366a41f1fe", "fitness": 0.12006700536032662, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.", "error": "", "parent_ids": ["ba2ae5aa-33bb-4e49-8a48-49fb4d7c96f0"], "operator": null, "metadata": {"aucs": [0.18111259971595883, 0.1448630075345123, 0.04505322000172396, 0.15936733974267192, 0.1666861801096584, 0.14258717452025482, 0.08594193586186327, 0.09181049375804018, 0.06318109699825603]}}
{"id": "00311707-14a8-4466-9bd9-2cca61716f58", "fitness": 0.10954003641927398, "name": "EnhancedHybridPSODE", "description": "A refined hybrid PSO-DE algorithm utilizing adaptive adjustment of inertia weight and mutation factors for improved performance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.rand(self.population_size))  # Change: using random.rand for more varied mutation factor\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10954 with standard deviation 0.03749.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.09124830096342118, 0.11507476146532336, 0.07005723908611994, 0.14575693874374995, 0.16610614381970956, 0.16462802467602877, 0.08594193586186327, 0.07705691415039151, 0.06999006900685834]}}
{"id": "bc1b3c2c-2f0a-483d-b072-a9e7335a1b69", "fitness": 0.11324177789145302, "name": "EnhancedHybridPSODEv2", "description": "A multi-population cooperative PSO-DE algorithm with adaptive local search intensification for enhanced diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest, pbest_fitness = population.copy(), fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest, pbest_fitness = population.copy(), fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            local_search_threshold = np.percentile(fitness, 20)  # Top 20% for local search intensification\n            for i in range(self.population_size):\n                if fitness[i] < local_search_threshold:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11324 with standard deviation 0.04054.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.11432777714344977, 0.1452733996864617, 0.07665713859915002, 0.15082245161716046, 0.17330884705604033, 0.14917796551792672, 0.08594193586186327, 0.06826180339584031, 0.05540468214518468]}}
{"id": "8238f704-59c1-4653-9b45-4becbb56128b", "fitness": 0.1115855559178091, "name": "EnhancedHybridPSODE", "description": "An enhanced PSO-DE hybrid with adaptive inertia weight, stochastic opposition-based learning, and elite-based mutation for accelerated convergence and robustness across diverse optimization landscapes.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        def stochastic_opposition(x, lb, ub):\n            return lb + ub - x + np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), x.shape)\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.rand(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.rand(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            elite = population[np.argsort(fitness)[:3]]  # Select top 3 elites\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                x0 = elite[np.random.randint(0, 3)]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Stochastic Opposition-Based Learning\n            opposition_population = stochastic_opposition(population, lb, ub)\n            opposition_fitness = np.array([func(x) for x in opposition_population])\n            evals += self.population_size\n\n            improved = opposition_fitness < fitness\n            population[improved] = opposition_population[improved]\n            fitness[improved] = opposition_fitness[improved]\n            pbest[improved] = opposition_population[improved]\n            pbest_fitness[improved] = opposition_fitness[improved]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11159 with standard deviation 0.04035.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.13343692286256525, 0.11818666827603463, 0.05799946292802238, 0.1580299440608841, 0.16610614381970956, 0.14983744860082382, 0.08779964866830081, 0.06977316863272809, 0.06310059541121316]}}
{"id": "4ca47979-4360-4b69-98a4-81852e2ab3e2", "fitness": 0.10291478561318801, "name": "AdaptiveHybridPSODE", "description": "Introducing adaptive inertia dynamics and multi-trial DE strategy to enhance convergence by balancing exploration and exploitation in a hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight based on fitness distribution\n            self.w = self.w_max - ((self.w_max - self.w_min) * np.var(fitness) / (np.mean(fitness) + 1e-10))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # New multi-trial DE strategy\n            for i in range(self.population_size):\n                if evals >= self.budget:\n                    break\n                for _ in range(3):  # Perform multiple trials\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n                        break\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10291 with standard deviation 0.04228.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.08437671286965231, 0.08422672671266418, 0.03218600629727264, 0.15143385146729804, 0.16610614381970956, 0.14933559011652853, 0.08594193586186327, 0.10926226548333962, 0.06336383789036393]}}
{"id": "fbc61b0d-0625-410b-87e8-34423957fdb2", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "Introduced adaptive crossover probability scaling based on generation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * (1 - evals / self.budget))  # Adaptive scaling for CR based on progress\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 22, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {}}
{"id": "f5fd492d-7f43-458f-8ff3-43bf08002b89", "fitness": 0.10850333791581704, "name": "EnhancedHybridPSODE", "description": "An enhanced adaptive hybrid PSO-DE algorithm with improved inertia weight and mutation strategies for better convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.7  # Tweaked Cognitive parameter\n        self.c2 = 1.3  # Tweaked Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.6  # Modified Base mutation factor for DE\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Improved inertia weight update\n            self.w = self.w_max - ((self.w_max - self.w_min) * ((evals/self.budget) ** 0.5))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.15 * np.random.randn(self.population_size))  # Changed random factor for F\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10850 with standard deviation 0.04165.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.11892739083921267, 0.11161126088199658, 0.047250128559230054, 0.16099987812288397, 0.16610614381970956, 0.1505740875679259, 0.08594193586186327, 0.0717252023467928, 0.06339401324273852]}}
{"id": "d1109913-89e0-403b-a7d3-e1491c756921", "fitness": 0.10272890883943282, "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid PSO-DE algorithm with meta-learning to dynamically adjust control parameters for enhanced convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.base_c1 = 1.5\n        self.base_c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.base_F = 0.5\n        self.base_CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evals / self.budget)\n            # Meta-learning to adjust cognitive and social parameters\n            self.c1, self.c2 = self._meta_learning(fitness, pbest_fitness)\n\n            generation += 1\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F = self.base_F + 0.2 * np.random.randn()\n                CR = self.base_CR + 0.1 * np.random.randn()\n                F = np.clip(F, 0, 2)\n                CR = np.clip(CR, 0, 1)\n\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\n    def _meta_learning(self, fitness, pbest_fitness):\n        # Adjust the cognitive and social parameters based on the improvement\n        improvement_ratio = np.mean(pbest_fitness) / np.mean(fitness)\n        c1 = self.base_c1 * (1 + improvement_ratio)\n        c2 = self.base_c2 * (1 - improvement_ratio)\n        return np.clip(c1, 0.5, 2.5), np.clip(c2, 0.5, 2.5)", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10273 with standard deviation 0.04349.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.06088058375785044, 0.0894622350199642, 0.049116956362659225, 0.17324082013053954, 0.16704116155043358, 0.14286914499917835, 0.08594193586186327, 0.07771284665676081, 0.07829449521564602]}}
{"id": "c981b6dc-ef10-4b29-af0f-58f54190b89c", "fitness": 0.08981693080332419, "name": "EnhancedHybridPSODEPlus", "description": "EnhancedHybridPSODE+: Improved enhanced hybrid PSO-DE with adaptive inertia weight modulation and crowding distance-based selection for better exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                else:\n                    # Use crowding distance-based selection to maintain diversity\n                    if np.linalg.norm(mutant - gbest) > np.linalg.norm(population[i] - gbest):\n                        population[i] = mutant\n                        fitness[i] = trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n        \n        return gbest", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSODEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08982 with standard deviation 0.04882.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.04699529539900582, 0.04086526977758109, 0.029712035229931377, 0.1527750357504959, 0.16610614381970956, 0.14486145890356672, 0.08615984721337644, 0.07410352356358385, 0.06677376757266695]}}
{"id": "de6b2002-3acf-473c-acfe-c549a0093305", "fitness": 0.11108040142110759, "name": "EnhancedHybridPSODE", "description": "A self-adaptive hybrid PSO-DE algorithm with chaotic initialization and elitist learning to enhance convergence and global exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def chaotic_initialization(self, lb, ub):\n        # Use a logistic map for chaotic sequence generation\n        x = np.random.rand(self.population_size, self.dim)\n        for _ in range(100):  # Iterate to spread chaos\n            x = 4 * x * (1 - x)\n        return lb + x * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = self.chaotic_initialization(lb, ub)\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11108 with standard deviation 0.04614.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.0728299921719866, 0.09382272061854935, 0.06645803127350636, 0.15634937504068436, 0.20929386649162074, 0.14757415864193857, 0.0965972263691195, 0.07400346958882908, 0.0827947725937338]}}
{"id": "08bddb6b-4d77-48ba-a8ca-0a812832d089", "fitness": 0.10388861205480059, "name": "EnhancedHybridPSODE", "description": "Refinement of inertia weight adaptation for improved convergence stability in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / (self.budget/self.population_size)))  # Changed line\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10389 with standard deviation 0.04403.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.07181385798038353, 0.10309835816629487, 0.029179267189485936, 0.16189237338198925, 0.16610614381970956, 0.1519873548911702, 0.08594193586186327, 0.07760784924611475, 0.0873703679561939]}}
{"id": "84e8d349-eaa5-4be8-914f-350aa7d544f3", "fitness": 0.10717872796014853, "name": "ImprovedHybridPSODE", "description": "An improved hybrid PSO-DE algorithm that integrates inertia weight adaptation based on fitness variance and implements a leader strategy for enhanced convergence stability.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            fitness_var = np.var(fitness)\n            self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_var / (fitness_var + gbest_fitness)))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 28, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10718 with standard deviation 0.03560.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.06914329038565459, 0.11689919479441702, 0.09856163219662495, 0.14211755262076897, 0.16610614381970956, 0.14805180022609554, 0.08721784024959689, 0.06855516338884171, 0.06795593395962751]}}
{"id": "e862414a-f884-4d37-935a-a1c951a5ccd6", "fitness": 0.10989132508423904, "name": "EnhancedHybridPSODERefined", "description": "Introduce an adaptive local search phase and diversity preservation strategy to enhance solution accuracy and convergence speed in the Enhanced Hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.local_search_prob = 0.1  # Probability to perform local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Adaptive local search for diversity preservation\n            for i in range(self.population_size):\n                if np.random.rand() < self.local_search_prob:\n                    candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_fitness = func(candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[i]:\n                        population[i] = candidate\n                        fitness[i] = candidate_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedHybridPSODERefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10989 with standard deviation 0.03368.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.09808792390387922, 0.11026715650009011, 0.09313891977658417, 0.14789236260194993, 0.16610614381970956, 0.1475773906004546, 0.08594193586186327, 0.06769112122528875, 0.07231897146833177]}}
{"id": "e12aef1f-88b7-43db-8d9e-130eca79fad7", "fitness": -Infinity, "name": "ExtendedAdaptivePSODE", "description": "An extended adaptive PSO-DE with self-learning mutation strategies based on performance feedback to enhance convergence and diversity.", "code": "import numpy as np\n\nclass ExtendedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.strategy_rates = np.array([1.0, 1.0])  # Performance feedback for mutation strategies\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE Strategy\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            # Evaluate DE strategies\n            strategy_performance = np.zeros(2)\n            for i in range(self.population_size):\n                if np.random.rand() < self.strategy_rates[0] / self.strategy_rates.sum():\n                    # Strategy 1: DE/rand/1/bin\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                else:\n                    # Strategy 2: DE/best/1/bin\n                    indices = np.random.choice(self.population_size, 2, replace=False)\n                    indices = np.append(indices, np.argmin(fitness))\n\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    strategy_performance[0 if indices[2] == x2 else 1] += 1\n\n            # Update strategy rates\n            self.strategy_rates += strategy_performance\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 30, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {}}
{"id": "584faa2c-c18a-489e-a908-6bf9f5772b3b", "fitness": 0.09283406235952035, "name": "AdvancedHybridPSODE", "description": "An advanced PSO-DE hybrid algorithm with adaptive strategies for inertia, mutation, and crossover rates to enhance search efficiency and solution accuracy.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.alpha = 0.05  # Scaling factor for adaptive parameters\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * ((gbest_fitness - np.min(fitness)) / np.ptp(fitness))\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Adaptive mutation and crossover rates\n            F = np.clip(self.F_base + self.alpha * np.tanh((gbest_fitness - fitness) / np.std(fitness)), 0, 2)\n            CR = np.clip(self.CR_base + self.alpha * np.tanh((fitness - np.mean(fitness)) / np.std(fitness)), 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 31, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09283 with standard deviation 0.04974.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.09811009288678563, 0.025914941212761056, 0.02291113091260355, 0.14764888737007698, 0.16610614381970956, 0.1497860730684044, 0.08911341491008706, 0.06806009940779767, 0.0678557776474572]}}
{"id": "497ca226-0607-4d74-a1da-780ad97696d2", "fitness": -Infinity, "name": "EnhancedHybridPSODEv2", "description": "Incorporate a multi-swarm strategy and adaptive diversity mechanism into the hybrid PSO-DE framework to enhance exploration and convergence balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_count = 3  # Number of swarms for multi-swarm strategy\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 0.1  # Threshold to trigger diversity enhancement\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [self._initialize_swarm(lb, ub) for _ in range(self.swarm_count)]\n        gbest_fitness_overall = np.inf\n        evals = 0\n        \n        while evals < self.budget:\n            for swarm in swarms:\n                population, velocities, fitness, pbest, pbest_fitness, gbest, gbest_fitness = swarm\n                generation = 0\n                while evals < self.budget:\n                    self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n                    generation += 1\n                    r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                    velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n                    population = np.clip(population + velocities, lb, ub)\n                    fitness = np.array([func(x) for x in population])\n                    evals += self.population_size\n\n                    better_indices = fitness < pbest_fitness\n                    pbest[better_indices] = population[better_indices]\n                    pbest_fitness[better_indices] = fitness[better_indices]\n\n                    if np.min(fitness) < gbest_fitness:\n                        gbest = population[np.argmin(fitness)]\n                        gbest_fitness = np.min(fitness)\n\n                    # Adaptive Diversity Mechanism\n                    if generation % 10 == 0:\n                        diversity = np.mean(np.std(population, axis=0))\n                        if diversity < self.diversity_threshold:\n                            # Introduce diversity by perturbing population\n                            population += np.random.uniform(-0.1, 0.1, population.shape) * (ub - lb)\n                            population = np.clip(population, lb, ub)\n                            fitness = np.array([func(x) for x in population])\n                            evals += self.population_size\n\n                    F = self.F_base + (0.2 * np.random.randn(self.population_size))\n                    CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n                    F = np.clip(F, 0, 2)\n                    CR = np.clip(CR, 0, 1)\n\n                    for i in range(self.population_size):\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size, 3, replace=False)\n                        x0, x1, x2 = population[indices]\n                        mutant = x0 + F[i] * (x1 - x2)\n                        cross_points = np.random.rand(self.dim) < CR[i]\n                        trial = np.where(cross_points, mutant, population[i])\n                        trial = np.clip(trial, lb, ub)\n                        trial_fitness = func(trial)\n                        evals += 1\n                        if trial_fitness < fitness[i]:\n                            population[i], fitness[i] = trial, trial_fitness\n\n                    better_indices = fitness < pbest_fitness\n                    pbest[better_indices] = population[better_indices]\n                    pbest_fitness[better_indices] = fitness[better_indices]\n\n                    if np.min(fitness) < gbest_fitness:\n                        gbest = population[np.argmin(fitness)]\n                        gbest_fitness = np.min(fitness)\n\n                # Update overall best\n                if gbest_fitness < gbest_fitness_overall:\n                    gbest_fitness_overall = gbest_fitness\n                    gbest_overall = gbest\n\n        return gbest_overall\n\n    def _initialize_swarm(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        return population, velocities, fitness, pbest, pbest_fitness, gbest, gbest_fitness", "configspace": "", "generation": 32, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {}}
{"id": "68c1f9b6-50ec-43d3-883d-adb8504090c7", "fitness": 0.11788209115012964, "name": "EnhancedHybridPSODE", "description": "Introducing adaptive inertia adjustment and local search enhancements to improve convergence and solution quality in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Introduce a local search phase at every 15 generations\n            if generation % 15 == 0:\n                for i in range(self.population_size):\n                    local_search_candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    local_search_candidate = np.clip(local_search_candidate, lb, ub)\n                    candidate_fitness = func(local_search_candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[i]:\n                        population[i], fitness[i] = local_search_candidate, candidate_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11788 with standard deviation 0.03561.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.13119424755550935, 0.14462752130545775, 0.07632986478354653, 0.1473848642030775, 0.16610614381970956, 0.15194270083427064, 0.08609164871312636, 0.09181049375804018, 0.06545133537842895]}}
{"id": "595537a4-133f-4820-b449-922b96735c5d", "fitness": 0.08570345675123352, "name": "GradientInformedHybridPSODE", "description": "A Gradient-Informed Hybrid PSO-DE algorithm that leverages gradient information for adaptive mutation and crossover strategies, improving convergence efficiency and precision.", "code": "import numpy as np\n\nclass GradientInformedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Calculate gradient approximation\n            gradients = np.zeros((self.population_size, self.dim))\n            for i in range(self.population_size):\n                perturbation = np.random.uniform(-1e-8, 1e-8, self.dim)\n                gradients[i] = (func(population[i] + perturbation) - fitness[i]) / perturbation\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population) - 0.1 * gradients\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2) - 0.1 * gradients[i]\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if evals >= self.budget:\n                    break\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 34, "feedback": "The algorithm GradientInformedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08570 with standard deviation 0.04760.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.031768097425748154, 0.06650065380245973, 0.026294709083007795, 0.13728903196991238, 0.1661061607854828, 0.14030591313168783, 0.08594194918325215, 0.05797348063806507, 0.05915111474148571]}}
{"id": "29ae0ef8-17c0-419c-ae99-4d52a696a093", "fitness": 0.10985253115180527, "name": "EnhancedHybridPSODE", "description": "A refined hybrid PSO-DE algorithm using adaptive learning rates and a multi-phase strategy for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.7  # Cognitive parameter\n        self.c2 = 1.7  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.learning_rate = 0.1   # New learning rate parameter\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Multi-phase strategy\n            if generation % 15 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 5)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities *= self.learning_rate\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.3 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.15 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10985 with standard deviation 0.03404.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.07550480751019151, 0.06654118295542832, 0.10491245363639312, 0.14467890516923254, 0.16610614381970956, 0.1540160594346558, 0.08616427205112753, 0.09092698428763168, 0.09982197150187733]}}
{"id": "f37e99d0-3774-4386-9d4e-90c3b9b723e1", "fitness": 0.11452130691158298, "name": "EnhancedHybridPSODE", "description": "Introduce a Levy flight mechanism for enhanced exploration and adaptively adjust DE parameters based on swarm diversity to optimize the EnhancedHybridPSODE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def levy_flight(self, lambda_=1.5):\n        sigma = (np.math.gamma(1 + lambda_) * np.sin(np.pi * lambda_ / 2) / \n                 (np.math.gamma((1 + lambda_) / 2) * lambda_ * 2**((lambda_ - 1) / 2)))** (1 / lambda_)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / lambda_)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        diversity_threshold = 0.1 * np.linalg.norm(ub - lb)\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic strategy based on diversity\n            diversity = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n            if diversity < diversity_threshold:\n                self.F_base = 0.5 + 0.5 * np.random.rand()\n                self.CR_base = 0.1 + 0.8 * np.random.rand()\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = np.random.uniform(0.5, 1.0, self.population_size)\n            CR = np.random.uniform(0.1, 1.0, self.population_size)\n\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:\n                    trial = population[i] + self.levy_flight()\n                else:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 36, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11452 with standard deviation 0.03489.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.10793880500830844, 0.1206984148938578, 0.1084633135772034, 0.15935250023708014, 0.16610614381970956, 0.14620722571841416, 0.08594193586186327, 0.06525005210045043, 0.07073337098735955]}}
{"id": "b29a6295-85ef-4067-a11e-b8e5b4895815", "fitness": 0.10640165158330599, "name": "EnhancedHybridPSODE", "description": "Improved hybrid PSO-DE algorithm enhancing velocity control and intermittent DE application for better convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Improved velocity control with adaptive inertia\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Applying DE selectively every few generations for diversity\n            if generation % 5 == 0:\n                for i in range(self.population_size):\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10640 with standard deviation 0.03534.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.10043074896922688, 0.08834552749090308, 0.08871456998353722, 0.14717339000224028, 0.16610614381970956, 0.1479755883813927, 0.08594193586186327, 0.0672193860522966, 0.06570757368858426]}}
{"id": "d1af2253-240d-46a7-b971-158958aa9b2f", "fitness": 0.11454192550433641, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive parameter tuning using historical fitness improvement for refined balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        fitness_history = [gbest_fitness]\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Adaptive parameter tuning\n            if len(fitness_history) > 5:\n                history_improvement = fitness_history[-5] - gbest_fitness\n                if history_improvement < 0.01 * abs(np.mean(fitness_history)):\n                    self.c1, self.c2 = 0.5, 0.5\n                else:\n                    self.c1, self.c2 = 2.0, 2.0\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                fitness_history.append(gbest_fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11454 with standard deviation 0.03813.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.12298191483013665, 0.13779576302057006, 0.05580072374686462, 0.15936733974267192, 0.1666861801096584, 0.14258717452025482, 0.08594193586186327, 0.09181049375804018, 0.06790580394896772]}}
{"id": "28bdee62-e0da-4a99-bb5f-c4bdf100f630", "fitness": 0.11169439995664836, "name": "EnhancedHybridPSODE", "description": "Fine-tuning crossover probability scaling to balance exploration and exploitation in the Enhanced Hybrid PSO-DE algorithm.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.15 * np.random.randn(self.population_size))  # Changed from 0.1 to 0.15\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11169 with standard deviation 0.03694.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.12426268846969213, 0.12679483362794974, 0.0641371247530017, 0.14770689913031465, 0.16610614381970956, 0.1485368278048821, 0.08594193586186327, 0.07416594530454901, 0.06759720083787313]}}
{"id": "f120790d-19bc-4a1f-80a0-6242451519b0", "fitness": 0.1182351000445985, "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid PSO-DE algorithm with periodically resettable populations and self-adaptive parameter tuning to enhance global exploration and local exploitation.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.population_size = self.initial_population_size\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.reset_interval = 50  # Reset population every 50 generations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            \n            if generation % self.reset_interval == 0 and generation > 0:\n                # Reset population periodically\n                self.population_size = self.initial_population_size\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1_initial * r1 * (pbest - population) + self.c2_initial * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            generation += 1\n\n        return gbest", "configspace": "", "generation": 40, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11824 with standard deviation 0.03553.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.13143148278192862, 0.14601083049001273, 0.07705610867157342, 0.1473834223773498, 0.16610614381970956, 0.15194270083427064, 0.08594193586186327, 0.09213874552307266, 0.06610453004160566]}}
{"id": "4491888d-c906-4f8f-bf18-2eeb2fedeb0a", "fitness": 0.09805065018232784, "name": "EnhancedHybridPSODE", "description": "Improved inertia weight adjustment and trial solution evaluation for enhanced convergence and accuracy.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / 1000))  # Linear adjustment over generations\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09805 with standard deviation 0.04408.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.05743154948159901, 0.06453950326421931, 0.05647343875566413, 0.16495675379339747, 0.16610614381970956, 0.14537244800669968, 0.08594193586186327, 0.06853616525362927, 0.07309791340416882]}}
{"id": "a2476135-64da-4c71-9ebc-f12becea5951", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm with adaptive inertia weight, dynamic parameter tuning, and elite learning strategy for efficient exploitation and exploration balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    extras = np.random.uniform(lb, ub, (self.population_size - len(population), self.dim))\n                    population = np.vstack((population, extras))\n                    velocities = np.vstack((velocities, np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size - len(velocities), self.dim))))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Elite Learning Strategy: Keep a portion of the best solutions intact\n            elite_size = int(0.1 * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]\n            non_elite_indices = np.argsort(fitness)[elite_size:]\n            \n            # Update personal best\n            better_indices = fitness[non_elite_indices] < pbest_fitness[non_elite_indices]\n            pbest[non_elite_indices[better_indices]] = population[non_elite_indices[better_indices]]\n            pbest_fitness[non_elite_indices[better_indices]] = fitness[non_elite_indices[better_indices]]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution with elitism\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in non_elite_indices:\n                indices = np.random.choice(non_elite_indices, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal best\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 42, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {}}
{"id": "4d789e09-b735-4349-bb24-78b6414d5ea6", "fitness": 0.17590864565864006, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.", "error": "", "parent_ids": ["e926bfdc-b0c2-434c-8b44-33366a41f1fe"], "operator": null, "metadata": {"aucs": [0.7546749617087607, 0.09654571452282035, 0.024413253636812238, 0.15559475437166348, 0.17811427983198602, 0.14842193549058358, 0.08594193586186327, 0.06998728309854607, 0.06948369240472496]}}
{"id": "dbba1d2f-47b4-4cf4-b1a0-47bcd1676ff9", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with time-variant crossover probability for improved diversity and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base * (1 - evals / self.budget)  # Adjusted line for time-variant crossover probability\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 44, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {}}
{"id": "7accd0dc-5567-4c82-a6d1-2ac4d1e21f79", "fitness": 0.10675591724874718, "name": "RefinedHybridPSODE", "description": "RefinedHybridPSODE with adaptive learning rates and enhanced selection mechanisms for improved convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.alpha = 0.5  # Dynamic adjustment parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Adaptive learning rate adjustment\n            adapt_factor = np.exp(-self.alpha * generation / self.budget)\n            self.c1 *= adapt_factor\n            self.c2 *= adapt_factor\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters with enhanced selection\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10676 with standard deviation 0.03779.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.08418588138514382, 0.09552382033761908, 0.07090191667729384, 0.14357388654376257, 0.16613924075197228, 0.16574301016891824, 0.08594193586186327, 0.06994443268736927, 0.07884913082478229]}}
{"id": "f45400fc-8544-4591-860d-3a6dd6397b1a", "fitness": 0.09010114074275384, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with adaptive parameter tuning and niche-based competition to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 3 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation based on generation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / (self.budget / self.population_size)))\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            new_fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = new_fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = new_fitness[better_indices]\n            \n            if np.min(new_fitness) < gbest_fitness:\n                gbest = population[np.argmin(new_fitness)]\n                gbest_fitness = np.min(new_fitness)\n\n            # Adaptive DE parameters based on fitness diversity\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * (np.std(new_fitness) / np.mean(new_fitness)))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < new_fitness[i]:\n                    population[i], new_fitness[i] = trial, trial_fitness\n\n            better_indices = new_fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = new_fitness[better_indices]\n\n            if np.min(new_fitness) < gbest_fitness:\n                gbest = population[np.argmin(new_fitness)]\n                gbest_fitness = np.min(new_fitness)\n\n        return gbest", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09010 with standard deviation 0.04882.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.018935437438739267, 0.06409954536858598, 0.04216712120367072, 0.14626038767795835, 0.16610614381970956, 0.14916220376936784, 0.08594193586186327, 0.07613587209876838, 0.06210161944612125]}}
{"id": "8de54324-75e6-44b8-8707-878ec2cc488c", "fitness": 0.1074888529901175, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive inertia weight and optimized dynamic DE parameters for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.6  # Base mutation factor for DE\n        self.CR_base = 0.95  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10749 with standard deviation 0.04105.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06286567200318449, 0.13586675453193975, 0.08314831342672002, 0.14854555227311383, 0.16610614381970956, 0.1567442378908096, 0.08594193586186327, 0.06350702128793162, 0.06467404581578529]}}
{"id": "cb80ce87-3ab5-4e3b-98e4-616e2b5a75a5", "fitness": 0.11090305991788704, "name": "ImprovedHybridPSODE", "description": "ImprovedHybridPSODE with diversity preservation and adaptive velocity clamping for enhanced convergence and stability.", "code": "import numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.max_velocity = None\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        # Set max velocity as a fraction of the dynamic range\n        self.max_velocity = (ub - lb) * 0.1\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                diversity = np.std(population, axis=0)\n                if np.any(diversity < 0.1 * (ub - lb)):\n                    population += np.random.normal(0, 0.1, population.shape) * (ub - lb)\n                    velocities = np.random.normal(0, 0.1, velocities.shape) * (ub - lb)\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -self.max_velocity, self.max_velocity)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 48, "feedback": "The algorithm ImprovedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11090 with standard deviation 0.03648.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07891217774140302, 0.11961029949674373, 0.08545337404983488, 0.14707195117489658, 0.16610614381970956, 0.1635901913039034, 0.08594193586186327, 0.07555850459194413, 0.07588296122068483]}}
{"id": "4e26856b-fb87-4603-9181-682d2f55c1a0", "fitness": 0.09357035866612294, "name": "EnhancedHybridPSODE", "description": "Introduced a novel time-varying population size strategy for enhanced adaptability to function landscape.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                self.population_size = int(self.population_size + np.sin(generation) * 2)  # Change 1\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09357 with standard deviation 0.05043.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.03474066758730343, 0.08245116774119565, 0.025830958263086234, 0.15559475437166348, 0.17811427983198602, 0.14254791564304314, 0.08594193586186327, 0.06839852098588872, 0.06851302770907652]}}
{"id": "e1fbe5d6-23d3-441c-a43d-7180d15ad894", "fitness": 0.09732022055666677, "name": "AdvancedHybridPSODE", "description": "AdvancedHybridPSODE with adaptive inertia weight using fitness variance, dynamic population size and improved DE parameters for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            fitness_variance = np.var(fitness)\n            fitness_mean = np.mean(fitness)\n            self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_variance / (fitness_variance + fitness_mean)))\n            generation += 1\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Dynamic DE parameters with Gaussian perturbations for more exploration\n            F = self.F_base + (0.5 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.3 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.1, 2)  # Ensure F is not too small\n            CR = np.clip(CR, 0.1, 1)  # Ensure CR is not too small\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 50, "feedback": "The algorithm AdvancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09732 with standard deviation 0.04413.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.060041655666803195, 0.048068651213133085, 0.05076913445598574, 0.15351875968549733, 0.16610614381970956, 0.1504024398467485, 0.09150989180320135, 0.08205799064264152, 0.07340731787628063]}}
{"id": "a15b1945-6b4c-478a-abe0-21405d73592e", "fitness": 0.10176895869543108, "name": "EnhancedHybridPSODE", "description": "Enhanced inertia weight adjustment by incorporating a feedback mechanism based on the convergence rate to improve exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation with feedback mechanism\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness))) * (1 - evals / self.budget)\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10177 with standard deviation 0.05039.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.055334492798829404, 0.11211457660198909, 0.018999998332516976, 0.1597395748542647, 0.16610614381970956, 0.16838410798886705, 0.08594193586186327, 0.06849224480599136, 0.08080755319484834]}}
{"id": "7e9828cd-a583-43df-a47a-12d70fcb2fe2", "fitness": 0.09751833885972856, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with periodic random restart to escape local optima.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Random restart\n            if generation % 50 == 0:  \n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.population_size\n\n        return gbest", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09752 with standard deviation 0.04924.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04916220051855713, 0.09654571452282035, 0.024413253636812238, 0.15559475437166348, 0.17811427983198602, 0.14842193549058358, 0.08594193586186327, 0.06998728309854607, 0.06948369240472496]}}
{"id": "cc4fb0a5-01c3-4b78-89d9-14befd6b75f0", "fitness": 0.10077796011899974, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive mutation scaling for better local search precision.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (1 - evals/self.budget)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10078 with standard deviation 0.04765.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.05649797806071333, 0.11469192909888493, 0.022559625751756185, 0.16318863812529805, 0.16610614381970956, 0.1480002889157468, 0.09278913103784037, 0.07214534207046475, 0.07102256419058373]}}
{"id": "fa3951b2-2646-408e-aeff-2f94a001174f", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with diversity preservation via crowding distance and elitist archive for improved convergence and robustness.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.archive_size = self.population_size // 2  # Size of the elitist archive\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        archive = []\n\n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Update the archive with non-dominated solutions\n            combined_pop = np.vstack((population, archive))\n            combined_fit = np.hstack((fitness, [func(x) for x in archive]))\n            non_dominated_indices = self._non_dominated_sorting(combined_pop, combined_fit)\n            archive = combined_pop[non_dominated_indices]\n            if len(archive) > self.archive_size:\n                archive = self._crowding_distance_sort(archive, combined_fit[non_dominated_indices])[:self.archive_size]\n\n        return gbest\n    \n    def _non_dominated_sorting(self, population, fitness):\n        dominated = set()\n        non_dominated = set(range(len(population)))\n        for i in range(len(population)):\n            for j in range(i + 1, len(population)):\n                if fitness[i] < fitness[j]:\n                    dominated.add(j)\n                elif fitness[j] < fitness[i]:\n                    dominated.add(i)\n        non_dominated -= dominated\n        return list(non_dominated)\n    \n    def _crowding_distance_sort(self, archive, fitness):\n        if len(archive) < 2:\n            return np.arange(len(archive))\n        distances = np.zeros(len(archive))\n        sorted_indices = np.argsort(fitness)\n        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            distances[sorted_indices[i]] = (fitness[sorted_indices[i + 1]] - fitness[sorted_indices[i - 1]]) / (np.max(fitness) - np.min(fitness))\n        return np.argsort(-distances)", "configspace": "", "generation": 54, "feedback": "An exception occurred: ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 1 has size 0').", "error": "ValueError('all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 1 has size 0')", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {}}
{"id": "f15b6317-39c6-4034-96fa-f60d2b5ec3f8", "fitness": 0.1088178200742579, "name": "EnhancedHybridPSODE", "description": "Introduced elitism, adaptive cognitive and social components, and improved mutation strategy for better convergence in EnhancedHybridPSODE.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_init = 1.5  # Initial cognitive parameter\n        self.c2_init = 1.5  # Initial social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            c1 = self.c1_init * np.exp(-generation / 100)  # Adaptive cognitive parameter\n            c2 = self.c2_init * np.exp(-generation / 100)  # Adaptive social parameter\n            velocities = self.w * velocities + c1 * r1 * (pbest - population) + c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10882 with standard deviation 0.03907.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.1263542943117435, 0.0929934220931179, 0.06570655369272937, 0.157273349073905, 0.16610614381970956, 0.15033311848265773, 0.08594193586186327, 0.06772903506431716, 0.0669225282682776]}}
{"id": "5fd48c05-f935-4456-8488-87de998914d5", "fitness": 0.097672752025524, "name": "EnhancedHybridPSODE", "description": "Improved inertia weight adaptation by incorporating fitness standard deviation to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))  # Changed line\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09767 with standard deviation 0.04678.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.044379439436303736, 0.07538431204880625, 0.05369773035863956, 0.14662120719748062, 0.1753620764486722, 0.161557174356466, 0.08594193586186327, 0.07090635089884534, 0.065204541622639]}}
{"id": "7d001bdb-3a51-404d-b8fe-aa01a59a94a9", "fitness": 0.09751833885972856, "name": "EnhancedHybridPSODE", "description": "Refine EnhancedHybridPSODE by introducing an elite solution preservation mechanism for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Preserve the best solution found so far in each generation\n            elite_solution = gbest\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n        \n        return elite_solution", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09752 with standard deviation 0.04924.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04916220051855713, 0.09654571452282035, 0.024413253636812238, 0.15559475437166348, 0.17811427983198602, 0.14842193549058358, 0.08594193586186327, 0.06998728309854607, 0.06948369240472496]}}
{"id": "1eca6b01-f547-4e03-87ef-eea0c05823ec", "fitness": 0.08577586719526961, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with dynamic neighborhood topology and self-adaptive DE parameters for enhanced convergence speed and diversity maintenance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        # Dynamic neighborhood topology: ring topology\n        neighbors = np.roll(np.arange(self.population_size), 1)\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - (gbest_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-10))\n            \n            # PSO velocity and position update with neighborhood topology\n            for i in range(self.population_size):\n                local_gbest = population[neighbors[i]]\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (pbest[i] - population[i])\n                                 + self.c2 * r2 * (local_gbest - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n            # Evaluate new solutions\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Self-adaptive DE parameters\n            F = np.radians(self.F_base + 0.2 * (1 - (gbest_fitness - pbest_fitness) / (np.max(pbest_fitness) - np.min(pbest_fitness) + 1e-10)))\n            CR = np.tanh(self.CR_base + 0.1 * np.random.randn(self.population_size))\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # Update personal and global bests again\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08578 with standard deviation 0.05538.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.023188681520402987, 0.025914941212761056, 0.017450654219395956, 0.13891713151284857, 0.18013685504845933, 0.1452296395085828, 0.08594193586186327, 0.07341421707309359, 0.08178874880001896]}}
{"id": "673d622e-5888-4cb8-9ab8-2475636dc8e5", "fitness": 0.10143255959654704, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive diversity and fitness-based selection pressure for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 15 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-3, 5)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i] or np.random.rand() < 0.05:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10143 with standard deviation 0.03971.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.053052812941981387, 0.08755611037557676, 0.06690838929268739, 0.1427773390235325, 0.16655351103965588, 0.1564986259023453, 0.08594193586186327, 0.07279723527682891, 0.08080707665445197]}}
{"id": "ed92f3d6-a7f1-4c4b-920b-59d9abf14d44", "fitness": 0.097672752025524, "name": "EnhancedHybridPSODE", "description": "Minor fine-tuning of the inertia weight calculation to enhance convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09767 with standard deviation 0.04678.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.044379439436303736, 0.07538431204880625, 0.05369773035863956, 0.14662120719748062, 0.1753620764486722, 0.161557174356466, 0.08594193586186327, 0.07090635089884534, 0.065204541622639]}}
{"id": "f903b0e2-703c-4f3f-b7f0-a1fa3c112b82", "fitness": 0.10077796011899974, "name": "EnhancedHybridPSODE", "description": "Introduce a small variation in the mutation factor calculation in the DE component to enhance exploration capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (1 - evals / self.budget)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10078 with standard deviation 0.04765.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.05649797806071333, 0.11469192909888493, 0.022559625751756185, 0.16318863812529805, 0.16610614381970956, 0.1480002889157468, 0.09278913103784037, 0.07214534207046475, 0.07102256419058373]}}
{"id": "f1f4d871-4b1a-45e4-8ced-e35ec5b5e7eb", "fitness": 0.09663371576584741, "name": "EnhancedHybridPSODE", "description": "Introduce adaptive population resizing to dynamically adjust exploration-exploitation balance based on diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Adaptive population resizing based on diversity (entropy measures diversity).\n            diversity = np.std(population, axis=0).sum()\n            if diversity < 0.1 * (ub - lb).sum():\n                self.population_size = max(5, self.population_size - 1)\n            elif diversity > 0.5 * (ub - lb).sum():\n                self.population_size = min(self.population_size + 1, 10 * self.dim)\n\n            if generation % 10 == 0 or self.population_size != len(population):\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09663 with standard deviation 0.04827.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04566112025305724, 0.08245116774119565, 0.034774880986708556, 0.15559475437166348, 0.17811427983198602, 0.147564381832047, 0.08594193586186327, 0.0760679908134646, 0.06353293020064088]}}
{"id": "7aba7d64-98b4-4bf3-8a03-094c4a1ddc28", "fitness": 0.10068932509677177, "name": "EnhancedHybridPSODE", "description": "Adjusted EnhancedHybridPSODE to integrate adaptive cognitive and social parameters for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Change: Add adaptive cognitive (c1) and social (c2) parameters\n            self.c1 = 1.5 - 1.0 * (evals / self.budget)\n            self.c2 = 1.5 + 1.0 * (evals / self.budget)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10069 with standard deviation 0.04044.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06621935584202088, 0.08711206980637354, 0.043961383880964267, 0.14319297119893948, 0.16635758612148832, 0.15441885066263372, 0.08594193586186327, 0.08168874008831695, 0.07731103240834547]}}
{"id": "3aa41cc4-9e74-4c09-ab31-b4afd4385c79", "fitness": 0.09759261593692811, "name": "EnhancedHybridPSODE", "description": "Introduce random initialization for DE parameters to enhance search diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Random initialization for DE parameters\n            F = np.random.uniform(0, 2, self.population_size)\n            CR = np.random.uniform(0, 1, self.population_size)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09759 with standard deviation 0.04876.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.03691950718688741, 0.06700108844107022, 0.07345089707591301, 0.16909807724886528, 0.17166757452338355, 0.1509397992268391, 0.08594193586186327, 0.06594017227751492, 0.057374491590016286]}}
{"id": "3344db05-2559-4d10-a0b6-636f794277f5", "fitness": 0.10293257680123377, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with improved dynamic DE parameters using Gaussian distribution for better solution diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = np.abs(np.random.normal(self.F_base, 0.1, self.population_size))  # Modified line\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10293 with standard deviation 0.04765.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.09210977560027367, 0.08891497397419135, 0.023568991278456464, 0.17360750543161374, 0.16610614381970956, 0.15333766778763647, 0.08594193586186327, 0.07448554961520581, 0.06832064784215364]}}
{"id": "97d36d32-fa16-4a13-8ed7-b30d303f973a", "fitness": 0.09525454878557452, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive local search and chaotic initialization for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def chaotic_initialization(self, lb, ub):\n        chaotic_seq = np.random.rand(self.population_size, self.dim)\n        return lb + chaotic_seq * (ub - lb)\n\n    def local_search(self, solution, lb, ub, func):\n        perturbed = solution + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        perturbed = np.clip(perturbed, lb, ub)\n        return perturbed if func(perturbed) < func(solution) else solution\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = self.chaotic_initialization(lb, ub)\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            population = np.array([self.local_search(x, lb, ub, func) for x in population])\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09525 with standard deviation 0.05164.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.0372753466934016, 0.07682155439225313, 0.02151869124792416, 0.17441778800104557, 0.16610614381970956, 0.14638849826591194, 0.08594193586186327, 0.07287409809133749, 0.0759468826967239]}}
{"id": "05792c48-0c8f-440a-b5f9-f3f667de41c6", "fitness": 0.10079780502490085, "name": "EnhancedHybridPSODE", "description": "Enhance adaptive diversity preservation by introducing a chaotic map-based dynamic component in DE parameters.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * generation / 10)  # Chaotic map integration\n            F = self.F_base + chaotic_factor * (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + chaotic_factor * (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10080 with standard deviation 0.04624.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06617224338094252, 0.11409046085657504, 0.021561370339866603, 0.1532665803377843, 0.16610614381970956, 0.14945056408969093, 0.08594193586186327, 0.09372574245791399, 0.05686520407976148]}}
{"id": "db912544-e093-4625-b555-cf630b62bdda", "fitness": 0.09867886096843709, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive mutation scaling based on diversity for improved convergence stability.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            # Calculate diversity for adaptive mutation scaling\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE parameters based on diversity\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (diversity / (diversity + 1))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09868 with standard deviation 0.04217.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06302927140105874, 0.08949665938180451, 0.04341899497817314, 0.15118816531485424, 0.16610614381970956, 0.14859062106030974, 0.08594193586186327, 0.06748208413289947, 0.07285587276526118]}}
{"id": "fdb90890-167f-4a69-9bd6-c4aff676da7a", "fitness": 0.10796139789964158, "name": "EnhancedHybridPSODE", "description": "Slightly refined EnhancedHybridPSODE with improved exploration dynamics through dynamic cognitive and social parameter adjustments.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_base = 1.5  # Cognitive parameter base\n        self.c2_base = 1.5  # Social parameter base\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            # Dynamic cognitive and social parameters\n            self.c1 = self.c1_base + 0.5 * (1 - gbest_fitness / np.mean(fitness))\n            self.c2 = self.c2_base - 0.5 * (1 - gbest_fitness / np.mean(fitness))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10796 with standard deviation 0.04075.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07356158349978492, 0.11864427973865876, 0.06517347769567972, 0.14309555875273094, 0.16610614381970956, 0.17321842459197156, 0.08594193586186327, 0.07455317359444491, 0.07135800354193056]}}
{"id": "e0752a18-691e-4820-bee0-a9db56f8fd00", "fitness": 0.09191248659955886, "name": "EnhancedHybridPSODE", "description": "The EnhancedHybridPSODE now includes an improved adaptive mutation factor to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * np.var(fitness))  # Changed line\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09191 with standard deviation 0.04785.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.046243249197834735, 0.08559450318236739, 0.02059908536938937, 0.14462498796580192, 0.16610614381970956, 0.15071427675866578, 0.08594193586186327, 0.06728137774862164, 0.0601068194917761]}}
{"id": "eb347fea-b32f-4bde-9119-14a4bb0c98ee", "fitness": 0.11195840706676538, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with adaptive scaling of parameters and random reinitialization for enhanced exploration-exploitation trade-off in dynamic landscapes.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.reinit_prob = 0.05  # Probability of random reinitialization\n\n    def adaptive_parameters(self, fitness):\n        # Adaptive scaling based on current population diversity\n        diversity = np.std(fitness)\n        self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + 1e-9))\n        self.F = self.F_base + 0.5 * (diversity / (diversity + 1e-9))\n        self.CR = self.CR_base + 0.1 * (diversity / (diversity + 1e-9))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            self.adaptive_parameters(fitness)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.reinit_prob:\n                    population[i] = np.random.uniform(lb, ub, self.dim)\n                    fitness[i] = func(population[i])\n                    evals += 1\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 71, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11196 with standard deviation 0.03950.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06724174415665574, 0.1390436952809342, 0.09281395835720285, 0.15721017690003902, 0.16610614381970956, 0.1565315949382411, 0.08594193586186327, 0.07244835907804192, 0.0702880552082007]}}
{"id": "b0e7bdbd-0148-4b5a-a057-2eeaccbaac31", "fitness": 0.10031005477749098, "name": "AdaptiveDynamicPSODE", "description": "AdaptiveDynamicPSODE with periodic reset and adaptive DE factors for enhanced convergence speed and robustness.", "code": "import numpy as np\n\nclass AdaptiveDynamicPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.reset_interval = 50  # Interval for periodic reset\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / (np.mean(fitness) + 1e-10)))\n            generation += 1\n\n            # Periodic population reset\n            if generation % self.reset_interval == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE parameters\n            F = np.clip(self.F_base + (0.5 * np.random.randn(self.population_size)), 0, 2)\n            CR = np.clip(self.CR_base + (0.3 * np.random.randn(self.population_size)), 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 72, "feedback": "The algorithm AdaptiveDynamicPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10031 with standard deviation 0.04386.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.05493305262501014, 0.08387791502783448, 0.050918702339966426, 0.15563165851849547, 0.16610614381970956, 0.1591709187464131, 0.08594193586186327, 0.07250737139375507, 0.07370279466437135]}}
{"id": "bfd4a44a-09db-4890-b6e9-29d9e0f7201a", "fitness": 0.10460269899010594, "name": "RefinedHybridPSODE", "description": "RefinedHybridPSODE with adaptive velocity clamping and enhanced DE strategy for improved convergence and stability.", "code": "import numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.alpha = 0.5  # Velocity clamping factor\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            vmax = self.alpha * (ub - lb)\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -vmax, vmax)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 73, "feedback": "The algorithm RefinedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10460 with standard deviation 0.03860.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.08211485894175963, 0.11264388853661567, 0.04714575638941054, 0.1448864182148164, 0.16610614381970956, 0.14927786723097236, 0.08594193586186327, 0.06604479917464334, 0.08726262274116259]}}
{"id": "32dd8955-08db-4b4e-890f-be5a6e1d47f8", "fitness": 0.11300006418777261, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with improved adaptive inertia and refined mutation strategy for better optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(pbest_fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11300 with standard deviation 0.03668.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.1290899388133645, 0.11820011555856447, 0.07236519391139429, 0.14381611915705317, 0.16845581505399643, 0.15666051249040436, 0.08594193586186327, 0.06796228888919464, 0.07450865795411854]}}
{"id": "52ce675f-c9b4-4946-a607-4461dd4ac10b", "fitness": 0.097672752025524, "name": "EnhancedHybridPSODE", "description": "Improved inertia weight adaptation to enhance convergence speed by reducing variance influence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness)**0.5 / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09767 with standard deviation 0.04678.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.044379439436303736, 0.07538431204880625, 0.05369773035863956, 0.14662120719748062, 0.1753620764486722, 0.161557174356466, 0.08594193586186327, 0.07090635089884534, 0.065204541622639]}}
{"id": "bb9aa427-43ad-42eb-b2ae-4aa165aee0ce", "fitness": 0.09717456480460301, "name": "AdaptiveParticleSwarmDifferentialEvolution", "description": "Adaptive Particle Swarm Differential Evolution (APSDE) with dynamic velocity adaptation and oscillating DE parameters for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 3 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Oscillating DE parameters\n            oscillation = np.sin(2 * np.pi * (evals / self.budget))\n            F = self.F_base + (0.4 * oscillation)\n            CR = self.CR_base + (0.2 * np.abs(oscillation))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 76, "feedback": "The algorithm AdaptiveParticleSwarmDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09717 with standard deviation 0.04411.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.05263427524413722, 0.05203588509188062, 0.06802927276729975, 0.1490554690713911, 0.16610614381970956, 0.1580877905695296, 0.08594193586186327, 0.0675811182777134, 0.07509919253790254]}}
{"id": "3fb427f1-bd3c-40d4-94f4-3024afed0fc5", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 44, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.7546749617087607, 0.09654571452282035, 0.024413253636812238, 0.15559475437166348, 0.17811427983198602, 0.14842193549058358, 0.08594193586186327, 0.06998728309854607, 0.06948369240472496]}}
{"id": "ba588161-973d-42c8-bd14-ec1be8bafd46", "fitness": 0.10246600767341191, "name": "EnhancedHybridPSODE", "description": "Incorporate fitness diversity and elitism to improve convergence by maintaining diversity and preserving the best solutions.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.elitism_rate = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = population[elite_indices]\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Preserve elite solutions\n            population[:elite_count] = elite_population\n\n        return gbest", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10247 with standard deviation 0.03921.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.0668900729765356, 0.09286718897204083, 0.06569840332209265, 0.15065666331828398, 0.16610614381970956, 0.1522487020200779, 0.08594193586186327, 0.07278820467316294, 0.0689967540969404]}}
{"id": "633c3010-aa29-4f0a-9b63-74411352f9e5", "fitness": 0.09284305419978303, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive population size and inertia weight decay for improved convergence dynamics.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight decay\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 5 == 0:\n                self.population_size = min(max(5, int(self.population_size * 0.9 + np.random.rand() * 0.2)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09284 with standard deviation 0.04531.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.045170061691299, 0.05670427580706594, 0.04386426667458598, 0.13946035488811048, 0.16610614381970956, 0.15576831902603794, 0.08594193586186327, 0.07477267912772034, 0.06779945090165473]}}
{"id": "b0af1c49-437b-4dfb-9871-d926fc5a1226", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive swarm size and gradient-informed mutation to enhance convergence speed and global search capabilities.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.population_size = self.initial_population_size\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        grad_weight = 0.02  # Weightage for gradient-based mutation\n\n        while evals < self.budget:\n            # Adaptive inertia weight and swarm size\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            if generation % 5 == 0 and evals < self.budget * 0.8:\n                self.population_size = max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n                if self.population_size != len(population):\n                    new_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    new_velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    evals += self.population_size\n                    population = new_population\n                    velocities = new_velocities\n                    fitness = new_fitness\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Gradient-informed mutation\n            for i in range(self.population_size):\n                gradient = np.gradient(fitness[i])\n                mutation_step = grad_weight * gradient * (ub - lb)\n                population[i] = np.clip(population[i] - mutation_step, lb, ub)\n                fitness[i] = func(population[i])\n                evals += 1\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 80, "feedback": "An exception occurred: TypeError(\"can't multiply sequence by non-int of type 'float'\").", "error": "TypeError(\"can't multiply sequence by non-int of type 'float'\")", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {}}
{"id": "7a045e7a-caa2-4cc6-b104-89d3318e0fde", "fitness": 0.11930799739189915, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with strategy diversification using chaotic maps for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        chaos = np.random.rand()\n\n        while evals < self.budget:\n            # Adaptive inertia weight with chaotic map\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            self.w *= self.logistic_map(chaos)\n            chaos = self.logistic_map(chaos)\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                new_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if new_size != self.population_size:\n                    self.population_size = new_size\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters with chaotic influence\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * chaos)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size) * chaos)\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 81, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11931 with standard deviation 0.03605.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.11540568940524587, 0.16306374947124336, 0.08830152316485651, 0.15406535753861805, 0.16610614381970956, 0.14629384763774178, 0.08594193586186327, 0.08163103537913063, 0.07296269424868329]}}
{"id": "56c962c0-5437-48a8-a49f-6b887580bdde", "fitness": 0.10355739090199813, "name": "AdaptivePSODE", "description": "Adaptive PSO-DE with self-tuning parameters via convergence feedback for enhanced robustness in diverse optimization landscapes.", "code": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_init, self.c2_init = 1.5, 1.5\n        self.c1, self.c2 = self.c1_init, self.c2_init\n        self.w_max, self.w_min = 0.9, 0.4\n        self.F_base, self.CR_base = 0.5, 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        prev_gbest_fitness = gbest_fitness\n\n        while evals < self.budget:\n            generation += 1\n            \n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Adaptive cognitive and social parameters\n            if gbest_fitness < prev_gbest_fitness:\n                self.c1 *= 0.9\n                self.c2 *= 1.1\n            else:\n                self.c1 *= 1.1\n                self.c2 *= 0.9\n                \n            prev_gbest_fitness = gbest_fitness\n            self.c1, self.c2 = np.clip(self.c1, 0.5, 2.5), np.clip(self.c2, 0.5, 2.5)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global best\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            # Update global best\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F, CR = np.clip(F, 0, 2), np.clip(CR, 0, 1)\n            \n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global best again after DE\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 82, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10356 with standard deviation 0.04231.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07599671750823522, 0.10005638408226636, 0.03322944277664075, 0.16349107332594737, 0.16610614381970956, 0.14373915506770218, 0.08594193586186327, 0.07965920651811786, 0.08379645915750056]}}
{"id": "a628c5a1-046e-4fb6-9620-e44d77dcfb43", "fitness": 0.09975136730585737, "name": "EnhancedAdaptivePSODE", "description": "EnhancedAdaptivePSODE with self-adaptive parameter tuning for dynamic balance and convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            fitness_var = np.var(fitness)\n            if fitness_var > 0:\n                self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_var / (np.mean(fitness) + 1e-9)))\n            else:\n                self.w = self.w_min\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09975 with standard deviation 0.04667.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.061729388403330865, 0.09453685394437694, 0.028729444547260452, 0.1556331110743473, 0.16610614381970956, 0.16141838093047878, 0.08594193586186327, 0.06995279987249381, 0.07371424729885545]}}
{"id": "f1de761c-b5f5-44a4-bb08-836441040143", "fitness": 0.09843778109572729, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with improved exploration by periodic random restarts and diverse initialization.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Periodic random restart to enhance exploration\n            if generation % 25 == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09844 with standard deviation 0.04817.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06172938839853315, 0.09453685688610125, 0.02867997759562957, 0.15816054554930414, 0.17811427983198602, 0.14748206583636803, 0.08594193586186327, 0.06951854244053668, 0.06177643746122352]}}
{"id": "1e8dceee-0654-42d5-a91e-be5fa51a76f4", "fitness": 0.10283887662004154, "name": "EnhancedHybridPSODEv2", "description": "EnhancedHybridPSODEv2 with adaptive differential evolution parameters and random local search for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.local_search_prob = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.local_search_prob:\n                    local_trial = population[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evals += 1\n                    if local_fitness < fitness[i]:\n                        population[i], fitness[i] = local_trial, local_fitness\n                \n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedHybridPSODEv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10284 with standard deviation 0.04149.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.0556765597006007, 0.09193846904133685, 0.05944762518456226, 0.15603977996072427, 0.16610614381970956, 0.15604434244790621, 0.08594193586186327, 0.07741386427975827, 0.07694116928391248]}}
{"id": "b0058074-86a5-4084-b879-8907a069cd1b", "fitness": 0.09770714505321125, "name": "EnhancedHybridPSODE", "description": "Introduce self-adaptive DE parameters adjustment for a more dynamic search capability.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive DE parameters\n            F = self.F_base * (1 + 0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base * (1 + 0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09771 with standard deviation 0.04552.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07285603788290052, 0.10019389091435804, 0.02365608357129889, 0.1517537228989625, 0.16610614381970956, 0.14912002038578576, 0.08594193586186327, 0.06460738299621704, 0.06512908714780563]}}
{"id": "fabd227c-d5c2-4ad7-a15d-3049a71c120e", "fitness": 0.10027670533713887, "name": "EnhancedHybridPSODE", "description": "Minor enhancement of mutation strategy in DE for improved diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                if np.random.rand() < 0.1:  # Enhance mutation strategy\n                    mutant = x0  # Use base vector sometimes to increase diversity\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10028 with standard deviation 0.04039.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.03512671229908704, 0.07755019011464426, 0.10034092963973451, 0.1436367132532489, 0.16610614381970956, 0.14506359092568233, 0.08594193586186327, 0.08306886550009907, 0.06565526662018084]}}
{"id": "40fba928-679d-40f1-b134-a1329ec5e58b", "fitness": 0.09751833885972856, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with dynamic strategies and diversity preservation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 1e-5  # Diversity threshold\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                if np.std(population) < self.diversity_threshold:\n                    population[i] = np.random.uniform(lb, ub, self.dim)  # Reinitialize when diversity is low\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09752 with standard deviation 0.04924.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04916220051855713, 0.09654571452282035, 0.024413253636812238, 0.15559475437166348, 0.17811427983198602, 0.14842193549058358, 0.08594193586186327, 0.06998728309854607, 0.06948369240472496]}}
{"id": "15b73fc3-3dc0-4efe-bc4e-11149dbb1aea", "fitness": 0.10233699373575396, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive velocity scaling and diversity maintenance strategy to improve global search and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight based on diversity measure\n            diversity = np.mean(np.std(population, axis=0))\n            self.w = self.w_max - ((self.w_max - self.w_min) * (diversity / np.max(ub - lb)))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Diversity maintenance via DE mutation and recombination\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10234 with standard deviation 0.03936.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07564474949860156, 0.08067104598224661, 0.058888671602071785, 0.14816294539222408, 0.16610614381970956, 0.15625731661159603, 0.08594193586186327, 0.07566138473256434, 0.07369875012090843]}}
{"id": "c3d4ab03-6291-472c-8b8c-60ca47a438dc", "fitness": 0.10925713224974565, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive velocity clamping for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            # Adaptive velocity clamping\n            vel_max = 0.1 * (ub - lb)\n            velocities = np.clip(velocities, -vel_max, vel_max)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10926 with standard deviation 0.03614.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.08062005391051452, 0.1275370176354519, 0.07295819963020622, 0.14540635359174658, 0.16610614381970956, 0.15339026197658834, 0.08594193586186327, 0.07547126260094561, 0.07588296122068483]}}
{"id": "ecd9aa37-bb8a-4860-8444-a329c0a48458", "fitness": 0.10246226488220928, "name": "ImprovedEnhancedHybridPSODE", "description": "ImprovedEnhancedHybridPSODE with adaptive velocity clamping and elitist selection to enhance convergence and maintain diversity.", "code": "import numpy as np\n\nclass ImprovedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Elitist selection for dynamic population adjustment\n            if generation % 10 == 0:\n                elite_size = max(1, self.population_size // 5)\n                elite_indices = np.argsort(fitness)[:elite_size]\n                population = population[elite_indices]\n                velocities = velocities[elite_indices]\n                fitness = fitness[elite_indices]\n                pbest = pbest[elite_indices]\n                pbest_fitness = pbest_fitness[elite_indices]\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                \n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                new_pop = np.random.uniform(lb, ub, (self.population_size - elite_size, self.dim))\n                population = np.vstack((population, new_pop))\n                velocities = np.vstack((velocities, np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size - elite_size, self.dim))))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -abs(ub - lb), abs(ub - lb))\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 91, "feedback": "The algorithm ImprovedEnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10246 with standard deviation 0.04059.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.07161738727332856, 0.09439215502437703, 0.06599295650059411, 0.1528190429869397, 0.16610614381970956, 0.1554115685510662, 0.08594193586186327, 0.06374350567491427, 0.06613568824709071]}}
{"id": "6760f765-b2fb-4ce3-a5c9-88a739a56c38", "fitness": 0.09748006583136565, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive multi-swarm topology and self-adaptive parameter adjustment for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.num_swarms = 3  # Number of swarms\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Create swarms and assign particles\n            swarm_size = self.population_size // self.num_swarms\n            swarms = [population[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_velocities = [velocities[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_pbest = [pbest[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_pbest_fitness = [pbest_fitness[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            \n            # Update each swarm\n            for s in range(self.num_swarms):\n                r1, r2 = np.random.rand(swarm_size, self.dim), np.random.rand(swarm_size, self.dim)\n                swarm_velocities[s] = self.w * swarm_velocities[s] + self.c1 * r1 * (swarm_pbest[s] - swarms[s]) + self.c2 * r2 * (gbest - swarms[s])\n                swarms[s] = np.clip(swarms[s] + swarm_velocities[s], lb, ub)\n                swarm_fitness = np.array([func(x) for x in swarms[s]])\n                evals += swarm_size\n                \n                better_indices = swarm_fitness < swarm_pbest_fitness[s]\n                swarm_pbest[s][better_indices] = swarms[s][better_indices]\n                swarm_pbest_fitness[s][better_indices] = swarm_fitness[better_indices]\n                \n                if np.min(swarm_fitness) < gbest_fitness:\n                    gbest = swarms[s][np.argmin(swarm_fitness)]\n                    gbest_fitness = np.min(swarm_fitness)\n            \n            # Recombination across swarms using DE\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09748 with standard deviation 0.04445.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.05915315435757673, 0.0448988462246781, 0.07591483620828265, 0.16321691418420092, 0.16680084129101347, 0.14402556170484115, 0.08594193586186327, 0.06915292983510268, 0.0682155728147319]}}
{"id": "546a6f5c-1c86-4c36-8298-d863b9925be9", "fitness": 0.10038947737183775, "name": "AdaptiveHybridPSODE", "description": "AdaptiveHybridPSODE with self-adaptive parameter scaling and elite preservation for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Self-adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            # Elite preservation\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Adaptive DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            # Update the global best\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 93, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10039 with standard deviation 0.04041.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04598110097817809, 0.10242346322356899, 0.06937390843792723, 0.14272011972302756, 0.16610614381970956, 0.1512344675046703, 0.08594193586186327, 0.07121957899001963, 0.06850457780757513]}}
{"id": "191f881d-a8de-4160-beec-d2e124dd52a9", "fitness": 0.10024441244061313, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE++ with stochastic restarts and adaptive population size scaling for improved global search capability and convergence speed.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.restart_threshold = 0.1  # Threshold for stagnation\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            if np.random.rand() < self.restart_threshold:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n        return gbest", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10024 with standard deviation 0.04601.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.04423720080974258, 0.07989543158766033, 0.053690083085971785, 0.14979857327434043, 0.16610614381970956, 0.17163089990884428, 0.08594193586186327, 0.0779454737063131, 0.07295396991107284]}}
{"id": "0fd686e0-7dca-4593-854b-a8860f41836a", "fitness": 0.097672752025524, "name": "EnhancedHybridPSODE", "description": "Minor improvement by tuning inertia weight variance calculation for better convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))  # Changed var to std\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09767 with standard deviation 0.04678.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.044379439436303736, 0.07538431204880625, 0.05369773035863956, 0.14662120719748062, 0.1753620764486722, 0.161557174356466, 0.08594193586186327, 0.07090635089884534, 0.065204541622639]}}
{"id": "ce819884-840f-4c3c-829c-09e20d906275", "fitness": 0.09739341285756176, "name": "AdaptiveDynamicPSODE", "description": "AdaptiveDynamicPSODE combines dynamic population resizing with adaptive differential evolution parameters and a diversity preservation mechanism for robust exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveDynamicPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 1e-5  # Diversity threshold for population refresh\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / (np.mean(fitness) + 1e-9)))\n            generation += 1\n            \n            if generation % 5 == 0 or np.var(fitness) < self.diversity_threshold:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    new_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    evals += self.population_size\n                    # Preserve top performers\n                    if np.min(new_fitness) < gbest_fitness:\n                        gbest = new_population[np.argmin(new_fitness)]\n                        gbest_fitness = np.min(new_fitness)\n                    population, fitness = new_population, new_fitness\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.rand(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.rand(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 96, "feedback": "The algorithm AdaptiveDynamicPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09739 with standard deviation 0.04380.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.049910161951799425, 0.07086973393905971, 0.048932101892187885, 0.14982943329590492, 0.1665574431191037, 0.15448945231677635, 0.08594193586186327, 0.07884561886168151, 0.07116483447967903]}}
{"id": "81a031ca-dd68-4ed9-8c2c-7301f8b4525c", "fitness": -Infinity, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with adaptive learning rates, dynamic topology, and chaotic search to improve convergence speed and stability.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.alpha = 0.5  # Learning rate for adaptive changes\n        self.beta = 0.05  # Learning rate for chaotic search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        topology = np.random.rand(self.population_size, self.population_size) < 0.5\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic topology adjustment\n            if generation % 5 == 0:\n                topology = np.random.rand(self.population_size, self.population_size) < 0.5\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 @ topology * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Dynamic DE parameters\n            F = self.F_base + self.alpha * (1 - generation/self.budget) * np.random.randn(self.population_size)\n            CR = self.CR_base + self.alpha * (1 - generation/self.budget) * np.random.randn(self.population_size)\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Introducing chaotic search for refining global best\n            chaos = self.beta * (gbest - np.mean(population, axis=0))\n            chaotic_candidate = np.clip(gbest + chaos, lb, ub)\n            chaotic_fitness = func(chaotic_candidate)\n            evals += 1\n\n            if chaotic_fitness < gbest_fitness:\n                gbest = chaotic_candidate\n                gbest_fitness = chaotic_fitness\n\n        return gbest", "configspace": "", "generation": 97, "feedback": "An exception occurred: ValueError('matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 10)').", "error": "ValueError('matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 10)')", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {}}
{"id": "daf5b065-282d-4bd2-b81c-ff8b9e593d70", "fitness": 0.10194010868774248, "name": "EnhancedHybridPSODE", "description": "EnhancedHybridPSODE with diversity-preserving mechanism and adaptive local search to improve exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Diversity-preserving mechanism\n            if generation % 5 == 0:\n                diversity = np.std(population, axis=0)\n                if np.all(diversity < 0.1):  # Threshold for diversity check\n                    rand_indices = np.random.choice(self.population_size, size=int(self.population_size * 0.1), replace=False)\n                    population[rand_indices] = np.random.uniform(lb, ub, (len(rand_indices), self.dim))\n                    velocities[rand_indices] = np.random.uniform(-abs(ub - lb), abs(ub - lb), (len(rand_indices), self.dim))\n                    fitness[rand_indices] = [func(x) for x in population[rand_indices]]\n                    evals += len(rand_indices)\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive Local Search\n            if evals < 0.9 * self.budget and np.random.rand() < 0.1:\n                perturbation = np.random.normal(0, 0.1 * (ub - lb), self.dim)\n                local_candidate = np.clip(gbest + perturbation, lb, ub)\n                local_fitness = func(local_candidate)\n                evals += 1\n                if local_fitness < gbest_fitness:\n                    gbest, gbest_fitness = local_candidate, local_fitness\n\n        return gbest", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10194 with standard deviation 0.04494.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06881778809238581, 0.09727939105579642, 0.0318679827025119, 0.16068145222578356, 0.16610614381970956, 0.15586684081424584, 0.08594193586186327, 0.0779454737063131, 0.07295396991107284]}}
{"id": "098386b8-43ea-47c6-b094-b2fcd0a96ada", "fitness": 0.1001593029036625, "name": "EnhancedHybridPSODE", "description": "Refinement of EnhancedHybridPSODE with increased mutation factor range for greater diversity.", "code": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.8  # Increased base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10016 with standard deviation 0.04778.", "error": "", "parent_ids": ["4d789e09-b735-4349-bb24-78b6414d5ea6"], "operator": null, "metadata": {"aucs": [0.06929961269319351, 0.0921619689901726, 0.027407260960540025, 0.15913296647908615, 0.16610614381970956, 0.1642617024981341, 0.08594193586186327, 0.07584136064718294, 0.06128077418308031]}}
