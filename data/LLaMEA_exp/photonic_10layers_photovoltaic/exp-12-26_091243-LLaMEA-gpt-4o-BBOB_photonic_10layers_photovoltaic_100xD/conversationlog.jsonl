{"role": "client", "time": "2025-12-26 09:12:43.802058", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:12:53.135021", "content": "# Description: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```\n"}
{"role": "client", "time": "2025-12-26 09:12:53.612318", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:12:58.646772", "content": "# Description: A hybrid particle swarm algorithm integrating adaptive velocity control and dynamic differential evolution to enhance convergence speed and precision in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9 # Maximum inertia weight\n        self.w_min = 0.4 # Minimum inertia weight\n        self.w = self.w_max\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.evals = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        self.evals += self.population_size\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        \n        while self.evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (self.evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F_dynamic = self.F * (1 - (self.evals / self.budget))  # Dynamic scaling factor\n                mutant = x0 + F_dynamic * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                self.evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:12:59.594154", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.5% of the code, which means if the code has 100 lines, you can only change 4.545454545454546 lines, and the rest of the lines should remain unchanged. This input code has 66 lines, so you can only change 3 lines, the rest 63 lines should remain unchanged. This changing rate 4.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:04.084661", "content": "# Description: Enhanced HybridPSODE by leveraging adaptive inertia weight for improved convergence in black box optimization.\n# Code: \n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_min = 0.4   # Minimum inertia weight\n        self.w_max = 0.9   # Maximum inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.evals = 0\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        self.evals = self.population_size\n        \n        while self.evals < self.budget:\n            # Adaptive Inertia Weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (self.evals / self.budget)\n\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            self.evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                self.evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:04.682530", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.5% of the code, which means if the code has 100 lines, you can only change 4.545454545454546 lines, and the rest of the lines should remain unchanged. This input code has 66 lines, so you can only change 3 lines, the rest 63 lines should remain unchanged. This changing rate 4.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:09.116283", "content": "# Description: A refined hybrid particle swarm algorithm with adaptive inertia weight for improved exploration-exploitation trade-off in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:09.595303", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.5% of the code, which means if the code has 100 lines, you can only change 4.545454545454546 lines, and the rest of the lines should remain unchanged. This input code has 66 lines, so you can only change 3 lines, the rest 63 lines should remain unchanged. This changing rate 4.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:14.219497", "content": "# Description: Improved the hybrid optimization strategy by introducing a dynamic inertia weight for better convergence.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F = 0.8  # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Update inertia weight dynamically\n            self.w = self.w_max - (self.w_max - self.w_min) * (evals / self.budget)\n\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:14.833389", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 4.5% of the code, which means if the code has 100 lines, you can only change 4.545454545454546 lines, and the rest of the lines should remain unchanged. This input code has 66 lines, so you can only change 3 lines, the rest 63 lines should remain unchanged. This changing rate 4.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:18.498208", "content": "# Description: A hybrid particle swarm algorithm with adaptive parameters for enhanced exploration and exploitation balance in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.9   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - 0.5 * (evals / self.budget)  # Adaptive inertia weight\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:18.974675", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHybridPSODE: A hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization. (Score: 0.0997303614338809)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating differential evolution for enhanced exploration and exploitation balance in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential evolution's mutation factor\n        self.CR = 0.9  # Crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09973 with standard deviation 0.04248.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:24.902404", "content": "# Description: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:25.725443", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.8% of the code, which means if the code has 100 lines, you can only change 3.8461538461538463 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 3 lines, the rest 75 lines should remain unchanged. This changing rate 3.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:29.807992", "content": "# Description: Enhanced hybrid PSO-DE with dynamic mutation factor scaling for improved convergence and exploration balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + ((0.2 + 0.1 * (generation / (self.budget / self.population_size))) * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:30.743109", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:38.460472", "content": "# Description: Quantum-inspired Enhanced Hybrid PSODE integrates quantum superposition and collapse mechanisms into the existing particle swarm and differential evolution framework for improved exploration and convergence in black box optimization.\n\n# Code:\n```python\nimport numpy as np\n\nclass QuantumEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                \n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Quantum-inspired step: Superposition and collapse\n            if generation % 5 == 0:\n                quantum_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                quantum_fitness = np.array([func(x) for x in quantum_population])\n                evals += self.population_size\n                for i in range(self.population_size):\n                    if quantum_fitness[i] < fitness[i]:\n                        population[i], fitness[i] = quantum_population[i], quantum_fitness[i]\n                        pbest[i] = population[i]\n                        pbest_fitness[i] = fitness[i]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:39.365549", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.3% of the code, which means if the code has 100 lines, you can only change 1.282051282051282 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 1 lines, the rest 77 lines should remain unchanged. This changing rate 1.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:43.498784", "content": "# Description: An improved hybrid particle swarm algorithm that enhances global best influence for better convergence in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + (self.c2 + 0.1) * r2 * (gbest - population)  # Modified line\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:43.987064", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.8% of the code, which means if the code has 100 lines, you can only change 3.8461538461538463 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 3 lines, the rest 75 lines should remain unchanged. This changing rate 3.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:48.842911", "content": "# Description: A refined hybrid PSO-DE algorithm with strategic non-uniform mutation and dynamic parameter adjustment for enhanced robustness in optimization.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.5, 2)  # Adjusted lower bound of F\n            CR = np.clip(CR, 0.1, 1)  # Adjusted lower bound of CR\n            \n            # Differential Evolution Step with strategic mutation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + F[i] * (x1 - x2), lb, ub)  # Ensure mutant is within bounds\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:49.891324", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:13:56.786948", "content": "# Description: An enhanced hybrid particle swarm and differential evolution algorithm utilizing dynamically adjusted learning rates based on population diversity to improve convergence and exploration in black box optimization.\n\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Calculate population diversity\n            diversity = np.mean(np.std(population, axis=0))\n            adapt_factor = 1 + (diversity / np.mean(ub - lb))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size)) * adapt_factor\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size)) * adapt_factor\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:13:57.302096", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.8% of the code, which means if the code has 100 lines, you can only change 3.8461538461538463 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 3 lines, the rest 75 lines should remain unchanged. This changing rate 3.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:03.171703", "content": "# Description: Introducing a dynamic mutation factor adjustment based on diversity metrics to improve convergence in the hybrid particle swarm and differential evolution algorithm.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic mutation factor based on diversity\n            diversity = np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n            F = self.F_base + 0.5 * (diversity / (ub - lb).max())\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:04.152740", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:09.536050", "content": "# Description: An enhanced hybrid particle swarm and differential evolution algorithm using dynamic parameters and Gaussian mutation for improved convergence in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Dynamic inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step with Gaussian Mutation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 4, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 4, replace=False)\n                x0, x1, x2, x3 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2) + np.random.normal(0, 0.001, self.dim)  # Gaussian mutation\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:10.054982", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.3% of the code, which means if the code has 100 lines, you can only change 1.282051282051282 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 1 lines, the rest 77 lines should remain unchanged. This changing rate 1.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:14.644519", "content": "# Description: An advanced hybrid particle swarm optimizer with a refined adaptive differential evolution for improved exploration and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.5, 2)  # Increased lower bound for mutation factor F\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:15.137540", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:20.468297", "content": "# Description: An enhanced hybrid particle swarm algorithm with dynamic parameter adaptation and elite selection to improve convergence and solution diversity in black box optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_min, self.c1_max = 1.0, 2.5  # Adaptive cognitive parameter\n        self.c2_min, self.c2_max = 1.0, 2.5  # Adaptive social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.elite_fraction = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            self.c1 = self.c1_max - ((self.c1_max - self.c1_min) * (evals / self.budget))\n            self.c2 = self.c2_min + ((self.c2_max - self.c2_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]\n            elite_population = population[elite_indices]\n            \n            for i in range(self.population_size):\n                if i in elite_indices:\n                    continue\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices or any(index in elite_indices for index in indices):\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:21.076533", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:26.912122", "content": "# Description: An enhanced hybrid particle swarm and differential evolution algorithm using dynamic population resizing and local search to improve convergence and exploration efficiency.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.local_search_prob = 0.1  # Probability threshold for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            # Differential Evolution Step\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Local Search Enhancement\n            if np.random.rand() < self.local_search_prob:\n                local_candidate = gbest + np.random.randn(self.dim) * 0.1 * (ub - lb)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_fitness = func(local_candidate)\n                evals += 1\n                if local_fitness < gbest_fitness:\n                    gbest, gbest_fitness = local_candidate, local_fitness\n\n            # Dynamic Population Resizing\n            population_size = max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:26.921282", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: A hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization. (Score: 0.1102580504789819)\n\nThe selected solution to update is:\nA hybrid particle swarm algorithm integrating adaptive inertia weight and self-adaptive differential evolution for enhanced exploration and convergence in black box optimization.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Particle Swarm Optimization Step\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive differential evolution parameters\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global bests again after DE step\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11026 with standard deviation 0.04223.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 21.8% of the code, which means if the code has 100 lines, you can only change 21.794871794871796 lines, and the rest of the lines should remain unchanged. This input code has 78 lines, so you can only change 17 lines, the rest 61 lines should remain unchanged. This changing rate 21.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:32.782227", "content": "# Description: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:33.767041", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.1764705882352942 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 1 lines, the rest 84 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:40.092763", "content": "# Description: A refined hybrid PSO-DE algorithm utilizing adaptive adjustment of inertia weight and mutation factors for improved performance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.rand(self.population_size))  # Change: using random.rand for more varied mutation factor\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:40.580340", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:49.562773", "content": "# Description: A multi-population cooperative PSO-DE algorithm with adaptive local search intensification for enhanced diversity and convergence speed.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest, pbest_fitness = population.copy(), fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest, pbest_fitness = population.copy(), fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            local_search_threshold = np.percentile(fitness, 20)  # Top 20% for local search intensification\n            for i in range(self.population_size):\n                if fitness[i] < local_search_threshold:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:50.022527", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:14:57.481809", "content": "# Description: An enhanced PSO-DE hybrid with adaptive inertia weight, stochastic opposition-based learning, and elite-based mutation for accelerated convergence and robustness across diverse optimization landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        def stochastic_opposition(x, lb, ub):\n            return lb + ub - x + np.random.uniform(-0.1 * (ub - lb), 0.1 * (ub - lb), x.shape)\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.rand(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.rand(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            elite = population[np.argsort(fitness)[:3]]  # Select top 3 elites\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                x0 = elite[np.random.randint(0, 3)]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Stochastic Opposition-Based Learning\n            opposition_population = stochastic_opposition(population, lb, ub)\n            opposition_fitness = np.array([func(x) for x in opposition_population])\n            evals += self.population_size\n\n            improved = opposition_fitness < fitness\n            population[improved] = opposition_population[improved]\n            fitness[improved] = opposition_fitness[improved]\n            pbest[improved] = opposition_population[improved]\n            pbest_fitness[improved] = opposition_fitness[improved]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:14:57.917383", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:04.573022", "content": "# Description: Introducing adaptive inertia dynamics and multi-trial DE strategy to enhance convergence by balancing exploration and exploitation in a hybrid PSO-DE algorithm.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight based on fitness distribution\n            self.w = self.w_max - ((self.w_max - self.w_min) * np.var(fitness) / (np.mean(fitness) + 1e-10))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # New multi-trial DE strategy\n            for i in range(self.population_size):\n                if evals >= self.budget:\n                    break\n                for _ in range(3):  # Perform multiple trials\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n                        break\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:05.174735", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.1764705882352942 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 1 lines, the rest 84 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:10.005691", "content": "# Description: Introduced adaptive crossover probability scaling based on generation to enhance exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * (1 - evals / self.budget))  # Adaptive scaling for CR based on progress\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:10.011701", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 14.1% of the code, which means if the code has 100 lines, you can only change 14.117647058823529 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 12 lines, the rest 73 lines should remain unchanged. This changing rate 14.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:15.033117", "content": "# Description: An enhanced adaptive hybrid PSO-DE algorithm with improved inertia weight and mutation strategies for better convergence efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.7  # Tweaked Cognitive parameter\n        self.c2 = 1.3  # Tweaked Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.6  # Modified Base mutation factor for DE\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Improved inertia weight update\n            self.w = self.w_max - ((self.w_max - self.w_min) * ((evals/self.budget) ** 0.5))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.15 * np.random.randn(self.population_size))  # Changed random factor for F\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```\n\n"}
{"role": "client", "time": "2025-12-26 09:15:15.521694", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:21.352426", "content": "# Description: An adaptive hybrid PSO-DE algorithm with meta-learning to dynamically adjust control parameters for enhanced convergence speed and solution accuracy.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.base_c1 = 1.5\n        self.base_c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.base_F = 0.5\n        self.base_CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * evals / self.budget)\n            # Meta-learning to adjust cognitive and social parameters\n            self.c1, self.c2 = self._meta_learning(fitness, pbest_fitness)\n\n            generation += 1\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                F = self.base_F + 0.2 * np.random.randn()\n                CR = self.base_CR + 0.1 * np.random.randn()\n                F = np.clip(F, 0, 2)\n                CR = np.clip(CR, 0, 1)\n\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\n    def _meta_learning(self, fitness, pbest_fitness):\n        # Adjust the cognitive and social parameters based on the improvement\n        improvement_ratio = np.mean(pbest_fitness) / np.mean(fitness)\n        c1 = self.base_c1 * (1 + improvement_ratio)\n        c2 = self.base_c2 * (1 - improvement_ratio)\n        return np.clip(c1, 0.5, 2.5), np.clip(c2, 0.5, 2.5)\n```"}
{"role": "client", "time": "2025-12-26 09:15:21.980653", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:30.831558", "content": "# Description: EnhancedHybridPSODE+: Improved enhanced hybrid PSO-DE with adaptive inertia weight modulation and crowding distance-based selection for better exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                else:\n                    # Use crowding distance-based selection to maintain diversity\n                    if np.linalg.norm(mutant - gbest) > np.linalg.norm(population[i] - gbest):\n                        population[i] = mutant\n                        fitness[i] = trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n        \n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:31.346864", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:38.165211", "content": "# Description: A self-adaptive hybrid PSO-DE algorithm with chaotic initialization and elitist learning to enhance convergence and global exploration.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def chaotic_initialization(self, lb, ub):\n        # Use a logistic map for chaotic sequence generation\n        x = np.random.rand(self.population_size, self.dim)\n        for _ in range(100):  # Iterate to spread chaos\n            x = 4 * x * (1 - x)\n        return lb + x * (ub - lb)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = self.chaotic_initialization(lb, ub)\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:39.119008", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.1764705882352942 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 1 lines, the rest 84 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:44.938440", "content": "# Description: Refinement of inertia weight adaptation for improved convergence stability in EnhancedHybridPSODE.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / (self.budget/self.population_size)))  # Changed line\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:45.430341", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:51.975076", "content": "# Description: An improved hybrid PSO-DE algorithm that integrates inertia weight adaptation based on fitness variance and implements a leader strategy for enhanced convergence stability.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            fitness_var = np.var(fitness)\n            self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_var / (fitness_var + gbest_fitness)))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:53.182211", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:15:59.310279", "content": "# Description: Introduce an adaptive local search phase and diversity preservation strategy to enhance solution accuracy and convergence speed in the Enhanced Hybrid PSO-DE algorithm.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODERefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.local_search_prob = 0.1  # Probability to perform local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Adaptive local search for diversity preservation\n            for i in range(self.population_size):\n                if np.random.rand() < self.local_search_prob:\n                    candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_fitness = func(candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[i]:\n                        population[i] = candidate\n                        fitness[i] = candidate_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:15:59.797027", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:09.617005", "content": "# Description: An extended adaptive PSO-DE with self-learning mutation strategies based on performance feedback to enhance convergence and diversity.\n# Code:\n```python\nimport numpy as np\n\nclass ExtendedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.strategy_rates = np.array([1.0, 1.0])  # Performance feedback for mutation strategies\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE Strategy\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            # Evaluate DE strategies\n            strategy_performance = np.zeros(2)\n            for i in range(self.population_size):\n                if np.random.rand() < self.strategy_rates[0] / self.strategy_rates.sum():\n                    # Strategy 1: DE/rand/1/bin\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                else:\n                    # Strategy 2: DE/best/1/bin\n                    indices = np.random.choice(self.population_size, 2, replace=False)\n                    indices = np.append(indices, np.argmin(fitness))\n\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n                    strategy_performance[0 if indices[2] == x2 else 1] += 1\n\n            # Update strategy rates\n            self.strategy_rates += strategy_performance\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```\n"}
{"role": "client", "time": "2025-12-26 09:16:09.623859", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:14.589634", "content": "# Description: An advanced PSO-DE hybrid algorithm with adaptive strategies for inertia, mutation, and crossover rates to enhance search efficiency and solution accuracy.\n# Code:\n```python\nimport numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.alpha = 0.05  # Scaling factor for adaptive parameters\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * ((gbest_fitness - np.min(fitness)) / np.ptp(fitness))\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Adaptive mutation and crossover rates\n            F = np.clip(self.F_base + self.alpha * np.tanh((gbest_fitness - fitness) / np.std(fitness)), 0, 2)\n            CR = np.clip(self.CR_base + self.alpha * np.tanh((fitness - np.mean(fitness)) / np.std(fitness)), 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:15.112850", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:22.181433", "content": "# Description: Incorporate a multi-swarm strategy and adaptive diversity mechanism into the hybrid PSO-DE framework to enhance exploration and convergence balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_count = 3  # Number of swarms for multi-swarm strategy\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 0.1  # Threshold to trigger diversity enhancement\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [self._initialize_swarm(lb, ub) for _ in range(self.swarm_count)]\n        gbest_fitness_overall = np.inf\n        evals = 0\n        \n        while evals < self.budget:\n            for swarm in swarms:\n                population, velocities, fitness, pbest, pbest_fitness, gbest, gbest_fitness = swarm\n                generation = 0\n                while evals < self.budget:\n                    self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n                    generation += 1\n                    r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                    velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n                    population = np.clip(population + velocities, lb, ub)\n                    fitness = np.array([func(x) for x in population])\n                    evals += self.population_size\n\n                    better_indices = fitness < pbest_fitness\n                    pbest[better_indices] = population[better_indices]\n                    pbest_fitness[better_indices] = fitness[better_indices]\n\n                    if np.min(fitness) < gbest_fitness:\n                        gbest = population[np.argmin(fitness)]\n                        gbest_fitness = np.min(fitness)\n\n                    # Adaptive Diversity Mechanism\n                    if generation % 10 == 0:\n                        diversity = np.mean(np.std(population, axis=0))\n                        if diversity < self.diversity_threshold:\n                            # Introduce diversity by perturbing population\n                            population += np.random.uniform(-0.1, 0.1, population.shape) * (ub - lb)\n                            population = np.clip(population, lb, ub)\n                            fitness = np.array([func(x) for x in population])\n                            evals += self.population_size\n\n                    F = self.F_base + (0.2 * np.random.randn(self.population_size))\n                    CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n                    F = np.clip(F, 0, 2)\n                    CR = np.clip(CR, 0, 1)\n\n                    for i in range(self.population_size):\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                        while i in indices:\n                            indices = np.random.choice(self.population_size, 3, replace=False)\n                        x0, x1, x2 = population[indices]\n                        mutant = x0 + F[i] * (x1 - x2)\n                        cross_points = np.random.rand(self.dim) < CR[i]\n                        trial = np.where(cross_points, mutant, population[i])\n                        trial = np.clip(trial, lb, ub)\n                        trial_fitness = func(trial)\n                        evals += 1\n                        if trial_fitness < fitness[i]:\n                            population[i], fitness[i] = trial, trial_fitness\n\n                    better_indices = fitness < pbest_fitness\n                    pbest[better_indices] = population[better_indices]\n                    pbest_fitness[better_indices] = fitness[better_indices]\n\n                    if np.min(fitness) < gbest_fitness:\n                        gbest = population[np.argmin(fitness)]\n                        gbest_fitness = np.min(fitness)\n\n                # Update overall best\n                if gbest_fitness < gbest_fitness_overall:\n                    gbest_fitness_overall = gbest_fitness\n                    gbest_overall = gbest\n\n        return gbest_overall\n\n    def _initialize_swarm(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        return population, velocities, fitness, pbest, pbest_fitness, gbest, gbest_fitness\n```"}
{"role": "client", "time": "2025-12-26 09:16:22.185335", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:28.477834", "content": "# Description: Introducing adaptive inertia adjustment and local search enhancements to improve convergence and solution quality in EnhancedHybridPSODE.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Introduce a local search phase at every 15 generations\n            if generation % 15 == 0:\n                for i in range(self.population_size):\n                    local_search_candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    local_search_candidate = np.clip(local_search_candidate, lb, ub)\n                    candidate_fitness = func(local_search_candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[i]:\n                        population[i], fitness[i] = local_search_candidate, candidate_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:28.982591", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:35.449384", "content": "# Description: A Gradient-Informed Hybrid PSO-DE algorithm that leverages gradient information for adaptive mutation and crossover strategies, improving convergence efficiency and precision.\n# Code:\n```python\nimport numpy as np\n\nclass GradientInformedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Calculate gradient approximation\n            gradients = np.zeros((self.population_size, self.dim))\n            for i in range(self.population_size):\n                perturbation = np.random.uniform(-1e-8, 1e-8, self.dim)\n                gradients[i] = (func(population[i] + perturbation) - fitness[i]) / perturbation\n                evals += 1\n                if evals >= self.budget:\n                    break\n\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population) - 0.1 * gradients\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2) - 0.1 * gradients[i]\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if evals >= self.budget:\n                    break\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:35.900329", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 29.4% of the code, which means if the code has 100 lines, you can only change 29.411764705882355 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 25 lines, the rest 60 lines should remain unchanged. This changing rate 29.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:41.451617", "content": "# Description: A refined hybrid PSO-DE algorithm using adaptive learning rates and a multi-phase strategy for enhanced convergence and diversity.\n\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.7  # Cognitive parameter\n        self.c2 = 1.7  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.learning_rate = 0.1   # New learning rate parameter\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Multi-phase strategy\n            if generation % 15 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 5)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities *= self.learning_rate\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.3 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.15 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:41.942021", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:50.058230", "content": "# Description: Introduce a Levy flight mechanism for enhanced exploration and adaptively adjust DE parameters based on swarm diversity to optimize the EnhancedHybridPSODE algorithm.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def levy_flight(self, lambda_=1.5):\n        sigma = (np.math.gamma(1 + lambda_) * np.sin(np.pi * lambda_ / 2) / \n                 (np.math.gamma((1 + lambda_) / 2) * lambda_ * 2**((lambda_ - 1) / 2)))** (1 / lambda_)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / lambda_)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        diversity_threshold = 0.1 * np.linalg.norm(ub - lb)\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic strategy based on diversity\n            diversity = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n            if diversity < diversity_threshold:\n                self.F_base = 0.5 + 0.5 * np.random.rand()\n                self.CR_base = 0.1 + 0.8 * np.random.rand()\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = np.random.uniform(0.5, 1.0, self.population_size)\n            CR = np.random.uniform(0.1, 1.0, self.population_size)\n\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:\n                    trial = population[i] + self.levy_flight()\n                else:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:51.460183", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 5.9% of the code, which means if the code has 100 lines, you can only change 5.88235294117647 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 5 lines, the rest 80 lines should remain unchanged. This changing rate 5.9% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:16:56.838152", "content": "# Description: Improved hybrid PSO-DE algorithm enhancing velocity control and intermittent DE application for better convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Improved velocity control with adaptive inertia\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            # Applying DE selectively every few generations for diversity\n            if generation % 5 == 0:\n                for i in range(self.population_size):\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    while i in indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = x0 + F[i] * (x1 - x2)\n                    cross_points = np.random.rand(self.dim) < CR[i]\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial = np.clip(trial, lb, ub)\n                    trial_fitness = func(trial)\n                    evals += 1\n                    if trial_fitness < fitness[i]:\n                        population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:16:57.177165", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 9.4% of the code, which means if the code has 100 lines, you can only change 9.411764705882353 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 8 lines, the rest 77 lines should remain unchanged. This changing rate 9.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:04.115846", "content": "# Description: EnhancedHybridPSODE with adaptive parameter tuning using historical fitness improvement for refined balance between exploration and exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        fitness_history = [gbest_fitness]\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Adaptive parameter tuning\n            if len(fitness_history) > 5:\n                history_improvement = fitness_history[-5] - gbest_fitness\n                if history_improvement < 0.01 * abs(np.mean(fitness_history)):\n                    self.c1, self.c2 = 0.5, 0.5\n                else:\n                    self.c1, self.c2 = 2.0, 2.0\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                fitness_history.append(gbest_fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:04.608428", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.2% of the code, which means if the code has 100 lines, you can only change 1.1764705882352942 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 1 lines, the rest 84 lines should remain unchanged. This changing rate 1.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:09.678714", "content": "# Description: Fine-tuning crossover probability scaling to balance exploration and exploitation in the Enhanced Hybrid PSO-DE algorithm.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.15 * np.random.randn(self.population_size))  # Changed from 0.1 to 0.15\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:10.174796", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:15.518084", "content": "# Description: An adaptive hybrid PSO-DE algorithm with periodically resettable populations and self-adaptive parameter tuning to enhance global exploration and local exploitation.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.population_size = self.initial_population_size\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.reset_interval = 50  # Reset population every 50 generations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            \n            if generation % self.reset_interval == 0 and generation > 0:\n                # Reset population periodically\n                self.population_size = self.initial_population_size\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1_initial * r1 * (pbest - population) + self.c2_initial * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            generation += 1\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:16.306936", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.5% of the code, which means if the code has 100 lines, you can only change 3.5294117647058822 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 3 lines, the rest 82 lines should remain unchanged. This changing rate 3.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:21.717821", "content": "# Description: Improved inertia weight adjustment and trial solution evaluation for enhanced convergence and accuracy.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / 1000))  # Linear adjustment over generations\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:22.215384", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:28.262996", "content": "Certainly! Below is the refined strategy for the EnhancedHybridPSODE algorithm.\n\n# Description: An enhanced hybrid PSO-DE algorithm with adaptive inertia weight, dynamic parameter tuning, and elite learning strategy for efficient exploitation and exploration balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    extras = np.random.uniform(lb, ub, (self.population_size - len(population), self.dim))\n                    population = np.vstack((population, extras))\n                    velocities = np.vstack((velocities, np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size - len(velocities), self.dim))))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Elite Learning Strategy: Keep a portion of the best solutions intact\n            elite_size = int(0.1 * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_size]\n            non_elite_indices = np.argsort(fitness)[elite_size:]\n            \n            # Update personal best\n            better_indices = fitness[non_elite_indices] < pbest_fitness[non_elite_indices]\n            pbest[non_elite_indices[better_indices]] = population[non_elite_indices[better_indices]]\n            pbest_fitness[non_elite_indices[better_indices]] = fitness[non_elite_indices[better_indices]]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Differential Evolution with elitism\n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in non_elite_indices:\n                indices = np.random.choice(non_elite_indices, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal best\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:28.339408", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: An enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence. (Score: 0.12006700536032662)\n\nThe selected solution to update is:\nAn enhanced hybrid PSO-DE algorithm incorporating a dynamic population strategy and fitness-based adaptive parameters for improved exploration and convergence.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.2 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.1 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12007 with standard deviation 0.04642.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.5% of the code, which means if the code has 100 lines, you can only change 3.5294117647058822 lines, and the rest of the lines should remain unchanged. This input code has 85 lines, so you can only change 3 lines, the rest 82 lines should remain unchanged. This changing rate 3.5% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:34.645591", "content": "# Description: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:35.103713", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:41.208676", "content": "# Description: EnhancedHybridPSODE with time-variant crossover probability for improved diversity and convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base * (1 - evals / self.budget)  # Adjusted line for time-variant crossover probability\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:41.215447", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:46.562348", "content": "# Description: RefinedHybridPSODE with adaptive learning rates and enhanced selection mechanisms for improved convergence speed and solution accuracy.\n# Code: \n```python\nimport numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.alpha = 0.5  # Dynamic adjustment parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Adaptive learning rate adjustment\n            adapt_factor = np.exp(-self.alpha * generation / self.budget)\n            self.c1 *= adapt_factor\n            self.c2 *= adapt_factor\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters with enhanced selection\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:47.060479", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:17:54.089677", "content": "# Description: AdaptiveHybridPSODE with adaptive parameter tuning and niche-based competition to enhance exploration-exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 3 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation based on generation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (generation / (self.budget / self.population_size)))\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            new_fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = new_fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = new_fitness[better_indices]\n            \n            if np.min(new_fitness) < gbest_fitness:\n                gbest = population[np.argmin(new_fitness)]\n                gbest_fitness = np.min(new_fitness)\n\n            # Adaptive DE parameters based on fitness diversity\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * (np.std(new_fitness) / np.mean(new_fitness)))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < new_fitness[i]:\n                    population[i], new_fitness[i] = trial, trial_fitness\n\n            better_indices = new_fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = new_fitness[better_indices]\n\n            if np.min(new_fitness) < gbest_fitness:\n                gbest = population[np.argmin(new_fitness)]\n                gbest_fitness = np.min(new_fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:17:54.786265", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.3% of the code, which means if the code has 100 lines, you can only change 2.2988505747126435 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 2 lines, the rest 85 lines should remain unchanged. This changing rate 2.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:00.148064", "content": "# Description: EnhancedHybridPSODE with adaptive inertia weight and optimized dynamic DE parameters for improved convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.6  # Base mutation factor for DE\n        self.CR_base = 0.95  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:00.647698", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:06.865510", "content": "# Description: ImprovedHybridPSODE with diversity preservation and adaptive velocity clamping for enhanced convergence and stability.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.max_velocity = None\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        # Set max velocity as a fraction of the dynamic range\n        self.max_velocity = (ub - lb) * 0.1\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                diversity = np.std(population, axis=0)\n                if np.any(diversity < 0.1 * (ub - lb)):\n                    population += np.random.normal(0, 0.1, population.shape) * (ub - lb)\n                    velocities = np.random.normal(0, 0.1, velocities.shape) * (ub - lb)\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -self.max_velocity, self.max_velocity)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:07.452506", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.4% of the code, which means if the code has 100 lines, you can only change 3.4482758620689653 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 3 lines, the rest 84 lines should remain unchanged. This changing rate 3.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:12.895038", "content": "# Description: Introduced a novel time-varying population size strategy for enhanced adaptability to function landscape.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                self.population_size = int(self.population_size + np.sin(generation) * 2)  # Change 1\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:13.415269", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:19.092162", "content": "# Description: AdvancedHybridPSODE with adaptive inertia weight using fitness variance, dynamic population size and improved DE parameters for enhanced exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass AdvancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            fitness_variance = np.var(fitness)\n            fitness_mean = np.mean(fitness)\n            self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_variance / (fitness_variance + fitness_mean)))\n            generation += 1\n\n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Dynamic DE parameters with Gaussian perturbations for more exploration\n            F = self.F_base + (0.5 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.3 * np.random.randn(self.population_size))\n            F = np.clip(F, 0.1, 2)  # Ensure F is not too small\n            CR = np.clip(CR, 0.1, 1)  # Ensure CR is not too small\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:19.630281", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:25.659489", "content": "# Description: Enhanced inertia weight adjustment by incorporating a feedback mechanism based on the convergence rate to improve exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation with feedback mechanism\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness))) * (1 - evals / self.budget)\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:26.158909", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:33.453512", "content": "# Description: EnhancedHybridPSODE with periodic random restart to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Random restart\n            if generation % 50 == 0:  \n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                evals += self.population_size\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:34.048777", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:39.420828", "content": "# Description: EnhancedHybridPSODE with adaptive mutation scaling for better local search precision.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (1 - evals/self.budget)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:40.022979", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:49.614390", "content": "# Description: EnhancedHybridPSODE with diversity preservation via crowding distance and elitist archive for improved convergence and robustness.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.archive_size = self.population_size // 2  # Size of the elitist archive\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        archive = []\n\n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Update the archive with non-dominated solutions\n            combined_pop = np.vstack((population, archive))\n            combined_fit = np.hstack((fitness, [func(x) for x in archive]))\n            non_dominated_indices = self._non_dominated_sorting(combined_pop, combined_fit)\n            archive = combined_pop[non_dominated_indices]\n            if len(archive) > self.archive_size:\n                archive = self._crowding_distance_sort(archive, combined_fit[non_dominated_indices])[:self.archive_size]\n\n        return gbest\n    \n    def _non_dominated_sorting(self, population, fitness):\n        dominated = set()\n        non_dominated = set(range(len(population)))\n        for i in range(len(population)):\n            for j in range(i + 1, len(population)):\n                if fitness[i] < fitness[j]:\n                    dominated.add(j)\n                elif fitness[j] < fitness[i]:\n                    dominated.add(i)\n        non_dominated -= dominated\n        return list(non_dominated)\n    \n    def _crowding_distance_sort(self, archive, fitness):\n        if len(archive) < 2:\n            return np.arange(len(archive))\n        distances = np.zeros(len(archive))\n        sorted_indices = np.argsort(fitness)\n        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            distances[sorted_indices[i]] = (fitness[sorted_indices[i + 1]] - fitness[sorted_indices[i - 1]]) / (np.max(fitness) - np.min(fitness))\n        return np.argsort(-distances)\n```"}
{"role": "client", "time": "2025-12-26 09:18:49.632308", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 13.8% of the code, which means if the code has 100 lines, you can only change 13.793103448275861 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 12 lines, the rest 75 lines should remain unchanged. This changing rate 13.8% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:18:55.061147", "content": "# Description: Introduced elitism, adaptive cognitive and social components, and improved mutation strategy for better convergence in EnhancedHybridPSODE.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_init = 1.5  # Initial cognitive parameter\n        self.c2_init = 1.5  # Initial social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            c1 = self.c1_init * np.exp(-generation / 100)  # Adaptive cognitive parameter\n            c2 = self.c2_init * np.exp(-generation / 100)  # Adaptive social parameter\n            velocities = self.w * velocities + c1 * r1 * (pbest - population) + c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:18:55.557802", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:02.751835", "content": "# Description: Improved inertia weight adaptation by incorporating fitness standard deviation to better balance exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))  # Changed line\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:03.262021", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:11.207315", "content": "# Description: Refine EnhancedHybridPSODE by introducing an elite solution preservation mechanism for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Preserve the best solution found so far in each generation\n            elite_solution = gbest\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n        \n        return elite_solution\n```"}
{"role": "client", "time": "2025-12-26 09:19:11.712098", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:19.234626", "content": "# Description: AdaptiveHybridPSODE with dynamic neighborhood topology and self-adaptive DE parameters for enhanced convergence speed and diversity maintenance.\n# Code: \n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        # Dynamic neighborhood topology: ring topology\n        neighbors = np.roll(np.arange(self.population_size), 1)\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_min + (self.w_max - self.w_min) * (1 - (gbest_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-10))\n            \n            # PSO velocity and position update with neighborhood topology\n            for i in range(self.population_size):\n                local_gbest = population[neighbors[i]]\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i]\n                                 + self.c1 * r1 * (pbest[i] - population[i])\n                                 + self.c2 * r2 * (local_gbest - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n            # Evaluate new solutions\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            # Update personal and global bests\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Self-adaptive DE parameters\n            F = np.radians(self.F_base + 0.2 * (1 - (gbest_fitness - pbest_fitness) / (np.max(pbest_fitness) - np.min(pbest_fitness) + 1e-10)))\n            CR = np.tanh(self.CR_base + 0.1 * np.random.randn(self.population_size))\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            # Update personal and global bests again\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:20.228371", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 35.6% of the code, which means if the code has 100 lines, you can only change 35.63218390804598 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 31 lines, the rest 56 lines should remain unchanged. This changing rate 35.6% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:25.252660", "content": "# Description: EnhancedHybridPSODE with adaptive diversity and fitness-based selection pressure for improved convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 15 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-3, 5)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i] or np.random.rand() < 0.05:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:25.765073", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:31.004416", "content": "# Description: Minor fine-tuning of the inertia weight calculation to enhance convergence speed.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:31.779173", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:36.841679", "content": "# Description: Introduce a small variation in the mutation factor calculation in the DE component to enhance exploration capabilities.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (1 - evals / self.budget)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:37.340430", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:42.805758", "content": "# Description: Introduce adaptive population resizing to dynamically adjust exploration-exploitation balance based on diversity.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Adaptive population resizing based on diversity (entropy measures diversity).\n            diversity = np.std(population, axis=0).sum()\n            if diversity < 0.1 * (ub - lb).sum():\n                self.population_size = max(5, self.population_size - 1)\n            elif diversity > 0.5 * (ub - lb).sum():\n                self.population_size = min(self.population_size + 1, 10 * self.dim)\n\n            if generation % 10 == 0 or self.population_size != len(population):\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```\n"}
{"role": "client", "time": "2025-12-26 09:19:43.313771", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:48.662590", "content": "# Description: Adjusted EnhancedHybridPSODE to integrate adaptive cognitive and social parameters for enhanced convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Change: Add adaptive cognitive (c1) and social (c2) parameters\n            self.c1 = 1.5 - 1.0 * (evals / self.budget)\n            self.c2 = 1.5 + 1.0 * (evals / self.budget)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:49.726952", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:19:54.429284", "content": "# Description: Introduce random initialization for DE parameters to enhance search diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Random initialization for DE parameters\n            F = np.random.uniform(0, 2, self.population_size)\n            CR = np.random.uniform(0, 1, self.population_size)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:19:54.925072", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:03.049589", "content": "# Description: EnhancedHybridPSODE with improved dynamic DE parameters using Gaussian distribution for better solution diversity.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = np.abs(np.random.normal(self.F_base, 0.1, self.population_size))  # Modified line\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:03.787174", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:12.176815", "content": "# Description: EnhancedHybridPSODE with adaptive local search and chaotic initialization for improved convergence and diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def chaotic_initialization(self, lb, ub):\n        chaotic_seq = np.random.rand(self.population_size, self.dim)\n        return lb + chaotic_seq * (ub - lb)\n\n    def local_search(self, solution, lb, ub, func):\n        perturbed = solution + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        perturbed = np.clip(perturbed, lb, ub)\n        return perturbed if func(perturbed) < func(solution) else solution\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = self.chaotic_initialization(lb, ub)\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            population = np.array([self.local_search(x, lb, ub, func) for x in population])\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:12.559096", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.3% of the code, which means if the code has 100 lines, you can only change 2.2988505747126435 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 2 lines, the rest 85 lines should remain unchanged. This changing rate 2.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:21.372064", "content": "# Description: Enhance adaptive diversity preservation by introducing a chaotic map-based dynamic component in DE parameters.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * generation / 10)  # Chaotic map integration\n            F = self.F_base + chaotic_factor * (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + chaotic_factor * (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:21.874520", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:28.147861", "content": "# Description: EnhancedHybridPSODE with adaptive mutation scaling based on diversity for improved convergence stability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            # Calculate diversity for adaptive mutation scaling\n            centroid = np.mean(population, axis=0)\n            diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE parameters based on diversity\n            F = self.F_base + (0.4 * np.random.randn(self.population_size)) * (diversity / (diversity + 1))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:28.914914", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.4% of the code, which means if the code has 100 lines, you can only change 3.4482758620689653 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 3 lines, the rest 84 lines should remain unchanged. This changing rate 3.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:34.076173", "content": "# Description: Slightly refined EnhancedHybridPSODE with improved exploration dynamics through dynamic cognitive and social parameter adjustments.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_base = 1.5  # Cognitive parameter base\n        self.c2_base = 1.5  # Social parameter base\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            # Dynamic cognitive and social parameters\n            self.c1 = self.c1_base + 0.5 * (1 - gbest_fitness / np.mean(fitness))\n            self.c2 = self.c2_base - 0.5 * (1 - gbest_fitness / np.mean(fitness))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:34.569761", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:40.377443", "content": "# Description: The EnhancedHybridPSODE now includes an improved adaptive mutation factor to enhance diversity and convergence speed.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * np.var(fitness))  # Changed line\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:40.890092", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:46.888132", "content": "# Description: AdaptiveHybridPSODE with adaptive scaling of parameters and random reinitialization for enhanced exploration-exploitation trade-off in dynamic landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.reinit_prob = 0.05  # Probability of random reinitialization\n\n    def adaptive_parameters(self, fitness):\n        # Adaptive scaling based on current population diversity\n        diversity = np.std(fitness)\n        self.w = self.w_max - (self.w_max - self.w_min) * (diversity / (diversity + 1e-9))\n        self.F = self.F_base + 0.5 * (diversity / (diversity + 1e-9))\n        self.CR = self.CR_base + 0.1 * (diversity / (diversity + 1e-9))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n\n        while evals < self.budget:\n            self.adaptive_parameters(fitness)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.reinit_prob:\n                    population[i] = np.random.uniform(lb, ub, self.dim)\n                    fitness[i] = func(population[i])\n                    evals += 1\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:47.386501", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:52.991847", "content": "# Description: AdaptiveDynamicPSODE with periodic reset and adaptive DE factors for enhanced convergence speed and robustness.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDynamicPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.reset_interval = 50  # Interval for periodic reset\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / (np.mean(fitness) + 1e-10)))\n            generation += 1\n\n            # Periodic population reset\n            if generation % self.reset_interval == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive DE parameters\n            F = np.clip(self.F_base + (0.5 * np.random.randn(self.population_size)), 0, 2)\n            CR = np.clip(self.CR_base + (0.3 * np.random.randn(self.population_size)), 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:53.583006", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:20:58.192870", "content": "# Description: RefinedHybridPSODE with adaptive velocity clamping and enhanced DE strategy for improved convergence and stability.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.alpha = 0.5  # Velocity clamping factor\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            vmax = self.alpha * (ub - lb)\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -vmax, vmax)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:20:58.691145", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.4% of the code, which means if the code has 100 lines, you can only change 3.4482758620689653 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 3 lines, the rest 84 lines should remain unchanged. This changing rate 3.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:04.304689", "content": "# Description: EnhancedHybridPSODE with improved adaptive inertia and refined mutation strategy for better optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (gbest_fitness / np.mean(pbest_fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:21:05.261496", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:10.411005", "content": "# Description: Improved inertia weight adaptation to enhance convergence speed by reducing variance influence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness)**0.5 / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:21:11.178085", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:30.006196", "content": "# Description: Adaptive Particle Swarm Differential Evolution (APSDE) with dynamic velocity adaptation and oscillating DE parameters for enhanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveParticleSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 3 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Oscillating DE parameters\n            oscillation = np.sin(2 * np.pi * (evals / self.budget))\n            F = self.F_base + (0.4 * oscillation)\n            CR = self.CR_base + (0.2 * np.abs(oscillation))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:21:30.474069", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:31.672070", "content": "# Description: Enhanced variance-based inertia weight adjustment for better convergence.\n# Code:\n```python\nself.w = self.w_max - ((self.w_max - self.w_min) * (np.log1p(np.var(fitness)) / np.log1p(np.mean(fitness))))\n```"}
{"role": "client", "time": "2025-12-26 09:21:31.673787", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 9.2% of the code, which means if the code has 100 lines, you can only change 9.195402298850574 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 8 lines, the rest 79 lines should remain unchanged. This changing rate 9.2% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:37.648503", "content": "# Description: Incorporate fitness diversity and elitism to improve convergence by maintaining diversity and preserving the best solutions.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.elitism_rate = 0.1\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = population[elite_indices]\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Preserve elite solutions\n            population[:elite_count] = elite_population\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:21:38.162557", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:43.853999", "content": "# Description: EnhancedHybridPSODE with adaptive population size and inertia weight decay for improved convergence dynamics.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight decay\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 5 == 0:\n                self.population_size = min(max(5, int(self.population_size * 0.9 + np.random.rand() * 0.2)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```\n"}
{"role": "client", "time": "2025-12-26 09:21:44.345828", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:21:51.980344", "content": "# Description: EnhancedHybridPSODE with adaptive swarm size and gradient-informed mutation to enhance convergence speed and global search capabilities.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, 2 * dim)\n        self.population_size = self.initial_population_size\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        grad_weight = 0.02  # Weightage for gradient-based mutation\n\n        while evals < self.budget:\n            # Adaptive inertia weight and swarm size\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            if generation % 5 == 0 and evals < self.budget * 0.8:\n                self.population_size = max(5, int(self.initial_population_size * (1 - evals / self.budget)))\n                if self.population_size != len(population):\n                    new_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    new_velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    evals += self.population_size\n                    population = new_population\n                    velocities = new_velocities\n                    fitness = new_fitness\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n            generation += 1\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Gradient-informed mutation\n            for i in range(self.population_size):\n                gradient = np.gradient(fitness[i])\n                mutation_step = grad_weight * gradient * (ub - lb)\n                population[i] = np.clip(population[i] - mutation_step, lb, ub)\n                fitness[i] = func(population[i])\n                evals += 1\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:21:52.004711", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:02.514202", "content": "# Description: AdaptiveHybridPSODE with strategy diversification using chaotic maps for improved exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        chaos = np.random.rand()\n\n        while evals < self.budget:\n            # Adaptive inertia weight with chaotic map\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            self.w *= self.logistic_map(chaos)\n            chaos = self.logistic_map(chaos)\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                new_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if new_size != self.population_size:\n                    self.population_size = new_size\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters with chaotic influence\n            F = self.F_base + (0.4 * np.random.randn(self.population_size) * chaos)\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size) * chaos)\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:02.976033", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:10.391287", "content": "# Description: Adaptive PSO-DE with self-tuning parameters via convergence feedback for enhanced robustness in diverse optimization landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1_init, self.c2_init = 1.5, 1.5\n        self.c1, self.c2 = self.c1_init, self.c2_init\n        self.w_max, self.w_min = 0.9, 0.4\n        self.F_base, self.CR_base = 0.5, 0.9\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        prev_gbest_fitness = gbest_fitness\n\n        while evals < self.budget:\n            generation += 1\n            \n            # Adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            \n            # Adaptive cognitive and social parameters\n            if gbest_fitness < prev_gbest_fitness:\n                self.c1 *= 0.9\n                self.c2 *= 1.1\n            else:\n                self.c1 *= 1.1\n                self.c2 *= 0.9\n                \n            prev_gbest_fitness = gbest_fitness\n            self.c1, self.c2 = np.clip(self.c1, 0.5, 2.5), np.clip(self.c2, 0.5, 2.5)\n            \n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            # Update personal and global best\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            # Update global best\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F, CR = np.clip(F, 0, 2), np.clip(CR, 0, 1)\n            \n            # Differential Evolution Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            # Update personal and global best again after DE\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:11.003346", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:16.483638", "content": "# Description: EnhancedAdaptivePSODE with self-adaptive parameter tuning for dynamic balance and convergence efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        \n        while evals < self.budget:\n            # Adaptive inertia weight\n            fitness_var = np.var(fitness)\n            if fitness_var > 0:\n                self.w = self.w_max - ((self.w_max - self.w_min) * (fitness_var / (np.mean(fitness) + 1e-9)))\n            else:\n                self.w = self.w_min\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:16.950719", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.4% of the code, which means if the code has 100 lines, you can only change 3.4482758620689653 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 3 lines, the rest 84 lines should remain unchanged. This changing rate 3.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:25.107793", "content": "# Description: EnhancedHybridPSODE with improved exploration by periodic random restarts and diverse initialization.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Periodic random restart to enhance exploration\n            if generation % 25 == 0:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:25.939090", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:33.870761", "content": "# Description: EnhancedHybridPSODEv2 with adaptive differential evolution parameters and random local search for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODEv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.local_search_prob = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.local_search_prob:\n                    local_trial = population[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    local_trial = np.clip(local_trial, lb, ub)\n                    local_fitness = func(local_trial)\n                    evals += 1\n                    if local_fitness < fitness[i]:\n                        population[i], fitness[i] = local_trial, local_fitness\n                \n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:34.339807", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 2.3% of the code, which means if the code has 100 lines, you can only change 2.2988505747126435 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 2 lines, the rest 85 lines should remain unchanged. This changing rate 2.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:39.662521", "content": "# Description: Introduce self-adaptive DE parameters adjustment for a more dynamic search capability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Self-adaptive DE parameters\n            F = self.F_base * (1 + 0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base * (1 + 0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:40.132558", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:46.210728", "content": "# Description: Minor enhancement of mutation strategy in DE for improved diversity.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                if np.random.rand() < 0.1:  # Enhance mutation strategy\n                    mutant = x0  # Use base vector sometimes to increase diversity\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:46.685966", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 10.3% of the code, which means if the code has 100 lines, you can only change 10.344827586206897 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 9 lines, the rest 78 lines should remain unchanged. This changing rate 10.3% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:52.869750", "content": "# Description: EnhancedHybridPSODE with dynamic strategies and diversity preservation for improved convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 1e-5  # Diversity threshold\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                if np.std(population) < self.diversity_threshold:\n                    population[i] = np.random.uniform(lb, ub, self.dim)  # Reinitialize when diversity is low\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:53.506940", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:22:58.647719", "content": "# Description: EnhancedHybridPSODE with adaptive velocity scaling and diversity maintenance strategy to improve global search and convergence speed.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            # Adaptive inertia weight based on diversity measure\n            diversity = np.mean(np.std(population, axis=0))\n            self.w = self.w_max - ((self.w_max - self.w_min) * (diversity / np.max(ub - lb)))\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Diversity maintenance via DE mutation and recombination\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:22:59.123645", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 3.4% of the code, which means if the code has 100 lines, you can only change 3.4482758620689653 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 3 lines, the rest 84 lines should remain unchanged. This changing rate 3.4% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:06.719630", "content": "# Description: EnhancedHybridPSODE with adaptive velocity clamping for improved exploration and exploitation balance.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            # Adaptive velocity clamping\n            vel_max = 0.1 * (ub - lb)\n            velocities = np.clip(velocities, -vel_max, vel_max)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:07.314744", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:16.036663", "content": "# Description: ImprovedEnhancedHybridPSODE with adaptive velocity clamping and elitist selection to enhance convergence and maintain diversity.\n# Code: \n```python\nimport numpy as np\n\nclass ImprovedEnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Elitist selection for dynamic population adjustment\n            if generation % 10 == 0:\n                elite_size = max(1, self.population_size // 5)\n                elite_indices = np.argsort(fitness)[:elite_size]\n                population = population[elite_indices]\n                velocities = velocities[elite_indices]\n                fitness = fitness[elite_indices]\n                pbest = pbest[elite_indices]\n                pbest_fitness = pbest_fitness[elite_indices]\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                \n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                new_pop = np.random.uniform(lb, ub, (self.population_size - elite_size, self.dim))\n                population = np.vstack((population, new_pop))\n                velocities = np.vstack((velocities, np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size - elite_size, self.dim))))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            velocities = np.clip(velocities, -abs(ub - lb), abs(ub - lb))\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:16.509696", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:25.887203", "content": "# Description: EnhancedHybridPSODE with adaptive multi-swarm topology and self-adaptive parameter adjustment for improved convergence and diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.num_swarms = 3  # Number of swarms\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            # Create swarms and assign particles\n            swarm_size = self.population_size // self.num_swarms\n            swarms = [population[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_velocities = [velocities[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_pbest = [pbest[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            swarm_pbest_fitness = [pbest_fitness[i*swarm_size:(i+1)*swarm_size] for i in range(self.num_swarms)]\n            \n            # Update each swarm\n            for s in range(self.num_swarms):\n                r1, r2 = np.random.rand(swarm_size, self.dim), np.random.rand(swarm_size, self.dim)\n                swarm_velocities[s] = self.w * swarm_velocities[s] + self.c1 * r1 * (swarm_pbest[s] - swarms[s]) + self.c2 * r2 * (gbest - swarms[s])\n                swarms[s] = np.clip(swarms[s] + swarm_velocities[s], lb, ub)\n                swarm_fitness = np.array([func(x) for x in swarms[s]])\n                evals += swarm_size\n                \n                better_indices = swarm_fitness < swarm_pbest_fitness[s]\n                swarm_pbest[s][better_indices] = swarms[s][better_indices]\n                swarm_pbest_fitness[s][better_indices] = swarm_fitness[better_indices]\n                \n                if np.min(swarm_fitness) < gbest_fitness:\n                    gbest = swarms[s][np.argmin(swarm_fitness)]\n                    gbest_fitness = np.min(swarm_fitness)\n            \n            # Recombination across swarms using DE\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:26.755841", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:31.975856", "content": "# Description: AdaptiveHybridPSODE with self-adaptive parameter scaling and elite preservation for enhanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Self-adaptive inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (evals / self.budget))\n            generation += 1\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            # Elite preservation\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Adaptive DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            # Update the global best\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:32.426978", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:43.299850", "content": "# Description: EnhancedHybridPSODE++ with stochastic restarts and adaptive population size scaling for improved global search capability and convergence speed.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.restart_threshold = 0.1  # Threshold for stagnation\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            if np.random.rand() < self.restart_threshold:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                fitness = np.array([func(x) for x in population])\n                pbest = population.copy()\n                pbest_fitness = fitness.copy()\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n                evals += self.population_size\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:43.794176", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:49.548604", "content": "# Description: Minor improvement by tuning inertia weight variance calculation for better convergence.\n# Code: \n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.std(fitness) / np.mean(fitness)))  # Changed var to std\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:50.166923", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:23:57.269949", "content": "# Description: AdaptiveDynamicPSODE combines dynamic population resizing with adaptive differential evolution parameters and a diversity preservation mechanism for robust exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDynamicPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.diversity_threshold = 1e-5  # Diversity threshold for population refresh\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / (np.mean(fitness) + 1e-9)))\n            generation += 1\n            \n            if generation % 5 == 0 or np.var(fitness) < self.diversity_threshold:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    new_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    new_fitness = np.array([func(x) for x in new_population])\n                    evals += self.population_size\n                    # Preserve top performers\n                    if np.min(new_fitness) < gbest_fitness:\n                        gbest = new_population[np.argmin(new_fitness)]\n                        gbest_fitness = np.min(new_fitness)\n                    population, fitness = new_population, new_fitness\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            F = self.F_base + (0.4 * np.random.rand(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.rand(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:23:58.028554", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:24:04.495942", "content": "# Description: EnhancedHybridPSODE with adaptive learning rates, dynamic topology, and chaotic search to improve convergence speed and stability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        self.alpha = 0.5  # Learning rate for adaptive changes\n        self.beta = 0.05  # Learning rate for chaotic search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        topology = np.random.rand(self.population_size, self.population_size) < 0.5\n\n        while evals < self.budget:\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n\n            # Dynamic topology adjustment\n            if generation % 5 == 0:\n                topology = np.random.rand(self.population_size, self.population_size) < 0.5\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 @ topology * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Dynamic DE parameters\n            F = self.F_base + self.alpha * (1 - generation/self.budget) * np.random.randn(self.population_size)\n            CR = self.CR_base + self.alpha * (1 - generation/self.budget) * np.random.randn(self.population_size)\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Introducing chaotic search for refining global best\n            chaos = self.beta * (gbest - np.mean(population, axis=0))\n            chaotic_candidate = np.clip(gbest + chaos, lb, ub)\n            chaotic_fitness = func(chaotic_candidate)\n            evals += 1\n\n            if chaotic_fitness < gbest_fitness:\n                gbest = chaotic_candidate\n                gbest_fitness = chaotic_fitness\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:24:04.499166", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\nRefine the strategy of the selected solution to improve it.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:24:13.294066", "content": "# Description: EnhancedHybridPSODE with diversity-preserving mechanism and adaptive local search to improve exploration and convergence.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Diversity-preserving mechanism\n            if generation % 5 == 0:\n                diversity = np.std(population, axis=0)\n                if np.all(diversity < 0.1):  # Threshold for diversity check\n                    rand_indices = np.random.choice(self.population_size, size=int(self.population_size * 0.1), replace=False)\n                    population[rand_indices] = np.random.uniform(lb, ub, (len(rand_indices), self.dim))\n                    velocities[rand_indices] = np.random.uniform(-abs(ub - lb), abs(ub - lb), (len(rand_indices), self.dim))\n                    fitness[rand_indices] = [func(x) for x in population[rand_indices]]\n                    evals += len(rand_indices)\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * self.dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n\n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n            # Adaptive Local Search\n            if evals < 0.9 * self.budget and np.random.rand() < 0.1:\n                perturbation = np.random.normal(0, 0.1 * (ub - lb), self.dim)\n                local_candidate = np.clip(gbest + perturbation, lb, ub)\n                local_fitness = func(local_candidate)\n                evals += 1\n                if local_fitness < gbest_fitness:\n                    gbest, gbest_fitness = local_candidate, local_fitness\n\n        return gbest\n```"}
{"role": "client", "time": "2025-12-26 09:24:13.803042", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between func.bounds.lb (lower bound) and func.bounds.ub (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedHybridPSODE: EnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation. (Score: 0.17590864565864006)\n\nThe selected solution to update is:\nEnhancedHybridPSODE with adaptive inertia weight and dynamic DE parameters for balanced exploration-exploitation.\n\nWith code:\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.5  # Base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n\nThe algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17591 with standard deviation 0.20977.\n\n\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.1% of the code, which means if the code has 100 lines, you can only change 1.1494252873563218 lines, and the rest of the lines should remain unchanged. This input code has 87 lines, so you can only change 1 lines, the rest 86 lines should remain unchanged. This changing rate 1.1% is the mandatory requirement, you cannot change more or less than this rate.\n    \n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code: \n```python\n<code>\n```\n\n"}
{"role": "gpt-4o", "time": "2025-12-26 09:24:18.992558", "content": "# Description: Refinement of EnhancedHybridPSODE with increased mutation factor range for greater diversity.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, 2 * dim)\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.F_base = 0.8  # Increased base mutation factor for DE\n        self.CR_base = 0.9  # Base crossover probability for DE\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        pbest = population.copy()\n        pbest_fitness = fitness.copy()\n        gbest = population[np.argmin(fitness)]\n        gbest_fitness = np.min(fitness)\n        evals = self.population_size\n        generation = 0\n        \n        while evals < self.budget:\n            # Enhance inertia weight calculation\n            self.w = self.w_max - ((self.w_max - self.w_min) * (np.var(fitness) / np.mean(fitness)))\n            generation += 1\n            \n            # Dynamic population adjustment\n            if generation % 10 == 0:\n                self.population_size = min(max(5, self.population_size + np.random.randint(-2, 3)), 10 * dim)\n                if self.population_size != len(population):\n                    population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in population])\n                    pbest = population.copy()\n                    pbest_fitness = fitness.copy()\n                    gbest = population[np.argmin(fitness)]\n                    gbest_fitness = np.min(fitness)\n                    evals += self.population_size\n            \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (pbest - population) + self.c2 * r2 * (gbest - population)\n            population = np.clip(population + velocities, lb, ub)\n            fitness = np.array([func(x) for x in population])\n            evals += self.population_size\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n            \n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n            \n            # Dynamic DE parameters\n            F = self.F_base + (0.4 * np.random.randn(self.population_size))\n            CR = self.CR_base + (0.2 * np.random.randn(self.population_size))\n            F = np.clip(F, 0, 2)\n            CR = np.clip(CR, 0, 1)\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                while i in indices:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F[i] * (x1 - x2)\n                cross_points = np.random.rand(self.dim) < CR[i]\n                trial = np.where(cross_points, mutant, population[i])\n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i], fitness[i] = trial, trial_fitness\n            \n            better_indices = fitness < pbest_fitness\n            pbest[better_indices] = population[better_indices]\n            pbest_fitness[better_indices] = fitness[better_indices]\n\n            if np.min(fitness) < gbest_fitness:\n                gbest = population[np.argmin(fitness)]\n                gbest_fitness = np.min(fitness)\n\n        return gbest\n```"}
