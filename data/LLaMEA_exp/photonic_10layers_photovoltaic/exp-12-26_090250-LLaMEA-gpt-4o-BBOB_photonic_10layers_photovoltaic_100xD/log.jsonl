{"id": "6490abaa-4c3e-4260-8c55-efee8a192a0a", "fitness": 0.11622421342706521, "name": "NovelMetaheuristicOptimizer", "description": "A population-based dynamic velocity adjustment algorithm inspired by particle swarm optimization and simulated annealing to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11622 with standard deviation 0.03633.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.09526221214638408, 0.14972829302922708, 0.07609213962338135, 0.1515235513363209, 0.16610614381970956, 0.15582460717584745, 0.09245632043761376, 0.08792764049078683, 0.0710970127843159]}}
{"id": "7a6d17b2-f265-49d2-abab-1896721f0278", "fitness": 0.09870783554796232, "name": "EnhancedMetaheuristicOptimizer", "description": "An enhanced population-based algorithm combining adaptive inertia weight tuning and rank-based selection to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_temp = 100.0\n        self.min_temp = 1.0\n        self.temperature = self.max_temp\n        self.cooling_rate = 0.95\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Rank-based selection for best positions\n            scores = np.array([func(pos) for pos in positions])\n            sorted_indices = np.argsort(scores)\n            top_indices = sorted_indices[:self.population_size // 2]\n            bottom_indices = sorted_indices[self.population_size // 2:]\n\n            for i in range(self.population_size):\n                # Adaptive inertia weight based on rank\n                rank = np.where(sorted_indices == i)[0][0] / self.population_size\n                dynamic_inertia_weight = self.inertia_weight * (1 - rank)\n\n                inertia = dynamic_inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if i in top_indices:\n                    self.temperature = max(self.min_temp, self.temperature * self.cooling_rate)\n                else:\n                    self.temperature = self.max_temp  # Reset temperature for exploration\n\n            # Rank-based velocity modification for added diversity\n            for i in bottom_indices:\n                velocities[i] *= np.random.rand() * 2\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09871 with standard deviation 0.03833.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.06764093234486235, 0.09315212150143093, 0.049209953226708736, 0.13906076190288819, 0.16610614381970956, 0.14268555195448063, 0.08594193586186327, 0.07980371841809186, 0.06476940090162542]}}
{"id": "addd668d-28b6-42ef-a894-161b4ea8ea5f", "fitness": 0.10823634489106147, "name": "NovelMetaheuristicOptimizer", "description": "Enhanced dynamic exploration via Lévy flight-inspired perturbations in the velocity update mechanism for improved search efficiency.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n\n                # Introduce Lévy flight-inspired perturbation\n                levy_flight = np.random.standard_cauchy(self.dim) * 0.01 * search_space\n                velocities[i] = inertia + cognitive_component + social_component + levy_flight\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10824 with standard deviation 0.03478.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.06996729528556811, 0.1072405167646393, 0.09554180665185963, 0.1495124746797678, 0.16610614381970956, 0.1474395473687914, 0.08594193586186327, 0.08389503676277876, 0.06848234682457544]}}
{"id": "4e29f728-c45c-49a9-8dd1-0b2b170bcc30", "fitness": 0.09590574233645742, "name": "EnhancedMetaheuristicOptimizer", "description": "A hybrid algorithm integrating adaptive differential evolution with dynamic velocity adjustment and simulated annealing to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.differential_weight = 0.8\n        self.crossover_prob = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                rand_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = positions[rand_indices]\n                mutant_vector = a + self.differential_weight * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant_vector, positions[i])\n\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < np.exp(-abs(trial_score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09591 with standard deviation 0.04814.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.05024528567136488, 0.04854568818638538, 0.05106456479711674, 0.1564791320645299, 0.16610614381970956, 0.1626363068337605, 0.08594193586186327, 0.07940004781166177, 0.06273257598172477]}}
{"id": "4143cfff-219d-4197-89ba-e17cb7ef83cc", "fitness": 0.10657447029970717, "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive coefficients for cognitive and social components to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                # Adaptive cognitive and social coefficients\n                adaptive_cognitive_coeff = self.cognitive_coeff * (1 - evaluations / self.budget)\n                adaptive_social_coeff = self.social_coeff * (evaluations / self.budget)\n                cognitive_component = adaptive_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = adaptive_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10657 with standard deviation 0.03581.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.07760166400868262, 0.09494574158166169, 0.05956220678505586, 0.14601383036211457, 0.1662100748896469, 0.15172826473730916, 0.09020581673974137, 0.09436032099579117, 0.07854231259736111]}}
{"id": "04ecaed8-cc60-4c8d-8fe9-2d717b922aab", "fitness": 0.12272654525990519, "name": "NovelMetaheuristicOptimizer", "description": "Enhanced velocity update by adding a learning factor to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 2)  # Adjust population size based on budget\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9  # New parameter to tweak velocity\n        self.temperature = 100.0  # Initial temperature for annealing\n        self.cooling_rate = 0.99  # Cooling rate for annealing\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n\n        # Initialize positions and velocities\n        positions = np.random.rand(self.population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(self.population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with dynamic inertia weight\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor  # Apply learning factor\n\n                # Update position\n                positions[i] += velocities[i]\n\n                # Keep within bounds\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / self.temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Cool down temperature\n            self.temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12273 with standard deviation 0.03114.", "error": "", "parent_ids": ["6490abaa-4c3e-4260-8c55-efee8a192a0a"], "operator": null, "metadata": {"aucs": [0.09496057854859552, 0.16639798920783477, 0.08911507576655109, 0.14567626025027358, 0.16610614381970956, 0.14762418714468772, 0.10313946349233205, 0.09049998850952079, 0.10101922059964163]}}
{"id": "e932fca9-d5a8-47f1-8f96-6624ed04462f", "fitness": 0.12282094622928295, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive population size and dynamic cooling rate to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12282 with standard deviation 0.03073.", "error": "", "parent_ids": ["04ecaed8-cc60-4c8d-8fe9-2d717b922aab"], "operator": null, "metadata": {"aucs": [0.09477432372460193, 0.16568601397047533, 0.08950094821946686, 0.14036885596159265, 0.16767864917434439, 0.1497678232937366, 0.10062198592425087, 0.09384962467523117, 0.10314029111984657]}}
{"id": "0b338993-e5f7-4fe5-a300-39dafb44cfe1", "fitness": 0.11403385321312756, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce a dynamic cognitive coefficient based on iteration progress to enhance personal best convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                progress_ratio = evaluations / self.budget  # New dynamic cognitive coefficient\n                cognitive_component = (self.cognitive_coeff * (1 - progress_ratio) + 1) * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11403 with standard deviation 0.03399.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08501249809471545, 0.1398900545102838, 0.07288406354558719, 0.14692774390199614, 0.16610614381970956, 0.14931916490922903, 0.10027889640797094, 0.08698375631985034, 0.07890235740880547]}}
{"id": "a7575ada-3ea3-4114-9d65-b7e3f4aa3f08", "fitness": 0.09842685034611265, "name": "EnhancedAdaptiveOptimizer", "description": "Enhance the adaptive algorithm by integrating differential evolution mutation and selection mechanisms for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Differential Evolution Mutation\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = positions[indices]\n                mutant = np.clip(a + self.mutation_factor * (b - c), bounds[0], bounds[1])\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_prob\n                trial = np.where(cross_points, mutant, positions[i])\n                \n                score = func(trial)\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = score\n                \n                if score < global_best_score:\n                    global_best_position = trial\n                    global_best_score = score\n\n                # Particle Swarm Optimization inspired update\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptiveOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09843 with standard deviation 0.04266.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.07616282000037489, 0.04899743112315358, 0.07088843383546717, 0.15104074026492909, 0.16610614381970956, 0.1524564591432448, 0.08594193586186327, 0.07940004781166177, 0.054847641254609725]}}
{"id": "753d1fd4-8ea1-4cda-9365-c6af9b88c071", "fitness": 0.1174162858237028, "name": "RefinedMetaheuristicOptimizer", "description": "Enhance the balance between exploration and exploitation by modifying the velocity update formula.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component + np.random.randn(self.dim) * 0.01 * search_space  # Slight random perturbation\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11742 with standard deviation 0.03587.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.10014715782005934, 0.09656659689751157, 0.0918882963985429, 0.16045954472592938, 0.16610614381970956, 0.17461189891477635, 0.10254743249041531, 0.08312101867685351, 0.08129848266952733]}}
{"id": "a0ff137c-e565-4419-bed2-41b44d04d47a", "fitness": 0.11569626996908935, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by introducing a mutation-based diversification and elitist selection mechanism.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                if np.random.rand() < 0.1:  # Mutation-based diversification\n                    velocities[i] += np.random.randn(self.dim) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                sorted_indices = np.argsort(personal_best_scores)\n                positions = positions[sorted_indices[:population_size]]\n                velocities = velocities[sorted_indices[:population_size]]\n                personal_best_positions = personal_best_positions[sorted_indices[:population_size]]\n                personal_best_scores = personal_best_scores[sorted_indices[:population_size]]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11570 with standard deviation 0.03347.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08874681905832316, 0.10975132628022544, 0.08682892143526588, 0.1581848187587186, 0.16610614381970956, 0.16083026263126277, 0.09091578600578454, 0.09908251091481246, 0.08081984081770166]}}
{"id": "3ef5c34a-f292-42bc-a19d-f67eda212e90", "fitness": 0.10371106067402835, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate multi-swarm dynamics and hybrid mutation strategies to diversify search and prevent premature convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.num_swarms = 3  # Number of swarms for multi-swarm dynamics\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        # Initialize swarms\n        swarms = []\n        for _ in range(self.num_swarms):\n            positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n            velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n            personal_best_positions = np.copy(positions)\n            personal_best_scores = np.array([func(pos) for pos in positions])\n            global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n            global_best_score = np.min(personal_best_scores)\n            swarms.append((positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score))\n        \n        evaluations = population_size * self.num_swarms\n\n        while evaluations < self.budget:\n            for swarm in swarms:\n                positions, velocities, personal_best_positions, personal_best_scores, global_best_position, global_best_score = swarm\n                for i in range(population_size):\n                    inertia = self.inertia_weight * velocities[i]\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                    velocities[i] = inertia + cognitive_component + social_component\n                    velocities[i] *= self.learning_factor\n                    positions[i] += velocities[i]\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                    \n                    if np.random.rand() < 0.1:  # Mutation strategy\n                        positions[i] += np.random.randn(self.dim) * search_space * 0.05\n\n                    score = func(positions[i])\n                    evaluations += 1\n\n                    if score < personal_best_scores[i]:\n                        personal_best_positions[i] = positions[i]\n                        personal_best_scores[i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n                    if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                        velocities[i] *= np.random.rand() * 2\n\n                if evaluations / self.budget > 0.5:\n                    population_size = max(self.min_population_size, population_size - 1)\n                    positions = positions[:population_size]\n                    velocities = velocities[:population_size]\n                    personal_best_positions = personal_best_positions[:population_size]\n                    personal_best_scores = personal_best_scores[:population_size]\n\n                temperature *= self.cooling_rate\n\n        best_swarm = min(swarms, key=lambda s: s[5])  # Find the best swarm based on global best score\n        return best_swarm[4], best_swarm[5]", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10371 with standard deviation 0.03923.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.07142335622909313, 0.08290028698629492, 0.06310944433823829, 0.1579320826090067, 0.16610614381970956, 0.15067272715283653, 0.086218899253371, 0.07940004781166177, 0.07563655786604329]}}
{"id": "57aa6c7c-3cd9-48f1-bf40-41b9aa63c8dc", "fitness": 0.12097456129689224, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate momentum into velocity updates to enhance convergence speed.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n        self.momentum = 0.1  # Incorporate momentum\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component + self.momentum * velocities[i] # Add momentum\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12097 with standard deviation 0.03510.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.08839955799165566, 0.14468858659779948, 0.09224907043508224, 0.17049173561774655, 0.16610614381970956, 0.15623112424387708, 0.09524255596222264, 0.08394430874024505, 0.09141796826369175]}}
{"id": "187803ba-81b9-47db-863e-5ae837c22edb", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Leverage self-adaptive mutation rates and neighborhood search to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.mutation_rate = 0.1\n        self.neighborhood_size = min(5, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                \n                # Adaptive mutation rate\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = (np.random.randn(self.neighborhood_size) * (search_space / 10))\n                    indices = np.random.choice(self.dim, self.neighborhood_size, replace=False)\n                    positions[i, indices] += mutation_vector\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            self.mutation_rate *= 0.95  # Reduce mutation over time\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (5,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (5,) (10,) ')", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {}}
{"id": "7e8fb108-105f-4412-aac0-32459af51b31", "fitness": 0.10830078396554461, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce a multi-phase strategy with adaptive crossover and mutation operations to strengthen genetic diversity and convergence quality.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Phase 1: Particle Swarm Optimization\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            # Phase 2: Genetic Operations\n            if np.random.rand() < self.crossover_rate:\n                parent1, parent2 = np.random.choice(range(population_size), 2, replace=False)\n                crossover_point = np.random.randint(1, self.dim)\n                offspring = np.concatenate((positions[parent1][:crossover_point], positions[parent2][crossover_point:]))\n                offspring_score = func(offspring)\n                evaluations += 1\n\n                if offspring_score < personal_best_scores[parent1]:\n                    positions[parent1] = offspring\n                    personal_best_scores[parent1] = offspring_score\n\n                if offspring_score < global_best_score:\n                    global_best_position = offspring\n                    global_best_score = offspring_score\n\n            for i in range(population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.randn(self.dim) * 0.1 * search_space\n                    positions[i] += mutation\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                    score = func(positions[i])\n                    evaluations += 1\n\n                    if score < personal_best_scores[i]:\n                        personal_best_positions[i] = positions[i]\n                        personal_best_scores[i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[i]\n                        global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10830 with standard deviation 0.03741.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.11085689290401324, 0.07133087667316318, 0.07386705570212448, 0.1540510655686469, 0.16610614381970956, 0.15558041940895995, 0.08728506631258681, 0.0835847436194661, 0.07204479168123135]}}
{"id": "e1bf9608-bc07-45fa-8d21-a9b2fdb33d4b", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Integrate Lévy flight mechanism and adaptive mutation strategies to enhance exploration and intensification in the solution space.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < 0.1:  # Apply Lévy flight with a low probability\n                    positions[i] += self.levy_flight(self.dim) * search_space\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {}}
{"id": "d42d7d00-d1b8-47e0-8582-f95106cc53e6", "fitness": 0.1275485407896941, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate variable inertia for better adaptability in velocity updates.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12755 with standard deviation 0.03516.", "error": "", "parent_ids": ["e932fca9-d5a8-47f1-8f96-6624ed04462f"], "operator": null, "metadata": {"aucs": [0.145688643170078, 0.1563068222001598, 0.053527371608239394, 0.15058453177622944, 0.16680044494771773, 0.15679205183757017, 0.11498905080290645, 0.10717009078032214, 0.09607785998402374]}}
{"id": "51087c34-b2bd-4706-a8c8-dcfdcbb3c638", "fitness": 0.1107112215484275, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration-exploitation trade-off using adaptive coefficients and Levy flights.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + L) * np.sin(np.pi * L / 2) / \n                 (np.math.gamma((1 + L) / 2) * L * 2**((L - 1) / 2)))**(1 / L)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        return u / abs(v)**(1 / L)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            inertia_weight_adaptive = self.inertia_weight * (1 - evaluations / self.budget)\n            for i in range(population_size):\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (inertia_weight_adaptive * velocities[i] +\n                                 cognitive_component + social_component) * self.learning_factor\n\n                if np.random.rand() < 0.3:\n                    velocities[i] += self.levy_flight(1.5) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                \n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11071 with standard deviation 0.03818.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.08657433943089599, 0.11816511686088904, 0.06258194342856915, 0.16324054397226706, 0.16752993071808653, 0.1511692148583833, 0.08815838193058956, 0.08582287472313122, 0.07315864801303562]}}
{"id": "93629999-ed95-4a58-a99e-520ca83ce188", "fitness": 0.11862312508188556, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate adaptive cognitive and social coefficients based on performance improvements.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    self.cognitive_coeff = min(2.0, self.cognitive_coeff * 1.05)  # Adaptive cognitive coefficient\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n                    self.social_coeff = min(2.0, self.social_coeff * 1.05)  # Adaptive social coefficient\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11862 with standard deviation 0.03777.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09388355784206659, 0.15172086775738036, 0.057094084489633934, 0.15531184148107013, 0.1667377258819528, 0.16057663026738522, 0.0957673089076394, 0.08560444204517925, 0.10091166706466226]}}
{"id": "e47a4526-88fe-4cc5-b40b-79f024960a20", "fitness": 0.11743390312523488, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce position perturbation to enhance local exploration in adaptive velocity updates.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n                positions[i] += np.random.randn(self.dim) * 0.01 * search_space  # Added perturbation\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11743 with standard deviation 0.03084.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10122331235039517, 0.10135632217401491, 0.09340264606734261, 0.14966965468351445, 0.16964241039869976, 0.15813018599409256, 0.11064461370816658, 0.09238277488097635, 0.08045320786991161]}}
{"id": "e7df51e8-1773-4db3-a44c-5da98210e718", "fitness": 0.1185468420194069, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive learning rate and diversity preservation to enhance global exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.learning_factor_decrease_rate = 0.995\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        learning_factor = self.initial_learning_factor\n        population_size = self.initial_population_size\n\n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity with adaptive learning factor\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing with adaptive exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= (np.random.rand() * 2)\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature and adapt learning factor\n            temperature *= self.cooling_rate\n            learning_factor *= self.learning_factor_decrease_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11855 with standard deviation 0.03629.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09709325578953465, 0.15624272152555208, 0.05418743727939179, 0.15885197293883757, 0.16629974977406647, 0.14236574561162474, 0.0957942888446719, 0.09712447532801127, 0.09896193108297158]}}
{"id": "92ad3f36-d6c6-426a-8241-6a40c078ee38", "fitness": 0.11978762942752136, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce dynamic learning and diversity preservation mechanisms to enhance exploration and robustness in optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.diversity_factor = 0.01  # To maintain population diversity\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update dynamic learning factor based on diversity\n                current_diversity = np.std(positions, axis=0).mean() / search_space.mean()\n                dynamic_learning_factor = self.learning_factor + self.diversity_factor * current_diversity\n\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= dynamic_learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11979 with standard deviation 0.03941.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.0966999833284653, 0.15712695741053107, 0.05537473145912053, 0.15983685230578626, 0.16693123662766474, 0.16012254841256024, 0.11007742912196405, 0.09156554177866971, 0.08035338440293016]}}
{"id": "23d8fe58-938d-4c5c-8c30-fd293ffe27f0", "fitness": 0.11605442611089985, "name": "AdvancedMetaheuristicOptimizer", "description": "Enhance adaptivity by dynamically adjusting cognitive and social components based on performance trends.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        previous_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                \n                # Dynamic adjustment of coefficients\n                progress = (previous_global_best_score - global_best_score) / max(1e-10, previous_global_best_score)\n                self.cognitive_coeff = 1.5 + 0.5 * (1 - progress)\n                self.social_coeff = 1.5 + 0.5 * progress\n\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    previous_global_best_score = global_best_score\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11605 with standard deviation 0.03797.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09639237819277635, 0.1620797086283431, 0.052046345782084114, 0.14971309799667631, 0.16754670070566247, 0.14237116415388384, 0.0966120223881457, 0.08440012584064283, 0.09332829130988407]}}
{"id": "52d57958-441b-44e8-bedd-5298768cf14b", "fitness": 0.11392894984151665, "name": "EnhancedMetaheuristicOptimizer", "description": "Combine dynamic inertia with stochastic mutation for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update inertia dynamically\n                inertia_weight = self.inertia_weight * (1 - evaluations / self.budget)\n                \n                # Update velocity\n                inertia = inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Stochastic mutation for exploration\n                if np.random.rand() < 0.1:\n                    mutation = np.random.randn(self.dim) * 0.1 * search_space\n                    velocities[i] += mutation\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11393 with standard deviation 0.03669.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.08641714492102781, 0.11625731739160017, 0.07978282520779456, 0.15658072160751657, 0.16657318878219318, 0.16500905078992456, 0.09575465035174158, 0.09147857834947459, 0.06750707117237686]}}
{"id": "99a86bf7-f4e6-470b-bd10-0596505fa62b", "fitness": 0.12494608806718269, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive velocity scaling for dynamic control of exploitation-exploration balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor * (1 + np.random.rand() * (evaluations / self.budget))  # Adaptive velocity scaling\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12495 with standard deviation 0.03132.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09756584781318978, 0.15334825429573784, 0.12468544198764919, 0.15710544645173619, 0.16610614381970956, 0.15212978011424927, 0.10522076913747658, 0.09087032800471995, 0.07748278098017602]}}
{"id": "0c5e3edb-7703-45db-911b-eaa2f1862499", "fitness": 0.1149453661057562, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate dynamic diversity preservation to enhance convergence stability by adjusting exploration and exploitation during optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.diversity_threshold = 0.1  # Threshold for diversity adjustment\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                if np.random.rand() < self.diversity_threshold:\n                    velocities[i] += np.random.randn(self.dim) * 0.1 * search_space\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11495 with standard deviation 0.03160.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10187080264636938, 0.09047567835590375, 0.12477505368598607, 0.15092954684967197, 0.16610614381970956, 0.14790814508781058, 0.0917433145636456, 0.09013954347123843, 0.0705600664714704]}}
{"id": "04892beb-09ee-413e-aa0d-b8c58e8365c1", "fitness": 0.11965855128412407, "name": "EnhancedMetaheuristicOptimizer", "description": "Utilize adaptive inertia and multi-population strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.population_fractions = [0.6, 0.4]  # Use two subpopulations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        evaluations = 0\n\n        # Initialize subpopulations\n        subpopulations = [int(population_size * f) for f in self.population_fractions]\n        positions = [np.random.rand(s, self.dim) * search_space + bounds[0] for s in subpopulations]\n        velocities = [np.random.randn(s, self.dim) * 0.1 * search_space for s in subpopulations]\n        personal_best_positions = [np.copy(p) for p in positions]\n        personal_best_scores = [np.array([func(pos) for pos in p]) for p in positions]\n\n        global_best_position = np.array(min((p[np.argmin(s)] for p, s in zip(personal_best_positions, personal_best_scores)), key=func))\n        global_best_score = func(global_best_position)\n\n        evaluations += sum(subpopulations)\n\n        while evaluations < self.budget:\n            for k in range(len(positions)):\n                for i in range(subpopulations[k]):\n                    # Update velocity with adaptive inertia\n                    velocity_inertia = self.inertia_weight * (1 - evaluations / self.budget) * velocities[k][i]\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[k][i] - positions[k][i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[k][i])\n                    velocities[k][i] = velocity_inertia + cognitive_component + social_component\n                    velocities[k][i] *= self.learning_factor\n\n                    # Update position\n                    positions[k][i] += velocities[k][i]\n                    positions[k][i] = np.clip(positions[k][i], bounds[0], bounds[1])\n\n                    # Evaluate new position\n                    score = func(positions[k][i])\n                    evaluations += 1\n\n                    # Update personal and global bests\n                    if score < personal_best_scores[k][i]:\n                        personal_best_positions[k][i] = positions[k][i]\n                        personal_best_scores[k][i] = score\n\n                    if score < global_best_score:\n                        global_best_position = positions[k][i]\n                        global_best_score = score\n\n                    # Simulated annealing inspired exploration-exploitation balance\n                    if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                        velocities[k][i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                for k in range(len(subpopulations)):\n                    subpopulations[k] = max(self.min_population_size, subpopulations[k] - 1)\n                    positions[k] = positions[k][:subpopulations[k]]\n                    velocities[k] = velocities[k][:subpopulations[k]]\n                    personal_best_positions[k] = personal_best_positions[k][:subpopulations[k]]\n                    personal_best_scores[k] = personal_best_scores[k][:subpopulations[k]]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11966 with standard deviation 0.02961.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09440705851784925, 0.14683262482018156, 0.09258880947765524, 0.14570948379043336, 0.16619254961847518, 0.14862290531311773, 0.09717505393280701, 0.10107904383887378, 0.08431943224772354]}}
{"id": "28972996-d3fc-47de-96a2-fc2463ab6d8e", "fitness": 0.12225268552957422, "name": "RefinedMetaheuristicOptimizer", "description": "Implement adaptive inertia weighting to enhance convergence speed and precision.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)  # Start with a smaller population\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.learning_factor = 0.9\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995  # More gradual cooling\n        self.min_population_size = 10  # Minimum population size during adaptations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        # Initialize positions and velocities\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                # Update velocity\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget) * (0.5 + 0.5 * np.random.rand())  # Change: adaptive inertia weight\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= self.learning_factor\n\n                # Update position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Simulated annealing inspired exploration-exploitation balance\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Adaptive population size reduction\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            # Cool down temperature gradually\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12225 with standard deviation 0.03703.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.10046956825459608, 0.1623271843666646, 0.0739067143212816, 0.141216227416332, 0.18653761297097327, 0.1530886262927872, 0.10037607356066125, 0.09712450333709788, 0.08522765924577425]}}
{"id": "449ad4b5-4d8e-4ab9-89c1-922bd4909be7", "fitness": 0.13127313015215872, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive learning rates and dimension-wise exploration strategies to enhance convergence and adaptability.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13127 with standard deviation 0.02904.", "error": "", "parent_ids": ["d42d7d00-d1b8-47e0-8582-f95106cc53e6"], "operator": null, "metadata": {"aucs": [0.09729165001525764, 0.15754443097396675, 0.13541611334674497, 0.1630885000804353, 0.16994204940327418, 0.15270886828559704, 0.11165324183297787, 0.0994988891844818, 0.094314428246693]}}
{"id": "5289c87f-337e-4dcc-96dc-2bf55f8954b2", "fitness": 0.11846673749692312, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate dynamic exploration-exploitation balance through nonlinear adaptive parameters and hybrid local search to enhance robustness and convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.exploration_factor = 0.7\n        self.exploitation_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            exploration_exploitation_ratio = (self.exploration_factor - self.exploitation_factor) * (1 - (evaluations/self.budget)**2) + self.exploitation_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia * exploration_exploitation_ratio + cognitive_component + social_component\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            if evaluations / self.budget > 0.7:\n                for j in range(population_size):\n                    local_search_step = np.random.uniform(-0.1, 0.1, self.dim) * search_space\n                    candidate_position = np.clip(positions[j] + local_search_step, bounds[0], bounds[1])\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    if candidate_score < personal_best_scores[j]:\n                        personal_best_positions[j] = candidate_position\n                        personal_best_scores[j] = candidate_score\n                        if candidate_score < global_best_score:\n                            global_best_position = candidate_position\n                            global_best_score = candidate_score\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11847 with standard deviation 0.03997.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.08109828155404308, 0.16924489000025766, 0.05221822652292363, 0.1453640691024367, 0.16846895089976666, 0.15525884219566222, 0.10984699895469474, 0.09305546275778132, 0.09164491548474218]}}
{"id": "0abf3f1a-4c62-4a65-bfce-1ae2e0c96227", "fitness": 0.10261304085487408, "name": "DynamicMomentumOptimizer", "description": "Incorporate dynamic diversification and intensification strategies with adaptive momentum to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicMomentumOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.4\n        self.diversification_factor = 1.2\n        self.intensification_factor = 0.8\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            alpha = evaluations / self.budget\n            momentum_factor = self.diversification_factor if alpha < 0.5 else self.intensification_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * momentum_factor\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                velocities *= np.random.rand(population_size, self.dim) * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm DynamicMomentumOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10261 with standard deviation 0.03844.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.07327843175714, 0.07878812790429957, 0.05113260580097023, 0.14866438324275255, 0.16610614381970956, 0.14925426930693275, 0.08741967786333704, 0.08472850201105031, 0.08414522598767471]}}
{"id": "f24f768a-e77f-4b1a-9557-6ee37d3a4271", "fitness": 0.12472176815341657, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive mutation and survival strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            \n            # Mutate a random individual's position to explore new areas in the search space\n            if np.random.rand() < 0.1:  # Change 1\n                random_idx = np.random.randint(0, population_size)  # Change 2\n                positions[random_idx] = np.random.rand(self.dim) * search_space + bounds[0]  # Change 3\n\n            # Elitism: Retain the best solution found so far in the population\n            positions[0] = global_best_position  # Change 4\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12472 with standard deviation 0.03387.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.0970201267526577, 0.16992740392524208, 0.09331551603417254, 0.155512142169288, 0.1679624804985621, 0.1484513782660739, 0.10481010493684595, 0.11153712135173388, 0.0739596394461729]}}
{"id": "57d372eb-e5a7-41cc-8940-17c9eac4f688", "fitness": 0.08756529621269665, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate dynamic neighborhood structures and adaptive inertia to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            inertia_weight = ((self.inertia_max - self.inertia_min) * \n                              (1 - evaluations / self.budget) + self.inertia_min)\n            learning_factor = ((self.initial_learning_factor - self.final_learning_factor) * \n                               (1 - evaluations / self.budget) + self.final_learning_factor)\n\n            for i in range(population_size):\n                neighborhood = positions[np.random.choice(population_size, 5, replace=False)]\n                local_best_position = neighborhood[np.argmin([func(n) for n in neighborhood])]\n                \n                inertia = inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (local_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08757 with standard deviation 0.04802.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.04511903121279115, 0.027149537422416326, 0.03872299956887759, 0.13861816939614324, 0.16610614381970956, 0.144659957660638, 0.08594193586186327, 0.08353643847630288, 0.058233452495527915]}}
{"id": "a79119c2-642c-4ff1-b861-6a7c21b99f4c", "fitness": 0.12812846574441544, "name": "EnhancedMetaheuristicOptimizer", "description": "Refine learning dynamics by adjusting inertia weight decay and temperature handling to enhance solution exploration.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (0.5 - evaluations / self.budget)  # Adjusted inertia weight decay\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / (temperature + 1e-8)):  # Added small value to temperature\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12813 with standard deviation 0.03136.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09791528733453192, 0.13766625822388068, 0.07674222865231539, 0.1709479764511438, 0.16677039903226665, 0.15578853602023268, 0.10841437578077362, 0.10247276695312613, 0.1364383632514683]}}
{"id": "cb82eb4d-d8a2-4fcf-8269-56a70d36f9a8", "fitness": 0.11005167775373813, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce probabilistic mutation and elitism to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_probability = 0.1  # Added mutation probability\n        self.elite_fraction = 0.1  # Added elite fraction\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < self.mutation_probability:  # Added mutation logic\n                    positions[i] += np.random.randn(self.dim) * 0.05 * search_space\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n            elite_size = int(self.elite_fraction * population_size)  # Added elitism logic\n            elite_indices = np.argsort(personal_best_scores)[:elite_size]\n            positions = np.concatenate((personal_best_positions[elite_indices], positions))\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11005 with standard deviation 0.03436.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09376744184128416, 0.07785359726095187, 0.11032268615439411, 0.15221635427753943, 0.16610614381970956, 0.1501880090477895, 0.08594193586186327, 0.08096041665614984, 0.07310851486396142]}}
{"id": "edca328a-c7b4-45ca-8b45-d498c62bc00f", "fitness": 0.10327476865967339, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate a multi-swarm strategy with adaptive diversity maintenance and dynamic search space partitioning to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.num_swarms = 3\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        swarms = [\n            {\n                'positions': np.random.rand(population_size, self.dim) * search_space + bounds[0],\n                'velocities': np.random.randn(population_size, self.dim) * 0.1 * search_space,\n                'personal_best_positions': np.empty((population_size, self.dim)),\n                'personal_best_scores': np.full(population_size, np.inf),\n                'global_best_position': None,\n                'global_best_score': np.inf\n            } for _ in range(self.num_swarms)\n        ]\n\n        for swarm in swarms:\n            swarm['personal_best_positions'] = np.copy(swarm['positions'])\n            swarm['personal_best_scores'] = np.array([func(pos) for pos in swarm['positions']])\n            best_idx = np.argmin(swarm['personal_best_scores'])\n            swarm['global_best_position'] = swarm['personal_best_positions'][best_idx]\n            swarm['global_best_score'] = swarm['personal_best_scores'][best_idx]\n\n        evaluations = population_size * self.num_swarms\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            \n            for swarm in swarms:\n                for i in range(population_size):\n                    inertia = self.inertia_weight * swarm['velocities'][i] * (1 - evaluations / self.budget)\n                    cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (swarm['personal_best_positions'][i] - swarm['positions'][i])\n                    social_component = self.social_coeff * np.random.rand(self.dim) * (swarm['global_best_position'] - swarm['positions'][i])\n                    swarm['velocities'][i] = inertia + cognitive_component + social_component\n                    swarm['velocities'][i] *= learning_factor\n\n                    swarm['positions'][i] += swarm['velocities'][i]\n                    swarm['positions'][i] = np.clip(swarm['positions'][i], bounds[0], bounds[1])\n\n                    score = func(swarm['positions'][i])\n                    evaluations += 1\n\n                    if score < swarm['personal_best_scores'][i]:\n                        swarm['personal_best_positions'][i] = swarm['positions'][i]\n                        swarm['personal_best_scores'][i] = score\n\n                    if score < swarm['global_best_score']:\n                        swarm['global_best_position'] = swarm['positions'][i]\n                        swarm['global_best_score'] = score\n\n                    if np.random.rand() < np.exp(-abs(score - swarm['global_best_score']) / temperature):\n                        swarm['velocities'][i] *= np.random.rand() * 2\n\n                if evaluations / self.budget > 0.5:\n                    population_size = max(self.min_population_size, population_size - 1)\n                    swarm['positions'] = swarm['positions'][:population_size]\n                    swarm['velocities'] = swarm['velocities'][:population_size]\n                    swarm['personal_best_positions'] = swarm['personal_best_positions'][:population_size]\n                    swarm['personal_best_scores'] = swarm['personal_best_scores'][:population_size]\n\n            temperature *= self.cooling_rate\n\n        best_swarm = min(swarms, key=lambda s: s['global_best_score'])\n        return best_swarm['global_best_position'], best_swarm['global_best_score']", "configspace": "", "generation": 35, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10327 with standard deviation 0.03673.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.08427473144349373, 0.0750493426472214, 0.07759972008095517, 0.14748957050290323, 0.1669695985602263, 0.14752926926780863, 0.08597458556383042, 0.08051029761438122, 0.06407580225624032]}}
{"id": "e8d61c38-6757-4ecf-8b6a-fffd6903e04e", "fitness": 0.11109072380443129, "name": "AdaptiveMetaheuristicOptimizer", "description": "Integrate self-adaptive mutation and crossover mechanisms alongside adaptive learning rates to boost exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < self.crossover_rate:\n                    partner_idx = np.random.randint(population_size)\n                    crossover_mask = np.random.rand(self.dim) > 0.5\n                    positions[i][crossover_mask] = personal_best_positions[partner_idx][crossover_mask]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutate_dim = np.random.randint(self.dim)\n                    positions[i][mutate_dim] += np.random.randn() * (bounds[1][mutate_dim] - bounds[0][mutate_dim]) * 0.1\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11109 with standard deviation 0.03499.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.10050854074820903, 0.11672772582717061, 0.068087043625768, 0.15439523619240536, 0.16759267023829671, 0.1472766924239748, 0.08595475143352205, 0.08407282835018837, 0.07520102540034668]}}
{"id": "36c35325-d27a-4497-bf10-2929e152c8f3", "fitness": 0.11583870931427977, "name": "EnhancedMetaheuristicOptimizer", "description": "Integrate adaptive mutation and dynamic population resizing strategies to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_prob = 0.1\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                mutation = np.random.rand(self.dim) * np.where(np.random.rand(self.dim) < self.mutation_prob, search_space * 0.05, 0)\n                velocities[i] = inertia + cognitive_component + social_component + mutation\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            temperature *= self.cooling_rate\n            if evaluations / self.budget > 0.5 and population_size > self.min_population_size:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11584 with standard deviation 0.03484.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.10524015525702624, 0.0970690748257248, 0.06652516888827176, 0.1593188963192601, 0.17084143416963682, 0.15678200908217488, 0.10591153906685391, 0.09527143961858175, 0.08558866660098763]}}
{"id": "da06dbb2-0756-48eb-a332-8ae60aaffd87", "fitness": 0.1041907005392782, "name": "AdvancedMetaheuristicOptimizer", "description": "Enhance exploration by introducing differential mutation and crossover from DE to improve diversity and convergence.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 4)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 15\n        self.differential_weight = 0.8\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            \n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Differential mutation and crossover\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = positions[indices[0]], positions[indices[1]], positions[indices[2]]\n                mutant_vector = a + self.differential_weight * (b - c)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, positions[i])\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n            temperature *= self.cooling_rate\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = np.resize(positions, (population_size, self.dim))\n                velocities = np.resize(velocities, (population_size, self.dim))\n                personal_best_positions = np.resize(personal_best_positions, (population_size, self.dim))\n                personal_best_scores = np.resize(personal_best_scores, population_size)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10419 with standard deviation 0.03857.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.06869188759626743, 0.09683062267195797, 0.07836558604751698, 0.15344001891382753, 0.16610614381970956, 0.15030779998687094, 0.08594193586186327, 0.07940004781166177, 0.05863226214382844]}}
{"id": "86ab4703-2b26-40af-935c-1141bc42bec1", "fitness": 0.0943412627592115, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate differential evolution strategies with adaptive temperature control to enhance global exploration and convergence accuracy.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(60, self.budget // 4)\n        self.inertia_weight = 0.4\n        self.cognitive_coeff = 1.2\n        self.social_coeff = 1.8\n        self.initial_learning_factor = 0.8\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 150.0\n        self.cooling_rate = 0.996\n        self.min_population_size = 8\n        self.differential_weight = 0.7\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant_vector = personal_best_positions[a] + self.differential_weight * (personal_best_positions[b] - personal_best_positions[c])\n                trial_vector = np.array([mutant_vector[j] if np.random.rand() < self.crossover_rate else positions[i, j] for j in range(self.dim)])\n                trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < np.exp(-abs(trial_score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09434 with standard deviation 0.04972.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.044681244019687094, 0.0371059733302852, 0.04241079416469673, 0.1600312075718382, 0.16610614381970956, 0.15558374859694557, 0.08716796120748527, 0.07940004781166177, 0.07658424431059407]}}
{"id": "fa2c6696-b80f-439f-b39d-9bb13a2777a1", "fitness": 0.11987932844352474, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate nonlinear cooling and adaptive inertia for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (0.5 - evaluations / self.budget) ** 2\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate ** np.sqrt(evaluations / self.budget)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11988 with standard deviation 0.03728.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [0.09954729037528565, 0.14056721697106067, 0.05556517445088627, 0.15894785441309356, 0.1787412583114919, 0.14941484383713333, 0.11332163292096487, 0.09005416369072738, 0.09275452102107906]}}
{"id": "e9695a05-30e2-49e6-b357-c6cf3d1bea52", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance exploration by adjusting temperature dynamically based on evaluations to improve convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / (temperature * (1 - evaluations / self.budget))):  # Adjusted\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "An exception occurred: ZeroDivisionError('float division by zero').", "error": "ZeroDivisionError('float division by zero')", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {}}
{"id": "77a32b2a-7b28-4ce0-95d6-45f75ead8408", "fitness": 0.2287364268625413, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce inertia weight decay for better exploitation as the optimization progresses.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22874 with standard deviation 0.27419.", "error": "", "parent_ids": ["449ad4b5-4d8e-4ab9-89c1-922bd4909be7"], "operator": null, "metadata": {"aucs": [1.0, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09086898748588956, 0.08530068055133899]}}
{"id": "0ec698be-b188-4573-89f3-d2bb35072ee9", "fitness": 0.11007218874633046, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cognitive and social coefficients based on convergence rate for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            self.cognitive_coeff = 2 - (evaluations / self.budget)  # Adaptive cognitive coefficient\n            self.social_coeff = 1 + (evaluations / self.budget)  # Adaptive social coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11007 with standard deviation 0.03172.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10095385911141574, 0.07701163784046694, 0.08807728166990014, 0.1472447886665178, 0.1668689154086973, 0.14548977738095148, 0.0954288340217253, 0.08936386347645864, 0.08021074114084081]}}
{"id": "3f7c2440-029f-4a14-9f76-ebb34aaf182f", "fitness": 0.11897301782973733, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive inertia weight for balanced exploration and exploitation.  ", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11897 with standard deviation 0.03507.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.0838613974181941, 0.15966576139248423, 0.07367620730577262, 0.1532091687373931, 0.16616801383372926, 0.14639498432186526, 0.10256325780998987, 0.10517423949404503, 0.08004413015416267]}}
{"id": "7c50798a-ecd9-4175-ac00-e47e17360c00", "fitness": 0.12481440223535471, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce adaptive population size scaling and dynamic social coefficient adjustment for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.initial_social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            social_coeff = self.initial_social_coeff * (1 - evaluations / self.budget)  # Dynamic social coefficient\n\n            # Adaptive population size scaling\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, int(self.initial_population_size * (1 - evaluations / self.budget)))\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12481 with standard deviation 0.03237.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08588279324005121, 0.15481582474212674, 0.13726413462654374, 0.14547665063133208, 0.16615260288996914, 0.15973496529628184, 0.0999207072772118, 0.09082082910319378, 0.08326111231148203]}}
{"id": "e4087313-696e-4ef1-8be5-d0257363e444", "fitness": 0.10921444291922086, "name": "RefinedMetaheuristicOptimizer", "description": "Combine adaptive learning rates with dynamic swarm diversity to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.4\n        self.social_coeff = 1.6\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                # Adjust the learning factor dynamically\n                learning_factor = 0.5 + 0.5 * np.abs(np.sin(evaluations / self.budget * np.pi))\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                diversity = np.std(positions, axis=0).mean()\n                if diversity < 0.01:  # Reinitialize some particles if the swarm is too homogenous\n                    positions += np.random.randn(population_size, self.dim) * 0.1 * search_space\n\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10921 with standard deviation 0.03602.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.0959182678016437, 0.06614821419688055, 0.07595564576711833, 0.143157711005082, 0.16610614381970956, 0.16287138079095642, 0.10423813493343026, 0.08501915048586683, 0.08351533747230011]}}
{"id": "2961bb14-64ac-48eb-9d99-16181bbb1608", "fitness": 0.1288026270438297, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive population resizing and elite selection for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.elite_fraction = 0.2\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            elite_count = max(1, int(self.elite_fraction * population_size))\n            elite_positions = positions[np.argsort(personal_best_scores)[:elite_count]]\n            elite_score = np.min(personal_best_scores)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12880 with standard deviation 0.03038.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10059580163159532, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09086898748588956, 0.08530068055133899]}}
{"id": "c45a5ff2-688a-40ab-a8a0-616ec46bdebe", "fitness": 0.125435867023875, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce self-adaptive parameter control and dynamic population resizing for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= (0.5 + 0.5 * np.tanh(2 * (0.5 - progress_ratio)))  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12544 with standard deviation 0.03024.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08691445939728049, 0.15477214243090698, 0.08683649200197552, 0.15644098367350434, 0.16708883641592165, 0.15111544932474974, 0.11390060170969829, 0.09744341531540524, 0.11441042294543258]}}
{"id": "32e22759-d6e6-4110-90ff-5f881deb08ea", "fitness": 0.12877631829453565, "name": "EnhancedMetaheuristicOptimizer", "description": "Adjust the cooling rate dynamically based on progress to improve convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate * (1 - evaluations / self.budget)  # Change line\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12878 with standard deviation 0.02999.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09836041639762505, 0.15222480022654128, 0.13395060207257548, 0.14867697813409708, 0.1672496260631079, 0.16694315598735987, 0.1079923510981804, 0.0985431354532802, 0.08504579921805355]}}
{"id": "ba5e00c8-3227-4f3a-9685-a3aceae26d0e", "fitness": 0.11040458563665964, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance global exploration by adapting cognitive and social coefficients dynamically during optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            # Dynamic adjustment of coefficients\n            self.cognitive_coeff = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.social_coeff = 1.5 - 0.5 * (1 - evaluations / self.budget)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11040 with standard deviation 0.03559.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09942477129688587, 0.07210317929262877, 0.07480412679740911, 0.15215185792380204, 0.16757081489555703, 0.1570349444710596, 0.09741298331061132, 0.09165003976882025, 0.08148855297316282]}}
{"id": "473f71ee-fb6e-40e4-8f39-5d8653c76417", "fitness": 0.12239804324312731, "name": "EnhancedMetaheuristicOptimizer", "description": "Add dynamic adjustment to the cognitive coefficient for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            \n            self.cognitive_coeff = 1.5 * (1 - evaluations / self.budget) + 0.5 * (evaluations / self.budget)  # Dynamic cognitive coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12240 with standard deviation 0.03098.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10323165280425961, 0.15720819204902015, 0.0808267513360843, 0.14364294394941068, 0.16782877169377108, 0.15300892702156932, 0.10829503703557841, 0.09824287299479506, 0.08929724030365715]}}
{"id": "7766f50a-b3a1-47cd-847d-6f74ecc404fc", "fitness": 0.11461600385269384, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce dynamic cognitive and social coefficients for adaptive exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            self.cognitive_coeff = 2.0 - progress  # Dynamic cognitive coefficient\n            self.social_coeff = 1.0 + progress  # Dynamic social coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - progress)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11462 with standard deviation 0.03185.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10068062966967983, 0.07522554562139627, 0.07963329144542897, 0.1536934610802969, 0.16877643996431013, 0.14809570692117058, 0.09778029786124498, 0.09813636896448041, 0.10952229314623663]}}
{"id": "edff20f2-80cf-4f1a-877a-fa90e34ab6e4", "fitness": 0.11793717501814394, "name": "RefinedMetaheuristicOptimizer", "description": "Enhance convergence by integrating adaptive population size reduction and dynamic parameter tuning.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.initial_learning_factor = 1.0\n        self.final_learning_factor = 0.3\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.99\n        self.min_population_size = 5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= 0.98  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - progress_ratio)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5 and evaluations % 10 == 0:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11794 with standard deviation 0.03317.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09597833219853757, 0.1430215084853218, 0.06803028110186171, 0.15131289861224095, 0.16763096331047223, 0.15049364120365938, 0.09527190286255283, 0.10108316338639345, 0.0886118840022555]}}
{"id": "a2e8bdbb-3513-461b-9827-67ae8a0260ca", "fitness": 0.11640483058770815, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive mutation and elitism to enhance exploration and exploitation balance in the optimization process.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        elitism_factor = 0.1  # Fraction of top performers maintained\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            indices = np.argsort(personal_best_scores)\n            elite_count = int(elitism_factor * population_size)\n            elites = positions[indices[:elite_count]]\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                if np.random.rand() < self.mutation_rate:\n                    mutations = np.random.randn(self.dim) * 0.1 * search_space\n                    velocities[i] += mutations\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            if population_size < self.initial_population_size:\n                positions[:elite_count] = elites[:elite_count]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11640 with standard deviation 0.03129.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10097455513089915, 0.08827179604754976, 0.124455620043045, 0.14695192930803047, 0.16872619339305528, 0.15375203476285382, 0.09306370353710058, 0.09626330593852983, 0.07518433712830941]}}
{"id": "8e57c96c-47eb-4bac-97d6-7271b24da097", "fitness": 0.0956337253085451, "name": "EnhancedMetaheuristicOptimizerV2", "description": "Incorporate adaptive velocity scaling and dynamic inertia adjustment to enhance convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.adaptive_scaling_factor = 1.0\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)  # Dynamic inertia adjustment\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * self.adaptive_scaling_factor\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    self.adaptive_scaling_factor = 1.5  # Increase scaling when improving\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Acceptance based on Metropolis criterion\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Gradually reduce population size and temperature\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n            if evaluations % 100 == 0:\n                self.adaptive_scaling_factor = 1.0  # Reset scaling factor periodically\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedMetaheuristicOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09563 with standard deviation 0.04542.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.04904638570143316, 0.07390673302929085, 0.035794710735143065, 0.1553633759205939, 0.16610614381970956, 0.1471044202078765, 0.08705505023045768, 0.07940004781166177, 0.06692666032073935]}}
{"id": "d828ce09-3504-42b2-8700-5d5d748315a0", "fitness": 0.11255986315027638, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate adaptive neighborhood size and dynamic exploration-exploitation balance to enhance convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            adaptive_neighborhood_radius = (1 - progress_ratio) * 0.5 * search_space.mean()\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.linalg.norm(positions[i] - global_best_position) < adaptive_neighborhood_radius:\n                    velocities[i] *= np.random.rand() * 2\n\n            if progress_ratio > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11256 with standard deviation 0.03312.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09913309699758144, 0.07050503297975586, 0.09043595285110961, 0.14278143005234767, 0.17352139161860403, 0.15312926659043558, 0.09835071076395352, 0.10151451624292152, 0.0836673702557783]}}
{"id": "8657e824-d4af-4b37-a11b-847c819169e3", "fitness": 0.12429183881676373, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive velocity scaling based on convergence rate to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            if evaluations < self.budget * 0.3:\n                velocities *= 1.2\n            elif evaluations > self.budget * 0.7:\n                velocities *= 0.8\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12429 with standard deviation 0.03392.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09245759106770135, 0.1666294916370329, 0.09445232074771737, 0.15597296007606265, 0.16688213904820426, 0.15826883250221868, 0.0996776040714491, 0.0949651849866382, 0.0893204252138492]}}
{"id": "0ae8c9aa-d0d5-4cee-a690-d551c051d91e", "fitness": 0.12752557390783523, "name": "EnhancedMetaheuristicOptimizer", "description": "Use adaptive cognitive coefficients for dynamic exploration and exploitation adjustment.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            adaptive_cognitive_coeff = self.cognitive_coeff * (1 - evaluations / self.budget)  # Adaptive cognitive coefficient\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = adaptive_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12753 with standard deviation 0.03262.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10071718945125041, 0.16001652098547625, 0.07582731978269508, 0.15926055896444102, 0.16890414507819929, 0.15841060310464783, 0.12180439556874578, 0.1067533304270123, 0.09603610180804889]}}
{"id": "8541c94e-1997-4a93-9d11-956d43d42a08", "fitness": 0.1288026270438297, "name": "AdvancedMetaheuristicOptimizer", "description": "Integrate adaptive velocity control and dynamic population resizing for enhanced balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12880 with standard deviation 0.03038.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10059580163159532, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09086898748588956, 0.08530068055133899]}}
{"id": "da0b403f-46fa-4b78-901f-f36ff3c51bfd", "fitness": 0.1093022928949244, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate adaptive inertia weight decay and dynamic cognitive and social coefficients for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.cognitive_coeff = 2.0 - (1.0 - evaluations / self.budget)  # Dynamic cognitive component\n            self.social_coeff = 2.0 - (1.0 - evaluations / self.budget)  # Dynamic social component\n            self.inertia_weight *= (0.99 + 0.01 * (evaluations / self.budget))  # Adaptive inertia decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10930 with standard deviation 0.03634.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10107757966063036, 0.0761488525770635, 0.07069119704182458, 0.15704380390751227, 0.1701361532141641, 0.14750719229782427, 0.09569757603960682, 0.0924533815208266, 0.07296489979486709]}}
{"id": "200b48b4-7b49-4f00-a2d4-8a41528017e8", "fitness": 0.09933682438073393, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce adaptive velocity normalization and stochastic decision-making to enhance exploration and adaptability.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                velocity_magnitude = np.linalg.norm(velocities[i])\n                if velocity_magnitude > 1e-5:\n                    velocities[i] /= velocity_magnitude\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                stochastic_threshold = np.random.rand()\n                if score < global_best_score or stochastic_threshold < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09934 with standard deviation 0.04410.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.06315570855064068, 0.08084345836625506, 0.033515997149021204, 0.15300902767444113, 0.16610614381970956, 0.1542591318076575, 0.08594193586186327, 0.0864180301496904, 0.07078198604732666]}}
{"id": "08734b52-8ac6-438a-a3f1-eaff05664bf5", "fitness": 0.12130247792420572, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate dynamic inertia weight adjustment and adaptive population resizing to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.9  # Changed from 0.5 to 0.9 for better initial exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Dynamic inertia weight adjustment\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 2)  # Adjusted decrement by 2\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12130 with standard deviation 0.03331.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08593692929844488, 0.15664703775670719, 0.08555990843446715, 0.16194894622069478, 0.16614376649911566, 0.14413058684441482, 0.10998474301071337, 0.09413239538531748, 0.0872379878679761]}}
{"id": "23b8604a-f00b-41db-b771-0d68934f561a", "fitness": 0.13030999473272745, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive inertia weight decay that slows down as the temperature decreases for enhanced stability in convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.995 + (temperature / self.initial_temperature) * 0.005  # Adaptive inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13031 with standard deviation 0.02942.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09729042914189101, 0.15754302653893582, 0.1354147807425261, 0.16036602672638656, 0.16998219927157254, 0.15176568079447939, 0.10780700951260547, 0.105677203067303, 0.08694359679884722]}}
{"id": "b2d7c044-72f4-4db0-99df-1de802659608", "fitness": 0.12533130051318533, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive learning factor decay and dynamic velocity scaling for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.2  # Changed from 0.4 to 0.2\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12533 with standard deviation 0.02995.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09927066156528319, 0.1583285293027531, 0.0898857512119231, 0.15064420881548457, 0.1682116527558709, 0.15260932802435845, 0.11587451557672757, 0.09025397587940587, 0.10290308148686134]}}
{"id": "c066da8a-2df8-490c-9764-f7038de1db9c", "fitness": 0.12831734922778967, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce adaptive population resizing and momentum control for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.momentum_decay_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= self.momentum_decay_rate\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                dec_factor = 1 + (evaluations / self.budget)\n                population_size = max(self.min_population_size, int(population_size / dec_factor))\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12832 with standard deviation 0.03050.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10022151059745121, 0.1638892373915175, 0.13846663067845677, 0.1404071648879084, 0.16868613903415008, 0.155991746173881, 0.11354481349972234, 0.08895035839873044, 0.08469854238828933]}}
{"id": "4f12e8aa-30c5-4460-935d-cf9bf53c18db", "fitness": 0.09616459456793516, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce dynamic social and cognitive coefficients to balance exploration and exploitation over time.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                # Dynamic coefficients based on evaluations progress\n                self.cognitive_coeff = 1.5 * (1 - evaluations / self.budget)\n                self.social_coeff = 1.5 * (evaluations / self.budget)\n                \n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09616 with standard deviation 0.04599.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.04794194582106548, 0.04948218507974189, 0.05140502184217699, 0.163321605240213, 0.16615116866752067, 0.14420106717185044, 0.0863332029591205, 0.0844660472627986, 0.07217910706692887]}}
{"id": "7020d454-cca5-4ce7-b354-b36f4453f492", "fitness": 0.08695945710263592, "name": "AdaptiveEvolutionaryStrategy", "description": "Incorporate adaptive mutation and crossover inspired by evolutionary strategies to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveEvolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 10\n        self.temperature = 100.0\n        self.cooling_rate = 0.995\n        self.learning_rate = 0.1\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Adaptive mutation and crossover\n            mutation_prob = np.clip(1.0 - (evaluations / self.budget), 0.1, 0.9)\n            crossover_prob = np.clip(evaluations / self.budget, 0.1, 0.9)\n\n            for i in range(population_size):\n                # Mutation\n                if np.random.rand() < mutation_prob:\n                    mutation = self.learning_rate * np.random.randn(self.dim)\n                    positions[i] += mutation\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Crossover (Blend crossover)\n                if np.random.rand() < crossover_prob:\n                    partner_index = np.random.choice(population_size)\n                    alpha = np.random.rand(self.dim)\n                    positions[i] = alpha * positions[i] + (1 - alpha) * positions[partner_index]\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            # Cool down the system\n            self.temperature *= self.cooling_rate\n\n            # Adapt population size\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm AdaptiveEvolutionaryStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08696 with standard deviation 0.05171.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.026072491131955977, 0.02794872375099977, 0.03828539319346713, 0.15249132199825832, 0.16731873655407825, 0.14116365411721987, 0.08594193586186327, 0.08488840062016445, 0.058524456695716154]}}
{"id": "06020cad-b30d-4804-b504-441cda105e31", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance global exploration by introducing dynamic search space scaling and adaptive mutation based on convergence progress.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n            \n            # Dynamic search space scaling\n            dynamic_scale = 0.5 + 0.5 * (evaluations / self.budget)\n            range_adjustment = (bounds[1] - bounds[0]) * dynamic_scale\n            positions += np.random.uniform(-range_adjustment, range_adjustment, positions.shape) * 0.1\n            \n            # Adaptive mutation\n            if evaluations / self.budget < 0.5:\n                mutation_probability = 0.05\n            else:\n                mutation_probability = 0.2\n            mutation_indices = np.random.rand(population_size, self.dim) < mutation_probability\n            positions[mutation_indices] += np.random.randn(*positions[mutation_indices].shape) * 0.05 * search_space\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (22,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (22,) (10,) ')", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {}}
{"id": "42d45913-6d45-414f-b054-af1e58972096", "fitness": 0.12948747323952337, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate adaptive velocity scaling and neighborhood search for enhanced convergence and exploration balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.velocity_scaling_factor = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * self.velocity_scaling_factor * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                if np.random.rand() < 0.1:\n                    velocities[i] += np.random.randn(self.dim) * self.velocity_scaling_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12949 with standard deviation 0.03530.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.19379803074920243, 0.08099974535537491, 0.1326789325908705, 0.14120552976440248, 0.1661146122845374, 0.15213232417776446, 0.10185103045244359, 0.10117246057495088, 0.09543459320616354]}}
{"id": "1dbf305b-a155-4353-a996-0598d0024d74", "fitness": 0.11750604645612972, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate adaptive velocity scaling and dynamic temperature adjustment for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.98  # More aggressive inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Adaptive velocity scaling\n                velocities[i] *= 1 + (1 - evaluations / self.budget) * 0.5\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                # Dynamic temperature adjustment\n                if score > global_best_score:\n                    velocities[i] *= np.random.rand() * 2 * (temperature / self.initial_temperature)\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11751 with standard deviation 0.03857.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09153877361834162, 0.13367078296850288, 0.0709889762185203, 0.15332758557422976, 0.16723822758660167, 0.1745330206142245, 0.11106111583292655, 0.08288660945757231, 0.0723093262342479]}}
{"id": "2fb1eafa-5ee0-4fd1-9c26-c67c3eaa0cd2", "fitness": 0.12008359592573672, "name": "EnhancedMetaheuristicOptimizer", "description": "Integrate adaptive mutation for enhanced exploration in late stages.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < 0.3 * (evaluations / self.budget):  # Adaptive mutation\n                    positions[i] += np.random.randn(self.dim) * 0.1 * search_space\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12008 with standard deviation 0.03200.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.06295717130398615, 0.14301944930346633, 0.12803242791691882, 0.1479324485009218, 0.1672311408134861, 0.14403257394987823, 0.0961782695430532, 0.09940790967455704, 0.09196097232536293]}}
{"id": "8275e619-4290-4a52-a683-edfc900f074e", "fitness": 0.12880098724769762, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cooling rate for improved convergence control over optimization.  ", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= (self.cooling_rate + 0.0005 * (evaluations / self.budget)) # Adaptive cooling rate adjustment\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12880 with standard deviation 0.03039.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10059580163159532, 0.16443675194623264, 0.1386531955373912, 0.14302923767139175, 0.16858264087696895, 0.155991746173881, 0.11176460151977774, 0.09085422932070097, 0.08530068055133899]}}
{"id": "13bcd548-6d4e-466d-a140-49fb91fdf66f", "fitness": 0.1205325915663787, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce adaptive population resizing and exploitation-intensifying mutations to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7\n        self.social_coeff = 1.7\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.exploitation_intensity = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.98  # Slightly faster decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Apply exploitation-intensifying mutation\n                if np.random.rand() < self.exploitation_intensity:\n                    mutation = np.random.randn(self.dim) * 0.01 * search_space\n                    positions[i] += mutation\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12053 with standard deviation 0.02656.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09879175471447377, 0.13386550706524014, 0.10306553816342856, 0.14983535296028228, 0.16612059445282257, 0.1451089634258652, 0.09958224344150912, 0.0980589243429757, 0.09036444553081091]}}
{"id": "96ebaaf4-d688-4009-a826-7e76f64fb62e", "fitness": 0.12335388986733761, "name": "AdaptiveMutationOptimizer", "description": "Introduce adaptive mutation strategy to balance exploration and exploitation dynamically during optimization.", "code": "import numpy as np\n\nclass AdaptiveMutationOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            mutation_strength = self.mutation_rate * np.exp(-evaluations / (0.5 * self.budget))\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Adaptive mutation\n                if np.random.rand() < mutation_strength:\n                    mutation_vector = np.random.randn(self.dim) * mutation_strength * search_space\n                    positions[i] = np.clip(positions[i] + mutation_vector, bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm AdaptiveMutationOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12335 with standard deviation 0.02577.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10483188946798994, 0.09813249715962835, 0.12492539370821232, 0.14449973506688008, 0.16885487802604038, 0.15794861041110642, 0.10772846506936007, 0.09488646589456229, 0.1083770740022586]}}
{"id": "05b93a99-26f1-46dc-a297-e5e0a5d03cce", "fitness": 0.09616459456793516, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cognitive and social coefficients for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                # Change: Adaptive cognitive and social coefficients based on progress\n                adaptive_cognitive_coeff = self.cognitive_coeff * (1 - evaluations / self.budget)\n                adaptive_social_coeff = self.social_coeff * (evaluations / self.budget)\n\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = adaptive_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = adaptive_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09616 with standard deviation 0.04599.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.04794194582106548, 0.04948218507974189, 0.05140502184217699, 0.163321605240213, 0.16615116866752067, 0.14420106717185044, 0.0863332029591205, 0.0844660472627986, 0.07217910706692887]}}
{"id": "a1c28f16-f655-46e1-b4da-0df1da3fd605", "fitness": 0.12123664069048837, "name": "EnhancedMetaheuristicOptimizer", "description": "Incorporate adaptive social coefficient adjustment to enhance convergence towards the global best.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                self.social_coeff = 1.0 + 0.5 * (1 - evaluations / self.budget)  # Adaptive social coefficient\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12124 with standard deviation 0.03449.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09421983281445268, 0.15525373230993822, 0.09576527919889011, 0.14824574140881852, 0.16900253723643832, 0.1602650912038086, 0.10356429664720668, 0.09479551862027469, 0.07001773677456735]}}
{"id": "dd465224-2112-4643-b391-1d6c2b4cd98b", "fitness": 0.11925030858054443, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance convergence through adaptive learning factor instead of static decay.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - (evaluations / self.budget)**2) + self.final_learning_factor  # Adjusted learning factor decay\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11925 with standard deviation 0.03641.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09352891980428346, 0.1463224325841569, 0.05216818097880882, 0.1565632192783304, 0.1673758437778763, 0.1550211932085076, 0.10405838475595841, 0.09777935224331225, 0.10043525059366576]}}
{"id": "7d785bd3-ef1e-4f0d-9e51-510234dd925d", "fitness": 0.12047562863888223, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cooling rate and variable inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.95 + 0.05 * (evaluations / self.budget)  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= np.exp(-0.01 * (evaluations / self.budget))  # Adaptive cooling rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12048 with standard deviation 0.03216.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09458668013376359, 0.1460439760830634, 0.0894051260700569, 0.15982313176797203, 0.1663938330156448, 0.14878818010261896, 0.10694590431389805, 0.08945001018292476, 0.08284381607999725]}}
{"id": "98317852-5071-4572-bca7-d2da989e25cb", "fitness": 0.12804055226529523, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cooling schedule and dynamic coefficient adjustments for a more responsive search strategy.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.min_cooling_rate = 0.9\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            adaptive_cooling_rate = self.cooling_rate - (self.cooling_rate - self.min_cooling_rate) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= adaptive_cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12804 with standard deviation 0.02868.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09990449050051342, 0.16443675194623264, 0.1323552152101517, 0.1432223517359037, 0.16622304988949776, 0.15221270330722192, 0.10953572280014934, 0.09892456830086882, 0.08555011669711776]}}
{"id": "5fc9499a-cbb6-4642-83d2-d3d4a3575db7", "fitness": 0.12632067000345804, "name": "AdaptiveMetaheuristicOptimizer", "description": "Introduce adaptive population resizing with dynamic inertia weight based on success rate for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.min_population_size = 5\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.success_threshold = 0.2\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        prev_global_best_score = global_best_score\n        successes = 0\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            \n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if global_best_score < prev_global_best_score:\n                successes += 1\n            prev_global_best_score = global_best_score\n\n            success_rate = successes / evaluations\n            if success_rate > self.success_threshold:\n                self.inertia_weight *= 0.9\n            else:\n                self.inertia_weight *= 1.1\n\n            population_size = max(self.min_population_size, population_size - 1)\n            positions = positions[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12632 with standard deviation 0.03474.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09591048094510268, 0.1569765374312715, 0.1207359003045434, 0.1618172705896349, 0.1693939295819047, 0.1650004744947018, 0.09660562205027745, 0.09206711607946827, 0.07837869855421764]}}
{"id": "f0ef55c7-44f1-48bd-a2e0-6b3e2c557ccd", "fitness": 0.1245533826696199, "name": "EnhancedMetaheuristicOptimizer", "description": "Enhance global exploration by introducing a dynamic adaptability feature for social influence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            dynamic_social_coeff = self.social_coeff * (0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi))  # Dynamic adaptation\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = dynamic_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12455 with standard deviation 0.03122.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10388457331002021, 0.15605935014246997, 0.13180522645266102, 0.14846775388528688, 0.16633165997881383, 0.1495063647742908, 0.09787388748520331, 0.09537715295537563, 0.07167447504245739]}}
{"id": "31c5a8d7-2393-4212-94a9-284b02848a01", "fitness": 0.10826430823720234, "name": "HybridMetaheuristicOptimizer", "description": "Hybridize inertia weight decay with adaptive differential evolution to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                if np.random.rand() < self.CR:\n                    a, b, c = np.random.choice(population_size, 3, replace=False)\n                    mutant_vector = personal_best_positions[a] + self.F * (personal_best_positions[b] - personal_best_positions[c])\n                    trial_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, positions[i])\n                    trial_vector = np.clip(trial_vector, bounds[0], bounds[1])\n                    trial_score = func(trial_vector)\n                    evaluations += 1\n                    if trial_score < personal_best_scores[i]:\n                        positions[i] = trial_vector\n                        personal_best_scores[i] = trial_score\n\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10826 with standard deviation 0.03762.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08342526962331975, 0.10475221503698118, 0.06519167688376715, 0.15222122033378827, 0.1675513938077554, 0.15277961479369162, 0.10327542119094535, 0.08378663070884507, 0.06139533175572731]}}
{"id": "63d284bf-f82d-45f7-ac33-9f9fcaf6ae8a", "fitness": 0.11704796921357478, "name": "RefinedMetaheuristicOptimizer", "description": "Incorporate self-adaptive learning rates and dynamic neighborhood structures for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.0\n        self.social_coeff = 1.0\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.993\n        self.min_population_size = 10\n        self.epsilon = 1e-8\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        learning_rates = np.full(population_size, 0.5)\n        success_counter = np.zeros(population_size)\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                \n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_rates[i]\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                    success_counter[i] += 1\n                else:\n                    success_counter[i] = max(0, success_counter[i] - 1)\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / (temperature + self.epsilon)):\n                    velocities[i] *= np.random.rand() * 2\n\n                learning_rates[i] = min(1.0, max(0.1, learning_rates[i] + 0.1 * (success_counter[i] - 1)))\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n                learning_rates = learning_rates[:population_size]\n                success_counter = success_counter[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11705 with standard deviation 0.03316.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09717387510604736, 0.09643788171635959, 0.11324565598579883, 0.15053013540029347, 0.17035079313618806, 0.16365263472098446, 0.09889207601928318, 0.08787695751908009, 0.07527171331813787]}}
{"id": "29bc0fb3-92dc-4ac4-87bc-880880fe8b78", "fitness": -Infinity, "name": "EnhancedMetaheuristicOptimizer", "description": "Implement a dynamic population size strategy driven by entropy to enhance exploration and exploitation balance during optimization.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def compute_entropy(self, scores):\n        probabilities = np.exp(-np.array(scores))\n        probabilities /= np.sum(probabilities)\n        entropy = -np.sum(probabilities * np.log(probabilities + 1e-12))\n        return entropy\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            \n            entropy = self.compute_entropy(personal_best_scores)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Dynamically adjust population size based on entropy\n            if entropy > 0.5:\n                population_size = min(self.initial_population_size, population_size + 1)\n            else:\n                population_size = max(self.min_population_size, population_size - 1)\n            \n            positions = positions[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "An exception occurred: IndexError('index 49 is out of bounds for axis 0 with size 49').", "error": "IndexError('index 49 is out of bounds for axis 0 with size 49')", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {}}
{"id": "f95225bc-faa9-4140-8959-372f0572135a", "fitness": 0.13494846676674235, "name": "AdaptiveMetaheuristicOptimizer", "description": "Integrate adaptive mutation and crossover operations inspired by genetic algorithms to enhance exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                if np.random.rand() < self.crossover_rate:\n                    partner_idx = np.random.randint(population_size)\n                    partner = personal_best_positions[partner_idx]\n                    crossover_mask = np.random.rand(self.dim) < 0.5\n                    positions[i][crossover_mask] = partner[crossover_mask]\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = (np.random.rand(self.dim) - 0.5) * search_space * 0.1\n                    positions[i] += mutation_vector\n\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13495 with standard deviation 0.05776.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.26870774511812157, 0.1291380488252214, 0.09426436445394615, 0.15023345076869565, 0.16888340646159172, 0.15784655176804707, 0.08675793453110026, 0.08300900060739269, 0.07569569836656465]}}
{"id": "72371727-4f69-46eb-9c82-39eec2c26a45", "fitness": 0.11061661222833748, "name": "AdaptiveNeighborhoodOptimizer", "description": "Introduce adaptive neighborhood search to enhance local exploration dynamically as the optimization progresses.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.neighborhood_radius = 0.1  # Initial neighborhood radius\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            self.neighborhood_radius *= 0.99  # Adaptive radius decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.2:  # 20% chance to explore neighborhood\n                    neighbor = positions[i] + np.random.uniform(-self.neighborhood_radius, self.neighborhood_radius, self.dim)\n                    neighbor = np.clip(neighbor, bounds[0], bounds[1])\n                    neighbor_score = func(neighbor)\n                    evaluations += 1\n                    if neighbor_score < personal_best_scores[i]:\n                        personal_best_positions[i] = neighbor\n                        personal_best_scores[i] = neighbor_score\n                        if neighbor_score < global_best_score:\n                            global_best_position = neighbor\n                            global_best_score = neighbor_score\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm AdaptiveNeighborhoodOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11062 with standard deviation 0.03449.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09027795192725341, 0.09974541997147068, 0.06950350818345974, 0.1540242398596492, 0.16639891559018283, 0.14560915619854242, 0.11086701705915758, 0.09244587703831353, 0.06667742422700795]}}
{"id": "dd3ca714-cb55-4dd8-a64f-0e45cd56e33e", "fitness": 0.11071238264269112, "name": "RefinedMetaheuristicOptimizer", "description": "Integrate adaptive velocity limits and dynamic population resizing to balance exploration and exploitation.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.velocity_limit_factor = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n\n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * self.velocity_limit_factor * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                velocity_limit = self.velocity_limit_factor * (bounds[1] - bounds[0]) * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -velocity_limit, velocity_limit)\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.33:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11071 with standard deviation 0.04348.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.056494887357870116, 0.10450757158667001, 0.07539540914411524, 0.17508566782210078, 0.17427587666302213, 0.1597147306842832, 0.08596813763184041, 0.08248485529594762, 0.08248430759837055]}}
{"id": "3ae62151-2c6e-4a91-a814-d5848e5cb742", "fitness": 0.12877631829453565, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive cooling based on evaluation progress for improved convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12878 with standard deviation 0.02999.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09836041639762505, 0.15222480022654128, 0.13395060207257548, 0.14867697813409708, 0.1672496260631079, 0.16694315598735987, 0.1079923510981804, 0.0985431354532802, 0.08504579921805355]}}
{"id": "2e2b45fe-36f2-466f-8f7e-19dffd2531e8", "fitness": 0.13052082360388356, "name": "EnhancedMetaheuristicOptimizer", "description": "Implement adaptive learning factor and limit inertia weight decay to initial budget ratio.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = self.initial_learning_factor - (self.initial_learning_factor - self.final_learning_factor) * (evaluations / self.budget)\n            self.inertia_weight *= 0.995 if evaluations < 0.5 * self.budget else 1.0  # Adjust decay limit\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13052 with standard deviation 0.02979.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10090394471418462, 0.1637497063303215, 0.13720498894863364, 0.14540011517506246, 0.17032041951304577, 0.15645888523717255, 0.12217326520620053, 0.0877958743573839, 0.09068021295294726]}}
{"id": "0616a30e-ec67-41eb-b884-7481fba8d4a8", "fitness": 0.1300805936295354, "name": "EnhancedMetaheuristicOptimizer", "description": "Adjust inertia weight decay to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.995  # Adjusted inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13008 with standard deviation 0.03001.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.10090029968838576, 0.16373569255974774, 0.13720276536707, 0.14369456853000817, 0.17035177154018166, 0.15645859169052123, 0.12184946260039542, 0.08743028627087057, 0.08910190441863786]}}
{"id": "8af55679-5ef0-4c38-b237-1306d2af1588", "fitness": 0.12334582369311864, "name": "EnhancedAdaptiveOptimizer", "description": "Introduce adaptive mutation strategies and dynamic population resizing to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.mutation_prob = 0.1\n        self.max_mutation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Adaptive mutation strategy\n                if np.random.rand() < self.mutation_prob:\n                    mutation = np.random.uniform(-self.max_mutation_rate, self.max_mutation_rate, self.dim) * search_space\n                    velocities[i] += mutation\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Dynamic population resizing\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12335 with standard deviation 0.02996.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.1060092819315358, 0.13176594409991993, 0.11845800380478233, 0.1523317442314409, 0.16779500348645637, 0.16050216893743485, 0.09693746847295004, 0.10070727447620809, 0.07560552379733931]}}
{"id": "d3997184-7891-4f37-ae3b-641911147992", "fitness": 0.11151410066582547, "name": "AdvancedMetaheuristicOptimizer", "description": "Integrate adaptive social-cognitive coefficients and dynamic population size to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AdvancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress) + self.final_learning_factor\n            self.inertia_weight *= 0.99\n            \n            for i in range(population_size):\n                local_cognitive_coeff = self.cognitive_coeff * (1 - progress) + 0.5 * progress\n                local_social_coeff = self.social_coeff * progress + 0.5 * (1 - progress)\n                \n                inertia = self.inertia_weight * velocities[i] * (1 - progress)\n                cognitive_component = local_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = local_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm AdvancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11151 with standard deviation 0.03685.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.06548884080224004, 0.10162602361130513, 0.06780997318663018, 0.1499795328996103, 0.16613735323817036, 0.16236351981858999, 0.09513847270151732, 0.11148613204401958, 0.08359705769034642]}}
{"id": "adc28dbe-2187-4092-af92-8abcdca1ca57", "fitness": 0.11938253774764915, "name": "EnhancedMetaheuristicOptimizer", "description": "Implement adaptive inertia weight to dynamically balance exploration and exploitation throughout the optimization process.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight = 0.9 - 0.8 * (evaluations / self.budget)  # Adaptive inertia weight\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11938 with standard deviation 0.03526.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09120638545652482, 0.1578638630248148, 0.07342200078038974, 0.14683683839476414, 0.1713853249687124, 0.1540462671848466, 0.09960254990776785, 0.09394573937337813, 0.086133870637644]}}
{"id": "6b156198-0556-4b8d-b5b0-d4f005a50b9d", "fitness": 0.09650326057858602, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive social-cognitive balance and stochastic velocity adjustment for enhanced convergence and stability.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n            \n            # Adaptive social-cognitive balance\n            social_cognitive_balance = evaluations / self.budget  \n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = (self.cognitive_coeff * (1 - social_cognitive_balance)) * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = (self.social_coeff * social_cognitive_balance) * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                # Stochastic velocity adjustment\n                if np.random.rand() < 0.2:  \n                    velocities[i] *= np.random.normal(1.0, 0.1)\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09650 with standard deviation 0.04578.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.04827617989755728, 0.05755081632887715, 0.04603224505183201, 0.1500170682906966, 0.16611842730373783, 0.15822148416159387, 0.09145515504777002, 0.08003577774836257, 0.07082219137684687]}}
{"id": "1fb5df11-a3ea-4e0b-8285-884a648fcf86", "fitness": 0.12014332293728001, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce adaptive velocity scaling based on function evaluations to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor * (1 + 0.5 * np.sin(np.pi * evaluations / self.budget))  # Adaptive velocity scaling\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12014 with standard deviation 0.03402.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.08745400110476242, 0.15793555809210846, 0.06673594664101201, 0.15041707116117142, 0.16655974506025784, 0.14732146357028486, 0.09151829176645965, 0.11274329279276152, 0.10060453624670196]}}
{"id": "1e5a47a1-7b0f-4450-bce7-450aa76252ff", "fitness": -Infinity, "name": "AdaptiveMetaheuristicOptimizer", "description": "Integrate adaptive population resizing based on performance feedback to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n        self.performance_threshold = 0.01\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        prev_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                performance_improvement = abs(prev_global_best_score - global_best_score)\n                if performance_improvement < self.performance_threshold:\n                    population_size = max(self.min_population_size, population_size - 1)\n                else:\n                    population_size = min(self.initial_population_size, population_size + 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            prev_global_best_score = global_best_score\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "An exception occurred: IndexError('index 48 is out of bounds for axis 0 with size 48').", "error": "IndexError('index 48 is out of bounds for axis 0 with size 48')", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {}}
{"id": "1b73224c-3282-4f9b-85b2-8ce079dd228d", "fitness": 0.2061815533293507, "name": "EnhancedMetaheuristicOptimizer", "description": "Introduce a dynamic cooling rate to enhance global exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i] * (1 - evaluations / self.budget)\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - 1)\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate * (1.0 - evaluations / self.budget)  # Dynamic cooling rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20618 with standard deviation 0.21005.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.7950075317109606, 0.15222480022654128, 0.13395060207257548, 0.14867697813409708, 0.1672496260631079, 0.16694315598735987, 0.1079923510981804, 0.0985431354532802, 0.08504579921805355]}}
{"id": "bfc2aada-d7e5-4959-b8fc-7f2093c37253", "fitness": 0.10612306511993962, "name": "RefinedMetaheuristicOptimizer", "description": "Introduce dynamic population sizing and adaptive cognitive and social coefficients for improved convergence.", "code": "import numpy as np\n\nclass RefinedMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.7  # Start with a slightly higher inertia weight\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            progress_ratio = evaluations / self.budget\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - progress_ratio) + self.final_learning_factor\n            self.inertia_weight *= 0.98  # Further decay of inertia weight\n            \n            adaptive_cognitive_coeff = self.cognitive_coeff * (1 - progress_ratio)\n            adaptive_social_coeff = self.social_coeff * (progress_ratio)\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = adaptive_cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = adaptive_social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            # Dynamic population size adjustment based on progress\n            if progress_ratio > 0.5:\n                population_size = max(self.min_population_size, int(self.initial_population_size * (1 - progress_ratio)))\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm RefinedMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10612 with standard deviation 0.03807.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.07879402983992312, 0.08484242729726688, 0.05489197105009325, 0.1531908687041431, 0.16673565547389224, 0.152088617131238, 0.09953289360502049, 0.08783460432632206, 0.07719651865155741]}}
{"id": "10391bec-f136-4644-9264-f3c4358e5c44", "fitness": 0.12605367314649063, "name": "AdaptiveMetaheuristicOptimizer", "description": "Implement adaptive learning factor and dynamic population resizing to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(50, self.budget // 5)\n        self.inertia_weight = 0.5\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.initial_learning_factor = 0.9\n        self.final_learning_factor = 0.4\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.995\n        self.min_population_size = 10\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        search_space = bounds[1] - bounds[0]\n        temperature = self.initial_temperature\n        population_size = self.initial_population_size\n        \n        positions = np.random.rand(population_size, self.dim) * search_space + bounds[0]\n        velocities = np.random.randn(population_size, self.dim) * 0.1 * search_space\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(pos) for pos in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            learning_factor = (self.initial_learning_factor - self.final_learning_factor) * (1 - evaluations / self.budget) + self.final_learning_factor\n            self.inertia_weight *= 0.99  # Inertia weight decay\n\n            for i in range(population_size):\n                inertia = self.inertia_weight * velocities[i]\n                cognitive_component = self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_coeff * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = inertia + cognitive_component + social_component\n                velocities[i] *= learning_factor\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                if score < global_best_score:\n                    global_best_position = positions[i]\n                    global_best_score = score\n\n                if np.random.rand() < np.exp(-abs(score - global_best_score) / temperature):\n                    velocities[i] *= np.random.rand() * 2\n\n            if evaluations / self.budget > 0.5:\n                population_size = max(self.min_population_size, population_size - (evaluations // self.budget))\n                positions = positions[:population_size]\n                velocities = velocities[:population_size]\n                personal_best_positions = personal_best_positions[:population_size]\n                personal_best_scores = personal_best_scores[:population_size]\n\n            temperature *= self.cooling_rate\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm AdaptiveMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12605 with standard deviation 0.02865.", "error": "", "parent_ids": ["77a32b2a-7b28-4ce0-95d6-45f75ead8408"], "operator": null, "metadata": {"aucs": [0.09943741527503891, 0.15571085791266137, 0.0902996542833453, 0.15059710272725502, 0.16895498813612175, 0.15124958852507364, 0.0999716485264851, 0.09936035859970205, 0.11890144433273242]}}
