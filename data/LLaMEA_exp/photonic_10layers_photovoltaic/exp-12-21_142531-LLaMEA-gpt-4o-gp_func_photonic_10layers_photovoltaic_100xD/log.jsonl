{"id": "1d54bfec-d08c-4949-a524-197708ca442f", "fitness": 0.052499564223224784, "name": "HybridPSO_DE", "description": "Hybrid Particle Swarm Optimization with Adaptive Differential Evolution, leveraging swarm intelligence and adaptive mutation strategies for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.5  # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cross_prob = 0.9  # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize swarm\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Particle Swarm Optimization step\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (\n                    self.w * velocity[i] +\n                    self.c1 * r1 * (personal_best[i] - swarm[i]) +\n                    self.c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] += velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n          \n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05250 with standard deviation 0.00302.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.053919385260413843, 0.05803273543903198, 0.055990403966151736, 0.049795944285773386, 0.053582622872074825, 0.05170604316570948, 0.04799103814890482, 0.05164321368674152, 0.04983469118422146]}}
{"id": "706e108b-eaff-4a75-8f38-c9f6ec2c576a", "fitness": 0.050317884846513956, "name": "HybridPSO_DE", "description": "Enhanced Hybrid Particle Swarm Optimization with Adaptive Differential Evolution using dynamic inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.5  # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cross_prob = 0.9  # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize swarm\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamically adjust inertia weight\n            # Particle Swarm Optimization step\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (\n                    self.w * velocity[i] +\n                    self.c1 * r1 * (personal_best[i] - swarm[i]) +\n                    self.c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] += velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n          \n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            # Differential Evolution step\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05032 with standard deviation 0.00302.", "error": "", "parent_ids": ["1d54bfec-d08c-4949-a524-197708ca442f"], "operator": null, "metadata": {"aucs": [0.0531404494282528, 0.05612820370959315, 0.051681571597406606, 0.04908298517998744, 0.05183603669074344, 0.047729686806789906, 0.04730503868420932, 0.049961309594835246, 0.0459956819268077]}}
{"id": "e0e4cb54-4912-4de8-b4b7-25e2be54d969", "fitness": 0.052633204179782137, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Integrative Adaptive Hybrid Swarm Optimization combines co-evolved adaptive strategies and dynamic parameter tuning for improved convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Hybrid PSO-DE steps\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 2, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05263 with standard deviation 0.00381.", "error": "", "parent_ids": ["1d54bfec-d08c-4949-a524-197708ca442f"], "operator": null, "metadata": {"aucs": [0.05905017602765905, 0.057303347135951865, 0.05202615499879626, 0.05451209372805377, 0.05291426309732161, 0.04805011160371775, 0.05253685953001319, 0.05099981864899783, 0.04630601284752789]}}
{"id": "24bb64be-2e66-4b4d-95b9-68e9e07ae127", "fitness": 0.0542270709853527, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Enhanced Integrative Adaptive Hybrid Swarm Optimization with refined velocity update logic for improved convergence.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Hybrid PSO-DE steps\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Modified line: Introduced scaling factor in velocity update.\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 3, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05423 with standard deviation 0.00308.", "error": "", "parent_ids": ["e0e4cb54-4912-4de8-b4b7-25e2be54d969"], "operator": null, "metadata": {"aucs": [0.05782050668312344, 0.05986025929961625, 0.05582477350503645, 0.05338116728854725, 0.055247262233335426, 0.051545164666369936, 0.05144652601435484, 0.05324177842671585, 0.04967620075107482]}}
{"id": "2c70e01f-3f5f-4d96-a654-f614a236dd45", "fitness": 0.05048160792369637, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Enhanced Integrative Adaptive Hybrid Swarm with a dynamic scaling factor for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Hybrid PSO-DE steps\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Modified line: Introduced dynamic scaling factor in velocity update.\n                velocity[i] = (1 + eval_ratio) * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 4, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05048 with standard deviation 0.00295.", "error": "", "parent_ids": ["24bb64be-2e66-4b4d-95b9-68e9e07ae127"], "operator": null, "metadata": {"aucs": [0.05194700337956437, 0.05609562595680295, 0.0534277922731492, 0.04797820760595595, 0.05180622650801947, 0.04934846541540783, 0.04623705528181388, 0.049932629505141435, 0.04756146538741224]}}
{"id": "cf70abe2-00da-4fed-b0ec-430f502ea16a", "fitness": 0.05293253194962019, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Improved swarm diversity through dynamic mutation scaling in the PSO-DE hybrid.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Hybrid PSO-DE steps\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Modified line: Introduced scaling factor in velocity update.\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                # Modified line: Dynamic mutation scaling based on eval_ratio.\n                mutant = np.clip(a + (diff_weight * (1 - eval_ratio) * (b - c)), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 5, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05293 with standard deviation 0.00261.", "error": "", "parent_ids": ["24bb64be-2e66-4b4d-95b9-68e9e07ae127"], "operator": null, "metadata": {"aucs": [0.05654557686731976, 0.05605626820041332, 0.05672838694458815, 0.05221017812158102, 0.05177004957393305, 0.05238162194221374, 0.05031816691961333, 0.049897759471550174, 0.050484779505369226]}}
{"id": "0d00afd9-92bb-4d76-9412-3e248461b9b3", "fitness": 0.05295315623940216, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Introduce an exponential decay factor in the inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        # Modified line: Introduced exponential decay factor in inertia weight.\n        w = self.w_final + (self.w_initial - self.w_final) * np.exp(-5 * eval_ratio)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Hybrid PSO-DE steps\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                # Modified line: Introduced scaling factor in velocity update.\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 6, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05295 with standard deviation 0.00267.", "error": "", "parent_ids": ["24bb64be-2e66-4b4d-95b9-68e9e07ae127"], "operator": null, "metadata": {"aucs": [0.057379923382115505, 0.05602960225024456, 0.05597733078824363, 0.05298246190323652, 0.05174552815533395, 0.05169724017320665, 0.05106470357261461, 0.049874119709333975, 0.049827496220290035]}}
{"id": "8baebb69-bea6-46b2-a166-904a082af80e", "fitness": 0.054652930721410226, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Introduced a dynamic population size reduction strategy to enhance convergence speed.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5  # initial cognitive coefficient\n        self.c2_initial = 1.5  # initial social coefficient\n        self.w_initial = 0.9  # initial inertia weight\n        self.diff_weight_initial = 0.5  # initial differential weight for DE\n        self.cross_prob_initial = 0.9  # initial crossover probability for DE\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Introduce dynamic population size reduction strategy\n            current_population_size = max(5, int(self.population_size * (1 - eval_ratio)))\n\n            # Hybrid PSO-DE steps\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 7, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05465 with standard deviation 0.00344.", "error": "", "parent_ids": ["24bb64be-2e66-4b4d-95b9-68e9e07ae127"], "operator": null, "metadata": {"aucs": [0.06148197345261408, 0.057252739544111475, 0.05614954913276771, 0.05671044714356244, 0.05286771739567453, 0.05184793138203392, 0.05464136191867619, 0.05095494274482126, 0.0499697137784304]}}
{"id": "d7360c83-9a3a-4313-9fd6-f1016bbf03af", "fitness": 0.05371219855066129, "name": "IntegrativeAdaptiveHybridSwarm", "description": "Enhanced parameter adaptation and convergence by integrating a chaos-inspired population diversification mechanism.", "code": "import numpy as np\n\nclass IntegrativeAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def chaos_inspired_diversification(self, swarm, lb, ub, eval_ratio):\n        chaotic_factor = np.sin(eval_ratio * np.pi)\n        perturbation = chaotic_factor * (swarm - lb) / (ub - lb)\n        return np.clip(swarm + perturbation, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            # Dynamic population size reduction strategy\n            current_population_size = max(5, int(self.population_size * (1 - eval_ratio)))\n\n            # Hybrid PSO-DE steps\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = w * velocity[i] + c1 * r1 * (personal_best[i] - swarm[i]) + c2 * r2 * (global_best - swarm[i])\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            # Apply chaos-inspired diversification\n            swarm = self.chaos_inspired_diversification(swarm, lb, ub, eval_ratio)\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 8, "feedback": "The algorithm IntegrativeAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05371 with standard deviation 0.00282.", "error": "", "parent_ids": ["8baebb69-bea6-46b2-a166-904a082af80e"], "operator": null, "metadata": {"aucs": [0.05772054574016938, 0.05830661742022625, 0.05581164787864812, 0.05328470138173236, 0.053834941163507066, 0.051539570644348, 0.05135173278237182, 0.051886640538819306, 0.04967338940612931]}}
{"id": "c12bcced-d390-4205-85dc-20fa8d092a98", "fitness": 0.05474418596863579, "name": "EnhancedAdaptiveHybridSwarm", "description": "Enhanced convergence by integrating adaptive parameter tuning and dynamic leader selection in hybrid PSO-DE.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5  # new parameter for dynamic leader selection\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05474 with standard deviation 0.00306.", "error": "", "parent_ids": ["8baebb69-bea6-46b2-a166-904a082af80e"], "operator": null, "metadata": {"aucs": [0.05632851549017759, 0.06001407152402871, 0.058835386075595686, 0.05200711481660136, 0.0553854628366508, 0.05430241226154475, 0.05012105032289893, 0.05337375166237002, 0.05232990872785426]}}
{"id": "b8f403cf-f57b-48b3-806e-38ca50eb4124", "fitness": 0.05145230324430534, "name": "RefinedHybridSwarm", "description": "Enhanced diversity and convergence through multi-strategy search and adaptive parameter control in hybrid PSO-DE with stochastic leader selection.", "code": "import numpy as np\n\nclass RefinedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.0\n        self.c2_final = 1.0\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.7\n        self.leader_selection_pressure = 5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def stochastic_leader_selection(self, personal_best_scores):\n        probabilities = np.exp(-personal_best_scores)\n        probabilities /= np.sum(probabilities)\n        leader_index = np.random.choice(len(personal_best_scores), p=probabilities)\n        return leader_index\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_index = self.stochastic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[leader_index]\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 10, "feedback": "The algorithm RefinedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05145 with standard deviation 0.00288.", "error": "", "parent_ids": ["c12bcced-d390-4205-85dc-20fa8d092a98"], "operator": null, "metadata": {"aucs": [0.054997507821958225, 0.05659591619446713, 0.05298403228502324, 0.05079626335863274, 0.052265771355060386, 0.0489354845679113, 0.04895893822519948, 0.050375449499406866, 0.04716136589108866]}}
{"id": "24db0f79-6108-4b92-ba77-83b826db894a", "fitness": 0.05236404562452241, "name": "EnhancedAdaptiveHybridSwarm", "description": "Enhancement by adjusting the crossover probability adaptation and incorporating nonlinear inertia weight reduction.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.7  # Adjusted crossover probability for better exploration\n        self.leader_selection_pressure = 5  # new parameter for dynamic leader selection\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio ** 2 * (self.w_initial - self.w_final) # Nonlinear inertia weight reduction for balance exploration and exploitation\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n        return global_best", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05236 with standard deviation 0.00365.", "error": "", "parent_ids": ["c12bcced-d390-4205-85dc-20fa8d092a98"], "operator": null, "metadata": {"aucs": [0.05284810546584817, 0.05951866056778732, 0.05515362718282346, 0.048811852969002034, 0.054937064067545616, 0.05093261219668521, 0.0470427334489919, 0.05294426540100372, 0.049087489321014255]}}
{"id": "ccddaa55-6c56-4e32-af91-15a75a70137b", "fitness": 0.05323839125456528, "name": "EnhancedAdaptiveHybridSwarmPlus", "description": "Improve convergence by incorporating adaptive inertia weight scheduling and elitist strategy in hybrid PSO-DE for enhanced solution refinement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridSwarmPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.elite_fraction = 0.1  # fraction of elite particles for elitism\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i])\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            elite_count = int(current_population_size * self.elite_fraction)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            # Update swarm with elite individuals to maintain quality\n            for i in elite_indices:\n                swarm[i] = personal_best[i]\n                velocity[i] = np.clip(velocity[i] * 0.5, -1, 1)  # reduce velocity to stabilize elite\n                        \n        return global_best", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveHybridSwarmPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05324 with standard deviation 0.00343.", "error": "", "parent_ids": ["c12bcced-d390-4205-85dc-20fa8d092a98"], "operator": null, "metadata": {"aucs": [0.05405179135231586, 0.05645397183322953, 0.05981322814806911, 0.04991713667705333, 0.05213474921425054, 0.05520993582750133, 0.048107645930606124, 0.05024894430963289, 0.05320811799842884]}}
{"id": "5f96b0cd-8eef-4495-be14-16b319d488cc", "fitness": 0.05580161467558479, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate adaptive chaos-based exploration and exploitation with enhanced leader selection in hybrid PSO-DE for improved convergence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)  # add chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 13, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05580 with standard deviation 0.00302.", "error": "", "parent_ids": ["c12bcced-d390-4205-85dc-20fa8d092a98"], "operator": null, "metadata": {"aucs": [0.061160290967940845, 0.057892483777116754, 0.05953399736388665, 0.05642837464032979, 0.05345598930573692, 0.05492463402751957, 0.0543748090135826, 0.05152205312010394, 0.05292189986404605]}}
{"id": "9cc8a90a-0f00-409e-a178-b212eefb0986", "fitness": 0.05132582613865812, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce dynamic inertia weight adaptation and chaos-enhanced Gaussian mutation in hybrid PSO-DE for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def gaussian_mutation(self, individual, chaotic_state, lb, ub):\n        mutation_strength = self.chaotic_factor * chaotic_state\n        mutation = individual + mutation_strength * np.random.randn(self.dim)\n        return np.clip(mutation, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n                \n                # Apply Gaussian mutation to enhance exploration\n                mutated = self.gaussian_mutation(swarm[i], chaotic_state, lb, ub)\n                f_mutated = func(mutated)\n                evaluations += 1\n                if f_mutated < personal_best_scores[i]:\n                    personal_best_scores[i] = f_mutated\n                    personal_best[i] = mutated\n                    if f_mutated < global_best_score:\n                        global_best_score = f_mutated\n                        global_best = mutated\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 14, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05133 with standard deviation 0.00325.", "error": "", "parent_ids": ["5f96b0cd-8eef-4495-be14-16b319d488cc"], "operator": null, "metadata": {"aucs": [0.05164391797405499, 0.05602915902849659, 0.056508340185032924, 0.0476995431182331, 0.05174512056578362, 0.05217724660907841, 0.04596843744028767, 0.049873726769472326, 0.05028694355748342]}}
{"id": "ed20d4af-1e6d-428b-a43c-2ee54a60d195", "fitness": 0.052598373995287204, "name": "EnhancedChaosAdaptiveSwarm", "description": "Integrate adaptive chaos-based exploration with adaptive inertia and mutation strategies in hybrid PSO-DE for improved convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedChaosAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05260 with standard deviation 0.00327.", "error": "", "parent_ids": ["5f96b0cd-8eef-4495-be14-16b319d488cc"], "operator": null, "metadata": {"aucs": [0.05833405484993781, 0.056728003083840184, 0.053203458350914, 0.05385923866661324, 0.05238675498520173, 0.049128415144259474, 0.05190971799060695, 0.05049189379365138, 0.047343829092560075]}}
{"id": "13aa7662-74c4-47ea-9c0b-64e32f79a08e", "fitness": 0.05861388328834492, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaotic map utilization for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 16, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05861 with standard deviation 0.00336.", "error": "", "parent_ids": ["5f96b0cd-8eef-4495-be14-16b319d488cc"], "operator": null, "metadata": {"aucs": [0.06486791992421681, 0.06051753076455546, 0.06228969574050569, 0.05979890580960334, 0.055834803855402626, 0.05745093989766914, 0.05760903369201675, 0.053801694587408355, 0.05535442532372614]}}
{"id": "f5050f7f-8631-4d4d-a155-6281e0da03ad", "fitness": 0.05225515970870328, "name": "MultiChaosHybridSwarm", "description": "Integrate a multi-chaotic map strategy to enhance exploration diversity and convergence speed.", "code": "import numpy as np\n\nclass MultiChaosHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map_logistic(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def chaotic_map_sinusoidal(self, x):\n        return np.sin(np.pi * x)  # sinusoidal map for chaos\n\n    def chaotic_map_tent(self, x):\n        return 2 * x if x < 0.5 else 2 * (1 - x)  # tent map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            # Select the chaotic map based on the evaluation ratio\n            if eval_ratio < 0.33:\n                chaos_map = self.chaotic_map_logistic\n            elif eval_ratio < 0.66:\n                chaos_map = self.chaotic_map_sinusoidal\n            else:\n                chaos_map = self.chaotic_map_tent\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * chaos_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = chaos_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "The algorithm MultiChaosHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05226 with standard deviation 0.00406.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.059669842976262766, 0.05602915902849659, 0.051473251590306135, 0.05507425059850479, 0.05174512056578362, 0.04754071853419439, 0.053075807759717764, 0.049873726769472326, 0.045814559555591106]}}
{"id": "b9eabd08-7d00-454f-ac22-25a33b8668b6", "fitness": 0.05395154729593167, "name": "AdaptiveChaoticMultiScaleSwarm", "description": "Introduce adaptive chaotic perturbations and multi-scale leader exploration to enhance convergence precision and robustness.", "code": "import numpy as np\n\nclass AdaptiveChaoticMultiScaleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.7\n        self.chaotic_factor_final = 0.3\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        chaotic_factor = self.chaotic_factor_initial - eval_ratio * (self.chaotic_factor_initial - self.chaotic_factor_final)\n        return c1, c2, w, diff_weight, cross_prob, chaotic_factor\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaotic_factor = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = chaotic_factor * self.chaotic_map(chaotic_state)  # adaptive chaotic influence\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveChaoticMultiScaleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05395 with standard deviation 0.00299.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05691203704663117, 0.0561113387428972, 0.05958371401029672, 0.052547410215747825, 0.05182063413953886, 0.05499691851742705, 0.050643390035322255, 0.04994650269886847, 0.05300198025665548]}}
{"id": "6a38dec0-b86c-4c34-b06d-854bd7fd3980", "fitness": 0.054069218631826406, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Fine-tune the balance between exploration and exploitation by adjusting the chaotic influence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.2 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 19, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00297.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0595534034598858, 0.05613016587529851, 0.05729758161606835, 0.05496520870466515, 0.05183793396040959, 0.0529097752117369, 0.052969899488483296, 0.04996317531421968, 0.05099582405567038]}}
{"id": "f2bbf5eb-bbf3-4db6-958e-992cd3cf98cd", "fitness": 0.05189163956884345, "name": "AdvancedChaosAdaptiveSwarm", "description": "Enhance ChaosEnhancedAdaptiveHybridSwarm by leveraging adaptive chaotic sequences with dynamic inertia weight adjustment for superior convergence.", "code": "import numpy as np\n\nclass AdvancedChaosAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.inertia_decay_rate = 0.95\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial * (self.inertia_decay_rate ** eval_ratio)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return np.sin(np.pi * x)  # sine map for adaptive chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 20, "feedback": "The algorithm AdvancedChaosAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05189 with standard deviation 0.00312.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05372305484827944, 0.058019987375799276, 0.05425774069238665, 0.04961428859024042, 0.05357206670982473, 0.05010311476686702, 0.047815457546284246, 0.05163349535226236, 0.04828555023764691]}}
{"id": "149d54f5-67b0-4aca-8774-31fb66313d2c", "fitness": 0.05396936999443322, "name": "MultiScaleChaosEnhancedHybridSwarm", "description": "Enhance chaotic exploration by introducing a multi-scale chaotic map for improved solution diversity.", "code": "import numpy as np\n\nclass MultiScaleChaosEnhancedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factors = [0.6, 0.9, 1.2]  # multiple chaotic factors for diversity\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def multi_scale_chaotic_map(self, x, scale_idx):\n        chaotic_factor = self.chaotic_factors[scale_idx % len(self.chaotic_factors)]\n        return chaotic_factor * 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.multi_scale_chaotic_map(chaotic_state, i)  # multi-scale chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.multi_scale_chaotic_map(chaotic_state, evaluations)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 21, "feedback": "The algorithm MultiScaleChaosEnhancedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05397 with standard deviation 0.00366.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.061341958946912856, 0.05608792951805963, 0.05523940809722361, 0.056599565975120725, 0.05179916366103143, 0.051017412744247315, 0.054541455647588055, 0.04992582639407417, 0.04917160896564121]}}
{"id": "df004f66-9fc1-45c8-980c-17e275207605", "fitness": -Infinity, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaotic map utilization for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0309278350515463 lines, and the rest of the lines should remain unchanged. This input code has 97 lines, so you can only change 1 lines, the rest 96 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.06486791992421681, 0.06051753076455546, 0.06228969574050569, 0.05979890580960334, 0.055834803855402626, 0.05745093989766914, 0.05760903369201675, 0.053801694587408355, 0.05535442532372614]}}
{"id": "580cf826-3ec5-4687-8449-5213f539fb6b", "fitness": 0.05456091013639367, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce adaptive chaotic scaling to enhance exploration dynamics with minimal changes.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = (1.1 + eval_ratio) * self.chaotic_factor * self.chaotic_map(chaotic_state)  # adaptive scaling\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 23, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05456 with standard deviation 0.00330.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05716840255540645, 0.05635955082180344, 0.06105540897777162, 0.05278436021537514, 0.05204883885810074, 0.05632304389997578, 0.05087230825397726, 0.05016648433853377, 0.05426979330659887]}}
{"id": "c14af95e-3492-4d9f-8eee-bb63b25b50a1", "fitness": 0.05223322994658018, "name": "AdaptiveChaosEnhancedHybridSwarm", "description": "Introduce an adaptive chaotic factor that intensifies over time, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdaptiveChaosEnhancedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.initial_chaotic_factor = 0.5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        chaotic_factor = self.initial_chaotic_factor + eval_ratio * (1.0 - self.initial_chaotic_factor)\n        return c1, c2, w, diff_weight, cross_prob, chaotic_factor\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaotic_factor = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * chaotic_factor * self.chaotic_map(chaotic_state)  # adaptive chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveChaosEnhancedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05223 with standard deviation 0.00277.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05439414231989159, 0.05710239897897429, 0.05558985047138676, 0.05023279796966562, 0.052729767706212516, 0.05133704603658373, 0.048412282435034926, 0.05082207145355411, 0.0494787121479181]}}
{"id": "62ebdf84-cb19-44c3-9d8b-0eda3dad5c8f", "fitness": 0.05277605616674471, "name": "MultiScaleChaosEnhancedSwarm", "description": "Integrate a multi-scale chaotic sequence to enhance global exploration and local exploitation in adaptive hybrid swarm optimization.", "code": "import numpy as np\n\nclass MultiScaleChaosEnhancedSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factors = [0.7, 1.1, 1.5]  # multi-scale chaotic influences\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, scale):\n        return 4 * scale * x * (1 - x)  # logistic map with scaling\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_states = np.random.rand(len(self.chaotic_factors))  # initialize chaotic states\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_components = sum(factor * self.chaotic_map(state, factor) for factor, state in zip(self.chaotic_factors, chaotic_states))\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_components\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_states = [self.chaotic_map(state, factor) for state, factor in zip(chaotic_states, self.chaotic_factors)]  # update chaotic states\n\n        return global_best", "configspace": "", "generation": 25, "feedback": "The algorithm MultiScaleChaosEnhancedSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05278 with standard deviation 0.00424.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05202571267405187, 0.05602915902849659, 0.06078553047975621, 0.04805307255133995, 0.05174512056578362, 0.05609888573342248, 0.04631023211151308, 0.049873726769472326, 0.054063065586866244]}}
{"id": "ec096782-83f1-4ac9-b14e-3049900e3b67", "fitness": 0.0553049374694902, "name": "EnhancedChaosAdaptiveSwarm", "description": "Enhance chaotic exploration by introducing iterative map switching and adaptive chaos intensity for better global search.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.5\n        self.chaotic_factor_final = 1.2\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        chaotic_factor = self.chaotic_factor_initial + eval_ratio * (self.chaotic_factor_final - self.chaotic_factor_initial)\n        return c1, c2, w, diff_weight, cross_prob, chaotic_factor\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def sinusoidal_map(self, x):\n        return np.abs(2 * np.sin(np.pi * x))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n        use_logistic_map = True\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaotic_factor = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * chaotic_factor * (self.logistic_map(chaotic_state) if use_logistic_map else self.sinusoidal_map(chaotic_state))\n                velocity[i] = w * velocity[i] + c1 * r1 * (personal_best[i] - swarm[i]) + c2 * r2 * (new_global_best - swarm[i]) + chaos_component\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.logistic_map(chaotic_state) if use_logistic_map else self.sinusoidal_map(chaotic_state)\n            use_logistic_map = not use_logistic_map  # switch map\n\n        return global_best", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedChaosAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05530 with standard deviation 0.00280.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.058057842914557956, 0.05977846105975526, 0.05911703131980528, 0.05360425329272711, 0.05518061441522193, 0.05457025144221628, 0.05166351397900082, 0.05318086432175528, 0.05259160448037192]}}
{"id": "4f2ef60b-301c-4309-8ed1-00347aa30292", "fitness": 0.05627042430236232, "name": "ChaosLevyAdaptiveSwarm", "description": "Enhance exploration by integrating Levy flight and adaptive chaos dynamics for diverse search patterns.", "code": "import numpy as np\n\nclass ChaosLevyAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.levy_beta = 1.5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def levy_flight(self):\n        sigma = (np.math.gamma(1 + self.levy_beta) * np.sin(np.pi * self.levy_beta / 2) /\n                 (np.math.gamma((1 + self.levy_beta) / 2) * self.levy_beta * 2**((self.levy_beta - 1) / 2)))**(1 / self.levy_beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        return u / np.abs(v)**(1 / self.levy_beta)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                levy_component = self.levy_flight()\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component + levy_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 27, "feedback": "The algorithm ChaosLevyAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05627 with standard deviation 0.00422.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.055258349702802745, 0.062021315795747656, 0.06283067623164607, 0.05102738539396856, 0.057225658655232325, 0.05793318062257591, 0.04917829168216514, 0.05514555730968518, 0.05581340332743734]}}
{"id": "c9bd561e-c747-4a92-94da-20728aa40d64", "fitness": 0.056679090590333076, "name": "MultiPhaseChaosAdaptiveSwarm", "description": "Integrate multi-phase chaotic maps with adaptive parameter scaling for enhanced diversification and convergence.", "code": "import numpy as np\n\nclass MultiPhaseChaosAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.chaos_phase_thresholds = [0.3, 0.6, 0.9]\n        \n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, phase):\n        if phase == 0:\n            return 4 * x * (1 - x)  # logistic map\n        elif phase == 1:\n            return np.sin(np.pi * x)  # sinusoidal map\n        else:\n            return np.abs(np.cos(np.pi * x))  # cosine map\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            if eval_ratio < self.chaos_phase_thresholds[0]:\n                phase = 0\n            elif eval_ratio < self.chaos_phase_thresholds[1]:\n                phase = 1\n            else:\n                phase = 2\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state, phase)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state, phase)\n\n        return global_best", "configspace": "", "generation": 28, "feedback": "The algorithm MultiPhaseChaosAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05668 with standard deviation 0.00402.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0645404442646278, 0.057026952400972664, 0.05984151182284847, 0.05950320266530551, 0.0526608566269996, 0.05523077965955625, 0.057326062416929724, 0.05075582222774688, 0.05322618322801076]}}
{"id": "f725720a-222c-4dd7-9bf1-821870a33de8", "fitness": 0.05560395575775226, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly enhance chaotic influence adaptation in swarm dynamics.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.05 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 29, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05560 with standard deviation 0.00313.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05712933741360848, 0.06096130036556302, 0.059853225851033476, 0.052742031957770275, 0.05625414213841751, 0.055232285042353335, 0.05082894473828847, 0.05421026134732354, 0.053224072965412206]}}
{"id": "6b270c6f-cfec-4419-b6de-555d9b49ea5a", "fitness": 0.053931356673213866, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic chaotic factor to enhance exploration adaptability over time.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * eval_ratio * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 30, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05393 with standard deviation 0.00288.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05751148066748746, 0.05602915902849659, 0.058997785933924574, 0.05309434265264046, 0.05174512056578362, 0.054467012904789835, 0.05116896304337348, 0.049873726769472326, 0.052494618492956446]}}
{"id": "1206492c-f682-480b-9ad0-272649da66d0", "fitness": 0.056162945377213655, "name": "MultiChaosAdaptiveHybridSwarm", "description": "Introduce a multi-chaotic map strategy to diversify and enhance global search exploration.", "code": "import numpy as np\n\nclass MultiChaosAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_logistic = 0.7\n        self.chaotic_factor_sinusoidal = 0.3\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def sinusoidal_map(self, x):\n        return np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                logistic_component = 1.1 * self.chaotic_factor_logistic * self.logistic_map(chaotic_state)\n                sinusoidal_component = self.chaotic_factor_sinusoidal * self.sinusoidal_map(chaotic_state)\n                chaos_component = logistic_component + sinusoidal_component\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.logistic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 31, "feedback": "The algorithm MultiChaosAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05616 with standard deviation 0.00318.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06095837882128674, 0.05757036618771039, 0.06123967567081101, 0.056195070799913704, 0.05315888724280504, 0.05651446443398234, 0.05413147429294385, 0.051235284386557445, 0.054462906558912394]}}
{"id": "bcf92388-78a1-41a8-80f9-b0b2969be08e", "fitness": 0.053420356971812494, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Refined chaotic influence by altering coefficient for enhanced exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.8  # changed parameter for refined chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 32, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05342 with standard deviation 0.00338.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05378254106096991, 0.05819512117503145, 0.05892673779960811, 0.04967335887361213, 0.05372876494303258, 0.05439589922590338, 0.047874144127362905, 0.051782859939430104, 0.05242378560136185]}}
{"id": "ec3aa765-3961-4738-bac8-eb8352279a07", "fitness": 0.054954622717917005, "name": "ChaosEnhancedLevyHybridSwarm", "description": "Integrate Levy flight for enhanced exploration and chaotic convergence refinement in a hybrid swarm optimization.", "code": "import numpy as np\n\nclass ChaosEnhancedLevyHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.power(np.abs(v), 1 / beta)\n        return 0.01 * step * L  # reduced scale for Levy flights\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                swarm[i] += self.levy_flight(chaos_component)  # integrate Levy flight\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 33, "feedback": "The algorithm ChaosEnhancedLevyHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05495 with standard deviation 0.00316.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05724249927670966, 0.061038187449409254, 0.0576017930684809, 0.05280413648163618, 0.05632812925630737, 0.05317526374518888, 0.050872559824728714, 0.05428285833547475, 0.05124617702331735]}}
{"id": "9fa41c79-5218-4bc2-b8dc-922ec2fa5fc0", "fitness": 0.05392045159957864, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate a novel chaotic mutation operator for enhanced diversity and convergence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c) + self.chaotic_map(np.random.rand()), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 34, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05392 with standard deviation 0.00368.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05408643974139049, 0.06077777922222016, 0.0576751286794438, 0.04994876175476759, 0.05606370340313194, 0.053252034789823766, 0.04813802378617016, 0.05401835683834011, 0.051323836180919735]}}
{"id": "7b7651c8-772d-450e-aec4-a41e49054a42", "fitness": 0.05450234146574468, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaos influence for improved convergence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.15 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 35, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.00418.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05432737682812161, 0.06263710645746146, 0.05743356503203689, 0.050176681701355474, 0.057786611193371806, 0.05301953112885649, 0.048360298992944806, 0.05568426801582904, 0.05109563384172455]}}
{"id": "8e6a22b1-f633-4c13-9df5-daedec6e824d", "fitness": 0.05486106388718411, "name": "MultiAgentChaoticSwarm", "description": "Integrate a multi-agent learning approach with chaotic exploration to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass MultiAgentChaoticSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.agent_learning_rate = 0.5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                learning_component = self.agent_learning_rate * (global_best - swarm[i])\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component + learning_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 36, "feedback": "The algorithm MultiAgentChaoticSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05486 with standard deviation 0.00316.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.056106292697309934, 0.059200956141421734, 0.06023844374071918, 0.05180805442748082, 0.05465207059571753, 0.055581507196778124, 0.04993125649081087, 0.05267231329444899, 0.053558680399969805]}}
{"id": "ad8c70e0-2a1a-4e30-9e38-d257d4f13c12", "fitness": 0.053931356673213866, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic adjustment factor to enhance chaotic influence for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * eval_ratio * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 37, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05393 with standard deviation 0.00288.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05751148066748746, 0.05602915902849659, 0.058997785933924574, 0.05309434265264046, 0.05174512056578362, 0.054467012904789835, 0.05116896304337348, 0.049873726769472326, 0.052494618492956446]}}
{"id": "a3456fd6-70f3-4384-af4e-dd5ad574c119", "fitness": 0.05602026424873414, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the chaotic influence by altering the logistic map formula slightly for better diverse exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 3.9 * x * (1 - x)  # modified logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 38, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05602 with standard deviation 0.00285.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06075571665610402, 0.05901648986771235, 0.05948469585300675, 0.056064849540175654, 0.054484596162349797, 0.05491290573987018, 0.05402767191260949, 0.05251170636367053, 0.05292374614310846]}}
{"id": "34269da5-fdba-4958-903c-07c015f1c7a8", "fitness": 0.053420356971812494, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Fine-tune chaotic influence factor to enhance convergence stability and exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.8  # adjusted parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 39, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05342 with standard deviation 0.00338.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05378254106096991, 0.05819512117503145, 0.05892673779960811, 0.04967335887361213, 0.05372876494303258, 0.05439589922590338, 0.047874144127362905, 0.051782859939430104, 0.05242378560136185]}}
{"id": "ba7c0e24-245b-46b2-a101-26a61f8e3933", "fitness": 0.05608517008182343, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance chaotic factor impact by increasing its multiplier for diverse exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 1.1  # increased multiplier for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 40, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05609 with standard deviation 0.00360.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06326197802329836, 0.05751443408914525, 0.058737513328288804, 0.05831596566309183, 0.05310918003039322, 0.054215297706986076, 0.05617705164020936, 0.051188043837990804, 0.05224706641700716]}}
{"id": "b0a4c06f-01b3-49fb-a9e7-7806a5fac4f7", "fitness": 0.053931356673213866, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic chaotic factor that adapts over time for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.7  # updated initial chaotic factor\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor_initial * eval_ratio * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 41, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05393 with standard deviation 0.00288.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05751148066748746, 0.05602915902849659, 0.058997785933924574, 0.05309434265264046, 0.05174512056578362, 0.054467012904789835, 0.05116896304337348, 0.049873726769472326, 0.052494618492956446]}}
{"id": "fb2f355c-5f26-4944-90fe-d8d9c2dc25bc", "fitness": 0.054757138286241576, "name": "EnhancedChaosAdaptiveSwarm", "description": "Enhance multi-faceted exploration by integrating chaotic maps with dynamic adaptive strategy adjustments and refined leader selection.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 3\n        self.chaotic_factor = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = np.mean(personal_best[leader_indices], axis=0)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedChaosAdaptiveSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05476 with standard deviation 0.00391.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05934844759398361, 0.06154615940423436, 0.05432379369333573, 0.05478295276969092, 0.05679506581050087, 0.050155475906922375, 0.0527966682925749, 0.054732923528751254, 0.04833275757618016]}}
{"id": "c7189d43-8903-4a40-ab4a-89da7a4a834b", "fitness": 0.05782370637513993, "name": "EnhancedAdaptiveChaosSwarm", "description": "Incorporate adaptive chaotic maps and multi-phase exploration strategies for enhanced convergence and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedAdaptiveChaosSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, phase):\n        if phase == 'logistic':\n            return 4 * x * (1 - x)\n        elif phase == 'sinusoidal':\n            return np.abs(np.sin(np.pi * x))\n        else:\n            raise ValueError(\"Unknown chaotic map phase\")\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n        phase = 'logistic'\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state, phase)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            if evaluations >= self.budget // 2 and phase == 'logistic':\n                phase = 'sinusoidal'\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state, phase)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveChaosSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05782 with standard deviation 0.00375.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0645404442646278, 0.058281205496958255, 0.06228969574050569, 0.05950320266530551, 0.053808047991073193, 0.05745093989766914, 0.057326062416929724, 0.05185933357946393, 0.05535442532372614]}}
{"id": "146ac4a6-e858-4849-a689-657e4ea5a5c3", "fitness": 0.057253140540693255, "name": "RefinedChaosEnhancedAdaptiveHybridSwarm", "description": "Incorporate dynamic search space reduction and multi-chaos strategies for enhanced convergence in hybrid swarm optimization.", "code": "import numpy as np\n\nclass RefinedChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, method='logistic'):\n        if method == 'logistic':\n            return 4 * x * (1 - x)\n        elif method == 'sinusoidal':\n            return np.sin(np.pi * x)\n        elif method == 'tent':\n            return 2 * x if x < 0.5 else 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        range_reduction_factor = 0.95\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            lb = lb * range_reduction_factor + global_best * (1 - range_reduction_factor)\n            ub = ub * range_reduction_factor + global_best * (1 - range_reduction_factor)\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(self.initial_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state, 'sinusoidal')\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(self.initial_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.initial_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state, 'tent')\n\n        return global_best", "configspace": "", "generation": 44, "feedback": "The algorithm RefinedChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05725 with standard deviation 0.00374.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06006236116795172, 0.06471099389952684, 0.05852387797941472, 0.055428590294071545, 0.05962134087302562, 0.05402488982960596, 0.05341482070698833, 0.05742549371402139, 0.05206589640163317]}}
{"id": "b2f3edee-6e3f-41e5-9acc-4d5e477e72f1", "fitness": 0.055709624633989464, "name": "FractionalOrderChaosEnhancedSwarm", "description": "Enhance global exploration using fractional-order calculus in chaotic swarms for better convergence.", "code": "import numpy as np\n\nclass FractionalOrderChaosEnhancedSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.alpha = 0.8  # fractional order\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def fractional_levy_flight(self, scale):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / self.alpha))\n        return scale * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.fractional_levy_flight(self.chaotic_map(chaotic_state))\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 45, "feedback": "The algorithm FractionalOrderChaosEnhancedSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05571 with standard deviation 0.00501.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06578373256863024, 0.05602915902849659, 0.0564815085974788, 0.06063840263059894, 0.05174512056578362, 0.05215338004268055, 0.05841733354020173, 0.049873726769472326, 0.0502642579625624]}}
{"id": "59841d94-c5ac-47c6-92cf-594ecf1e8f59", "fitness": 0.05293484636312034, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance swarm diversity by introducing a stochastic component in chaotic dynamics.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state + np.random.rand())  # added stochastic term\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 46, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05293 with standard deviation 0.00308.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.056125962246983296, 0.05874649743842575, 0.05447357588414703, 0.05181655291605258, 0.05423784052727487, 0.05031202377779109, 0.04993561928755541, 0.052274421848842234, 0.0484911233410108]}}
{"id": "bb5e47d3-e08d-4597-ae39-93eb0470816d", "fitness": 0.05488882277672423, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate a refined chaotic influence by adjusting the chaos_component calculation for more balanced exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * (1 + 0.1 * np.sin(2 * np.pi * eval_ratio)) * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 47, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05489 with standard deviation 0.00311.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05662569285735275, 0.06065572466793179, 0.058339831044515233, 0.052286582478481614, 0.055980155496040296, 0.05386041862131774, 0.05039293574498849, 0.05394885200507393, 0.05190921207481625]}}
{"id": "48dd065b-43d1-4d54-b92c-995c09160771", "fitness": 0.054069218631826406, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the chaotic component's influence on velocity for better exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  \n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.2 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  \n\n        return global_best", "configspace": "", "generation": 48, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00297.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0595534034598858, 0.05613016587529851, 0.05729758161606835, 0.05496520870466515, 0.05183793396040959, 0.0529097752117369, 0.052969899488483296, 0.04996317531421968, 0.05099582405567038]}}
{"id": "ac3601e9-ef60-4a2e-a4b2-8f46baeedacb", "fitness": 0.05450234146574468, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaotic map utilization for improved exploration by slightly adjusting the chaotic influence scaling factor.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.15 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 49, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.00418.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05432737682812161, 0.06263710645746146, 0.05743356503203689, 0.050176681701355474, 0.057786611193371806, 0.05301953112885649, 0.048360298992944806, 0.05568426801582904, 0.05109563384172455]}}
{"id": "d4fa4846-6fca-4dad-b038-0c85ec15d6dc", "fitness": 0.05242117811219647, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance chaotic influence by modifying the logistic map scaling factor to improve exploration adaptability.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4.1 * x * (1 - x)  # increased scaling factor for chaotic map\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 50, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05242 with standard deviation 0.00298.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.057539332938047916, 0.05644171868213532, 0.05370624180501393, 0.05312703476648395, 0.052124202883650606, 0.04960321294081782, 0.05120327370696276, 0.05023906125854549, 0.047806524028110475]}}
{"id": "392d227c-259d-4830-8476-441ab50bda43", "fitness": 0.04772833964570833, "name": "ChaosEnhancedAdaptiveParabolicSwarm", "description": "Leverage chaotic maps and adaptive parabolic trajectory modifications for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveParabolicSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def parabolic_trajectory(self, swarm, personal_best, global_best):\n        return (personal_best + global_best) / 2 - (swarm - (personal_best + global_best) / 2) ** 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = w * velocity[i] + c1 * r1 * (personal_best[i] - swarm[i]) + c2 * r2 * (new_global_best - swarm[i]) + chaos_component\n                swarm[i] = self.parabolic_trajectory(swarm[i], personal_best[i], new_global_best)\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 51, "feedback": "The algorithm ChaosEnhancedAdaptiveParabolicSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04773 with standard deviation 0.00417.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.04770589680898163, 0.05602915902849659, 0.04895936394902256, 0.04404360746117708, 0.05174512056578362, 0.045209209636772885, 0.04243003578848625, 0.049873726769472326, 0.04355893680318201]}}
{"id": "d200f972-7230-4e8b-9449-843ee5f62443", "fitness": 0.05317353357238039, "name": "DualChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate a dual-chaotic system to enhance exploration during the search process.", "code": "import numpy as np\n\nclass DualChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_1 = 0.7\n        self.chaotic_factor_2 = 0.3\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map_1(self, x):\n        return 4 * x * (1 - x)\n\n    def chaotic_map_2(self, x):\n        return np.sin(np.pi * x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state_1 = np.random.rand()\n        chaotic_state_2 = 0.5  # Initialize at median for sinusoidal map\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = (\n                    1.1 * self.chaotic_factor_1 * self.chaotic_map_1(chaotic_state_1) +\n                    self.chaotic_factor_2 * self.chaotic_map_2(chaotic_state_2)\n                )\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state_1 = self.chaotic_map_1(chaotic_state_1)\n            chaotic_state_2 = self.chaotic_map_2(chaotic_state_2)\n\n        return global_best", "configspace": "", "generation": 52, "feedback": "The algorithm DualChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05317 with standard deviation 0.00335.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05443508840280509, 0.05975815030329701, 0.05592219652507746, 0.05026579354455629, 0.05516356312665083, 0.05163998638443268, 0.0484422685722824, 0.0531650625651503, 0.049769692727171466]}}
{"id": "9069bec7-d013-4286-96ac-d887aedf42f8", "fitness": 0.05426349136257728, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly adjusted chaotic influence for a more refined exploration balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 0.9 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 53, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05426 with standard deviation 0.00274.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05881276188598328, 0.057314091737619255, 0.057501295802957375, 0.05426268125997258, 0.052924741088462346, 0.053091884268892, 0.05228447365621458, 0.05101015490893768, 0.05116933765415643]}}
{"id": "031c3ac3-3add-4fa5-a384-24c8d4672830", "fitness": 0.05432402406859271, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic adaptation of the chaotic factor for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n            \n            self.chaotic_factor = 0.7 + 0.3 * eval_ratio  # dynamically adapt chaotic factor\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 54, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05432 with standard deviation 0.00395.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.059974380652197956, 0.06028731702660339, 0.05355122323192929, 0.055355716683276324, 0.05564310133802519, 0.049461689042160306, 0.05334769065652456, 0.05362459287319854, 0.04767050511341886]}}
{"id": "10bdf4c3-1fdb-47eb-8e0e-6fb5f22ac2aa", "fitness": 0.05670792280276755, "name": "MultiPhaseChaoticSwarm", "description": "Incorporate a multi-phase chaotic diversity mechanism to enhance convergence efficiency and exploration balance.", "code": "import numpy as np\n\nclass MultiPhaseChaoticSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.7\n        self.chaotic_factor_final = 0.3  # decreasing chaotic influence over time\n        self.phase_thresholds = [0.3, 0.6, 0.9]  # thresholds for different phases\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        chaotic_factor = self.chaotic_factor_initial - eval_ratio * (self.chaotic_factor_initial - self.chaotic_factor_final)\n        return c1, c2, w, diff_weight, cross_prob, chaotic_factor\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaotic_factor = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                phase_chaos = chaotic_factor * (1 + 0.5 * np.sin(np.pi * eval_ratio))  # phase-specific chaotic influence\n                chaos_component = phase_chaos * self.chaotic_map(chaotic_state) \n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state) \n\n        return global_best", "configspace": "", "generation": 55, "feedback": "The algorithm MultiPhaseChaoticSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05671 with standard deviation 0.00308.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05963962857888627, 0.05941744946330185, 0.06244650941194796, 0.05504738915453078, 0.054851278464694064, 0.05758059076686872, 0.05305027189540845, 0.052864406278342435, 0.055473781210927386]}}
{"id": "93f2c0a5-d237-4985-a7f1-769e20f84432", "fitness": 0.05642507258489782, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a more effective chaotic state initialization for better exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = 0.5  # more effective chaotic state initialization\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 56, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05643 with standard deviation 0.00382.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05850924445182493, 0.05792740182057887, 0.06414642237800838, 0.054010422839661065, 0.053485022714305774, 0.059153238766025185, 0.05205155276755735, 0.05154883424993073, 0.05699351327618807]}}
{"id": "d7d861f3-54a1-4d68-bd32-5175b058dd62", "fitness": 0.05560395575775226, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly adjust chaotic component calculation for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.05 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 57, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05560 with standard deviation 0.00313.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05712933741360848, 0.06096130036556302, 0.059853225851033476, 0.052742031957770275, 0.05625414213841751, 0.055232285042353335, 0.05082894473828847, 0.05421026134732354, 0.053224072965412206]}}
{"id": "7ed2adf0-e7bc-4e24-a408-5434dba07d36", "fitness": -Infinity, "name": "ChaosLevyEnhancedSwarm", "description": "Improve exploration by incorporating Lvy flight with chaos to enhance global search capabilities.", "code": "import numpy as np\n\nclass ChaosLevyEnhancedSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.levy_factor = 1.5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, u):\n        sigma = (Gamma(1 + self.levy_factor) * np.sin(np.pi * self.levy_factor / 2) / \n                 (Gamma((1 + self.levy_factor) / 2) * self.levy_factor * 2**((self.levy_factor - 1) / 2)))**(1/self.levy_factor)\n        v = np.random.normal(0, 1)\n        return u * sigma / np.abs(v)**(1/self.levy_factor)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                levy_component = self.levy_flight(np.random.rand())\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component +\n                    levy_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 58, "feedback": "An exception occurred: NameError(\"name 'Gamma' is not defined\").", "error": "NameError(\"name 'Gamma' is not defined\")", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {}}
{"id": "5cf7c3df-0d04-4005-b1bf-80f95c8f1130", "fitness": 0.05407067900797338, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic adaptation mechanism for the chaotic factor to enhance exploration as the algorithm progresses.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.7  # updated initial chaotic factor\n    \n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n            chaotic_factor = self.chaotic_factor_initial * (1 - eval_ratio)  # dynamic adaptation of chaotic factor\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 59, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00399.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.053936149266335276, 0.05734342727845454, 0.06171970059291665, 0.04981094077581105, 0.05295100701533273, 0.056951647593780574, 0.0480053279992132, 0.051035196218487844, 0.05488271433142855]}}
{"id": "33bb91a5-225d-4080-be55-8bf96ff271f8", "fitness": 0.05224089163695208, "name": "AdaptiveNeighborhoodChaoticSwarm", "description": "Employ adaptive neighborhood-based chaotic influence for enhanced convergence and exploration balance.", "code": "import numpy as np\n\nclass AdaptiveNeighborhoodChaoticSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.neighborhood_size = 5\n        self.chaotic_factor = 0.8\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            sorted_indices = np.argsort(personal_best_scores)\n            neighborhood_indices = sorted_indices[:self.neighborhood_size]\n            local_best = personal_best[np.random.choice(neighborhood_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (local_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 60, "feedback": "The algorithm AdaptiveNeighborhoodChaoticSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05224 with standard deviation 0.00273.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.056693480224470294, 0.05610518340391446, 0.05430311988381642, 0.05235526552122893, 0.051815023032426466, 0.05015438429501795, 0.05046166050676204, 0.04994111280680957, 0.04833879505812255]}}
{"id": "12ce9cd4-1b69-4801-b061-ccdbd9bb70ee", "fitness": 0.055408894265748986, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Refine chaotic map for enhanced exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * np.sin(np.pi * chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 61, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05541 with standard deviation 0.00336.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05719730883152563, 0.058067144497654155, 0.062033589252637356, 0.05280889412044143, 0.05361244941180354, 0.05723731519148889, 0.050895141992947535, 0.051671257186951314, 0.055156947906291]}}
{"id": "6536e600-be3c-479d-99fe-fa898aa5e8a7", "fitness": 0.05517536806239314, "name": "EnhancedChaosAdaptiveHybridSwarm", "description": "Introduce multi-phase chaotic maps and adaptive elitist strategies to enhance exploration and exploitation balance for improved convergence.", "code": "import numpy as np\n\nclass EnhancedChaosAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, phase='logistic'):\n        if phase == 'logistic':\n            return 4 * x * (1 - x)\n        elif phase == 'sine':\n            return np.sin(np.pi * x)\n        elif phase == 'tent':\n            return 1 - np.abs(2 * x - 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n            \n            # Multi-phase chaotic maps\n            phase = 'logistic' if eval_ratio < 0.3 else 'sine' if eval_ratio < 0.6 else 'tent'\n            chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state, phase)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state, phase)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedChaosAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05518 with standard deviation 0.00312.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.061160290967940845, 0.057892483777116754, 0.05750502050466555, 0.05642837464032979, 0.05345598930573692, 0.05308317732131684, 0.0543748090135826, 0.05152205312010394, 0.05115611391074504]}}
{"id": "e2639687-5dba-4243-92cd-3e6560fbff11", "fitness": 0.053420356971812494, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Adjust chaotic factor to enhance exploration through increased chaotic influence.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.8  # increased chaotic factor for enhanced influence\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 63, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05342 with standard deviation 0.00338.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05378254106096991, 0.05819512117503145, 0.05892673779960811, 0.04967335887361213, 0.05372876494303258, 0.05439589922590338, 0.047874144127362905, 0.051782859939430104, 0.05242378560136185]}}
{"id": "6eb6ba27-5095-4044-a5f6-8a2345f1b7ce", "fitness": 0.05336039372321306, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Increase the chaotic influence factor for improved exploration capacity.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.75  # Increase chaotic factor slightly\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 64, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05336 with standard deviation 0.00362.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06011122863563367, 0.05701091481858822, 0.05359905612532945, 0.05547455947458024, 0.052645276047675105, 0.04949887069990966, 0.05345953090525746, 0.05074047777110702, 0.04770362903083669]}}
{"id": "f3e6b9a0-a4ca-41fe-a08a-c7ba70e679a0", "fitness": 0.054069218631826406, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Adjust the chaotic influence multiplier to improve exploration efficiency.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.2 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 65, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00297.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0595534034598858, 0.05613016587529851, 0.05729758161606835, 0.05496520870466515, 0.05183793396040959, 0.0529097752117369, 0.052969899488483296, 0.04996317531421968, 0.05099582405567038]}}
{"id": "5a4b3d93-3f17-45b9-a2c0-928f7ab839c9", "fitness": 0.05450234146574468, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the chaotic influence by slightly tweaking its scaling factor for improved exploration dynamics.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.15 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 66, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.00418.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05432737682812161, 0.06263710645746146, 0.05743356503203689, 0.050176681701355474, 0.057786611193371806, 0.05301953112885649, 0.048360298992944806, 0.05568426801582904, 0.05109563384172455]}}
{"id": "4395fb80-e89c-407d-93dd-17aca5574413", "fitness": 0.05157220581186009, "name": "LevyChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate Lvy flight for enhanced exploration and diversity in chaotic adaptive hybrid swarm optimization.", "code": "import numpy as np\n\nclass LevyChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                levy_step = self.levy_flight(self.dim)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component +\n                    levy_step\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 67, "feedback": "The algorithm LevyChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05157 with standard deviation 0.00275.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05414660114044112, 0.05660185608164581, 0.05421251786654391, 0.050007717808012275, 0.052271501012385535, 0.050072212787660164, 0.048196327272799766, 0.050381078865402995, 0.0482600394718492]}}
{"id": "8cc939bd-ee92-453a-bfca-09f9760207b9", "fitness": 0.05455997396621834, "name": "ChaosDrivenAdaptiveSwarmOptimizer", "description": "Enhance exploration and convergence by incorporating adaptive chaotic inertia and dynamic mutation strategy.", "code": "import numpy as np\n\nclass ChaosDrivenAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 2.0 \n        self.c2_initial = 2.0 \n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7 \n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * (x - 0.5) ** 2  # modified chaos for more diverse exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutation_factor = diff_weight * np.random.rand()  # dynamic mutation factor\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 68, "feedback": "The algorithm ChaosDrivenAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05456 with standard deviation 0.00360.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.056757560117797756, 0.05602915902849659, 0.0618132745279496, 0.05239175324105494, 0.05174512056578362, 0.057011240248550754, 0.05048799772741308, 0.049873726769472326, 0.05492993346944641]}}
{"id": "8411eae4-9554-40fc-91e2-af55a8c9d568", "fitness": 0.05336039372321306, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly adjusted chaotic influence scaling factor for enhanced solution diversity.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.75  # slight adjustment for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 69, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05336 with standard deviation 0.00362.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06011122863563367, 0.05701091481858822, 0.05359905612532945, 0.05547455947458024, 0.052645276047675105, 0.04949887069990966, 0.05345953090525746, 0.05074047777110702, 0.04770362903083669]}}
{"id": "9bf5daca-a0b3-4f49-8524-b1d41ab0aef9", "fitness": 0.054886129204827654, "name": "ChaosLevyHybridSwarm", "description": "Integrate Lvy flights alongside chaotic maps for diversified exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosLevyHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                  (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1/beta)\n        u = np.random.randn(dim) * sigma_u\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1/beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                levy_component = self.levy_flight(self.dim)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component +\n                    levy_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 70, "feedback": "The algorithm ChaosLevyHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05489 with standard deviation 0.00439.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.055198102143410255, 0.06375456706154048, 0.056729496174944605, 0.05098091215369083, 0.05873556515836431, 0.05238343811089441, 0.049137021309065276, 0.056569209938413634, 0.05048685079312509]}}
{"id": "2566f153-f4a3-4b99-9360-0078142d899f", "fitness": 0.05313312597216266, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the chaotic influence and leader selection to improve convergence and exploration balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.8  # Adjusted chaotic factor for more influence\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:int(self.leader_selection_pressure * 1.2)]  # Slight increase in leader selection pressure\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x) + 0.01  # Enhanced logistic map for increased chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 71, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05313 with standard deviation 0.00312.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.058972230737013076, 0.056532435937173164, 0.054477289457805944, 0.05443047425736036, 0.05220758592296648, 0.05031313787128788, 0.052454272154136006, 0.05031943103082015, 0.048491276380900894]}}
{"id": "94cb205c-db5a-446f-a07f-5c79cc02da4c", "fitness": 0.05407067900797338, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Adjust chaotic factor dynamically to enhance the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state) * (1 - eval_ratio)  # adjusted chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 72, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00399.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.053936149266335276, 0.05734342727845454, 0.06171970059291665, 0.04981094077581105, 0.05295100701533273, 0.056951647593780574, 0.0480053279992132, 0.051035196218487844, 0.05488271433142855]}}
{"id": "3096a16a-6e70-41ee-b623-c0f664e01ee9", "fitness": -Infinity, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaotic map utilization for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 17, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": "\n    Refine the strategy of the selected solution to improve it. Make sure you only change 1.0% of the code, which means if the code has 100 lines, you can only change 1.0309278350515463 lines, and the rest of the lines should remain unchanged. This input code has 97 lines, so you can only change 1 lines, the rest 96 lines should remain unchanged. This changing rate 1.0% is the mandatory requirement, you cannot change more or less than this rate.\n    ", "metadata": {"aucs": [0.06486791992421681, 0.06051753076455546, 0.06228969574050569, 0.05979890580960334, 0.055834803855402626, 0.05745093989766914, 0.05760903369201675, 0.053801694587408355, 0.05535442532372614]}}
{"id": "dd701717-307f-4d42-98f1-1e9274f1f894", "fitness": 0.05650124059355038, "name": "LevyFlightEnhancedHybridSwarm", "description": "Integrate a Lvy flight-based exploration mechanism to enhance the search process and improve convergence.", "code": "import numpy as np\n\nclass LevyFlightEnhancedHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.levy_factor = 0.05  # parameter for Levy flight\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            # Introduce Levy flight for exploration\n            if evaluations < self.budget:\n                step = self.levy_factor * self.levy_flight(self.dim)\n                for i in range(current_population_size):\n                    levy_position = np.clip(swarm[i] + step, lb, ub)\n                    f_levy = func(levy_position)\n                    evaluations += 1\n                    if f_levy < personal_best_scores[i]:\n                        personal_best_scores[i] = f_levy\n                        personal_best[i] = levy_position\n                        if f_levy < global_best_score:\n                            global_best_score = f_levy\n                            global_best = levy_position\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 74, "feedback": "The algorithm LevyFlightEnhancedHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05650 with standard deviation 0.00423.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0645404442646278, 0.06011128746663408, 0.05618954110168772, 0.05950320266530551, 0.05548111012456236, 0.05188523657828559, 0.057326062416929724, 0.05346838149761868, 0.05000589922630194]}}
{"id": "7c0b5fd8-f70a-4771-b18a-16cf250ff905", "fitness": 0.054374256393036086, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a dynamic chaotic map and adaptive leader selection improvement to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.dynamic_chaotic_step = 20  # new parameter for dynamic chaos\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores, eval_ratio):\n        pressure = max(1, int(self.leader_selection_pressure * (1 + eval_ratio)))  # dynamic pressure\n        leader_indices = np.argsort(personal_best_scores)[:pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return np.sin(np.pi * x)  # changed to sine map for dynamic chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores, eval_ratio)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 75, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05437 with standard deviation 0.00461.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.054348998767643875, 0.05602915902849659, 0.06360519070364257, 0.05019618199883702, 0.05174512056578362, 0.058664791919139314, 0.048378943927412044, 0.049873726769472326, 0.05652619385689739]}}
{"id": "69f9863e-ea44-4f8d-94f0-029fa1e943d3", "fitness": 0.05450234146574468, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly adjust chaotic influence to enhance diversity in exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.15 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 76, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.00418.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05432737682812161, 0.06263710645746146, 0.05743356503203689, 0.050176681701355474, 0.057786611193371806, 0.05301953112885649, 0.048360298992944806, 0.05568426801582904, 0.05109563384172455]}}
{"id": "443def73-778c-4b8d-b19b-a5885f7bc8f9", "fitness": 0.05455517874635317, "name": "DualChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance adaptive swarm with dual chaotic maps for diverse exploration and exploitation balance.", "code": "import numpy as np\n\nclass DualChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_1 = 0.7\n        self.chaotic_factor_2 = 0.5  # secondary chaotic influence\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map_1(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def chaotic_map_2(self, x):\n        return np.sin(np.pi * x)  # sinusoidal map for secondary exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state_1 = np.random.rand()\n        chaotic_state_2 = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component_1 = 1.1 * self.chaotic_factor_1 * self.chaotic_map_1(chaotic_state_1)\n                chaos_component_2 = 0.9 * self.chaotic_factor_2 * self.chaotic_map_2(chaotic_state_2)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component_1 + chaos_component_2\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state_1 = self.chaotic_map_1(chaotic_state_1)\n            chaotic_state_2 = self.chaotic_map_2(chaotic_state_2)\n\n        return global_best", "configspace": "", "generation": 77, "feedback": "The algorithm DualChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05456 with standard deviation 0.00390.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06056341230947182, 0.06008335168682111, 0.05392379048064877, 0.05589339446342423, 0.055440055929775744, 0.04980436498720131, 0.05386447834249963, 0.053422873948924754, 0.04800088656841117]}}
{"id": "afdef775-ba2c-44d5-87f2-7c7f1b86244e", "fitness": 0.05666076606210816, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Fine-tune the chaotic influence multiplier to enhance exploration capability.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.9  # minor adjustment to enhance exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 78, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05666 with standard deviation 0.00545.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0675313301745577, 0.05608736117606927, 0.05781448831283398, 0.06214873667845455, 0.051798490069070446, 0.05337056444752064, 0.05983646677534671, 0.04992511751706319, 0.05143433940805697]}}
{"id": "f4b77277-0df9-4bd1-afdf-8265d537f55e", "fitness": 0.055464000814733336, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the chaotic influence by amplifying its impact on velocity for improved exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 2.0 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 79, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05546 with standard deviation 0.00329.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.061796708062747396, 0.05710375026086334, 0.0585881110394616, 0.05701509680674155, 0.052730323476365304, 0.0540719727116451, 0.054941002705501285, 0.050822337889412594, 0.05210670437986187]}}
{"id": "cfb1aa68-7bcd-4e9e-855b-a34a95621f7f", "fitness": 0.05157220581186009, "name": "ChaosEnhancedLevyHybridSwarm", "description": "Enhance swarm dynamics by integrating Levy flights for improved global search capability.", "code": "import numpy as np\n\nclass ChaosEnhancedLevyHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        return np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                levy_component = self.levy_flight(self.dim)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component +\n                    levy_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 80, "feedback": "The algorithm ChaosEnhancedLevyHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05157 with standard deviation 0.00275.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05414660114044112, 0.05660185608164581, 0.05421251786654391, 0.050007717808012275, 0.052271501012385535, 0.050072212787660164, 0.048196327272799766, 0.050381078865402995, 0.0482600394718492]}}
{"id": "672539aa-97c8-4358-b388-ab1d2612a423", "fitness": 0.050876109889149625, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Integrate a progressive chaotic perturbation mechanism to enhance global exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state) * (1 + eval_ratio)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 81, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05088 with standard deviation 0.00342.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05125968287543614, 0.05734642281662683, 0.054139837666815516, 0.047340168966442, 0.05295170319811371, 0.050001814759428886, 0.045619549413036475, 0.05103506101105182, 0.04819074829539527]}}
{"id": "8550b292-7044-4f13-8d50-ff9d70d08288", "fitness": 0.053420356971812494, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Fine-tune chaotic map coefficient for more effective exploration and exploitation balance.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.8  # fine-tuned parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 82, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05342 with standard deviation 0.00338.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05378254106096991, 0.05819512117503145, 0.05892673779960811, 0.04967335887361213, 0.05372876494303258, 0.05439589922590338, 0.047874144127362905, 0.051782859939430104, 0.05242378560136185]}}
{"id": "22c47307-702c-412d-a713-af3c0c7d6dd0", "fitness": 0.05417222382299384, "name": "MultiLevelChaosHybridSwarm", "description": "Introduce a multi-level chaotic exploration strategy to enhance convergence and robustness.", "code": "import numpy as np\n\nclass MultiLevelChaosHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.secondary_chaos_factor = 0.5  # secondary chaos factor for multi-level chaos\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            secondary_chaotic_state = self.chaotic_map(chaotic_state)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # primary chaotic influence\n                secondary_chaos_component = self.secondary_chaos_factor * secondary_chaotic_state  # secondary chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component +\n                    secondary_chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 83, "feedback": "The algorithm MultiLevelChaosHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05417 with standard deviation 0.00402.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.053256800868187515, 0.0596500278598725, 0.06042729229773902, 0.049189150451286356, 0.05504770126983216, 0.055773721965196144, 0.047407055433947964, 0.05304699703856475, 0.053751267222318155]}}
{"id": "15d0a526-ca76-4443-a526-4e7939de5768", "fitness": 0.05633304520222579, "name": "StochasticNeighborhoodChaosSwarm", "description": "Introduce stochastic neighborhood-based perturbations for enhanced local search capability in chaotic hybrid swarm optimization.", "code": "import numpy as np\n\nclass StochasticNeighborhoodChaosSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.neighborhood_radius = 0.1  # new parameter for local search radius\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def stochastic_local_search(self, position, lb, ub):\n        perturbation = np.random.uniform(-self.neighborhood_radius, self.neighborhood_radius, self.dim)\n        return np.clip(position + perturbation, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                local_candidate = self.stochastic_local_search(swarm[i], lb, ub)\n                f_local_candidate = func(local_candidate)\n                evaluations += 1\n                if f_local_candidate < personal_best_scores[i]:\n                    personal_best_scores[i] = f_local_candidate\n                    personal_best[i] = local_candidate\n                    if f_local_candidate < global_best_score:\n                        global_best_score = f_local_candidate\n                        global_best = local_candidate\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 84, "feedback": "The algorithm StochasticNeighborhoodChaosSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05633 with standard deviation 0.00406.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0645404442646278, 0.05727207812607138, 0.058487623874393546, 0.05950320266530551, 0.052886433586085024, 0.05398428989180126, 0.057326062416929724, 0.05097335306654338, 0.052023918928274515]}}
{"id": "3ea4e751-98b4-440b-b9a3-26523987854e", "fitness": 0.05319544426002565, "name": "DynamicInertiaAdaptiveHybridSwarm", "description": "Enhance convergence speed by introducing dynamic inertia weight adaptation based on success rate.", "code": "import numpy as np\n\nclass DynamicInertiaAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.success_threshold = 0.1\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, diff_weight, cross_prob\n\n    def dynamic_inertia_weight(self, success_rate):\n        return self.w_max - (self.w_max - self.w_min) * success_rate\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n        improvement_count = 0\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            success_rate = improvement_count / self.initial_population_size\n            w = self.dynamic_inertia_weight(success_rate)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            improvement_count = 0\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    improvement_count += 1\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    improvement_count += 1\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicInertiaAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05320 with standard deviation 0.00295.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05550809335798845, 0.05878522248403906, 0.055874944772516755, 0.05126239568121049, 0.05427356222272883, 0.051602709652667667, 0.04940695820847063, 0.05230890258587839, 0.049736209374730556]}}
{"id": "8cc34615-2f62-4202-9608-1390bfa20556", "fitness": 0.053931356673213866, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce dynamic chaotic influence scaling based on evaluation ratio to enhance exploration diversity.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * eval_ratio * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 86, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05393 with standard deviation 0.00288.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05751148066748746, 0.05602915902849659, 0.058997785933924574, 0.05309434265264046, 0.05174512056578362, 0.054467012904789835, 0.05116896304337348, 0.049873726769472326, 0.052494618492956446]}}
{"id": "5c11cfe5-0e0e-427a-b37d-cf99551ac960", "fitness": 0.054069218631826406, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Enhance the calculation of chaotic factor to improve the algorithm's exploration capabilities.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.2 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 87, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05407 with standard deviation 0.00297.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0595534034598858, 0.05613016587529851, 0.05729758161606835, 0.05496520870466515, 0.05183793396040959, 0.0529097752117369, 0.052969899488483296, 0.04996317531421968, 0.05099582405567038]}}
{"id": "573056c2-998e-4962-84d4-0332924e0385", "fitness": 0.05450234146574468, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly enhance chaotic component scaling for improved exploratory behavior.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.15 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 88, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05450 with standard deviation 0.00418.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05432737682812161, 0.06263710645746146, 0.05743356503203689, 0.050176681701355474, 0.057786611193371806, 0.05301953112885649, 0.048360298992944806, 0.05568426801582904, 0.05109563384172455]}}
{"id": "bfa68ec7-1781-40b8-bb94-182b32ae5f76", "fitness": 0.05242117811219647, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Introduce a subtle enhancement in chaotic map utilization for improved exploration by adjusting the logistic map formula.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4.1 * x * (1 - x)  # slight change in logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 89, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05242 with standard deviation 0.00298.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.057539332938047916, 0.05644171868213532, 0.05370624180501393, 0.05312703476648395, 0.052124202883650606, 0.04960321294081782, 0.05120327370696276, 0.05023906125854549, 0.047806524028110475]}}
{"id": "cf49b03f-3360-4269-a5a5-d130ac3f1199", "fitness": 0.05390000736229095, "name": "EnhancedAdaptiveMultiSwarm", "description": "Introduce adaptive multi-swarm strategy with enhanced chaotic map influence for diversified exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveMultiSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.swarm_count = 3  # Introduce multiple swarms for diversified exploration\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_sizes = [self.initial_population_size // self.swarm_count] * self.swarm_count\n        swarms = [np.random.uniform(lb, ub, (size, self.dim)) for size in swarm_sizes]\n        velocities = [np.random.uniform(-1, 1, (size, self.dim)) for size in swarm_sizes]\n        personal_bests = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(p) for p in best]) for best in personal_bests]\n        global_bests = [personal_bests[i][np.argmin(scores)] for i, scores in enumerate(personal_best_scores)]\n        global_best_scores = [np.min(scores) for scores in personal_best_scores]\n\n        evaluations = sum(swarm_sizes)\n        chaotic_states = np.random.rand(self.swarm_count)\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n            \n            for swarm_index in range(self.swarm_count):\n                swarm = swarms[swarm_index]\n                velocity = velocities[swarm_index]\n                personal_best = personal_bests[swarm_index]\n                personal_best_score = personal_best_scores[swarm_index]\n                global_best = global_bests[swarm_index]\n                global_best_score = global_best_scores[swarm_index]\n\n                current_population_size = max(5, int(swarm_sizes[swarm_index] * (1 - eval_ratio)))\n                leader_indices = self.dynamic_leader_selection(personal_best_score)\n                new_global_best = personal_best[np.random.choice(leader_indices)]\n\n                for i in range(current_population_size):\n                    r1, r2 = np.random.rand(2)\n                    chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_states[swarm_index])\n                    velocity[i] = 0.5 * (\n                        w * velocity[i] +\n                        c1 * r1 * (personal_best[i] - swarm[i]) +\n                        c2 * r2 * (new_global_best - swarm[i]) +\n                        chaos_component\n                    )\n                    swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_score[i]:\n                        personal_best_score[i] = f_value\n                        personal_best[i] = swarm[i]\n                        if f_value < global_best_score:\n                            global_best_score = f_value\n                            global_best = swarm[i]\n\n                for i in range(current_population_size):\n                    if evaluations >= self.budget:\n                        break\n                    idxs = [idx for idx in range(current_population_size) if idx != i]\n                    a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                    cross_points = np.random.rand(self.dim) < cross_prob\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, swarm[i])\n                    f_trial = func(trial)\n                    evaluations += 1\n                    if f_trial < personal_best_score[i]:\n                        personal_best_score[i] = f_trial\n                        personal_best[i] = trial\n                        if f_trial < global_best_score:\n                            global_best_score = f_trial\n                            global_best = trial\n\n                chaotic_states[swarm_index] = self.chaotic_map(chaotic_states[swarm_index])\n                global_bests[swarm_index] = global_best\n                global_best_scores[swarm_index] = global_best_score\n\n        best_index = np.argmin(global_best_scores)\n        return global_bests[best_index]", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveMultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05390 with standard deviation 0.00293.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05929199864715884, 0.05706869475996568, 0.05609796445187443, 0.05471180536954856, 0.05269920342970491, 0.051797369326182285, 0.05272051058670413, 0.05079277513623004, 0.049919744553249656]}}
{"id": "10b5f45e-89c7-4fb1-a0b8-dd5424a90f51", "fitness": 0.05245446651698663, "name": "EnhancedHybridSwarmWithAdaptiveChaos", "description": "Integrate self-adaptive chaotic intensity and hybrid mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridSwarmWithAdaptiveChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        chaos_intensity = self.chaotic_factor * (1 - eval_ratio)\n        return c1, c2, w, diff_weight, cross_prob, chaos_intensity\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaos_intensity = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = chaos_intensity * self.chaotic_map(chaotic_state)\n                velocity[i] = (w * velocity[i] +\n                               c1 * r1 * (personal_best[i] - swarm[i]) +\n                               c2 * r2 * (new_global_best - swarm[i]) +\n                               chaos_component)\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedHybridSwarmWithAdaptiveChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05245 with standard deviation 0.00267.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.0555523096486189, 0.05700747715165555, 0.05523490812904075, 0.05130302862950731, 0.052643516645224486, 0.051005910447134206, 0.04944611485507577, 0.050739329824037505, 0.04915760332258523]}}
{"id": "549833b2-8312-4885-92f9-77ccd85c8e8e", "fitness": 0.051881953372251814, "name": "RefinedChaosAdaptiveHybridSwarm", "description": "Introduce a self-adaptive chaotic factor and enhanced leader selection for further exploration refinement.", "code": "import numpy as np\n\nclass RefinedChaosAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_initial = 0.7\n        self.chaotic_factor_final = 1.0\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = np.interp(eval_ratio, [0, 1], [self.c1_initial, self.c1_final])\n        c2 = np.interp(eval_ratio, [0, 1], [self.c2_initial, self.c2_final])\n        w = np.interp(eval_ratio, [0, 1], [self.w_initial, self.w_final])\n        diff_weight = np.interp(eval_ratio, [0, 1], [self.diff_weight_initial, self.diff_weight_final])\n        cross_prob = np.interp(eval_ratio, [0, 1], [self.cross_prob_initial, self.cross_prob_final])\n        chaotic_factor = np.interp(eval_ratio, [0, 1], [self.chaotic_factor_initial, self.chaotic_factor_final])\n        return c1, c2, w, diff_weight, cross_prob, chaotic_factor\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob, chaotic_factor = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i])\n                ) * chaos_component\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 92, "feedback": "The algorithm RefinedChaosAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05188 with standard deviation 0.00283.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05481327674881209, 0.05711463656601523, 0.05402548724148026, 0.05062305650986232, 0.05274241846947636, 0.04989979481821227, 0.048790442353460195, 0.05083481781090615, 0.04809364983204145]}}
{"id": "a7babcd2-04b1-48cb-80a8-75f44a914c0f", "fitness": 0.05861388328834492, "name": "ImprovedChaosEnhancedAdaptiveHybridSwarm", "description": "Incorporate a dynamic population size and diversity maintenance strategy to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass ImprovedChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n        self.min_population_size = 5\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def maintain_diversity(self, swarm, lb, ub, diversity_threshold):\n        centroid = np.mean(swarm, axis=0)\n        for i in range(len(swarm)):\n            if np.linalg.norm(swarm[i] - centroid) < diversity_threshold:\n                swarm[i] = np.random.uniform(lb, ub, self.dim)\n        return swarm\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(self.min_population_size,\n                                          int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            diversity_threshold = np.std(personal_best_scores) * 0.1\n            swarm = self.maintain_diversity(swarm, lb, ub, diversity_threshold)\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 93, "feedback": "The algorithm ImprovedChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05861 with standard deviation 0.00336.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06486791992421681, 0.06051753076455546, 0.06228969574050569, 0.05979890580960334, 0.055834803855402626, 0.05745093989766914, 0.05760903369201675, 0.053801694587408355, 0.05535442532372614]}}
{"id": "2414cad2-1297-49c2-a812-9bf00e857202", "fitness": 0.05602026424873414, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Slightly adjust the chaotic map function to enhance chaotic diversity in exploration.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 3.9 * x * (1 - x)  # slightly adjusted logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 94, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05602 with standard deviation 0.00285.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06075571665610402, 0.05901648986771235, 0.05948469585300675, 0.056064849540175654, 0.054484596162349797, 0.05491290573987018, 0.05402767191260949, 0.05251170636367053, 0.05292374614310846]}}
{"id": "0b81f179-033d-43a5-992d-e0eb9c934f36", "fitness": 0.05861388328834492, "name": "MultiChaoticAdaptiveHybridSwarm", "description": "Enhance swarm adaptability by introducing a multi-chaotic map approach to diversify exploration.", "code": "import numpy as np\n\nclass MultiChaoticAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x, map_type='logistic'):\n        if map_type == 'logistic':\n            return 4 * x * (1 - x)\n        elif map_type == 'sine':\n            return np.sin(np.pi * x)\n        elif map_type == 'tent':\n            if x < 0.5:\n                return 2 * x\n            else:\n                return 2 * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n        map_type = 'logistic'\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state, map_type)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state, map_type)\n            if evaluations % (self.budget // 3) == 0:\n                # Switch chaotic map type to diversify exploration\n                map_type = 'sine' if map_type == 'logistic' else 'tent' if map_type == 'sine' else 'logistic'\n\n        return global_best", "configspace": "", "generation": 95, "feedback": "The algorithm MultiChaoticAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05861 with standard deviation 0.00336.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.06486791992421681, 0.06051753076455546, 0.06228969574050569, 0.05979890580960334, 0.055834803855402626, 0.05745093989766914, 0.05760903369201675, 0.053801694587408355, 0.05535442532372614]}}
{"id": "127a5a9a-6c61-4378-a6b7-2fa725c4e6e2", "fitness": -Infinity, "name": "EnhancedDiverseChaoticSwarm", "description": "Implement a diversity-maintenance strategy with chaotic mutation to prevent premature convergence and improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedDiverseChaoticSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            diversity_threshold = 0.1 * (ub - lb)\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i] or np.linalg.norm(swarm[i] - global_best) < diversity_threshold:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)\n\n        return global_best", "configspace": "", "generation": 96, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {}}
{"id": "15993d4c-dd7e-4584-9a36-2b04e8876f30", "fitness": 0.056248503011966836, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Augment chaotic exploration with a Lvy flight mechanism for enhanced global search capabilities.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.7  # new parameter for chaos-based exploration\n        self.levy_alpha = 1.5  # Lvy flight parameter\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def levy_flight(self, size):\n        return np.random.standard_normal(size) * (np.random.pareto(self.levy_alpha, size) + 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                levy_component = self.levy_flight(self.dim) * chaos_component\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    levy_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 97, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05625 with standard deviation 0.00400.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.060418083352480445, 0.05602915902849659, 0.0635677487873818, 0.05576428573344727, 0.05174512056578362, 0.05861895802104444, 0.05374182008602968, 0.049873726769472326, 0.056477624763565326]}}
{"id": "c813c2b1-f9dd-493e-b0e8-ceef526a737c", "fitness": 0.05209319541997827, "name": "DualChaosHybridSwarm", "description": "Implement a dual-chaos strategy by combining logistic and tent chaotic maps to enhance exploration and avoid premature convergence.", "code": "import numpy as np\n\nclass DualChaosHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor_logistic = 0.7\n        self.chaotic_factor_tent = 0.3\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def tent_map(self, x):\n        return 1 - 2 * np.abs(0.5 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state_logistic = np.random.rand()\n        chaotic_state_tent = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component_logistic = 1.1 * self.chaotic_factor_logistic * self.logistic_map(chaotic_state_logistic)\n                chaos_component_tent = 1.1 * self.chaotic_factor_tent * self.tent_map(chaotic_state_tent)\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component_logistic + chaos_component_tent\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state_logistic = self.logistic_map(chaotic_state_logistic)\n            chaotic_state_tent = self.tent_map(chaotic_state_tent)\n\n        return global_best", "configspace": "", "generation": 98, "feedback": "The algorithm DualChaosHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05209 with standard deviation 0.00289.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05504175612644335, 0.05750102815643454, 0.054099258336298695, 0.05082540858159568, 0.05309505134883552, 0.049964854530488156, 0.04898242700467659, 0.051173715928500285, 0.048155258766531595]}}
{"id": "dea12451-4673-4cab-826f-10862c6a77e9", "fitness": 0.05270961849276796, "name": "ChaosEnhancedAdaptiveHybridSwarm", "description": "Fine-tune the chaotic influence factor for a more balanced exploration-exploitation trade-off.", "code": "import numpy as np\n\nclass ChaosEnhancedAdaptiveHybridSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.diff_weight_initial = 0.5\n        self.cross_prob_initial = 0.9\n        self.c1_final = 2.5\n        self.c2_final = 0.5\n        self.w_final = 0.4\n        self.diff_weight_final = 1.0\n        self.cross_prob_final = 0.8\n        self.leader_selection_pressure = 5\n        self.chaotic_factor = 0.6  # modified parameter for chaos-based exploration\n\n    def adaptive_parameters(self, eval_ratio):\n        c1 = self.c1_initial + eval_ratio * (self.c1_final - self.c1_initial)\n        c2 = self.c2_initial + eval_ratio * (self.c2_final - self.c2_initial)\n        w = self.w_initial - eval_ratio * (self.w_initial - self.w_final)\n        diff_weight = self.diff_weight_initial + eval_ratio * (self.diff_weight_final - self.diff_weight_initial)\n        cross_prob = self.cross_prob_initial - eval_ratio * (self.cross_prob_initial - self.cross_prob_final)\n        return c1, c2, w, diff_weight, cross_prob\n\n    def dynamic_leader_selection(self, personal_best_scores):\n        leader_indices = np.argsort(personal_best_scores)[:self.leader_selection_pressure]\n        return leader_indices\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)  # logistic map for chaos\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best = np.copy(swarm)\n        personal_best_scores = np.array([func(p) for p in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.initial_population_size\n        chaotic_state = np.random.rand()\n\n        while evaluations < self.budget:\n            eval_ratio = evaluations / self.budget\n            c1, c2, w, diff_weight, cross_prob = self.adaptive_parameters(eval_ratio)\n\n            current_population_size = max(5, int(self.initial_population_size * (1 - eval_ratio)))\n\n            leader_indices = self.dynamic_leader_selection(personal_best_scores)\n            new_global_best = personal_best[np.random.choice(leader_indices)]\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.rand(2)\n                chaos_component = 1.1 * self.chaotic_factor * self.chaotic_map(chaotic_state)  # modified chaotic influence\n                velocity[i] = 0.5 * (\n                    w * velocity[i] +\n                    c1 * r1 * (personal_best[i] - swarm[i]) +\n                    c2 * r2 * (new_global_best - swarm[i]) +\n                    chaos_component\n                )\n                swarm[i] = np.clip(swarm[i] + velocity[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_scores[i]:\n                    personal_best_scores[i] = f_value\n                    personal_best[i] = swarm[i]\n                    if f_value < global_best_score:\n                        global_best_score = f_value\n                        global_best = swarm[i]\n\n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(current_population_size) if idx != i]\n                a, b, c = swarm[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < cross_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, swarm[i])\n                f_trial = func(trial)\n                evaluations += 1\n                if f_trial < personal_best_scores[i]:\n                    personal_best_scores[i] = f_trial\n                    personal_best[i] = trial\n                    if f_trial < global_best_score:\n                        global_best_score = f_trial\n                        global_best = trial\n\n            chaotic_state = self.chaotic_map(chaotic_state)  # update chaotic state\n\n        return global_best", "configspace": "", "generation": 99, "feedback": "The algorithm ChaosEnhancedAdaptiveHybridSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05271 with standard deviation 0.00270.", "error": "", "parent_ids": ["13aa7662-74c4-47ea-9c0b-64e32f79a08e"], "operator": null, "metadata": {"aucs": [0.05536339043202998, 0.057331839054175604, 0.05591139701858372, 0.05112960300008962, 0.05294094281094519, 0.051636169969973444, 0.04927905315750225, 0.05102572681594131, 0.0497684441756705]}}
