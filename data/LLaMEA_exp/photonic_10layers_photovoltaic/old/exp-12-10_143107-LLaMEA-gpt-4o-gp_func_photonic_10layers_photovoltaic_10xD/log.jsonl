{"id": "23b32237-0f43-42a3-ae00-113ea1d5beb2", "fitness": 0.05524267975922984, "name": "HybridPSOLevy", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization (PSO) with dynamic Lévy flights for enhanced exploratory capabilities.", "code": "import numpy as np\n\nclass HybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n\n    def levy_flight(self, L):\n        # Lévy flights using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        # Initialize personal bests and global best\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Update particle velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Update particle position\n                particles[i] += velocities[i]\n                \n                # Apply Lévy flight for exploration\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                # Ensure the particle is within bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Evaluate the new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05524 with standard deviation 0.00286.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "ec42cba2-802c-4f69-8d5d-ef780d84a41f", "fitness": 0.05524267975922984, "name": "HybridPSOLevyAdaptive", "description": "HybridPSOLevyAdaptive introduces adaptive parameter tuning based on population diversity to balance exploration and exploitation effectively, thereby enhancing convergence on optimization tasks.", "code": "import numpy as np\n\nclass HybridPSOLevyAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.diversity_threshold = 0.1  # threshold to adapt parameters\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def compute_diversity(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        diversity = np.mean(np.linalg.norm(particles - mean_position, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                particles[i] += velocities[i]\n\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n\n                particles[i] = np.clip(particles[i], lb, ub)\n                score = func(particles[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n            diversity = self.compute_diversity(particles)\n            if diversity < self.diversity_threshold:\n                self.inertia_weight = 0.9\n            else:\n                self.inertia_weight = 0.7\n\n        return global_best_position", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSOLevyAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05524 with standard deviation 0.00286.", "error": "", "parent_ids": ["23b32237-0f43-42a3-ae00-113ea1d5beb2"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "88fda016-83c9-426f-bb03-ab16627ab3fb", "fitness": 0.05547226462126147, "name": "HybridPSOLevy", "description": "Improved global search capability by adjusting inertia dynamically based on the diversity of particles.", "code": "import numpy as np\n\nclass HybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n\n    def levy_flight(self, L):\n        # Lévy flights using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        # Initialize personal bests and global best\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Calculate diversity of particles\n            diversity = np.mean(np.std(particles, axis=0))\n            # Adjust inertia weight based on diversity\n            self.inertia_weight = 0.5 + (0.5 * (diversity / (ub - lb).mean()))\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Update particle velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Update particle position\n                particles[i] += velocities[i]\n                \n                # Apply Lévy flight for exploration\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                # Ensure the particle is within bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Evaluate the new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05547 with standard deviation 0.00275.", "error": "", "parent_ids": ["23b32237-0f43-42a3-ae00-113ea1d5beb2"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.05415958906586393, 0.05390349159814678, 0.06017282610106767, 0.05521217208681828, 0.052205618306337964, 0.0582425616809461, 0.05346779822961811]}}
{"id": "62b78e4c-7c0e-45f1-9607-58a964704195", "fitness": 0.05524267975922984, "name": "EnhancedPSOLevy", "description": "Enhanced PSO with Lévy flights and dynamic learning rates for adaptive exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.min_learning_rate = 0.1\n        self.max_learning_rate = 2.0\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_learning_rate(self, iteration, max_iterations):\n        return self.min_learning_rate + (self.max_learning_rate - self.min_learning_rate) * (1 - (iteration / max_iterations))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        iteration = 0\n        max_iterations = self.budget // self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.mean(np.std(particles, axis=0))\n            self.inertia_weight = 0.5 + (0.5 * (diversity / (ub - lb).mean()))\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_coefficient = self.cognitive_coefficient * self.dynamic_learning_rate(iteration, max_iterations)\n                social_coefficient = self.social_coefficient * self.dynamic_learning_rate(iteration, max_iterations)\n                \n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n                \n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n            iteration += 1\n\n        return global_best_position", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05524 with standard deviation 0.00286.", "error": "", "parent_ids": ["88fda016-83c9-426f-bb03-ab16627ab3fb"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "13f8ad75-38e7-42ac-8017-4d6315c504f7", "fitness": 0.05524267975922984, "name": "HybridPSOLevy", "description": "Introduced adaptive social and cognitive coefficients based on diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n\n    def levy_flight(self, L):\n        # Lévy flights using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        # Initialize personal bests and global best\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Calculate diversity of particles\n            diversity = np.mean(np.std(particles, axis=0))\n            # Adjust inertia weight and coefficients based on diversity\n            self.inertia_weight = 0.5 + (0.5 * (diversity / (ub - lb).mean()))\n            self.social_coefficient = 1.5 + 0.5 * (1 - diversity / (ub - lb).mean())  # Change\n            self.cognitive_coefficient = 1.2 + 0.8 * (diversity / (ub - lb).mean())    # Change\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Update particle velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Update particle position\n                particles[i] += velocities[i]\n                \n                # Apply Lévy flight for exploration\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                # Ensure the particle is within bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Evaluate the new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 4, "feedback": "The algorithm HybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05524 with standard deviation 0.00286.", "error": "", "parent_ids": ["88fda016-83c9-426f-bb03-ab16627ab3fb"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "8be7d628-8e92-42ca-872f-f5ada1261987", "fitness": 0.056090192966220614, "name": "HybridPSOLevy", "description": "Enhanced local search capability by leveraging a dynamic adjustment of cognitive and social coefficients based on convergence rate.", "code": "import numpy as np\n\nclass HybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n\n    def levy_flight(self, L):\n        # Lévy flights using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        # Initialize personal bests and global best\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            # Calculate diversity of particles\n            diversity = np.mean(np.std(particles, axis=0))\n            # Adjust inertia weight based on diversity\n            self.inertia_weight = 0.5 + (0.5 * (diversity / (ub - lb).mean()))\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                # Dynamic adjustment based on convergence rate\n                convergence_rate = np.abs((personal_best_scores[i] - global_best_score) / global_best_score)\n                self.cognitive_coefficient = 1.5 + convergence_rate\n                self.social_coefficient = 1.5 - convergence_rate\n                \n                # Update particle velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Update particle position\n                particles[i] += velocities[i]\n                \n                # Apply Lévy flight for exploration\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                # Ensure the particle is within bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Evaluate the new position\n                score = func(particles[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05609 with standard deviation 0.00239.", "error": "", "parent_ids": ["88fda016-83c9-426f-bb03-ab16627ab3fb"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05631795888822966, 0.06017282610106767, 0.05480171147224022, 0.05482996978846588, 0.0582425616809461, 0.055087827572965486]}}
{"id": "0b8fe5a5-594a-45ae-b43d-c810878cca9c", "fitness": 0.057086874623964584, "name": "AdaptiveHybridPSOLevy", "description": "Enhance exploration by integrating adaptive Lévy flight intervals and dynamic parameter tuning based on particle success.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05709 with standard deviation 0.00304.", "error": "", "parent_ids": ["8be7d628-8e92-42ca-872f-f5ada1261987"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05274262519853434, 0.0582425616809461, 0.05417433597321475]}}
{"id": "8bb11433-91ad-4c35-b9d4-3be3da6708e8", "fitness": 0.05632329854006754, "name": "AdaptiveHybridPSOLevy", "description": "Introduce dynamic population size adjustment for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.final_population_size = 10  # New final population size\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_population_size(self, evaluations):  # New function\n        return int(self.initial_population_size - (self.initial_population_size - self.final_population_size) * \n                   (evaluations / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            current_population_size = self.update_population_size(evaluations)  # Adjust population size\n            \n            for i in range(current_population_size):  # Use current population size\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05632 with standard deviation 0.00292.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.06027980028553048, 0.05516449752940744, 0.06017282610106767, 0.05456928427917562, 0.05274262519853434, 0.0582425616809461, 0.0538517672633918]}}
{"id": "c94fec77-2ccd-443b-968a-d6ca49d35cf2", "fitness": 0.05545479646226211, "name": "EnhancedAdaptivePSOLevy", "description": "Enhance exploration and convergence by integrating adaptive Lévy flight with elitism and adaptive neighborhood-based learning.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # Exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # Threshold for successful particle movement\n        self.elite_portion = 0.1  # Portion of elite particles\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            # Sort particles based on performance\n            elite_count = int(self.elite_portion * self.population_size)\n            sorted_indices = np.argsort(personal_best_scores)\n            elite_indices = sorted_indices[:elite_count]\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                \n                # Adaptive neighborhood-based learning\n                if i in elite_indices:\n                    neighbor_index = np.random.choice(elite_indices)\n                else:\n                    neighbor_index = np.random.choice(sorted_indices)\n                \n                neighbor_term = np.random.rand() * (personal_best_positions[neighbor_index] - particles[i])\n                \n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term + neighbor_term)\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05545 with standard deviation 0.00274.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05460870184729816, 0.05900715030715742, 0.05365207936490535, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "a2e49106-2870-4bb6-a927-b6f621c1ad8d", "fitness": 0.05559235741545368, "name": "AdaptiveHybridPSOLevy", "description": "Introduce a momentum coefficient to particle velocity update to enhance convergence stability.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.momentum_coefficient = 0.3  # newly introduced momentum coefficient\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (self.momentum_coefficient * velocities[i] + inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05559 with standard deviation 0.00277.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.0558812820175576, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.060317817204921576, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "a8938fe7-da28-471c-9a1e-429eb2fd07af", "fitness": 0.056321221577262506, "name": "AdaptiveHybridPSOLevy", "description": "Improved convergence by incorporating a dynamic adaptation of the population size based on performance and evaluations.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.dynamic_population = True  # New flag for dynamic population\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_population_size(self, evaluations):  # New method for dynamic population\n        if self.dynamic_population:\n            self.population_size = max(10, int(30 * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            self.update_population_size(evaluations)  # Update population size dynamically\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05632 with standard deviation 0.00287.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.06027980028553048, 0.05408840775750845, 0.06017282610106767, 0.05451055550968997, 0.05337297977160882, 0.0582425616809461, 0.05433753856645662]}}
{"id": "9cb469f0-2867-4813-b77f-6b28dbe1abfd", "fitness": 0.05599662604036748, "name": "ChaoticHybridPSOLevy", "description": "Introduce diversity through chaotic maps to enhance exploration and convergence in adaptive Lévy flight-based PSO.", "code": "import numpy as np\n\nclass ChaoticHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.chaotic_parameter = 0.7\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def chaotic_map(self, x):\n        return self.chaotic_parameter * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        chaotic_variable = np.random.rand()\n\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            chaotic_variable = self.chaotic_map(chaotic_variable)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim) * chaotic_variable\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 11, "feedback": "The algorithm ChaoticHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05600 with standard deviation 0.00277.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05534187014161218, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.0581373214315829]}}
{"id": "797753ae-3de3-4ec7-a0c8-071685638533", "fitness": 0.05565370805062507, "name": "EnhancedPSOLevyDE", "description": "Integrate adaptive Lévy flight and differential evolution to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass EnhancedPSOLevyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.f = 0.5  # scaling factor for DE\n        self.cr = 0.9  # crossover probability for DE\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def differential_evolution(self, particles, i, lb, ub):\n        indices = [idx for idx in range(self.population_size) if idx != i]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant_vector = particles[a] + self.f * (particles[b] - particles[c])\n        mutant_vector = np.clip(mutant_vector, lb, ub)\n        trial_vector = np.copy(particles[i])\n        crossover = np.random.rand(self.dim) < self.cr\n        trial_vector[crossover] = mutant_vector[crossover]\n        return trial_vector\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                trial_vector = self.differential_evolution(particles, i, lb, ub)\n                new_score = func(trial_vector)\n                evaluations += 1\n                \n                if new_score < personal_best_scores[i]:\n                    personal_best_scores[i] = new_score\n                    personal_best_positions[i] = trial_vector\n                    \n                    if new_score < global_best_score:\n                        global_best_score = new_score\n                        global_best_position = trial_vector\n\n        return global_best_position", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedPSOLevyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05565 with standard deviation 0.00277.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05382144024402391, 0.05900715030715742, 0.053472556669516114, 0.05666048019207692, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "027e3dba-2e01-41e2-8505-1bdcee2d0a8d", "fitness": 0.05725572559662268, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive exploration through Lévy flights with enhanced global best consideration.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 13, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["0b8fe5a5-594a-45ae-b43d-c810878cca9c"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "b3045118-d9a7-4b30-a8d0-07b149797074", "fitness": 0.05598215971893142, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced cognitive and social coefficient adjustment based on evaluation progress.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure * evaluations / self.budget)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5) * evaluations / self.budget\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05598 with standard deviation 0.00272.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05418970572957449, 0.05900715030715742, 0.053472556669516114, 0.058212171896631415, 0.06017282610106767, 0.054665944680162504, 0.052635284793505877, 0.0582425616809461, 0.05324123561182115]}}
{"id": "42e6ae15-8458-4c06-b5ed-3847edf701e7", "fitness": 0.056036100726544684, "name": "EnhancedPSOLevy", "description": "Enhanced population diversity through chaos-inspired velocity updates and adaptive Lévy flight weighting.", "code": "import numpy as np\n\nclass EnhancedPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.chaos_factor = 0.6  # factor for introducing chaos\n\n    def levy_flight(self, L, success_measure):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step * (1 + success_measure)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term) * (1 + self.chaos_factor * (np.random.rand() - 0.5))\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim, success_measure)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, success_measure) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05604 with standard deviation 0.00294.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05357861126709562, 0.05900715030715742, 0.053472556669516114, 0.059020851425553245, 0.06017282610106767, 0.05583454733641846, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "83b7ff5f-3d27-45d3-9ebb-679fe4c96db3", "fitness": 0.05725572559662268, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Particle Swarm Optimization with Lévy flights and Success-based Parameter Adaptation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (0.5 + success_measure)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "2e3786fd-9152-432c-9c8b-eb855885699a", "fitness": 0.05547042578311629, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Improved inertia weight adaptation and dynamic population size adjustment for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.min_population_size = 10\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.3\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.adaptation_rate = 0.1  # rate at which population size is adjusted\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_population_size(self, evaluations):\n        return int(self.initial_population_size - \n                   ((self.initial_population_size - self.min_population_size) * \n                    (evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            current_population_size = self.update_population_size(evaluations)\n            \n            for i in range(current_population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 17, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05547 with standard deviation 0.00269.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05383751095694711, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.054832427287721974, 0.052883863481044235, 0.0582425616809461, 0.05288144396549921]}}
{"id": "cbaa489a-75b1-4ab8-b330-e9123acfdd17", "fitness": 0.057032787779414465, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive Particle Swarm Optimization with Dynamic Lévy Flight Adjustments for Enhanced Convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.levy_scale_factor = 0.1\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_scale_factor * self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_scale_factor * self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05703 with standard deviation 0.00310.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "bae6ac6f-ae22-4eb6-a40f-7dcf382851dd", "fitness": 0.05725572559662268, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced dynamic adaptive exploration balancing exploitation with individual-based Lévy perturbations and dynamic inertia.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)  # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "c40000b3-5cc7-49cd-ad89-24488cd8974f", "fitness": 0.05524267975922984, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Introduce a dynamic population size and adaptive acceleration coefficients based on swarm diversity to enhance search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1\n        \n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def update_population_size(self, evaluations):\n        return int(self.initial_population_size * (1 - evaluations / self.budget) + 10)\n    \n    def calculate_swarm_diversity(self, particles):\n        return np.mean(np.std(particles, axis=0))\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.update_population_size(0)\n        \n        particles = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        while evaluations < self.budget:\n            population_size = self.update_population_size(evaluations)\n            inertia_weight = self.update_inertia_weight(evaluations)\n            swarm_diversity = self.calculate_swarm_diversity(particles)\n            \n            cognitive_coefficient = 2.0 * (1 - swarm_diversity)\n            social_coefficient = 2.0 * (swarm_diversity + 0.5)\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n                \n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05524 with standard deviation 0.00286.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "cea8f12a-fdc7-4bc7-9a6d-b93b04f58e88", "fitness": 0.05596281027979958, "name": "AdaptiveHybridPSOLevy", "description": "Modified inertia weight adaptation and enhanced global best update with memory factor.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_factor = 0.1  # memory factor for global best update\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        adaptive_scale = (1 + self.memory_factor * evaluations / self.budget)\n        return ((self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final) * adaptive_scale\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] * (1 - self.memory_factor) + global_best_position * self.memory_factor\n\n        return global_best_position", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05596 with standard deviation 0.00285.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.057139759427026426, 0.06017282610106767, 0.0573633967622037, 0.05233615907025335, 0.0582425616809461, 0.05305170828462846]}}
{"id": "22a808a9-512e-47b6-b717-8d0184a6d816", "fitness": 0.0566282437682675, "name": "DynamicAdaptiveHybridPSOLevy", "description": "Introduce dynamic social coefficients and chaotic maps for enhanced exploitation and exploration balance.", "code": "import numpy as np\n\nclass DynamicAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.chaotic_sequence = self.chebyshev_map(self.budget)\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n    \n    def chebyshev_map(self, size):\n        x = np.random.rand()\n        seq = []\n        for _ in range(size):\n            x = np.cos(np.arccos(x) * 2)\n            seq.append(x)\n        return seq\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            chaotic_factor = self.chaotic_sequence[evaluations % self.budget]\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + chaotic_factor)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 22, "feedback": "The algorithm DynamicAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05663 with standard deviation 0.00402.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.06176005488811653, 0.0593810521534468, 0.051025924077896745, 0.05872307498037288, 0.056927311651214674, 0.05205688914609996, 0.0609551420396679, 0.05805334999861966, 0.05077139497897232]}}
{"id": "c62474d0-68ca-4290-8998-5695853174cb", "fitness": 0.05530851063695173, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced balance between exploration and exploitation with adaptive inertia and cognitive-social coefficients.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.2  # Modified for better exploration-exploitation balance\n        self.cognitive_coefficient_initial = 1.5  # Modified to enhance adaptive behavior\n        self.social_coefficient_initial = 2.5  # Modified to enhance global best attraction\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 23, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05531 with standard deviation 0.00283.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053171588434901995, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.054810619189682, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "e8bb743c-b17e-43c8-8a0d-21e67774cf11", "fitness": 0.05566068392696419, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced particle updating strategy with adaptive social coefficient adjustment based on recent success rates.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (max(success_measure, 0.7)) # Changed line\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 24, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05566 with standard deviation 0.00260.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05357264159392572, 0.05900715030715742, 0.05364170008605251, 0.05461134898489395, 0.06017282610106767, 0.05550019806035422, 0.05324070666571967, 0.0582425616809461, 0.05295702186256046]}}
{"id": "bc0b2250-f0e8-469b-b520-8070d4a34f86", "fitness": 0.056278499326925524, "name": "AdaptiveHybridPSOLevyImproved", "description": "Integrating dynamic adaptive decay rates for inertia and social coefficients in PSO with Lévy flight-based exploration to improve convergence stability.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevyImproved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.decay_rate = 0.99  # decay rate for adaptive adjustments\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5) * self.decay_rate**evaluations\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveHybridPSOLevyImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05628 with standard deviation 0.00262.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053570333346905974, 0.05900715030715742, 0.053472556669516114, 0.05631277959053549, 0.06017282610106767, 0.05451055550968997, 0.05842754729170141, 0.0582425616809461, 0.05279018344480957]}}
{"id": "b4924604-101c-4b71-afaa-262dfdf423b9", "fitness": 0.056689389829325, "name": "EnhancedAdaptivePSOLevy", "description": "Enhanced Adaptive PSO with Diversity Preservation and Dynamic Lévy Flight adaptation.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha_initial = 1.5\n        self.alpha_final = 0.5\n        self.success_threshold = 0.1\n        self.diversity_threshold = 1e-5\n\n    def levy_flight(self, L, alpha):\n        sigma = (np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                 (np.math.gamma((1 + alpha) / 2) * alpha * \n                  2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_alpha(self, evaluations):\n        return self.alpha_initial - (self.alpha_initial - self.alpha_final) * (evaluations / self.budget)\n\n    def calculate_diversity(self, particles):\n        centroid = np.mean(particles, axis=0)\n        diversity = np.mean(np.linalg.norm(particles - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            alpha = self.update_alpha(evaluations)\n            diversity = self.calculate_diversity(particles)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold or diversity < self.diversity_threshold:\n                    particles[i] += self.levy_flight(self.dim, alpha)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, alpha)\n\n        return global_best_position", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05669 with standard deviation 0.00281.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.05762051702807325, 0.06017282610106767, 0.05462381459865251, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "5556e237-d847-4d4d-98da-cac3600f114d", "fitness": 0.05534211293625865, "name": "AdaptiveHybridPSOLevy", "description": "Improved global consideration with adaptive social coefficient using success history.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.success_history = []\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (0.5 + np.mean(self.success_history[-10:]) if self.success_history else 1.0)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n                \n                self.success_history.append(score_improvement)\n\n        return global_best_position", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05534 with standard deviation 0.00279.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053632586321309406, 0.05390349159814678, 0.06017282610106767, 0.05467395819061427, 0.0526192335498844, 0.0582425616809461, 0.05294803446180485]}}
{"id": "07073248-0e7c-430a-ae91-c0da87f21871", "fitness": 0.05704846792402125, "name": "AdaptiveDynamicPSOLevy", "description": "Adaptive multi-phase PSO with dynamic inertia and Lévy-inspired exploration to enhance convergence and global diversity.", "code": "import numpy as np\n\nclass AdaptiveDynamicPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha *\n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim) * success_measure\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) * 0.5\n\n        return global_best_position", "configspace": "", "generation": 28, "feedback": "The algorithm AdaptiveDynamicPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05705 with standard deviation 0.00309.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05259973745025859, 0.0582425616809461, 0.05397156342200049]}}
{"id": "711ab160-4780-4ccc-9beb-0e9a9972e9fe", "fitness": 0.057032787779414465, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced AdaptiveHybridPSOLevy with dynamic Levy flight scaling and adaptive social-cognitive balance based on particle's performance improvement rate.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.levy_scale_factor_initial = 1.0\n        self.levy_scale_factor_final = 0.1\n\n    def levy_flight(self, L, scale):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = scale * (u / abs(v) ** (1 / self.alpha))\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def update_levy_scale(self, evaluations):\n        return (self.levy_scale_factor_initial - self.levy_scale_factor_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.levy_scale_factor_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            levy_scale = self.update_levy_scale(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim, levy_scale)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, levy_scale)  # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05703 with standard deviation 0.00310.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "5c6268e1-c423-4d91-8898-94e29a4e74c5", "fitness": 0.0553666796720084, "name": "EnhancedChaoticPSOLevy", "description": "Incorporate chaotic maps for enhancing diversity and escape from local optima in Lévy-driven PSO.", "code": "import numpy as np\n\nclass EnhancedChaoticPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.chaotic_map_idx = 0  # To switch between different chaotic maps\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def chaotic_map(self, x):\n        maps = [\n            lambda x: 4 * x * (1 - x),  # Logistic map\n            lambda x: np.sin(np.pi * x),  # Sinusoidal map\n            lambda x: 1 - 2 * x ** 2  # Tent map\n        ]\n        self.chaotic_map_idx = (self.chaotic_map_idx + 1) % len(maps)\n        return maps[self.chaotic_map_idx](x)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        chaos = np.random.rand(self.population_size)\n\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n                \n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                # Apply chaotic perturbation for diversity\n                chaos[i] = self.chaotic_map(chaos[i])\n                chaotic_perturbation = (ub - lb) * chaos[i]\n                particles[i] += chaotic_perturbation\n\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedChaoticPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05537 with standard deviation 0.00277.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053250272760713147, 0.05900715030715742, 0.053472556669516114, 0.0542822358588414, 0.06017282610106767, 0.05451055550968997, 0.05257177471533425, 0.0582425616809461, 0.05279018344480957]}}
{"id": "b5f942f1-26ca-429e-bfe1-cc0f0ed67783", "fitness": 0.05630609931178486, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced exploration through dynamic population size and adaptive velocity magnitude adjustment.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(budget / (dim * 5))  # Dynamic population size based on budget and dimension\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.velocity_scale_factor = 0.1  # Added velocity scale factor\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                velocities[i] *= self.velocity_scale_factor  # Adjust velocity magnitude\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05631 with standard deviation 0.00528.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.054154958686412735, 0.05604404553179354, 0.05948035832793064, 0.06884256657918764, 0.0544781366015471, 0.05728801024227792, 0.05574867777801429, 0.04901042504532316, 0.05170771501357674]}}
{"id": "69cfb943-f7fd-45f6-a7b3-5396d550b347", "fitness": 0.05605669380175207, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Introduce adaptive particle memory decay and nonlinear social learning rates for enhanced solution convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_max = 3.0\n        self.social_coefficient_min = 1.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay rate for personal best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def adaptive_social_learning(self, success_measure):\n        return self.social_coefficient_min + (self.social_coefficient_max - self.social_coefficient_min) * (1 - success_measure) ** 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n\n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.adaptive_social_learning(success_measure)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score * self.memory_decay + personal_best_scores[i] * (1 - self.memory_decay)\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05606 with standard deviation 0.00250.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.05533574734329316, 0.05672392861040021, 0.06017282610106767, 0.055021224282643555, 0.05433744823005393, 0.0582425616809461, 0.05279018344480957]}}
{"id": "de69f121-0f04-4eee-96bb-e4c01005a330", "fitness": 0.05725572559662268, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced adaptive exploration with dynamic Lévy flight adjustment based on success rate and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.diversity_threshold = 0.05  # New parameter for diversity-based adaptation\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def calculate_diversity(self, particles):\n        mean_particle = np.mean(particles, axis=0)\n        diversity = np.mean(np.linalg.norm(particles - mean_particle, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            diversity = self.calculate_diversity(particles)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold or diversity < self.diversity_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "d28f5f90-01a9-4e41-9ddd-3560ebfaade9", "fitness": 0.055617499233198954, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced mutation by incorporating random perturbations to diversify search dynamics.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim) + np.random.uniform(-0.1, 0.1, self.dim)  # small random perturbation\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 34, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05562 with standard deviation 0.00259.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.05407095120374905, 0.05403640253737407, 0.06017282610106767, 0.05497626679413059, 0.0537918960003263, 0.0582425616809461, 0.053380264258642396]}}
{"id": "17042675-c3de-4c05-bbba-4934fbf8a328", "fitness": 0.055949003012780225, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive exploration through Lévy flights with enhanced inertia weight adjustment.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final + 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 35, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05595 with standard deviation 0.00267.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05605994260889813, 0.06017282610106767, 0.05659774334331258, 0.052205618306337964, 0.05834251381620548, 0.05480350174712967]}}
{"id": "19a6249b-a6c0-4ff6-a35d-5e6d1dbf5dd2", "fitness": 0.055446495258463485, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive exploration through Lévy flights with enhanced global best consideration and refined inertia weight decay.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / (self.budget + 10)) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05545 with standard deviation 0.00275.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05300489239074524, 0.05900715030715742, 0.053472556669516114, 0.0550380824760327, 0.06017282610106767, 0.05451055550968997, 0.05277964874620655, 0.0582425616809461, 0.05279018344480957]}}
{"id": "a9ba999c-2de8-43fa-af7a-55cb4927504f", "fitness": 0.05720754277987245, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Hybrid PSO with Lévy flights and dynamic parameter adaptation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def dynamic_parameter_adjustment(self, evaluations):\n        factor = (self.budget - evaluations) / self.budget\n        cognitive_coefficient = self.cognitive_coefficient_initial * factor\n        social_coefficient = self.social_coefficient_initial * (1 - factor)\n        return cognitive_coefficient, social_coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            cognitive_coefficient, social_coefficient = self.dynamic_parameter_adjustment(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if np.random.rand() < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05721 with standard deviation 0.00199.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05743347797345766, 0.059131238569063216, 0.05467336883770069, 0.058558478671841274, 0.060299937855206265, 0.05573759858516647, 0.05669500285314666, 0.05836470737048716, 0.05397407430278267]}}
{"id": "84f1d418-7e1e-4799-a412-6719fcb9e7ed", "fitness": 0.05542286106263775, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced particle swarm optimization with Lévy flights and momentum adaptation for efficient exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term +\n                                 0.1 * np.random.normal(size=self.dim))  # Added random shock term\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05542 with standard deviation 0.00270.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05322386902548715, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05451055550968997, 0.05304808188505272, 0.0582425616809461, 0.05322465678667587]}}
{"id": "eb77bd4f-e514-4637-ab48-e2a8df34e63d", "fitness": 0.0558008366038064, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Incorporate dynamic population resizing and adaptive learning rates based on convergence trends to enhance global exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.min_population_size = 10\n        self.max_population_size = 50\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def adjust_population(self, evaluations):\n        scaling_factor = (1 - evaluations / self.budget)\n        return int(self.min_population_size + scaling_factor * (self.max_population_size - self.min_population_size))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        particles = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            population_size = self.adjust_population(evaluations)\n            if particles.shape[0] != population_size:\n                particles = np.resize(particles, (population_size, self.dim))\n                velocities = np.resize(velocities, (population_size, self.dim))\n                if personal_best_positions.shape[0] > population_size:\n                    indices_to_keep = np.argsort(personal_best_scores)[:population_size]\n                    personal_best_positions = personal_best_positions[indices_to_keep]\n                    personal_best_scores = personal_best_scores[indices_to_keep]\n                else:\n                    new_indices = population_size - personal_best_positions.shape[0]\n                    new_particles = np.random.uniform(lb, ub, (new_indices, self.dim))\n                    new_velocities = np.random.uniform(-1, 1, (new_indices, self.dim))\n                    particles[-new_indices:] = new_particles\n                    velocities[-new_indices:] = new_velocities\n                    new_scores = np.array([func(p) for p in new_particles])\n                    evaluations += new_indices\n                    personal_best_positions = np.vstack((personal_best_positions, new_particles))\n                    personal_best_scores = np.append(personal_best_scores, new_scores)\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = 2.0 * (1 - success_measure)\n                social_coefficient = 2.0 * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 39, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05580 with standard deviation 0.00249.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05435540010626427, 0.05900715030715742, 0.05405633866403259, 0.05541065681932045, 0.06017282610106767, 0.05451055550968997, 0.053661856800969576, 0.0582425616809461, 0.05279018344480957]}}
{"id": "f6c3b134-1eb9-4769-9061-2aaaa520025b", "fitness": 0.05704846792402125, "name": "EnhancedAdaptivePSO", "description": "Enhanced Adaptive PSO with Dynamic Lévy Flight Scaling and Contextual Exploration for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.exploration_factor = 0.5  # New exploration factor for dynamic scaling\n\n    def levy_flight(self, L, scale=1.0):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = scale * (u / abs(v) ** (1 / self.alpha))\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    scale = self.exploration_factor / max(1, np.linalg.norm(velocities[i]))\n                    particles[i] += self.levy_flight(self.dim, scale=scale)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, scale=self.exploration_factor) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05705 with standard deviation 0.00309.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05259973745025859, 0.0582425616809461, 0.05397156342200049]}}
{"id": "8dd7b5ef-a0d7-4413-94a5-20044edbaed2", "fitness": 0.05725572559662268, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive exploration through Lévy flights with enhanced global best consideration and dynamic population size.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Original code: self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "9975b4f3-cd4c-47a3-af27-6425537d3f38", "fitness": 0.055609456911994704, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced AdaptiveHybridPSOLevy with dynamic population adjustment and memory-based velocity updates for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.dynamic_population_toggle = True  # Enable dynamic population adjustment\n        self.memory_factor = 0.7  # Factor for memory-based velocity update\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def adjust_population_size(self, evaluations):\n        return max(5, int(self.population_size * (self.budget - evaluations) / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            if self.dynamic_population_toggle:\n                self.population_size = self.adjust_population_size(evaluations)\n                \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                memory_term = self.memory_factor * velocities[i]\n                \n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term + memory_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05561 with standard deviation 0.00281.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.056070134279122774, 0.06017282610106767, 0.055644907203597715, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "16e379f3-3646-497d-aec0-3894779703dc", "fitness": 0.05678906406465994, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced AdaptiveHybridPSOLevy by adjusting the success threshold for more dynamic adaptability.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.05  # threshold for successful particle movement (adjusted)\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 43, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05679 with standard deviation 0.00271.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053843835976202126, 0.05900715030715742, 0.053744378862122355, 0.060824357667841, 0.06017282610106767, 0.056832082258316485, 0.05458485266228019, 0.0582425616809461, 0.053849531066006096]}}
{"id": "6e9a2e8a-3569-4aae-bc37-a17c6f0f74fa", "fitness": -Infinity, "name": "AdaptiveHybridPSOLevy", "description": "Improve convergence by dynamically adjusting the population size based on success measure.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n            # Dynamically adjust population size based on success measure\n            self.population_size = max(10, int(self.population_size * (1 + success_measure)))\n\n        return global_best_position", "configspace": "", "generation": 44, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {}}
{"id": "49f0b262-0b24-471c-94aa-b21d4bd9393e", "fitness": 0.057032787779414465, "name": "AdaptiveHybridPSOLevy", "description": "Introduced adaptive Lévy flight scaling to enhance exploration dynamics.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step * (1 - self.success_threshold)  # Adaptive scaling\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 45, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05703 with standard deviation 0.00310.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "d7de804b-0580-470f-b140-1fd8ab76b5fb", "fitness": 0.055451601196960326, "name": "AdaptiveHybridPSOLevy", "description": "Introduce dynamic population size adaptation and enhanced inertia weight strategy to improve convergence efficiency.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_population_size(self, evaluations):\n        return max(10, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def update_inertia_weight(self, evaluations):\n        # Enhanced inertia weight strategy\n        if evaluations / self.budget < 0.5:\n            return self.inertia_weight_initial\n        return self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            self.population_size = self.dynamic_population_size(evaluations)\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 46, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05545 with standard deviation 0.00269.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05319863574230965, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.05457775018336786, 0.05280756191154079, 0.0582425616809461, 0.05368187657859058]}}
{"id": "780ff907-5f93-459f-8113-6209b8a2a776", "fitness": 0.05725572559662268, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced global consideration by adapting the cognitive coefficient based on global-best improvement.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure * 0.5) # Modified line\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 47, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "553a82a6-2457-41d2-9289-b52c9b2131f0", "fitness": 0.05654410645061027, "name": "AdaptiveHybridPSOLevyEnhanced", "description": "AdaptiveHybridPSOLevyEnhanced introduces adaptive velocity scaling and adaptive Lévy flight scaling based on convergence rate to refine exploration and exploitation phases.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevyEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.velocity_scale = 0.5  # base velocity scale\n        self.levy_scale = 0.1  # base Levy flight scale\n\n    def levy_flight(self, L, scale):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return scale * step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        prev_global_best_score = global_best_score\n        \n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += self.velocity_scale * velocities[i]\n\n                if success_measure < self.success_threshold:\n                    scale_factor = (global_best_score - prev_global_best_score) / (abs(prev_global_best_score) + np.finfo(float).eps)\n                    particles[i] += self.levy_flight(self.dim, self.levy_scale * (1 + scale_factor))\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        prev_global_best_score = global_best_score\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, self.levy_scale) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 48, "feedback": "The algorithm AdaptiveHybridPSOLevyEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05654 with standard deviation 0.00293.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05507074939454171, 0.05900715030715742, 0.053472556669516114, 0.06069412867043067, 0.06017282610106767, 0.05623473554538061, 0.05226495277036991, 0.0582425616809461, 0.0537372969160822]}}
{"id": "9443b633-84e8-4c6d-aa7e-8972a71fdea0", "fitness": 0.057073617867720756, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced particle update with adaptive Lévy flight scaling based on success measure.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L, success_measure):  # Modified to adaptively scale the step size\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma * (1 - success_measure), size=L)  # Scale by (1 - success_measure)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim, success_measure)  # Use adaptive Lévys\n\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim, success_measure)  # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 49, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05707 with standard deviation 0.00310.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06045290644592649, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.054046131897752425]}}
{"id": "6274fe7f-c2e6-4d43-bba1-11c35e5d7f1e", "fitness": 0.05725572559662268, "name": "AdaptiveHybridPSOLevy", "description": "Refined inertia weight adjustment for smoother transition in particle dynamics.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / (self.budget + np.finfo(float).eps)) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 50, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "d42e00b9-1e70-48f5-bbba-deb8b8e69ca9", "fitness": 0.05636146000284405, "name": "ImprovedAdaptiveHybridPSOLevy", "description": "Introduce dynamic population size and adaptive inertia for enhanced search diversity and convergence.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.min_population_size = 10\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_population_size(self, evaluations):\n        return max(self.min_population_size, \n                   int(self.initial_population_size * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        particles = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            population_size = self.update_population_size(evaluations)\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 51, "feedback": "The algorithm ImprovedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05636 with standard deviation 0.00283.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.06027980028553048, 0.05408840775750845, 0.06017282610106767, 0.05451055550968997, 0.0542208969049075, 0.0582425616809461, 0.0538517672633918]}}
{"id": "87bc7d83-2aa9-496c-9633-f1561f5cbae2", "fitness": 0.055656698170210434, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced adaptive parameter tuning for improved convergence balance.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.6)  # Adjusted to 0.6\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 52, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05566 with standard deviation 0.00266.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05310316738037957, 0.05900715030715742, 0.053472556669516114, 0.054577953744716745, 0.06017282610106767, 0.055266906074843525, 0.052205618306337964, 0.0582425616809461, 0.054861543266928825]}}
{"id": "cd9058b1-ab69-4bc5-8ed1-be0a86c82796", "fitness": 0.057086874623964584, "name": "AdaptiveHybridPSOLevy", "description": "Enhanced global best update mechanism for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] # Removed Levy flight from global best update\n\n        return global_best_position", "configspace": "", "generation": 53, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05709 with standard deviation 0.00304.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05274262519853434, 0.0582425616809461, 0.05417433597321475]}}
{"id": "2bd770df-3377-4426-b134-a30c9a30a0f0", "fitness": 0.05625819599696907, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Improved adaptive exploration with dynamic Lévy flight scaling and particle convergence acceleration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.05  # Lowered threshold for more frequent exploration\n        self.dynamic_levy_factor = 0.1  # Factor to scale Lévy flight dynamically based on success measure\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    dynamic_levy = self.levy_flight(self.dim) * (1 / (1 + success_measure))\n                    particles[i] += self.dynamic_levy_factor * dynamic_levy\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.dynamic_levy_factor * self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05626 with standard deviation 0.00246.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053968194156100546, 0.05900715030715742, 0.053744378862122355, 0.05492412316521633, 0.06017282610106767, 0.056832082258316485, 0.05257841230740623, 0.0582425616809461, 0.05685403513438847]}}
{"id": "3321acf8-6ac8-4b10-a9c1-d7910e24cc16", "fitness": 0.055319576720130624, "name": "EnhancedAdaptivePSOLevy", "description": "Enhanced Adaptive PSO with Lévy Flights and Dynamic Parameters adjusts exploration and exploitation dynamically based on population diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.diversity_threshold = 1e-5  # threshold for population diversity\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def calculate_diversity(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        diversity = np.mean(np.linalg.norm(particles - mean_position, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            diversity = self.calculate_diversity(particles)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient_initial * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient_initial * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if diversity < self.diversity_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n        return global_best_position", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptivePSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05532 with standard deviation 0.00280.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.053109304283110226, 0.05900715030715742, 0.053472556669516114, 0.054138378658529995, 0.06017282610106767, 0.05451055550968997, 0.05243267382634853, 0.0582425616809461, 0.05279018344480957]}}
{"id": "d2aae82e-49e6-4be3-95da-1a6c33ace9f2", "fitness": 0.055771789062221896, "name": "AdaptiveHybridPSOLevy", "description": "Improved hybrid PSO leveraging Lévy flights with dynamic social coefficients and adaptive personal best restart.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.3) # Change 1\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                    personal_best_positions[i] = global_best_position + self.levy_flight(self.dim) # Change 2\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 56, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05577 with standard deviation 0.00257.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05353615263658751, 0.05900715030715742, 0.054307386353777964, 0.055524098401487976, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.05443975226294451]}}
{"id": "98a19f42-b333-489c-8b2f-a69e0087062b", "fitness": 0.05705103365620648, "name": "AdaptiveHybridPSOLevy", "description": "Adaptive exploration with dynamic velocity adjustment through Lévy flight incorporation for enhanced convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + velocities[i] # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 57, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05705 with standard deviation 0.00308.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05274262519853434, 0.0582425616809461, 0.0538517672633918]}}
{"id": "c013befe-ff68-4467-9041-78fc120aaca3", "fitness": 0.05725572559662268, "name": "AdaptiveHybridPSOLevy", "description": "Introduced dynamic coefficient adaptation to improve convergence speed and accuracy.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim) # Enhanced global consideration\n\n        return global_best_position", "configspace": "", "generation": 58, "feedback": "The algorithm AdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "3a4d45a5-85ba-4ded-a691-039a4d03dc8a", "fitness": 0.05725572559662268, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced convergence through dynamic parameter adaptation and diversity maintenance using Lévy-flight-inspired perturbations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.diversity_threshold = 1e-5  # diversity threshold for stagnation\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha *\n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n    \n    def update_parameters(self, evaluations):\n        inertia_weight = (self.inertia_weight_initial - self.inertia_weight_final) * \\\n                         ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n        return inertia_weight\n\n    def measure_diversity(self, particles):\n        centroid = np.mean(particles, axis=0)\n        return np.mean(np.linalg.norm(particles - centroid, axis=1))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_parameters(evaluations)\n            diversity = self.measure_diversity(particles)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient * (1 - success_measure)\n                social_coefficient = self.social_coefficient * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold or diversity < self.diversity_threshold:\n                    particles[i] += self.levy_flight(self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i] + self.levy_flight(self.dim)\n\n        return global_best_position", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05726 with standard deviation 0.00284.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05458485266228019, 0.0582425616809461, 0.0538517672633918]}}
{"id": "951c469d-5756-4def-a166-df4591bddcde", "fitness": 0.0572952010984773, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Exploration PSO with Dynamic Lévy Flight Scaling and Memory-based Global Best Enrichment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 60, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00291.", "error": "", "parent_ids": ["027e3dba-2e01-41e2-8505-1bdcee2d0a8d"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.053926408541190685]}}
{"id": "aba95cd4-66a1-481a-9ff2-119dfa8b7932", "fitness": 0.057089702290678446, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Improved Enhanced PSO with Adaptive Neighborhood Influence and Dynamic Velocity Tuning.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.neighborhood_size = 5  # Added neighborhood size for local influence\n        self.velocity_scaling_factor = 0.5  # Added velocity scaling factor\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                neighborhood_best = personal_best_positions[np.argmin(personal_best_scores[max(0, i-self.neighborhood_size):i+self.neighborhood_size])]\n                neighborhood_term = r3 * (neighborhood_best - particles[i])  # Added local neighborhood influence\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term + neighborhood_term) * self.velocity_scaling_factor\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05709 with standard deviation 0.00212.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05776466900225041, 0.05900715030715742, 0.05352829685757432, 0.057958419502131764, 0.06017282610106767, 0.056968100879311034, 0.05646772798791855, 0.0582425616809461, 0.05369756829774874]}}
{"id": "58c7052e-9251-4cb1-bd6c-432e4f30f55a", "fitness": 0.05550742714870179, "name": "EnhancedDynamicMultiPhasePSO", "description": "Enhanced Dynamic Multi-Phase PSO with Adaptive Lévy Flight and Convergence-Driven Memory Adjustment for Robust Optimization.", "code": "import numpy as np\n\nclass EnhancedDynamicMultiPhasePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.exploration_phase_ratio = 0.5  # ratio of budget spent on exploration\n        self.exploitation_phase_ratio = 0.3  # ratio of budget spent on exploitation\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = np.exp(-1.0 * evaluations / self.budget)\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        exploration_budget = int(self.budget * self.exploration_phase_ratio)\n        exploitation_budget = int(self.budget * self.exploitation_phase_ratio)\n\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if evaluations < exploration_budget or success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedDynamicMultiPhasePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05551 with standard deviation 0.00273.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05500185796588253, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.054770598264451964, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "b400e3cb-1ca0-4b95-98c6-ee3a5edb5949", "fitness": 0.05589633020879502, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Improved Adaptive Hybrid PSO with Enhanced Convergence Control Using Dynamic Population and Adaptive Mutation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_rate = 0.1  # Adaptation for mutation rate\n        self.dynamic_population = True  # Enable dynamic population size\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def adapt_population_size(self, evaluations):\n        if self.dynamic_population:\n            new_size = max(5, int(self.population_size * (1 - evaluations / self.budget)))\n            return new_size\n        return self.population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                if np.random.rand() < self.mutation_rate:\n                    velocities[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n            self.population_size = self.adapt_population_size(evaluations)\n\n        return global_best_position", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05590 with standard deviation 0.00268.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.056875324952227135, 0.05900715030715742, 0.05411196260667028, 0.053960554587672904, 0.06017282610106767, 0.05570078989226612, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "eca8ef2a-aa68-450d-a224-47e7f0666740", "fitness": 0.057032787779414465, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Hybrid PSO with Adaptive Control Parameters and Multi-Phase Dynamic Lévy Flight for Enhanced Global Search Efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.phase_split = [0.3, 0.6, 1.0]  # dynamic Lévy scaling phase split ratios\n        \n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n    \n    def dynamic_levy_scale(self, evaluations):\n        eval_ratio = evaluations / self.budget\n        phase = next(idx for idx, boundary in enumerate(self.phase_split) if eval_ratio <= boundary)\n        scale_factor = (self.phase_split[phase] - eval_ratio) / self.phase_split[phase]\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 64, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05703 with standard deviation 0.00310.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "1dd15193-24fa-4c64-8563-8b7a63d2bab2", "fitness": 0.0572952010984773, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Improved Enhanced Adaptive Hybrid PSO with dynamic memory adjustment and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00291.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.053926408541190685]}}
{"id": "ac85e596-a6e0-4ef6-bf49-2c17ef89c62a", "fitness": 0.056282557534551705, "name": "ImprovedAdaptiveHybridPSOLevy", "description": "Improved Adaptive Hybrid PSO with Hierarchical Lévy Flight Strategy and Enhanced Memory Retention for Global Optimization.", "code": "import numpy as np\n\nclass ImprovedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.hierarchical_factor = 0.5\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                hierarchical_levy = self.hierarchical_factor * self.dynamic_levy_scale(evaluations)\n                if success_measure < self.success_threshold:\n                    particles[i] += hierarchical_levy\n\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations) * (1 - self.hierarchical_factor)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 66, "feedback": "The algorithm ImprovedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05628 with standard deviation 0.00272.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.055845991539157036, 0.06017282610106767, 0.05451055550968997, 0.053275777043955364, 0.0582425616809461, 0.05913642474407865]}}
{"id": "c66c49b3-2f69-4aa2-b1d8-d08a38f680ea", "fitness": 0.055659012799056225, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Exploration PSO with Dynamic Lévy Flight Scaling and Nonlinear Inertia Weight Update for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        # Nonlinear update for inertia weight\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) ** 2 + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05566 with standard deviation 0.00278.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.053335338954949574, 0.05900715030715742, 0.05365705680083355, 0.05479893034162797, 0.06017282610106767, 0.0567214492537762, 0.052205618306337964, 0.0582425616809461, 0.05279018344480957]}}
{"id": "71c46443-7dfc-490c-8910-897cd005d429", "fitness": 0.055797953064969624, "name": "EnhancedAdaptiveHybridPSOLevyV2", "description": "Improved Exploration-Exploitation Balance by Adaptive Parameter Tuning and Dynamic Neighborhood Search Inspired by Simulated Annealing for Enhanced Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevyV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.temperature_initial = 1.0  # initial temperature for simulated annealing\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def update_temperature(self, evaluations):\n        return self.temperature_initial * (1 - (evaluations / self.budget))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            temperature = self.update_temperature(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                # Simulated annealing-inspired local search\n                particles[i] += np.random.normal(0, temperature, size=self.dim)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevyV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05580 with standard deviation 0.00250.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05408021397497331, 0.05900715030715742, 0.05478678048014185, 0.054959821826225164, 0.06017282610106767, 0.054842390050824474, 0.05322648319192336, 0.0582425616809461, 0.052863349971467244]}}
{"id": "6851c2b7-6e1b-435a-8d55-1f323b486ffc", "fitness": 0.055317061126785486, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Local Search Memory and Optimized Inertia Weight Decay.  ", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.95  # changed from 0.99\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        exp_decay = np.exp(-evaluations / (self.budget / 5))  # changed from linear to exponential decay\n        return (self.inertia_weight_initial - self.inertia_weight_final) * exp_decay + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05532 with standard deviation 0.00283.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.05353095090305171, 0.05447925390977948, 0.06017282610106767, 0.05451055550968997, 0.05224089406917043, 0.0582425616809461, 0.05279018344480957]}}
{"id": "aade92db-63d7-4867-bb8e-15853c295003", "fitness": 0.05529351421599644, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Hybrid PSO with Time-Varying Parameters and Progressive Lévy Flight Intensity for Robust Global Search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.05  # reduced threshold for successful particle movement\n        self.memory_decay = 0.95  # slightly stronger decay factor for global best memory\n        self.levy_intensity = 0.1  # initial intensity for Lévy flight\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step * self.levy_intensity\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = ((self.budget - evaluations) / self.budget) ** 2\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def update_coefficients(self, evaluations):\n        progress = evaluations / self.budget\n        cognitive_coefficient = self.cognitive_coefficient_initial * (1 - progress)\n        social_coefficient = self.social_coefficient_initial * (1 + progress)\n        return cognitive_coefficient, social_coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            cognitive_coefficient, social_coefficient = self.update_coefficients(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05529 with standard deviation 0.00283.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.05362467393688919, 0.05390349159814678, 0.06017282610106767, 0.05466594001956404, 0.052205618306337964, 0.0582425616809461, 0.052940191778461765]}}
{"id": "ce471e40-49b1-4ca3-8819-09859fabb92f", "fitness": 0.05708495845347175, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhancing exploration by adjusting the success threshold for better adaptability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.05  # threshold for successful particle movement, previously 0.1\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05708 with standard deviation 0.00255.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.05473045973819868, 0.060824357667841, 0.06017282610106767, 0.056832082258316485, 0.05257841230740623, 0.0582425616809461, 0.055262038534846014]}}
{"id": "8b5f5151-29c3-43ee-b42c-72f44bba646e", "fitness": 0.0572952010984773, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Exploration PSO with Dynamic Lévy Flight Scaling, Memory-based Global Best Enrichment, and Improved Success Threshold Adaptation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:  # Line modified\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00291.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.053926408541190685]}}
{"id": "feac2f4c-5d42-457e-bffc-489ffcb7a154", "fitness": 0.05586878810121194, "name": "EnhancedAdaptiveDynamicPSOLevy", "description": "Adaptive PSO with Dynamic Lévy Flight and Self-Adaptive Parameters for Improved Exploration and Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveDynamicPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.adaptation_factor = 0.1\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n\n                # Self-adaptive coefficients\n                cognitive_coefficient = max(0.5, self.cognitive_coefficient_initial * (1 - success_measure) + \n                                            self.adaptation_factor * np.random.uniform(-0.1, 0.1))\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveDynamicPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05587 with standard deviation 0.00273.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.05390349159814678, 0.06017282610106767, 0.054579698356231, 0.05777145053763577, 0.0582425616809461, 0.05279018344480957]}}
{"id": "1e322857-ddb8-4d6f-8d6c-e64fe65c5135", "fitness": 0.05582485840571411, "name": "RefinedAdaptiveHybridPSOLevy", "description": "Adaptive Hybrid PSO with Lévy Flight and Contextual Velocity Memory for Robust Global Convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.contextual_velocity_factor = 0.1  # new factor for velocity adjustment\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                if np.random.rand() < self.contextual_velocity_factor:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 74, "feedback": "The algorithm RefinedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05582 with standard deviation 0.00261.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05287917421539701, 0.05900715030715742, 0.053472556669516114, 0.055095711297812655, 0.06017282610106767, 0.055902354685924416, 0.05244678347006826, 0.0582425616809461, 0.05520460722353737]}}
{"id": "5628b361-a184-4469-acfb-4ceccffe8ff3", "fitness": 0.057032787779414465, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Exploration with Improved Memory Mechanism for PSO Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position * self.memory_decay + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = global_best_memory\n\n        return global_best_position", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05703 with standard deviation 0.00310.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.0538517672633918]}}
{"id": "3fcf49be-ae06-4f82-bf90-01115b9bbd15", "fitness": 0.0572952010984773, "name": "AdvancedDynamicInertiaPSOLevy", "description": "Advanced Dynamic Inertia PSO with Lévy Flight and Success-Driven Adaptive Coefficients for Enhanced Exploration and Exploitation.", "code": "import numpy as np\n\nclass AdvancedDynamicInertiaPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def adaptive_coefficients(self, success_measure):\n        cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n        social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n        return cognitive_coefficient, social_coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient, social_coefficient = self.adaptive_coefficients(success_measure)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 76, "feedback": "The algorithm AdvancedDynamicInertiaPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05730 with standard deviation 0.00291.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05257841230740623, 0.0582425616809461, 0.053926408541190685]}}
{"id": "65277697-d003-4e36-992f-677726e5ddc9", "fitness": 0.055872996589444, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Hybrid PSO with Momentum-based Velocity Update and Adaptive Cognitive-Social Balancing.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.momentum_factor = 0.5  # new momentum factor for velocity update\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + \n                                 self.momentum_factor * (cognitive_term + social_term))  # updated line\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 77, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05587 with standard deviation 0.00280.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.053139861797202204, 0.05900715030715742, 0.053472556669516114, 0.05402118966847458, 0.06017282610106767, 0.058065956988990974, 0.052205618306337964, 0.0582425616809461, 0.05452924778530299]}}
{"id": "2f51083f-510a-4787-a283-ca52557dc0ea", "fitness": 0.05722832580856799, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive PSO with Lévy Flight and Success-based Dynamic Scaling for Improved Convergence Stability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.dynamic_scale_factor = 0.2  # New factor for dynamic scaling\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = self.dynamic_scale_factor * (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_term + social_term\n                \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05723 with standard deviation 0.00286.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.054338254569787914, 0.0582425616809461, 0.0538517672633918]}}
{"id": "78cb467c-40b4-4016-bf31-4d6fff8029af", "fitness": 0.057317198742691415, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Exploration PSO with Dynamic Lévy Flight Scaling, Memory-based Global Best Enrichment, and Adaptive Velocity Clipping.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Change made: Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 79, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05732 with standard deviation 0.00287.", "error": "", "parent_ids": ["951c469d-5756-4def-a166-df4591bddcde"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.052776391105333276, 0.0582425616809461, 0.053926408541190685]}}
{"id": "539686d1-5237-405b-8cd0-0e4364bf2ae4", "fitness": 0.05719648525298255, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive Exploration PSO with Dynamic Lévy Flight and Adaptive Informed Memory Enrichment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n                if evaluations % 10 == 0:  # Memory enrichment condition\n                    global_best_memory = np.mean(personal_best_positions, axis=0)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05720 with standard deviation 0.00290.", "error": "", "parent_ids": ["78cb467c-40b4-4016-bf31-4d6fff8029af"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.054051689569519, 0.0582425616809461, 0.0538517672633918]}}
{"id": "5bf815e9-e0ec-4245-b60b-d8150a654af4", "fitness": 0.05696352202296801, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Hybrid PSO with Adaptive Lévy Flight Scale and Dynamic Inertia Weight, Memory-Augmented Global Best, and Contextual Velocity Regulation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.velocity_damping = 0.95  # new damping factor for velocity\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_term + social_term\n                \n                # Apply velocity damping to control the exploration/exploitation balance\n                velocities[i] *= self.velocity_damping\n                \n                # Clamp velocities to feasible range\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05696 with standard deviation 0.00197.", "error": "", "parent_ids": ["78cb467c-40b4-4016-bf31-4d6fff8029af"], "operator": null, "metadata": {"aucs": [0.05878018635836357, 0.05900715030715742, 0.05459988203521349, 0.05498338558989058, 0.06017282610106767, 0.05566447133794328, 0.05505185175656668, 0.0582425616809461, 0.056169383039563314]}}
{"id": "6ff169b1-a0ae-4698-83ed-d050f4a6d203", "fitness": 0.057317198742691415, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Introduced adaptive penalty for particles exceeding search bounds to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Change made: Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                # New change: Adaptive penalty for exceeding bounds\n                if np.any(particles[i] < lb) or np.any(particles[i] > ub):\n                    particles[i] = np.clip(particles[i], lb, ub) + 0.1 * (ub - lb) * np.random.uniform(-1, 1)\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05732 with standard deviation 0.00287.", "error": "", "parent_ids": ["78cb467c-40b4-4016-bf31-4d6fff8029af"], "operator": null, "metadata": {"aucs": [0.05611473748546614, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.052776391105333276, 0.0582425616809461, 0.053926408541190685]}}
{"id": "637f7e44-2029-43fc-958b-cd1f75898e4d", "fitness": 0.057375891380008044, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Advanced Memory-Driven Hybrid PSO with Dynamic Lévy Strategy and Differential Evolution-Inspired Mutation for Global Best Diversification.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.mutation_factor = 0.5  # mutation factor for DE-inspired mutation\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Change made: Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05738 with standard deviation 0.00294.", "error": "", "parent_ids": ["78cb467c-40b4-4016-bf31-4d6fff8029af"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05460859408460539, 0.05228583189575231, 0.0582425616809461, 0.0538517672633918]}}
{"id": "224f1e0f-1afb-49a7-be9e-c73d9c08b25b", "fitness": 0.051491851248562065, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Introduced chaotic initialization for particle positions to enhance exploration and convergence speed.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5  # exponent for Lévy flight distribution\n        self.success_threshold = 0.1  # threshold for successful particle movement\n        self.memory_decay = 0.99  # decay factor for global best memory\n        self.mutation_factor = 0.5  # mutation factor for DE-inspired mutation\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = lb + (ub - lb) * np.sin(np.linspace(0, np.pi, self.population_size * self.dim)).reshape(self.population_size, self.dim)  # Chaotic initialization\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05149 with standard deviation 0.00214.", "error": "", "parent_ids": ["637f7e44-2029-43fc-958b-cd1f75898e4d"], "operator": null, "metadata": {"aucs": [0.05126390183216756, 0.0488182162898646, 0.05629555936726316, 0.05029069875467984, 0.05387128503864813, 0.05033653922039516, 0.05065425699850834, 0.05011451300040892, 0.05178169073512284]}}
{"id": "d1fa68bb-7f88-4db5-b1c6-591ae0629d2f", "fitness": 0.05746156168611749, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Inertia and Dynamic Crowd-Inspired Exploration for Robust Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1  # New parameter for crowd-inspired exploration\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05746 with standard deviation 0.00286.", "error": "", "parent_ids": ["637f7e44-2029-43fc-958b-cd1f75898e4d"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05532528111111068, 0.05226270114995202, 0.0582425616809461, 0.05392924373767183]}}
{"id": "b924552d-3f28-4fa3-8140-88e7e88678be", "fitness": 0.0573560855839714, "name": "EnhancedAdaptiveHybridPSOQuantumLevy", "description": "Enhanced PSO with Adaptive Inertia, Dynamic Levy Flight, and Quantum-Inspired Exploration for Superior Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOQuantumLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.quantum_exploration_factor = 0.2\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def quantum_inspired_exploration(self, particles, global_best_position):\n        mean_position = np.mean(particles, axis=0)\n        quantum_jump = self.quantum_exploration_factor * np.random.uniform(-1, 1, size=(self.population_size, self.dim))\n        return mean_position + quantum_jump * (global_best_position - mean_position)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply quantum-inspired exploration\n            quantum_exploration = self.quantum_inspired_exploration(particles, global_best_position)\n            particles = quantum_exploration\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveHybridPSOQuantumLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05736 with standard deviation 0.00296.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.0538517672633918]}}
{"id": "10213811-2fee-4f70-b501-8b86deb9c06e", "fitness": 0.05673106022115831, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced Adaptive PSO with Dynamic Velocity Scaling and Improved Memory Update for Robust Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1  # New parameter for crowd-inspired exploration\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity scaling\n                velocities[i] = np.clip(velocities[i], 0.5 * (lb - particles[i]), 0.5 * (ub - particles[i]))  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_position + (1 - self.memory_decay) * global_best_memory\n\n        return global_best_position", "configspace": "", "generation": 87, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05673 with standard deviation 0.00290.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05477504736407479, 0.05917847484745398, 0.054789677863477215, 0.05843610863396276, 0.06017282610106767, 0.055764966829790374, 0.053122601011397985, 0.06123480774172263, 0.05310503159747737]}}
{"id": "b1d12a21-eb96-4cca-b7cc-1d3bcaa41a6a", "fitness": 0.056561665790205225, "name": "AdaptivePSOQuantumExploration", "description": "Adaptive PSO integrating Dynamic Mutation and Quantum-Inspired Exploration for Enhanced Convergence and Stability.", "code": "import numpy as np\n\nclass AdaptivePSOQuantumExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.alpha = 1.5\n        self.mutation_factor = 0.5\n        self.quantum_factor = 0.1  # New parameter for quantum-inspired exploration\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n\n    def quantum_exploration(self, particles, global_best):\n        mean_position = np.mean(particles, axis=0)\n        exploration_vector = self.quantum_factor * (global_best - mean_position)\n        return exploration_vector\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = self.cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = self.social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = inertia_weight * velocities[i] + cognitive_term + social_term\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_position, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n\n            exploration_vector = self.quantum_exploration(particles, global_best_position)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n        return global_best_position", "configspace": "", "generation": 88, "feedback": "The algorithm AdaptivePSOQuantumExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05656 with standard deviation 0.00197.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05505045300884315, 0.05900715030715742, 0.05524794618534523, 0.05612302962640059, 0.06017282610106767, 0.056324607436170626, 0.05434578833668169, 0.0582425616809461, 0.054540629429234544]}}
{"id": "51ca0806-6554-4332-a6bc-6793e2ef6461", "fitness": 0.057018016939612774, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Inertia and Dynamic Crowd-Inspired Exploration, now with improved mutation scaling for robust convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1  # New parameter for crowd-inspired exploration\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * 1.1 * (a - b)  # Adjusted mutation scaling\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05702 with standard deviation 0.00313.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.05236799827491101, 0.0582425616809461, 0.05392924373767183]}}
{"id": "f5399a72-1503-4a1c-836d-55a5d7621722", "fitness": 0.05746156168611749, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Differentially Evolved Memory and Adaptive Inertia for Improved Global and Local Search Capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n\n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05746 with standard deviation 0.00286.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05532528111111068, 0.05226270114995202, 0.0582425616809461, 0.05392924373767183]}}
{"id": "6a415c84-d058-4659-af09-f3579107ad57", "fitness": 0.056863766670509235, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Inertia and Dynamic Crowd-Inspired Exploration for Robust Convergence, with improved success threshold adaptation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1  # Changed to be adaptive based on evaluations\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1  # New parameter for crowd-inspired exploration\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                self.success_threshold = 0.1 * (evaluations / self.budget)  # Update success threshold dynamically\n                \n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05686 with standard deviation 0.00289.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.053472556669516114, 0.060824357667841, 0.06017282610106767, 0.056832082258316485, 0.05226270114995202, 0.0582425616809461, 0.053849531066006096]}}
{"id": "5aa0938a-fb31-40db-9fa9-fce6fa0f032c", "fitness": 0.05621682597063428, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Hybrid Swarm Algorithm with Adaptive Velocity Control and Stochastic Ranking for Improved Robustness and Exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1\n        self.velocity_scaling_factor = 0.5  # New parameter for velocity scaling\n        self.stochastic_ranking_prob = 0.45  # New parameter for stochastic ranking\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def stochastic_ranking(self, particles, scores):\n        ranks = np.argsort(scores)\n        for i in range(self.population_size - 1):\n            for j in range(self.population_size - 1 - i):\n                if np.random.rand() < self.stochastic_ranking_prob or scores[ranks[j]] > scores[ranks[j + 1]]:\n                    ranks[j], ranks[j + 1] = ranks[j + 1], ranks[j]\n        return ranks\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            ranks = self.stochastic_ranking(personal_best_positions, personal_best_scores)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term) * self.velocity_scaling_factor\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05622 with standard deviation 0.00277.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.053001638340599344, 0.06014511215396867, 0.05746534968154238, 0.055796193807573946, 0.06017282610106767, 0.05484936841285626, 0.05250051430287361, 0.0582425616809461, 0.05377786925428052]}}
{"id": "bc8de98a-630a-43f8-9587-c9cd6bb47be8", "fitness": 0.0564927047720987, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Inertia, Dynamic Crowd-Inspired Exploration, and Tuned Mutation Control for Improved Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.05  # Reduced success threshold for finer adjustments\n        self.memory_decay = 0.98  # Adjusted decay for better memory retention\n        self.mutation_factor = 0.8  # Increased mutation factor for better exploration\n        self.crowd_distance_factor = 0.15  # Slightly increased crowd distance factor\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05649 with standard deviation 0.00304.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.053472556669516114, 0.060824357667841, 0.06017282610106767, 0.056832082258316485, 0.052205618306337964, 0.0582425616809461, 0.053849531066006096]}}
{"id": "f77ccff0-9468-4033-abd9-8cfa89adf2e6", "fitness": 0.05711592722298761, "name": "EnhancedDynamicMemeticPSO", "description": "Enhanced PSO with Dynamic Memetic Integration and Adaptive Neighborhood for Improved Exploration-Exploitation Balance.", "code": "import numpy as np\n\nclass EnhancedDynamicMemeticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.neighborhood_size = 5\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def local_search(self, position, func):\n        local_position = position + np.random.uniform(-0.1, 0.1, self.dim)\n        local_position = np.clip(local_position, func.bounds.lb, func.bounds.ub)\n        return local_position, func(local_position)\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n\n            for i in range(self.population_size):\n                if evaluations < self.budget:\n                    local_position, local_score = self.local_search(particles[i], func)\n                    evaluations += 1\n                    if local_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_score\n                        personal_best_positions[i] = local_position\n                        if local_score < global_best_score:\n                            global_best_score = local_score\n                            global_best_position = local_position\n        \n        return global_best_position", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedDynamicMemeticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05712 with standard deviation 0.00309.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05561200005984146, 0.052205618306337964, 0.0582425616809461, 0.05387137170646694]}}
{"id": "0cfc7c39-53f6-4494-892e-ab94c6931ea6", "fitness": 0.057420821387479774, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Enhanced PSO with Adaptive Inertia, Evolutionary Memory Diversification, and Cooperative Learning for Robust Convergence in Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1\n        self.cooperative_factor = 0.05  # New parameter for cooperative learning\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n\n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n\n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def cooperative_learning(self, particles, global_best_position):\n        cooperative_term = self.cooperative_factor * np.random.rand(self.population_size, self.dim) * (global_best_position - particles)\n        return cooperative_term\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            cooperative_vector = self.cooperative_learning(particles, global_best_position)\n            particles += exploration_vector + cooperative_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05742 with standard deviation 0.00290.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.057110133133780216, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05498361785886341, 0.05229774407995602, 0.05825999578972996, 0.0538517672633918]}}
{"id": "df4f3b8c-70f4-4a63-b4b2-12ba49c0ec29", "fitness": 0.05602584698158229, "name": "EnhancedAdaptiveHybridPSOLevy", "description": "Fine-tuned inertia weight decay to enhance particle exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveHybridPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        # Fine-tuning line: Adjusted inertia weight update formula\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               (((self.budget - evaluations) / self.budget) ** 0.5) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                # Adaptive velocity clipping\n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])  \n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            # Differential Evolution-inspired mutation for global best diversification\n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            # Apply crowd-inspired exploration\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveHybridPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05603 with standard deviation 0.00241.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05423410262819561, 0.05900715030715742, 0.05402546635876637, 0.05630139017011093, 0.06017282610106767, 0.05451055550968997, 0.05494838663349699, 0.0582425616809461, 0.05279018344480957]}}
{"id": "66703b66-7dee-408f-9004-589d78dc3803", "fitness": 0.056578096567864264, "name": "HybridDynamicMultiSwarmPSO", "description": "Hybrid Dynamic Multi-Swarm PSO with Progressive Search Space Reduction and Adaptive Velocity Regulation for Enhanced Global Optimization.", "code": "import numpy as np\n\nclass HybridDynamicMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.num_swarms = 4\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.progressive_reduction_rate = 0.95\n        self.velocity_scaling_factor = 0.8\n        self.mutation_factor = 0.6\n\n    def adaptive_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n\n    def progressive_search_space_reduction(self, evaluations, lb, ub):\n        reduction_factor = self.progressive_reduction_rate ** (evaluations / self.budget)\n        center = (ub + lb) / 2.0\n        return center - reduction_factor * (center - lb), center + reduction_factor * (ub - center)\n\n    def swarm_communication(self, swarms):\n        combined_swarm = np.vstack(swarms)\n        return np.mean(combined_swarm, axis=0)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [np.random.uniform(lb, ub, (self.population_size // self.num_swarms, self.dim))\n                  for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.population_size // self.num_swarms, self.dim))\n                      for _ in range(self.num_swarms)]\n\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(p) for p in swarm]) for swarm in swarms]\n        global_best_positions = [swarm[np.argmin(scores)] for swarm, scores in zip(swarms, personal_best_scores)]\n        global_best_scores = [np.min(scores) for scores in personal_best_scores]\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            for idx in range(self.num_swarms):\n                inertia_weight = self.adaptive_inertia_weight(evaluations)\n                lb_dynamic, ub_dynamic = self.progressive_search_space_reduction(evaluations, lb, ub)\n\n                for i in range(self.population_size // self.num_swarms):\n                    if evaluations >= self.budget:\n                        break\n\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_term = self.cognitive_coefficient_initial * r1 * (personal_best_positions[idx][i] - swarms[idx][i])\n                    social_term = self.social_coefficient_initial * r2 * (global_best_positions[idx] - swarms[idx][i])\n                    velocities[idx][i] = inertia_weight * velocities[idx][i] + cognitive_term + social_term\n\n                    # Adaptive velocity clipping\n                    velocities[idx][i] = np.clip(velocities[idx][i], lb_dynamic - swarms[idx][i], ub_dynamic - swarms[idx][i])\n\n                    swarms[idx][i] += self.velocity_scaling_factor * velocities[idx][i]\n                    swarms[idx][i] = np.clip(swarms[idx][i], lb_dynamic, ub_dynamic)\n\n                    score = func(swarms[idx][i])\n                    evaluations += 1\n\n                    if score < personal_best_scores[idx][i]:\n                        personal_best_scores[idx][i] = score\n                        personal_best_positions[idx][i] = swarms[idx][i]\n\n                        if score < global_best_scores[idx]:\n                            global_best_scores[idx] = score\n                            global_best_positions[idx] = swarms[idx][i]\n\n            # Inter-swarm communication\n            global_best_combined = self.swarm_communication(global_best_positions)\n            for idx in range(self.num_swarms):\n                global_best_positions[idx] = global_best_combined\n\n        best_swarm_idx = np.argmin(global_best_scores)\n        return global_best_positions[best_swarm_idx]", "configspace": "", "generation": 97, "feedback": "The algorithm HybridDynamicMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05658 with standard deviation 0.00205.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.054430486656887545, 0.05900715030715742, 0.05591722883218697, 0.05548780167660439, 0.06017282610106767, 0.05700903426019355, 0.05373562458681547, 0.0582425616809461, 0.05520015500891928]}}
{"id": "cc3537de-ecd9-4948-873e-68efeed25ba3", "fitness": 0.05730683495067062, "name": "EnhancedAdaptivePSO", "description": "Enhanced PSO with Adaptive Inertia, Multi-Scale Levy Flights, and Adaptive Memory for Improved Convergence and Exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.99\n        self.mutation_factor = 0.5\n        self.crowd_distance_factor = 0.1\n        self.levy_scale_factor = 0.01  # New parameter for scaling Levy flight steps\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def differential_mutation(self, target, best, a, b):\n        return target + self.mutation_factor * (best - target) + self.mutation_factor * (a - b)\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.differential_mutation(global_best_position, global_best_memory, a, b)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05731 with standard deviation 0.00292.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.05382765889169949, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05532824566750105, 0.05227375208588536, 0.0582425616809461, 0.055805161868407005]}}
{"id": "5a649791-d443-4b14-a835-abf3bf2dea96", "fitness": 0.05737110899059821, "name": "AdvancedHybridPSOTemporalMemory", "description": "Advanced Hybrid PSO integrated with Temporal Memory and Adaptive Mutation for Enhanced Convergence Efficiency.", "code": "import numpy as np\n\nclass AdvancedHybridPSOTemporalMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.cognitive_coefficient_initial = 2.0\n        self.social_coefficient_initial = 2.0\n        self.alpha = 1.5\n        self.success_threshold = 0.1\n        self.memory_decay = 0.98\n        self.mutation_factor = 0.6\n        self.crowd_distance_factor = 0.15\n        self.mutation_probability = 0.05\n\n    def levy_flight(self, L):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * \n                  2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size=L)\n        v = np.random.normal(0, 1, size=L)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def dynamic_levy_scale(self, evaluations):\n        scale_factor = (self.budget - evaluations) / self.budget\n        return scale_factor * self.levy_flight(self.dim)\n        \n    def update_inertia_weight(self, evaluations):\n        return (self.inertia_weight_initial - self.inertia_weight_final) * \\\n               ((self.budget - evaluations) / self.budget) + self.inertia_weight_final\n    \n    def adaptive_mutation(self, best, a, b, c):\n        if np.random.rand() < self.mutation_probability:\n            return best + self.mutation_factor * (a - b + c - best)\n        return best\n    \n    def crowd_inspired_exploration(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - mean_position, axis=1)\n        max_distance = np.max(distances)\n        if max_distance > 0:\n            exploration_vector = self.crowd_distance_factor * (particles - mean_position) / max_distance\n            return exploration_vector\n        return np.zeros_like(particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        \n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        global_best_memory = global_best_position\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            inertia_weight = self.update_inertia_weight(evaluations)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                score_improvement = personal_best_scores[i] - global_best_score\n                success_measure = score_improvement / (abs(global_best_score) + np.finfo(float).eps)\n                \n                cognitive_coefficient = self.cognitive_coefficient_initial * (1 - success_measure)\n                social_coefficient = self.social_coefficient_initial * (success_measure + 0.5)\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_term = cognitive_coefficient * r1 * (personal_best_positions[i] - particles[i])\n                social_term = social_coefficient * r2 * (global_best_position - particles[i])\n                velocities[i] = (inertia_weight * velocities[i] + cognitive_term + social_term)\n                \n                velocities[i] = np.clip(velocities[i], lb - particles[i], ub - particles[i])\n                particles[i] += velocities[i]\n\n                if success_measure < self.success_threshold:\n                    particles[i] += self.dynamic_levy_scale(evaluations)\n                \n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                score = func(particles[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n                    \n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = particles[i]\n                        global_best_memory = global_best_position + self.dynamic_levy_scale(evaluations)\n                \n            if evaluations < self.budget:\n                random_indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = particles[random_indices]\n                mutated_gbest = self.adaptive_mutation(global_best_position, a, b, c)\n                mutated_gbest = np.clip(mutated_gbest, lb, ub)\n                mutated_score = func(mutated_gbest)\n                evaluations += 1\n                \n                if mutated_score < global_best_score:\n                    global_best_score = mutated_score\n                    global_best_position = mutated_gbest\n                    global_best_memory = mutated_gbest\n\n            exploration_vector = self.crowd_inspired_exploration(particles)\n            particles += exploration_vector\n            particles = np.clip(particles, lb, ub)\n\n            global_best_position = self.memory_decay * global_best_memory + (1 - self.memory_decay) * global_best_position\n\n        return global_best_position", "configspace": "", "generation": 99, "feedback": "The algorithm AdvancedHybridPSOTemporalMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05737 with standard deviation 0.00296.", "error": "", "parent_ids": ["d1fa68bb-7f88-4db5-b1c6-591ae0629d2f"], "operator": null, "metadata": {"aucs": [0.0572453437934215, 0.05900715030715742, 0.06027980028553048, 0.060824357667841, 0.06017282610106767, 0.05451055550968997, 0.052205618306337964, 0.0582425616809461, 0.0538517672633918]}}
