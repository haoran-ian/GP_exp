{"id": "db58b805-bd2c-4f23-bb47-028a55dc8470", "fitness": 0.05923123620227988, "name": "HybridPSOSA", "description": "A hybrid algorithm combining Particle Swarm Optimization (PSO) and Simulated Annealing (SA) to balance exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05923 with standard deviation 0.00409.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.06457029367133127, 0.06140681159617278, 0.0556480880498621, 0.06469012870086455, 0.06151914589828256, 0.0557477564070894, 0.06020602796222296, 0.057303536624960016, 0.051989336909733286]}}
{"id": "e7119dc0-7e5f-4b12-867c-8ce8efcca0cf", "fitness": 0.057078436102630956, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm integrating Particle Swarm Optimization (PSO) with a more adaptive Simulated Annealing (SA) strategy and dynamic parameters for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Adaptable Inertia weight, starts higher for exploration\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.0  # Increased cognitive component\n        self.c2 = 2.0  # Increased social component\n        self.temp_factor = 0.9  # More dynamic cooling factor for SA\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Dynamic weight adjustment\n            self.w = self.w_min + (0.5 * (self.budget - self.func_eval_count) / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05708 with standard deviation 0.00296.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05793809859506738, 0.06140681159617278, 0.0556480880498621, 0.05804256231558225, 0.06151914589828256, 0.0557477564070894, 0.05411058852692885, 0.057303536624960016, 0.051989336909733286]}}
{"id": "03c12879-2c35-4e4d-b652-7743b72f1351", "fitness": 0.057166891494439626, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and Lévy flights for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Adaptive inertia weight max\n        self.w_min = 0.4  # Adaptive inertia weight min\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * self.func_eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Lévy flight for diversification\n            levy_flight = np.random.standard_cauchy((self.pop_size, self.dim))\n            self.particles += levy_flight * 0.01\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 2, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05717 with standard deviation 0.00280.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.057478821911413736, 0.06140681159617278, 0.0563770959749571, 0.05758215145512069, 0.06151914589828256, 0.05647826528241784, 0.05369077675160694, 0.057303536624960016, 0.052665417955024996]}}
{"id": "73548be3-5e07-4c9b-90c3-4bdb960871f7", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm using adaptive inertia weight in PSO combined with simulated annealing to improve convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)  # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "e80c3e49-98bf-4781-bfca-37e6b02a3544", "fitness": 0.05661055902562214, "name": "RefinedHybridPSOASA", "description": "A refined hybrid algorithm combining Particle Swarm Optimization (PSO) and Adaptive Simulated Annealing (ASA) to intensify the search around promising regions and balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass RefinedHybridPSOASA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.init_temp = 1.0  # Initial temperature for ASA\n        self.cooling_rate = 0.95  # Adaptive cooling rate\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n\n            temp = self.init_temp * (self.cooling_rate ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n            # Adaptive cooling rate adjustment based on progress\n            if self.func_eval_count % (self.budget // 10) == 0:\n                if self.best_global_score < np.min(self.best_personal_scores) * 1.01:  # Minimal improvement threshold\n                    self.cooling_rate *= 0.9\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 4, "feedback": "The algorithm RefinedHybridPSOASA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05661 with standard deviation 0.00308.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05649814765283312, 0.06140681159617278, 0.0556480880498621, 0.05659941224196019, 0.06151914589828256, 0.0557477564070894, 0.0527827958497058, 0.057303536624960016, 0.051989336909733286]}}
{"id": "b11ec92e-d737-413b-aa32-440179d336db", "fitness": 0.05656854059920899, "name": "HybridPSOSA", "description": "An enhanced hybrid algorithm integrating PSO and SA with adaptive inertia weight and temperature schedule for improved convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.9  # Adapted cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (1 + self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 5, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05657 with standard deviation 0.00310.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.056368888819502305, 0.06140681159617278, 0.0556480880498621, 0.05646987171124196, 0.06151914589828256, 0.0557477564070894, 0.05266342937603652, 0.057303536624960016, 0.051989336909733286]}}
{"id": "8996920e-48dd-4378-b330-81c933e59c2b", "fitness": 0.05619649739339833, "name": "HybridPSOSA_Enhanced", "description": "An improved hybrid algorithm using adaptive inertia PSO and enhanced simulated annealing for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Adaptive inertia weight (max)\n        self.w_min = 0.4  # Adaptive inertia weight (min)\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.temp_factor = 0.95  # Cooling factor for enhanced Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Enhanced Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 6, "feedback": "The algorithm HybridPSOSA_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05620 with standard deviation 0.00331.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.05584409110803856, 0.05512901154455907, 0.06151914589828256, 0.05594415337508307, 0.05141960306510418, 0.057303536624960016, 0.05217142480461623]}}
{"id": "89df68b8-4fb0-410d-9214-0ed944fd10ad", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "Enhanced Hybrid PSO-SA with Dynamic Inertia Weight and Adaptive Cooling for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Adaptive simulated annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "fa670887-6ad8-46e7-8ab2-1928abf9deea", "fitness": 0.058253672725102366, "name": "EnhancedHybridPSOSA", "description": "Enhanced HybridPSOSA using adaptive inertia weight and chaos-driven perturbation to improve exploration and convergence in optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Chaos-driven perturbation\n            chaos = np.random.rand(self.pop_size, self.dim)\n            perturbation = np.random.normal(0, chaos, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05825 with standard deviation 0.00395.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.056394516704221354, 0.06451309715215803, 0.05770587638261648, 0.05649557386504245, 0.06463294086363347, 0.05780982515037236, 0.05268649296760364, 0.06014842494789785, 0.053896306492375645]}}
{"id": "a611d287-d0f9-4c3f-a796-152b37a7a273", "fitness": 0.05672893401052184, "name": "EnhancedHybridPSOSA", "description": "A hybrid algorithm enhancing Particle Swarm Optimization (PSO) with Adaptive Learning Rate (ALR) and Simulated Annealing (SA) to improve convergence speed and accuracy in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.adaptive_lr = 0.9  # Adaptive Learning Rate\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with Adaptive Learning Rate\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.adaptive_lr = max(0.4, self.adaptive_lr * (1.0 - self.func_eval_count / self.budget))\n            self.velocities = (self.adaptive_lr * self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05673 with standard deviation 0.00300.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05628025654969704, 0.06140681159617278, 0.056229173358248064, 0.056381050699798596, 0.06151914589828256, 0.05633001532151327, 0.052581437314492385, 0.057303536624960016, 0.05252897873153184]}}
{"id": "d919b775-2eb5-4ffa-a521-d4778bbe3f2f", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm combining Particle Swarm Optimization (PSO) with a dynamic inertia weight and a novel adaptive Simulated Annealing (SA) mechanism to improve convergence speed and solution quality in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.temp_factor = 0.9\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (1 + self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "25bedf41-3624-4d3f-9d0c-0be4cc9d3ff8", "fitness": 0.05716520229810183, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm integrating Particle Swarm Optimization (PSO) with adaptive Simulated Annealing (SA) for improved exploration-exploitation balance and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.7  # Increased Inertia weight for better exploration\n        self.c1 = 1.8  # Increased Cognitive component\n        self.c2 = 1.8  # Increased Social component\n        self.temp_factor = 0.95  # Faster cooling factor to encourage early exploitation\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Adaptive Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, np.sqrt(temp), (self.pop_size, self.dim))  # Using sqrt for more gradual perturbation\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05717 with standard deviation 0.00295.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05820617902294101, 0.06140681159617278, 0.0556480880498621, 0.05831133650228493, 0.06151914589828256, 0.0557477564070894, 0.05435462967159044, 0.057303536624960016, 0.051989336909733286]}}
{"id": "9322f026-3c5e-4477-a60a-ce297f94abe2", "fitness": -Infinity, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm combining Particle Swarm Optimization (PSO) and Simulated Annealing (SA) with adaptive learning rates and dynamic population size for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_pop_size = 30\n        self.max_pop_size = 50\n        self.min_pop_size = 10\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.init_pop_size, dim)\n        self.velocities = np.random.rand(self.init_pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.init_pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            current_pop_size = int(self.min_pop_size + \n                                   (self.max_pop_size - self.min_pop_size) * \n                                   (1 - self.func_eval_count / self.budget))\n            self.particles = self.particles[:current_pop_size]\n            self.velocities = self.velocities[:current_pop_size]\n            self.best_personal_positions = self.best_personal_positions[:current_pop_size]\n            self.best_personal_scores = self.best_personal_scores[:current_pop_size]\n            \n            for i in range(current_pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive learning rates\n            r1 = np.random.rand(current_pop_size, self.dim)\n            r2 = np.random.rand(current_pop_size, self.dim)\n            adaptive_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adaptive_c2 = self.c2 * (self.func_eval_count / self.budget)\n            self.velocities = (self.w * self.velocities +\n                               adaptive_c1 * r1 * (self.best_personal_positions - self.particles) +\n                               adaptive_c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (current_pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 12, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {}}
{"id": "24f18bc9-04e4-478b-84e4-fbeb96315bc2", "fitness": 0.056656044509847625, "name": "HybridPSOSA", "description": "Enhance inertia weight adaptation in HybridPSOSA for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            # Adaptive inertia weight update\n            self.w = 0.9 - 0.7 * (self.func_eval_count / self.budget) \n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 13, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05666 with standard deviation 0.00312.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.055236103468861875, 0.06140681159617278, 0.057051019589503316, 0.05533482050331173, 0.06151914589828256, 0.057153631663896975, 0.05161071376184656, 0.057303536624960016, 0.05328861748179281]}}
{"id": "b45edd83-71cd-4233-8c5d-60c07e7cc49e", "fitness": 0.056504740521199345, "name": "EnhancedHybridPSOSA", "description": "Introducing an Adaptive Inertia Weight and Dynamic Cooling Rate in HybridPSOSA to enhance convergence and adaptability in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor_initial = 0.9  # Initial cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (inertia_weight * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Dynamic Cooling for Simulated Annealing\n            temp = self.temp_factor_initial ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05650 with standard deviation 0.00314.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05543641168318658, 0.06140681159617278, 0.056385727742223946, 0.05553554754073187, 0.06151914589828256, 0.05648695047676089, 0.05179626929572034, 0.057303536624960016, 0.05267226383275514]}}
{"id": "ba2f561b-0967-478b-b0a2-c79ad04c225b", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid algorithm combining Particle Swarm Optimization (PSO) with adaptive inertia weight and Simulated Annealing (SA) with dynamic cooling to improve exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.max_w = 0.9  # Maximum inertia weight\n        self.min_w = 0.4  # Minimum inertia weight\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.initial_temp = 1.0  # Initial temperature for Simulated Annealing\n        self.final_temp = 0.01  # Final temperature for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            w = self.max_w - (self.max_w - self.min_w) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation with dynamic cooling\n            temp = self.initial_temp * (self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "5052f22a-2073-458b-9289-8ab301eada37", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "Enhanced HybridPSOSA utilizing adaptive inertia weight and differential evolution-inspired mutation for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation and DE mutation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.1:  # Mutation probability\n                    indices = np.random.choice(self.pop_size, 3, replace=False)\n                    trial_vector = (self.particles[indices[0]] +\n                                    0.8 * (self.particles[indices[1]] - self.particles[indices[2]]))\n                    trial_vector = np.clip(trial_vector, bounds_lb, bounds_ub)\n                    trial_score = func(trial_vector)\n                    self.func_eval_count += 1\n                    if trial_score < self.best_personal_scores[i]:\n                        self.particles[i] = trial_vector\n                \n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "a730f8dd-aa79-48b5-988d-81b41dceacd0", "fitness": 0.05774300238022502, "name": "HybridPSOSA", "description": "Enhance exploration and exploitation balance in HybridPSOSA by adaptive velocity and dynamic inertia adjustment.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.velocities *= (0.5 + np.random.rand(self.pop_size, self.dim)) # Adaptive velocity\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 17, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05774 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.06061214834216044, 0.05512901154455907, 0.06151914589828256, 0.06072361478986321, 0.05141960306510418, 0.057303536624960016, 0.056542451037154384]}}
{"id": "ce0189aa-e3a7-4a5b-bf2a-2824f15b60b1", "fitness": 0.05680223764764287, "name": "HybridPSOSA", "description": "Enhanced velocity update formula in HybridPSOSA to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * (1 - r2) * (self.best_global_position - self.particles))  # Change made here\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 18, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05680 with standard deviation 0.00314.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.05770548778373508, 0.05512901154455907, 0.06151914589828256, 0.057809421101968184, 0.05141960306510418, 0.057303536624960016, 0.053896422690235424]}}
{"id": "ed8f625b-d8c2-44b4-9f4c-4c784c303402", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "Enhanced PSO with dynamic parameters and adaptive local search to improve convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.0  # Initial cognitive component\n        self.c2 = 2.0  # Initial social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (\n                inertia_weight * self.velocities +\n                self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation with adaptive probability\n            temp = self.temp_factor ** ((self.func_eval_count / (self.budget * 2)))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "9f9a0196-1388-4f93-8842-7d56089ec51c", "fitness": 0.0564536198162969, "name": "RefinedHybridPSOSA", "description": "A refined hybrid algorithm blending PSO and SA with adaptive parameters and multi-phase exploration-exploitation strategy for enhanced black-box optimization.", "code": "import numpy as np\n\nclass RefinedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Higher inertia weight for more exploration\n        self.c1 = 2.0  # Increased cognitive component\n        self.c2 = 2.0  # Increased social component\n        self.temp_factor = 0.95  # Faster cooling for SA\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adaptive inertia weight and learning factors\n            self.w = 0.9 - 0.5 * (self.func_eval_count / self.budget)\n            self.c1 = 1.5 + 0.5 * (self.func_eval_count / self.budget)\n            self.c2 = 1.5 + 0.5 * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 20, "feedback": "The algorithm RefinedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05645 with standard deviation 0.00315.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.055994074634858504, 0.06140681159617278, 0.05566995166402289, 0.056094297158626905, 0.06151914589828256, 0.05576966423940288, 0.05231545732174281, 0.057303536624960016, 0.0520096392086028]}}
{"id": "65bdfe69-f584-48c7-b920-84bf9ce760f6", "fitness": 0.05704524273035599, "name": "ImprovedHybridPSOSA", "description": "An improved hybrid optimization algorithm combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) and dynamic parameter adjustment to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass ImprovedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Start with higher inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.0  # Start with higher cognitive component\n        self.c2 = 2.0  # Start with higher social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Linearly decrease inertia weight\n            self.w = self.w_min + (0.9 - self.w_min) * ((self.budget - self.func_eval_count) / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 21, "feedback": "The algorithm ImprovedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05705 with standard deviation 0.00296.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05783394616417281, 0.06140681159617278, 0.0556480880498621, 0.057937993055980685, 0.06151914589828256, 0.0557477564070894, 0.05402056986695025, 0.057303536624960016, 0.051989336909733286]}}
{"id": "2d7a9e70-3cf2-4c4b-b7b9-af86bd7a6428", "fitness": 0.056861080716665194, "name": "EnhancedPSO", "description": "An enhanced PSO algorithm using dynamic inertia weight and adaptive local search to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)  # Dynamic inertia weight\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Adaptive local search with perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation * (np.random.rand(self.pop_size, self.dim) < 0.05)\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05686 with standard deviation 0.00300.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05559961214956799, 0.06140681159617278, 0.05731689526299644, 0.05569905035183509, 0.06151914589828256, 0.05742003229901982, 0.05194872289280672, 0.057303536624960016, 0.05353591937434532]}}
{"id": "4624cf90-a481-4238-a049-e820edfe9ff8", "fitness": 0.05923123620227988, "name": "HybridPSOSA", "description": "This hybrid algorithm enhances exploration by introducing a random velocity reset mechanism in Particle Swarm Optimization (PSO) and Simulated Annealing (SA) to improve convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Random velocity reset for exploration\n            if np.random.rand() < 0.01:\n                self.velocities = np.random.rand(self.pop_size, self.dim) * 0.1\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 23, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05923 with standard deviation 0.00409.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.06457029367133127, 0.06140681159617278, 0.0556480880498621, 0.06469012870086455, 0.06151914589828256, 0.0557477564070894, 0.06020602796222296, 0.057303536624960016, 0.051989336909733286]}}
{"id": "a447ea9a-8043-4f71-8675-ba02e7d5fe98", "fitness": 0.05923123620227988, "name": "HybridPSOSA", "description": "Enhance the global best update mechanism by adding a particle diversity check to reduce premature convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score and np.std(self.particles, axis=0).mean() > 0.1:  # Added diversity check\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 24, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05923 with standard deviation 0.00409.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.06457029367133127, 0.06140681159617278, 0.0556480880498621, 0.06469012870086455, 0.06151914589828256, 0.0557477564070894, 0.06020602796222296, 0.057303536624960016, 0.051989336909733286]}}
{"id": "c9cd678c-ead9-42ba-8916-750fa3d98127", "fitness": 0.05613266540217021, "name": "EnhancedHybridPSOSA", "description": "A hybrid algorithm combining enhanced Particle Swarm Optimization (PSO) with dynamic inertia and adaptive learning factors, alongside Simulated Annealing (SA), for improved exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1_initial = 2.0  # Initial cognitive component\n        self.c2_initial = 2.0  # Initial social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            inertia_weight = self.w_max - (\n                (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            )\n            c1 = self.c1_initial - (\n                (self.c1_initial - 0.5) * (self.func_eval_count / self.budget)\n            )\n            c2 = self.c2_initial - (\n                (self.c2_initial - 0.5) * (self.func_eval_count / self.budget)\n            )\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (inertia_weight * self.velocities +\n                               c1 * r1 * (self.best_personal_positions - self.particles) +\n                               c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 25, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "fd59b259-f567-41de-ae0e-52840f0d9edb", "fitness": 0.05652385972346685, "name": "EnhancedHybridPSOSA", "description": "An enhanced hybrid PSO-SA algorithm with adaptive inertia weight and neighborhood-based perturbation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Neighborhood-based perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, 5, replace=False)\n                neighborhood_best = min(neighbors, key=lambda x: self.best_personal_scores[x])\n                perturbation[i] += self.particles[neighborhood_best] - self.particles[i]\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 26, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05652 with standard deviation 0.00319.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.056852453650129586, 0.05512901154455907, 0.06151914589828256, 0.05695483793077327, 0.05141960306510418, 0.057303536624960016, 0.05309863867745168]}}
{"id": "91635528-fc3a-48b4-90f0-c3cb8d8abefe", "fitness": 0.057801126602229504, "name": "ImprovedHybridPSOSADE", "description": "An improved hybrid algorithm combining Particle Swarm Optimization (PSO), Simulated Annealing (SA), and Differential Evolution (DE) to enhance exploration, exploitation, and diversity in black-box optimization.", "code": "import numpy as np\n\nclass ImprovedHybridPSOSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with PSO\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Differential Evolution step\n            for i in range(self.pop_size):\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = self.particles[indices]\n                mutant = np.clip(a + self.F * (b - c), bounds_lb, bounds_ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, self.particles[i])\n                \n                # Evaluate trial particle\n                trial_score = func(trial)\n                self.func_eval_count += 1\n                \n                # Greedy selection\n                if trial_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = trial_score\n                    self.best_personal_positions[i] = trial.copy()\n                \n                # Update global best if needed\n                if trial_score < self.best_global_score:\n                    self.best_global_score = trial_score\n                    self.best_global_position = trial.copy()\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 27, "feedback": "The algorithm ImprovedHybridPSOSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05780 with standard deviation 0.00306.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.06016740360322648, 0.06140681159617278, 0.0556480880498621, 0.060277305397955394, 0.06151914589828256, 0.0557477564070894, 0.05615075493278354, 0.057303536624960016, 0.051989336909733286]}}
{"id": "7c06aa3b-5f2d-4d41-80ce-779afee4e694", "fitness": 0.05613266540217021, "name": "HybridPSOSA", "description": "Enhance exploration by adding a dynamic adjustment factor to the inertia weight in the PSO component of the algorithm.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Dynamic inertia weight adjustment\n            self.w = 0.9 - 0.4 * (self.func_eval_count / self.budget)\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 28, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "ab7acd78-67ca-4a7a-a0c9-9bb3699365dd", "fitness": 0.05647423716174956, "name": "HybridPSOASA", "description": "A hybrid algorithm combining Particle Swarm Optimization (PSO) with Adaptive Simulated Annealing (ASA) for enhanced temperature control and balancing exploration-exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOASA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Initial cooling factor for Adaptive Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Adaptive Simulated Annealing inspired perturbation\n            temp = self.temp_factor * np.exp(-self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 29, "feedback": "The algorithm HybridPSOASA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05647 with standard deviation 0.00319.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05514017073445898, 0.06140681159617278, 0.0565876874193576, 0.05523869772628953, 0.06151914589828256, 0.056689272206360775, 0.05152150144354417, 0.057303536624960016, 0.05286131080631962]}}
{"id": "1b450210-afc2-4823-8236-3fa0b5fd42de", "fitness": 0.056186097978733716, "name": "HybridPSOASA", "description": "A hybrid algorithm incorporating Particle Swarm Optimization (PSO) with Adaptive Simulated Annealing (ASA) for dynamic exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOASA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.adaptive_factor = 0.1  # Adaptive component\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            adaptive_temp = temp * (1 + self.adaptive_factor * np.sin(self.func_eval_count * np.pi / self.budget))\n            perturbation = np.random.normal(0, adaptive_temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 30, "feedback": "The algorithm HybridPSOASA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05619 with standard deviation 0.00331.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.05581220692679301, 0.05512901154455907, 0.06151914589828256, 0.05591220958605647, 0.05141960306510418, 0.057303536624960016, 0.052141658042906824]}}
{"id": "ecb9f843-ce60-4394-b5da-3ab8c0608d01", "fitness": 0.05613266540217021, "name": "HybridPSOSA", "description": "An enhanced hybrid algorithm integrating Particle Swarm Optimization (PSO) with dynamic Simulated Annealing (SA) and adaptive parameters to optimize exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_initial = 0.9  # Increased initial inertia weight\n        self.w_final = 0.4  # Decreased final inertia weight\n        self.c1 = 2.0  # Increased cognitive component\n        self.c2 = 2.0  # Increased social component\n        self.temp_factor = 0.95  # Adjusted cooling factor\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_final + (self.w_initial - self.w_final) * (1 - self.func_eval_count / self.budget)  # Adaptive inertia weight\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 31, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "583669a3-5b84-4d0f-aa66-d6863c5fdc04", "fitness": 0.057581911148653644, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and dynamic perturbation scaling to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            dynamic_scale = np.exp(-5 * self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp * dynamic_scale, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 32, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05758 with standard deviation 0.00299.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.05948459475358303, 0.06140681159617278, 0.0556480880498621, 0.05959221454982344, 0.06151914589828256, 0.0557477564070894, 0.05554571554837617, 0.057303536624960016, 0.051989336909733286]}}
{"id": "7b3e1053-8df3-4ceb-8ad8-ff77624a3323", "fitness": 0.057801126602229504, "name": "EnhancedPSOSA_DE", "description": "A synergy of Particle Swarm Optimization, Simulated Annealing, and Differential Evolution to enhance adaptive exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedPSOSA_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.F = 0.8  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions for PSO\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.pop_size):\n                idxs = [idx for idx in range(self.pop_size) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), bounds_lb, bounds_ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                trial = np.where(cross_points, mutant, self.particles[i])\n                trial_score = func(trial)\n                self.func_eval_count += 1\n\n                if trial_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = trial_score\n                    self.best_personal_positions[i] = trial.copy()\n\n                if trial_score < self.best_global_score:\n                    self.best_global_score = trial_score\n                    self.best_global_position = trial.copy()\n\n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 33, "feedback": "The algorithm EnhancedPSOSA_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05780 with standard deviation 0.00306.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.06016740360322648, 0.06140681159617278, 0.0556480880498621, 0.060277305397955394, 0.06151914589828256, 0.0557477564070894, 0.05615075493278354, 0.057303536624960016, 0.051989336909733286]}}
{"id": "08afb2bb-121b-4eb1-95cc-34ee1ad65d91", "fitness": -Infinity, "name": "HybridPSOSA", "description": "An enhanced HybridPSOSA with adaptive inertia weight and dynamic population size to further balance exploration and exploitation in black-box optimization.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_pop_size = 30  # Initial population size\n        self.w = 0.9  # Adaptive inertia weight (updated)\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Adaptive inertia weight\n            self.w = 0.9 - (0.5 * (self.func_eval_count / self.budget))  # Adaptive update to inertia weight\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            \n            # Adjust population size dynamically\n            self.pop_size = max(1, int(self.initial_pop_size * (1 - (self.func_eval_count / self.budget))))  # Dynamic pop size\n            \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 34, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (30,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (30,10) ')", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {}}
{"id": "ca485d96-c017-48b4-a64e-1a1baae5ed6a", "fitness": 0.059483745514013364, "name": "HybridPSOSA", "description": "An enhanced HybridPSOSA algorithm with improved velocity update using personal and global best distance proportionality for better convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            # Modified velocity update rule\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 35, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05948 with standard deviation 0.00245.", "error": "", "parent_ids": ["db58b805-bd2c-4f23-bb47-028a55dc8470"], "operator": null, "metadata": {"aucs": [0.06061009408828055, 0.06275763288972447, 0.05903360358562493, 0.06072037792568974, 0.06287335876449096, 0.05914106800857322, 0.05657839224997763, 0.058536706960816365, 0.05510247515294242]}}
{"id": "a1ebd790-f2d9-4fdb-a090-42e5ff64cd1d", "fitness": -Infinity, "name": "EnhancedHybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and chaotic perturbations to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Chaotic perturbation for diversification\n            chaotic_factor = np.sin(self.func_eval_count + np.pi)\n            perturbation = np.random.normal(0, chaotic_factor * 0.1, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 36, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {}}
{"id": "1d0875ad-8f30-4870-ba86-c3e61bcd9a6f", "fitness": 0.056951750486536876, "name": "HybridPSOSA", "description": "Modified HybridPSOSA with adaptive inertia weight and elite particles to enhance exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Elite strategy: retain a portion of best particles\n            num_elites = int(self.pop_size * 0.1)\n            elite_indices = np.argsort(self.best_personal_scores)[:num_elites]\n            elite_particles = self.best_personal_positions[elite_indices]\n            self.particles[:num_elites] = elite_particles\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 37, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05695 with standard deviation 0.00298.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.05754619578176079, 0.06140681159617278, 0.0556480880498621, 0.05764960207225056, 0.06151914589828256, 0.0557477564070894, 0.053755281038720404, 0.057303536624960016, 0.051989336909733286]}}
{"id": "81e65cb4-efdd-45e5-ade3-64eba05ac78c", "fitness": 0.05785588039068993, "name": "AdaptiveHybridPSOSA", "description": "An improved HybridPSOSA algorithm with adaptive inertia weight and dynamic population size to enhance exploration and exploitation balance for better convergence.", "code": "import numpy as np\n\nclass AdaptiveHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.max_pop_size = 50\n        self.min_pop_size = 10\n        self.population_growth_factor = 0.1\n        self.w_min = 0.2\n        self.w_max = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_factor = 0.99\n        self.particles = np.random.rand(self.initial_pop_size, dim)\n        self.velocities = np.random.rand(self.initial_pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.initial_pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            pop_size = len(self.particles)\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            for i in range(pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(pop_size, self.dim)\n            r2 = np.random.rand(pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n            # Dynamic population adjustment\n            new_pop_size = int(self.initial_pop_size + self.population_growth_factor * (self.func_eval_count / self.budget) * (self.max_pop_size - self.initial_pop_size))\n            new_pop_size = max(self.min_pop_size, new_pop_size)\n            new_pop_size = min(self.max_pop_size, new_pop_size)\n            if new_pop_size != pop_size:\n                self.particles = np.resize(self.particles, (new_pop_size, self.dim))\n                self.velocities = np.resize(self.velocities, (new_pop_size, self.dim))\n                self.best_personal_positions = np.resize(self.best_personal_positions, (new_pop_size, self.dim))\n                self.best_personal_scores = np.resize(self.best_personal_scores, new_pop_size)\n                if new_pop_size > pop_size:\n                    self.particles[pop_size:] = np.random.rand(new_pop_size - pop_size, self.dim)\n                    self.velocities[pop_size:] = np.random.rand(new_pop_size - pop_size, self.dim) * 0.1\n                    self.best_personal_scores[pop_size:] = np.inf\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 38, "feedback": "The algorithm AdaptiveHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05786 with standard deviation 0.00370.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.057072103691021114, 0.06375381211028086, 0.05656135763487502, 0.05717454016915624, 0.0638717835029331, 0.05666289003309399, 0.053315401890613234, 0.05945420133956514, 0.05283683314467069]}}
{"id": "412527ba-0bd1-4a04-ae0e-606acf35fd9c", "fitness": 0.05736949651143936, "name": "QuantumHybridPSOSA", "description": "An adaptive Quantum-inspired HybridPSOSA, integrating quantum superposition principles for dynamic exploration and exploitation balance, enhancing convergence accuracy.", "code": "import numpy as np\n\nclass QuantumHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.quantum_factor = 0.1  # Quantum influence factor\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n\n            # Quantum-inspired position update\n            quantum_influence = self.quantum_factor * np.random.randn(self.pop_size, self.dim)\n            self.particles += quantum_influence\n\n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 39, "feedback": "The algorithm QuantumHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05737 with standard deviation 0.00291.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.05870320325896272, 0.06140681159617278, 0.05577659351299891, 0.058809192949646705, 0.06151914589828256, 0.055876520086211245, 0.05482174408963114, 0.057303536624960016, 0.052108720586088175]}}
{"id": "4218241d-e926-46d9-9f46-8ea5c692fba4", "fitness": 0.056713208190485004, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and mutation-based diversity for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Adaptive inertia weight starts higher\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.w = 0.5 + (0.4 * (1 - self.func_eval_count / self.budget))  # Adaptive inertia weight update\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            mutation_mask = np.random.rand(self.pop_size, self.dim) < 0.1  # Mutation-based diversity\n            self.particles += perturbation * mutation_mask\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 40, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05671 with standard deviation 0.00304.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.05681357061431258, 0.06140681159617278, 0.0556480880498621, 0.056915490131796975, 0.06151914589828256, 0.0557477564070894, 0.05307513748215531, 0.057303536624960016, 0.051989336909733286]}}
{"id": "9e79e05c-bc28-4e01-a524-c166c0816f99", "fitness": 0.057035595528821564, "name": "RefinedHybridPSOSA", "description": "Introducing adaptive learning rates and dynamic population resizing in HybridPSOSA for enhanced convergence and efficient exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.pop_size = self.initial_pop_size\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temp_factor = 0.99\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            adaptive_w = 0.4 + 0.5 * (1 - self.func_eval_count / self.budget)\n            self.velocities = (adaptive_w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            \n            if self.func_eval_count % (self.budget // 10) == 0:\n                self.pop_size = max(10, self.pop_size // 2)\n                self.particles = self.particles[:self.pop_size]\n                self.velocities = self.velocities[:self.pop_size]\n                self.best_personal_positions = self.best_personal_positions[:self.pop_size]\n                self.best_personal_scores = self.best_personal_scores[:self.pop_size]\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 41, "feedback": "The algorithm RefinedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05704 with standard deviation 0.00288.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.05733642618258483, 0.06140681159617278, 0.056115385214548286, 0.05743941232031602, 0.06151914589828256, 0.05621599794541521, 0.05356035700081985, 0.057303536624960016, 0.0524232869762945]}}
{"id": "31bcbfb7-b545-4b4e-b9e8-5b8a18f1e339", "fitness": 0.05802951847722656, "name": "RefinedHybridPSOSA", "description": "A refined HybridPSOSA algorithm incorporating adaptive weight adjustment and dynamic population size scaling based on convergence rate for enhanced performance.", "code": "import numpy as np\n\nclass RefinedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_pop_size = self.pop_size\n        self.w = 0.9  # Starting inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Adaptive inertia weight\n            self.w = self.max_w - (self.max_w - self.min_w) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            \n            # Dynamic population size scaling\n            if self.func_eval_count % (self.budget // 10) == 0:\n                new_population_size = max(10, int(self.pop_size * 0.9))\n                self.particles = np.random.rand(new_population_size, self.dim) * (bounds_ub - bounds_lb) + bounds_lb\n                self.velocities = np.random.rand(new_population_size, self.dim) * 0.1\n                self.best_personal_positions = np.copy(self.particles)\n                self.best_personal_scores = np.full(new_population_size, np.inf)\n                self.pop_size = new_population_size\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05803 with standard deviation 0.00294.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.06042836503548399, 0.06140681159617278, 0.05608410556535404, 0.06053833113867346, 0.06151914589828256, 0.05618470149972854, 0.05640793986752646, 0.057303536624960016, 0.05239272906885717]}}
{"id": "d85e000a-8411-407c-a771-bc96ab1e937e", "fitness": 0.05804266349740924, "name": "EnhancedHybridPSOSA", "description": "An enhanced HybridPSOSA algorithm with dynamic inertia weight and adaptive cooling schedule for improved convergence and exploration.", "code": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor_init = 0.99  # Initial cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            temp_factor = self.temp_factor_init / (1 + 0.01 * (self.func_eval_count / self.budget))\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05804 with standard deviation 0.00362.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.057646475463927205, 0.06375381211028086, 0.05656135763487502, 0.057750143660958986, 0.0638717835029331, 0.05666289003309399, 0.053846474586378146, 0.05945420133956514, 0.05283683314467069]}}
{"id": "e6349c91-ee93-47f9-a55f-a83023cbcdee", "fitness": -Infinity, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with Adaptive Velocity and Dynamic Population for Balanced Exploration-Exploitation.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Increased inertia weight for exploration\n        self.c1 = 2.0  # Increased cognitive component\n        self.c2 = 2.0  # Increased social component\n        self.temp_factor = 0.99\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.adaptive_pop_size_factor = 1.05  # Factor to increase population\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            \n            if self.func_eval_count % (self.budget // 10) == 0 and self.pop_size < 60:\n                additional_particles = np.random.rand(int(self.pop_size * self.adaptive_pop_size_factor), self.dim)\n                self.particles = np.vstack((self.particles, additional_particles))\n                self.pop_size = self.particles.shape[0]\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 44, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {}}
{"id": "4533f856-e9ec-4cbd-9fb4-3f1a6183aa3b", "fitness": 0.05677896150357068, "name": "HybridPSOSA", "description": "Introduced adaptive inertia weight for dynamic exploration-exploitation balance in HybridPSOSA.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            # Modified velocity update rule\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            # Adaptive inertia weight\n            self.w = 0.9 - 0.7 * (self.func_eval_count / self.budget)\n            self.velocities = (self.w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Simulated Annealing inspired perturbation\n            temp = self.temp_factor ** (self.func_eval_count / self.budget)\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 45, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05678 with standard deviation 0.00297.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.05634371320209919, 0.06140681159617278, 0.0563197373028782, 0.056444643260143534, 0.06151914589828256, 0.056420790460836256, 0.052640114463573195, 0.057303536624960016, 0.052612160723190415]}}
{"id": "46813195-0555-41db-96cd-dafbea5947c7", "fitness": 0.05654421451559577, "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and diversity preservation for improved exploration and convergence.", "code": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.temp_factor = 0.99  # Cooling factor for Simulated Annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.rand(self.pop_size, dim) * 0.1\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               self.c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Diversity preservation strategy\n            if self.func_eval_count % 10 == 0:\n                diversity_factor = np.random.uniform(0, 0.05, self.particles.shape)\n                self.particles += diversity_factor * (bounds_ub - bounds_lb)\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 46, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05654 with standard deviation 0.00329.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.0551309958751266, 0.061663763105279545, 0.056556024266082416, 0.055229504759570336, 0.06177669929281715, 0.05665757531390625, 0.051512967083977235, 0.057539479559086004, 0.052830921384516394]}}
{"id": "0ffc8586-75b0-4267-b419-15ca57fb135c", "fitness": 0.05995952688691911, "name": "APSO_DTA", "description": "Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (APSO-DTA) using adaptive coefficients and dynamic temperature scaling for enhanced exploration and exploitation balance.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 47, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05996 with standard deviation 0.00440.", "error": "", "parent_ids": ["ca485d96-c017-48b4-a64e-1a1baae5ed6a"], "operator": null, "metadata": {"aucs": [0.06488065652703279, 0.0633413504841509, 0.055648577520214015, 0.06500124803222984, 0.06345829212841703, 0.05574824685694435, 0.06049009198714117, 0.05907748667849422, 0.05198979176764762]}}
{"id": "a3350f0b-c83f-4c6e-82c3-9b7dc0eb68d3", "fitness": 0.05788637595421109, "name": "APSO_DTA", "description": "Enhanced APSO-DTA with adaptive inertia weight and elite archiving for improved convergence and diversity.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Changed inertia weight for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.elite_archive = []  # Archive for elite solutions\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n                    self.elite_archive.append((self.particles[i].copy(), current_score))  # Track elite\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            w_adapt = 0.9 - 0.5 * (self.func_eval_count / self.budget)  # Adaptive inertia weight\n            self.velocities = (w_adapt * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        # Return the best from the archive if it's better\n        if self.elite_archive:\n            best_elite = min(self.elite_archive, key=lambda x: x[1])\n            if best_elite[1] < self.best_global_score:\n                return best_elite[0], best_elite[1]\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 48, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05789 with standard deviation 0.00309.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06042748673025822, 0.06140681159617278, 0.0556480880498621, 0.06053775116931959, 0.06151914589828256, 0.0557477564070894, 0.056397470202221855, 0.057303536624960016, 0.051989336909733286]}}
{"id": "439ae4c9-358c-41aa-9d7b-4019903801f5", "fitness": 0.05995952688691911, "name": "EAPSO", "description": "Enhanced Adaptive Particle Swarm Optimization (EAPSO) with Dynamic Temperature Annealing and Adaptive Population Size for improved convergence and diversity maintenance.", "code": "import numpy as np\n\nclass EAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 30\n        self.pop_size = self.initial_pop_size\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            \n            if self.func_eval_count % (self.budget // 10) == 0:\n                diversity_metric = np.mean(np.std(self.particles, axis=0))\n                if diversity_metric < 0.1:\n                    self.pop_size = min(self.pop_size + 5, self.initial_pop_size * 2)\n                    new_particles = np.random.rand(5, self.dim) * (bounds_ub - bounds_lb) + bounds_lb\n                    new_velocities = np.random.uniform(-0.1, 0.1, (5, self.dim))\n                    self.particles = np.vstack((self.particles, new_particles))\n                    self.velocities = np.vstack((self.velocities, new_velocities))\n                    self.best_personal_positions = np.vstack((self.best_personal_positions, new_particles))\n                    self.best_personal_scores = np.append(self.best_personal_scores, np.full(5, np.inf))\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 49, "feedback": "The algorithm EAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05996 with standard deviation 0.00440.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06488065652703279, 0.0633413504841509, 0.055648577520214015, 0.06500124803222984, 0.06345829212841703, 0.05574824685694435, 0.06049009198714117, 0.05907748667849422, 0.05198979176764762]}}
{"id": "7702ce3f-8af3-4ad4-86af-c534dda883f8", "fitness": 0.05852270834413256, "name": "QAPSO", "description": "Quantum-inspired Adaptive Particle Swarm Optimization (QAPSO) enhances diversity and convergence by incorporating quantum superposition principles into dynamic temperature annealing and inertia adaptation.", "code": "import numpy as np\n\nclass QAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation with quantum superposition\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            quantum_perturbation = np.random.choice([-1, 1], size=(self.pop_size, self.dim)) * perturbation\n            self.particles += quantum_perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 50, "feedback": "The algorithm QAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05852 with standard deviation 0.00276.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06111538588880061, 0.06140681159617278, 0.056913685436246864, 0.06122692339593716, 0.06151914589828256, 0.05701596390223895, 0.05704001463451869, 0.057303536624960016, 0.0531629077200354]}}
{"id": "149f5931-c459-4777-9269-c43c94262429", "fitness": 0.05995936746712786, "name": "Enhanced_APSO_DTA_CRS", "description": "Enhanced APSO-DTA with Complementary Random Search (CRS) introduces occasional broad random searches to diversify exploration and escape local optima while preserving exploitation through adaptive coefficients and dynamic temperature annealing.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_CRS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.crs_prob = 0.1  # Probability of performing complementary random search\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            # Complementary Random Search\n            if np.random.rand() < self.crs_prob:\n                random_indices = np.random.choice(self.pop_size, size=int(self.pop_size * 0.1), replace=False)\n                random_positions = np.random.rand(len(random_indices), self.dim) * (bounds_ub - bounds_lb) + bounds_lb\n                for idx, pos in zip(random_indices, random_positions):\n                    score = func(pos)\n                    self.func_eval_count += 1\n                    if score < self.best_personal_scores[idx]:\n                        self.best_personal_scores[idx] = score\n                        self.best_personal_positions[idx] = pos.copy()\n                    if score < self.best_global_score:\n                        self.best_global_score = score\n                        self.best_global_position = pos.copy()\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 51, "feedback": "The algorithm Enhanced_APSO_DTA_CRS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05996 with standard deviation 0.00440.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06488065652703279, 0.0633413504841509, 0.0556480880498621, 0.06500124803222984, 0.06345829212841703, 0.0557477564070894, 0.06049009198714117, 0.05907748667849422, 0.051989336909733286]}}
{"id": "6fe034f7-fea6-4704-95ef-8ffe7ac70d2c", "fitness": 0.05659027716628527, "name": "HPSO_QAE", "description": "Hybrid Particle Swarm Optimization with Quantum-inspired Adaptive Exploration (HPSO-QAE) enhances search diversity using quantum-inspired exploration and adaptive inertia based on convergence progress.", "code": "import numpy as np\n\nclass HPSO_QAE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.quantum_exploration_factor = 0.05  # Quantum exploration factor\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Calculate adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            self.velocities = (w * self.velocities +\n                               self.c1 * r1 * (self.best_personal_positions - self.particles) +\n                               self.c2 * r2 * (self.best_global_position - self.particles))\n            self.particles += self.velocities\n            \n            # Quantum-inspired exploration mechanism\n            quantum_jump = np.random.normal(0, self.quantum_exploration_factor, (self.pop_size, self.dim))\n            exploration_mask = np.random.rand(self.pop_size, self.dim) < self.quantum_exploration_factor\n            self.particles += exploration_mask * quantum_jump\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 52, "feedback": "The algorithm HPSO_QAE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05659 with standard deviation 0.00317.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05507484875981761, 0.06140681159617278, 0.05701069312376705, 0.0551732482974433, 0.06151914589828256, 0.05711325151967639, 0.05146069146646792, 0.057303536624960016, 0.05325026720997983]}}
{"id": "7d58a93d-ae06-4c95-87f7-56ca50ea5571", "fitness": 0.05806220654850626, "name": "APSO_DTA", "description": "Introducing a momentum component in velocity update to improve convergence in APSO-DTA.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            momentum = 0.9  # Momentum component for velocity update\n            self.velocities = (momentum * self.velocities +  # Modified line\n                               self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 53, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05806 with standard deviation 0.00436.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.0554098760822791, 0.06487900686693637, 0.05773919636481717, 0.05550893526857403, 0.06499985705830924, 0.05784319784748815, 0.051772381847318916, 0.06047968297230999, 0.053927724628523355]}}
{"id": "e8347e8b-1f3f-4634-ba6d-291b30ad856e", "fitness": 0.05613266540217021, "name": "EAPSO_GIP", "description": "Enhanced Adaptive Particle Swarm Optimization with Gradient-Inspired Perturbation (EAPSO-GIP) leveraging adaptive coefficients and gradient-based perturbations for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass EAPSO_GIP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        def gradient_estimation(position, func, epsilon=1e-8):\n            grad = np.zeros_like(position)\n            for d in range(self.dim):\n                perturbation = np.zeros_like(position)\n                perturbation[d] = epsilon\n                grad[d] = (func(position + perturbation) - func(position)) / epsilon\n            return grad\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Gradient-inspired perturbation\n            for i in range(self.pop_size):\n                grad = gradient_estimation(self.particles[i], func)\n                perturbation = -0.01 * grad\n                self.particles[i] += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 54, "feedback": "The algorithm EAPSO_GIP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05613 with standard deviation 0.00334.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0556480880498621, 0.05512901154455907, 0.06151914589828256, 0.0557477564070894, 0.05141960306510418, 0.057303536624960016, 0.051989336909733286]}}
{"id": "24b8273f-0077-48b2-914b-b95fcb7347be", "fitness": 0.05875693046394719, "name": "APSO_DTA", "description": "Enhanced APSO-DTA with Perturbation Decay Rate (APSO-DTA-PDR) by incorporating a perturbation decay factor to improve convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.perturbation_decay = 0.99  # Perturbation decay rate\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation with decay\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += self.perturbation_decay * perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 55, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05876 with standard deviation 0.00357.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.0629685927657917, 0.06140681159617278, 0.05578418206496738, 0.06308433878379605, 0.06151914589828256, 0.05588412796671083, 0.05874600141884456, 0.057303536624960016, 0.052115637055998865]}}
{"id": "2cb19eec-a79b-4962-afcc-26af59878c7b", "fitness": 0.05639847468347852, "name": "QPSO_A", "description": "Quantum-inspired Particle Swarm Optimization with Annealing (QPSO-A) enhancing convergence using quantum superposition principles and adaptive annealing for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass QPSO_A:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with quantum-inspired updates\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            mean_best = (self.best_personal_positions + self.best_global_position) / 2.0\n            phi = np.arccos(1 - 2 * np.random.rand(self.pop_size, self.dim))\n            delta = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * np.sin(phi) * delta +\n                               adapt_c2 * r2 * np.cos(phi) * delta)\n            self.particles += self.velocities\n            \n            # Quantum superposition-inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 56, "feedback": "The algorithm QPSO_A got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05640 with standard deviation 0.00318.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05584682292806664, 0.06140681159617278, 0.0556480880498621, 0.05594676952189925, 0.06151914589828256, 0.0557477564070894, 0.05217800421524066, 0.057303536624960016, 0.051989336909733286]}}
{"id": "4bf113df-0201-4292-b7b1-d5210861f389", "fitness": -Infinity, "name": "EAPSO_DTA", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (EAPSO-DTA) leveraging nonlinear inertia weight descent and adaptive boundary control for improved convergence and solution diversity.", "code": "import numpy as np\n\nclass EAPSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Nonlinear inertia weight descent\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget) ** 2\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True) + 1e-6\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True) + 1e-6\n            \n            self.velocities = (inertia_weight * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / personal_dist +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / global_dist)\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Adaptive boundary control to prevent stagnation\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n            out_of_bounds = np.logical_or(self.particles < bounds_lb, self.particles > bounds_ub)\n            self.particles[out_of_bounds] = bounds_lb + np.random.rand(*self.particles[out_of_bounds].shape) * (bounds_ub - bounds_lb)\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (0,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (0,) (10,) ')", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {}}
{"id": "7cf36b62-08ac-45f6-8605-12c365551998", "fitness": 0.05668451858181408, "name": "EPSO_ASA", "description": "Enhanced Particle Swarm Optimization with Adaptive Simulated Annealing (EPSO-ASA) combines dynamic inertia and temperature scaling with adaptive annealing for improved convergence in diverse search spaces.", "code": "import numpy as np\n\nclass EPSO_ASA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Calculate dynamic inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Adaptive simulated annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation * np.exp(-self.func_eval_count / self.budget)\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 58, "feedback": "The algorithm EPSO_ASA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05668 with standard deviation 0.00305.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05672580375677927, 0.06140681159617278, 0.0556480880498621, 0.056827577426532105, 0.06151914589828256, 0.0557477564070894, 0.05299261056691518, 0.057303536624960016, 0.051989336909733286]}}
{"id": "dc981d3f-0822-4824-8d61-fef756e7964c", "fitness": 0.05787688919866105, "name": "QI_APSO", "description": "Quantum-Inspired Adaptive Particle Swarm Optimization (QI-APSO) enhances APSO-DTA by leveraging quantum superposition principles to explore multiple potential solutions simultaneously for improved convergence speed and solution quality.", "code": "import numpy as np\n\nclass QI_APSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Quantum superposition-inspired update\n            q_factor = np.random.uniform(0, 1, (self.pop_size, self.dim))\n            self.particles = (1 - q_factor) * self.particles + q_factor * (self.best_global_position + np.random.uniform(-0.5, 0.5, self.particles.shape))\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 59, "feedback": "The algorithm QI_APSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05788 with standard deviation 0.00284.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.0598493163144026, 0.06140681159617278, 0.05619208790624941, 0.05995794047354319, 0.06151914589828256, 0.056292854476238, 0.055875755139546346, 0.057303536624960016, 0.052494554358554546]}}
{"id": "0108fa0e-0998-42fe-9f92-2f91847aa127", "fitness": 0.05746354672845037, "name": "EAPSO", "description": "Enhanced Adaptive Particle Swarm Optimization (EAPSO) with Nonlinear Dynamic Temperature Annealing to improve convergence by continuously adapting exploration-exploitation balance using nonlinear temperature scaling and adaptive inertia weights.", "code": "import numpy as np\n\nclass EAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Calculate dynamic inertia weight\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (inertia_weight * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Nonlinear dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** ((self.func_eval_count / self.budget) ** 2))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 60, "feedback": "The algorithm EAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05746 with standard deviation 0.00267.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05801994409102729, 0.06140681159617278, 0.056748523276749396, 0.05812451089399828, 0.06151914589828256, 0.05685044175236431, 0.05418861949554388, 0.057303536624960016, 0.05301038692695481]}}
{"id": "660b9666-adf4-4f89-a29e-471d720bcb1a", "fitness": 0.05920639369394953, "name": "Enhanced_APSO_DTA", "description": "Enhanced APSO-DTA integrating Lévy Flight and inertia weight decay to improve exploration and exploitation dynamics for black-box optimization.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * (L**(-1/3))\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1/3)\n        return step\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Incorporate Levy Flight for additional exploration\n            if np.random.rand() < 0.3:  # 30% chance to perform Levy Flight\n                L = np.random.uniform(0.1, 0.5)\n                levy_steps = np.array([self.levy_flight(L) for _ in range(self.pop_size)])\n                self.particles += levy_steps\n            \n            # Dynamic inertia weight decay\n            self.w = self.w_min + (0.5 * (1 - self.func_eval_count / self.budget) * (self.w - self.w_min))\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 61, "feedback": "The algorithm Enhanced_APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05921 with standard deviation 0.00292.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05742933808784256, 0.06140681159617278, 0.06270532753264402, 0.05753265247396111, 0.06151914589828256, 0.06282064525059694, 0.05364206517862058, 0.057303536624960016, 0.05849802060246523]}}
{"id": "dbc3a565-b946-4f0a-9fbf-2c0557945c3f", "fitness": 0.056993482989849555, "name": "EAPSO_DTA", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (EAPSO-DTA) incorporating adaptive inertia weight and nonlinear convergence strategies for improved solution accuracy and convergence speed.", "code": "import numpy as np\n\nclass EAPSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_w = 0.9  # Initial inertia weight\n        self.final_w = 0.4    # Final inertia weight\n        self.c1 = 2.0         # Cognitive component\n        self.c2 = 2.0         # Social component\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - (self.func_eval_count / self.budget)**2)\n            adapt_c2 = self.c2 * ((self.func_eval_count / self.budget)**2)\n            inertia_weight = self.initial_w - (self.initial_w - self.final_w) * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (inertia_weight * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 62, "feedback": "The algorithm EAPSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05699 with standard deviation 0.00297.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05767449922486689, 0.06140681159617278, 0.0556480880498621, 0.05777817810682806, 0.06151914589828256, 0.0557477564070894, 0.05387399409085092, 0.057303536624960016, 0.051989336909733286]}}
{"id": "e0765895-09ba-4eb5-8411-ea06e2f3e6bf", "fitness": 0.05697145471628825, "name": "E_APSO_DTA", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (E-APSO-DTA) incorporating nonlinear inertia weight adjustment and diversity-based perturbation for improved convergence and exploration.", "code": "import numpy as np\n\nclass E_APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Nonlinear inertia weight adjustment\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget) ** 2)\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (inertia_weight * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            # Diversity-based perturbation\n            diversity = np.std(self.particles, axis=0)\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp * diversity, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 63, "feedback": "The algorithm E_APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05697 with standard deviation 0.00287.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.056407089212878625, 0.06140681159617278, 0.056847724859919735, 0.056508149433461496, 0.06151914589828256, 0.056949863383043864, 0.05269890067815619, 0.057303536624960016, 0.05310187075971895]}}
{"id": "fbeec372-3a96-4164-a28e-e72b084ff799", "fitness": 0.056788467144020895, "name": "APSO_DTA", "description": "Enhanced Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (EAPSO-DTA) integrating a Lévy flight strategy for improved exploration capabilities.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        def levy_flight(Lambda):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            sigma2 = 1\n            u = np.random.normal(0, sigma1, self.dim)\n            v = np.random.normal(0, sigma2, self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return step\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n            \n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            if self.func_eval_count % (self.budget // 10) == 0:\n                LF_step = levy_flight(1.5)\n                self.particles += LF_step\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 64, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05679 with standard deviation 0.00392.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.05540581471192918, 0.06305214810888526, 0.0556480880498621, 0.055504867018079884, 0.06316843559193319, 0.0557477564070894, 0.051768566618979106, 0.05881119087969666, 0.051989336909733286]}}
{"id": "3f3e6ac0-34f7-41da-b739-6f94c6fe3e98", "fitness": 0.05788637595421109, "name": "APSO_DTA", "description": "Improved Adaptive Particle Swarm Optimization with Dynamic Temperature Annealing (APSO-DTA) using adaptive inertia weight for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass APSO_DTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            # Adaptive inertia weight\n            self.w = 0.9 - (0.9 - 0.4) * (self.func_eval_count / self.budget)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n\n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 65, "feedback": "The algorithm APSO_DTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05789 with standard deviation 0.00309.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06042748673025822, 0.06140681159617278, 0.0556480880498621, 0.06053775116931959, 0.06151914589828256, 0.0557477564070894, 0.056397470202221855, 0.057303536624960016, 0.051989336909733286]}}
{"id": "31f7bfc6-acbf-423a-bb6c-3b05b87f4caa", "fitness": 0.05754282622196186, "name": "EAPSO_MDTA", "description": "Enhanced Adaptive Particle Swarm Optimization with Multi-Scale Dynamic Temperature Annealing (EAPSO-MDTA) introducing multi-scale perturbations and adaptive inertia for improved convergence.", "code": "import numpy as np\n\nclass EAPSO_MDTA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Start with a high inertia weight\n        self.w_min = 0.4  # Minimum value of inertia weight\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            self.w = self.w_min + (0.9 - self.w_min) * ((self.budget - self.func_eval_count) / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            self.velocities = (self.w * self.velocities +\n                               adapt_c1 * r1 * (self.best_personal_positions - self.particles) / (personal_dist + 1e-6) +\n                               adapt_c2 * r2 * (self.best_global_position - self.particles) / (global_dist + 1e-6))\n            self.particles += self.velocities\n\n            # Multi-scale dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            large_scale_perturbation = np.random.normal(0, temp * 10, (self.pop_size, self.dim))  # Large scale factor\n            self.particles += perturbation + large_scale_perturbation * (np.random.rand(self.pop_size, 1) < 0.1)\n\n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 66, "feedback": "The algorithm EAPSO_MDTA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00302.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.059218301328732514, 0.061555473586670795, 0.0556480880498621, 0.05932556240998077, 0.061668152960762224, 0.0557477564070894, 0.055292619548136246, 0.05744014479668935, 0.051989336909733286]}}
{"id": "7c564eac-6f71-469c-9583-895c39785958", "fitness": 0.06021721879799745, "name": "APSO_DTA_Plus", "description": "APSO-DTA+ with Dynamic Neighborhood Learning enhances exploration by dynamically adjusting social learning based on neighborhood success rates.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 67, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06022 with standard deviation 0.00447.", "error": "", "parent_ids": ["0ffc8586-75b0-4267-b419-15ca57fb135c"], "operator": null, "metadata": {"aucs": [0.06584728993232503, 0.06283158895237717, 0.055996722580746616, 0.0659712903139007, 0.06294734845881034, 0.05609709409392838, 0.061341470255047326, 0.05860902619008046, 0.05231313840476104]}}
{"id": "01387030-f788-462e-a6d1-f9bfd9572164", "fitness": 0.05689585985524729, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Stochastic Diffusion Mechanism to boost exploration by integrating random diffusion for particle diversity.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            \n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                \n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]))\n            \n            self.particles += self.velocities\n            \n            # Stochastic diffusion mechanism for particle diversity enhancement\n            diffusion_prob = 0.1\n            diffusion_strength = 0.05 * (bounds_ub - bounds_lb)\n            random_indices = np.random.rand(self.pop_size, self.dim) < diffusion_prob\n            self.particles += random_indices * np.random.uniform(-diffusion_strength, diffusion_strength, (self.pop_size, self.dim))\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 68, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05690 with standard deviation 0.00299.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05737467262162488, 0.06140681159617278, 0.0556480880498621, 0.057477743009262006, 0.06151914589828256, 0.0557477564070894, 0.0535956475802386, 0.057303536624960016, 0.051989336909733286]}}
{"id": "ae46794e-b61f-4cc5-8b1a-01cf7b3860f4", "fitness": 0.0564686448719556, "name": "APSO_DTA_Plus", "description": "APSO-DTA+ introduces a diversity-driven mutation strategy to enhance exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Diversity-driven mutation strategy\n            diversity_factor = np.std(self.particles, axis=0) * 0.1\n            mutation = np.random.normal(0, diversity_factor, (self.pop_size, self.dim))\n            self.particles += mutation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 69, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05647 with standard deviation 0.00321.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.056680006606714906, 0.05512901154455907, 0.06151914589828256, 0.056781772591165236, 0.05141960306510418, 0.057303536624960016, 0.052947217396873136]}}
{"id": "43fb9b42-3e0e-4317-a596-219b81b46ab3", "fitness": 0.05633969635102403, "name": "APSO_DTA_PP", "description": "APSO-DTA++ incorporates adaptive velocity clamping and elite selection to enhance convergence by dynamically controlling exploration and exploitation phases.  ", "code": "import numpy as np\n\nclass APSO_DTA_PP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning with elite selection\n            neighborhood_size = max(1, self.pop_size // 5)\n            elite_indices = np.argsort(self.best_personal_scores)[:neighborhood_size]\n            for i in range(self.pop_size):\n                if i in elite_indices:  # Skip elite particles\n                    continue\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n                \n                # Adaptive velocity clamping\n                velocity_norm = np.linalg.norm(self.velocities[i])\n                if velocity_norm > (bounds_ub - bounds_lb).mean() / 2:\n                    self.velocities[i] *= (bounds_ub - bounds_lb).mean() / (2 * velocity_norm)\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 70, "feedback": "The algorithm APSO_DTA_PP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05634 with standard deviation 0.00325.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.0562841721210765, 0.05512901154455907, 0.06151914589828256, 0.05638515336701555, 0.05141960306510418, 0.057303536624960016, 0.05257913441827711]}}
{"id": "b83b427f-16d7-4edf-9a4c-f575a184dfc1", "fitness": 0.05705126964842143, "name": "Improved_APSO_DTA_Plus", "description": "Improved APSO-DTA+ with Adaptive Neighborhood Size dynamically adjusts neighborhood size and inertia weight based on convergence rate to balance exploration and exploitation.", "code": "import numpy as np\n\nclass Improved_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_min = 0.3  # Minimum inertia weight\n        self.w_max = 0.9  # Maximum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            # Calculate dynamic inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Adaptive neighborhood learning\n            neighborhood_size = max(1, int(self.pop_size / (1 + 4 * self.func_eval_count / self.budget)))\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 71, "feedback": "The algorithm Improved_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05705 with standard deviation 0.00286.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.057315108667116754, 0.06140681159617278, 0.05618630032759708, 0.05741818815647248, 0.06151914589828256, 0.056287055791239604, 0.05353611928211366, 0.057303536624960016, 0.05248916049183794]}}
{"id": "6a397e6e-9d91-4b06-b9b8-96988866d515", "fitness": 0.057992983959296716, "name": "APSO_DTA_Plus", "description": "Improved adaptive coefficients favor exploration early on by modifying the adaptation rates for personal and global components.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - (self.func_eval_count / self.budget)**0.5)  # Modified line\n            adapt_c2 = self.c2 * ((self.func_eval_count / self.budget)**0.5)  # Modified line\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 72, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05799 with standard deviation 0.00269.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056651743362916895, 0.06140681159617278, 0.05974437721258008, 0.056753292698295654, 0.06151914589828256, 0.05985276628879144, 0.0529262690018385, 0.057303536624960016, 0.055778912949832504]}}
{"id": "3c159014-f71e-49fd-9934-b76a56de2a14", "fitness": 0.057759979407847974, "name": "APSO_DTA_Plus", "description": "Enhanced velocity update by incorporating nonlinear inertia weight to balance exploration and exploitation.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                inertia_weight = 0.9 - 0.5 * (self.func_eval_count / self.budget)  # Nonlinear inertia weight\n                self.velocities[i] = (inertia_weight * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 73, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05776 with standard deviation 0.00272.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05923179688585489, 0.06140681159617278, 0.05645236791940211, 0.059339317840455985, 0.06151914589828256, 0.0565536840727614, 0.05529766352508059, 0.057303536624960016, 0.05273549030766145]}}
{"id": "97e39ae0-c1aa-4f9d-964b-d42430c03fbd", "fitness": 0.05775559081492819, "name": "APSO_DTA_Plus", "description": "Improved APSO-DTA+ with adaptive inertia weight for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * (1 - self.func_eval_count / self.budget) * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 74, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05776 with standard deviation 0.00285.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056107504672555986, 0.06140681159617278, 0.05956344989743545, 0.05620806017424007, 0.06151914589828256, 0.059671728528786216, 0.052417408276158706, 0.057303536624960016, 0.05560267166576194]}}
{"id": "792b4ab7-9ce1-45d1-8f01-70d53d82f709", "fitness": 0.0574032234744201, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ integrates stochastic gradient descent-based velocity updates and adaptive inertia weight to improve convergence speed and precision in diverse landscapes.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_w = 0.9  # Initial inertia weight\n        self.final_w = 0.4  # Final inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.learning_rate = 0.01  # Learning rate for SGD-based update\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update inertia weight dynamically\n            w = self.initial_w - ((self.initial_w - self.final_w) * (self.func_eval_count / self.budget))\n            \n            # Update velocities and positions with SGD-based updates\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                velocity_gradient = (adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) +\n                                     adapt_c2 * r2[i] * (self.best_global_position - self.particles[i]))\n                self.velocities[i] = w * self.velocities[i] + self.learning_rate * velocity_gradient\n                \n            self.particles += self.velocities\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 75, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05740 with standard deviation 0.00296.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.058937833265366946, 0.06140681159617278, 0.0556480880498621, 0.05904453384652242, 0.06151914589828256, 0.0557477564070894, 0.05503196867179139, 0.057303536624960016, 0.051989336909733286]}}
{"id": "804c7277-5472-47e8-b95d-c7bffe348603", "fitness": 0.05775559081492819, "name": "APSO_DTA_Plus", "description": "Enhanced exploration with adaptive inertia weight based on progress.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * (1 - self.func_eval_count / self.budget) * self.velocities[i] +  # Adaptive inertia weight\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 76, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05776 with standard deviation 0.00285.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056107504672555986, 0.06140681159617278, 0.05956344989743545, 0.05620806017424007, 0.06151914589828256, 0.059671728528786216, 0.052417408276158706, 0.057303536624960016, 0.05560267166576194]}}
{"id": "ea33cd21-87fe-4254-b1c1-dbd45c3b4d16", "fitness": 0.059924759811642615, "name": "APSO_DTA_Plus", "description": "Enhanced velocity update by incorporating an additional damping factor to improve convergence.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            damping_factor = 0.98  # New damping factor for velocity\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = damping_factor * (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 77, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05992 with standard deviation 0.00381.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.06528192509917763, 0.06140681159617278, 0.05707878628562002, 0.06540432541952901, 0.06151914589828256, 0.057181408332037775, 0.06083099604974773, 0.057303536624960016, 0.05331590299925604]}}
{"id": "06290b4d-5432-4f50-86e7-848964d3eaa2", "fitness": 0.057434187879800785, "name": "APSO_DTA_Plus", "description": "APSO-DTA+ with Enhanced Neighborhood Influence increases influence of best neighborhood particle by slightly adjusting the global influence calculation.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                # Enhanced influence of best neighbor\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6) * 1.1)\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 78, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05743 with standard deviation 0.00296.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.059021100159402096, 0.06140681159617278, 0.05565774858767536, 0.05912776687461918, 0.06151914589828256, 0.055757436298491725, 0.0551158312689044, 0.057303536624960016, 0.051998313609698976]}}
{"id": "5954271a-3b10-4439-a113-78817945abcd", "fitness": 0.05654675364408748, "name": "APSO_DTA_Plus", "description": "Introduced an exponential weighting factor to the cognitive component to enhance personal best attraction over iterations.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * np.exp(-self.func_eval_count / self.budget) * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 79, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05655 with standard deviation 0.00313.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05539381665685783, 0.06140681159617278, 0.05655708734828224, 0.05549284154537115, 0.06151914589828256, 0.05665865751484489, 0.05175752892902352, 0.057303536624960016, 0.052831356682992325]}}
{"id": "20cea3f1-e062-440b-a545-43d9df649703", "fitness": 0.05701783375302808, "name": "APSO_DTA_Plus", "description": "Improved APSO-DTA+ by increasing inertia weight `w` for enhanced exploration in early iterations.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 80, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05702 with standard deviation 0.00296.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05775125048806662, 0.06140681159617278, 0.0556480880498621, 0.05785526770184224, 0.06151914589828256, 0.0557477564070894, 0.053939310101243754, 0.057303536624960016, 0.051989336909733286]}}
{"id": "c518ae93-1f70-4254-916d-9f6b1bcca05b", "fitness": 0.0562963574043789, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Adaptive Inertia and Neighborhood-based Local Search improves convergence speed by dynamically adjusting inertia and using intensive local searches in promising regions.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.initial_w = 0.9  # Initial inertia weight\n        self.final_w = 0.4  # Final inertia weight\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.local_search_prob = 0.1  # Probability of performing local search\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            w = self.initial_w - (self.func_eval_count / self.budget) * (self.initial_w - self.final_w)\n\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            neighborhood_size = max(1, self.pop_size // 5)\n            \n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                \n                self.velocities[i] = (w * self.velocities[i] +\n                                      self.c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) +\n                                      self.c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]))\n            \n            self.particles += self.velocities\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n            if np.random.rand() < self.local_search_prob:\n                best_particle_idx = np.argmin(self.best_personal_scores)\n                local_search_radius = 0.1 * (bounds_ub - bounds_lb)\n                local_search_point = self.particles[best_particle_idx] + np.random.uniform(-local_search_radius, local_search_radius, self.dim)\n                local_search_point = np.clip(local_search_point, bounds_lb, bounds_ub)\n                local_search_score = func(local_search_point)\n                self.func_eval_count += 1\n                if local_search_score < self.best_global_score:\n                    self.best_global_score = local_search_score\n                    self.best_global_position = local_search_point\n\n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 81, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05630 with standard deviation 0.00323.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05553391434117538, 0.06140681159617278, 0.0556480880498621, 0.05563329278403928, 0.06151914589828256, 0.0557477564070894, 0.051885334028095254, 0.057303536624960016, 0.051989336909733286]}}
{"id": "43bc2835-f6c9-4b89-84ae-284d0603cda2", "fitness": 0.056176626372145835, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Adaptive Inertia and Quantum-Inspired Perturbation for improved convergence by dynamically adjusting inertia and incorporating quantum tunneling for better exploration.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adapt inertia weight linearly\n            inertia = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            \n            # Adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                personal_dist = np.linalg.norm(self.best_personal_positions[i] - self.particles[i])\n                global_dist = np.linalg.norm(self.best_global_position - self.particles[i])\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Quantum-inspired perturbation\n            prob_tunnel = (self.budget - self.func_eval_count) / self.budget\n            quantum_perturbation = np.random.uniform(-1, 1, (self.pop_size, self.dim)) * prob_tunnel\n            self.particles += quantum_perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 82, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05618 with standard deviation 0.00336.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05508023617115143, 0.06149251225635122, 0.0556480880498621, 0.055178646104461215, 0.06160504494089192, 0.0557477564070894, 0.05146571056679694, 0.057382305942975, 0.051989336909733286]}}
{"id": "8fda3750-1ed1-42e6-b0c0-057b2cf1f2de", "fitness": 0.0561373339190035, "name": "APSO_DTA_PlusPlus", "description": "APSO-DTA++ incorporates adaptive learning rates and stochastic ranking to balance exploration and exploitation, optimizing convergence speed and solution quality.", "code": "import numpy as np\n\nclass APSO_DTA_PlusPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1_start = 2.0  # Start cognitive component\n        self.c2_start = 2.0  # Start social component\n        self.c1_end = 0.5  # End cognitive component\n        self.c2_end = 0.5  # End social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            scores = np.zeros(self.pop_size)\n            \n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                scores[i] = current_score\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Sort particles by their scores\n            sorted_indices = np.argsort(scores)\n            self.particles = self.particles[sorted_indices]\n            self.best_personal_positions = self.best_personal_positions[sorted_indices]\n            self.velocities = self.velocities[sorted_indices]\n            self.best_personal_scores = self.best_personal_scores[sorted_indices]\n\n            # Update learning rates\n            adapt_c1 = self.c1_start + (self.c1_end - self.c1_start) * (self.func_eval_count / self.budget)\n            adapt_c2 = self.c2_start + (self.c2_end - self.c2_start) * (self.func_eval_count / self.budget)\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            # Stochastic ranking and adaptive velocity update\n            for i in range(self.pop_size):\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) +\n                                      adapt_c2 * r2[i] * (self.best_global_position - self.particles[i]))\n\n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 83, "feedback": "The algorithm APSO_DTA_PlusPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05614 with standard deviation 0.00333.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.05566242196104065, 0.05512901154455907, 0.06151914589828256, 0.05576211900750294, 0.05141960306510418, 0.057303536624960016, 0.0520026570496408]}}
{"id": "c8538424-7a44-4b05-9bef-93860d8a0010", "fitness": 0.056515585568504494, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Multi-Phase Velocity Adjustment introduces phase-based velocity adaptation to balance exploration and exploitation over time effectively.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.phase_switch = self.budget // 3\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with phase-based adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            \n            if self.func_eval_count < self.phase_switch:  # Early phase: emphasize exploration\n                phase_factor = 1.0\n            elif self.func_eval_count < 2 * self.phase_switch:  # Middle phase: balance\n                phase_factor = 0.5\n            else:  # Late phase: emphasize exploitation\n                phase_factor = 0.2\n            \n            adapt_c1 = self.c1 * phase_factor\n            adapt_c2 = self.c2 * (1 - phase_factor)\n            \n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 84, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05652 with standard deviation 0.00311.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.055935262357732496, 0.06140681159617278, 0.0559195214459417, 0.05603539952853909, 0.06151914589828256, 0.05601974754976735, 0.05225974515821974, 0.057303536624960016, 0.05224109995692472]}}
{"id": "d5082f75-8941-46db-94dd-7288276d4027", "fitness": 0.057012141779687414, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Adaptive Inertia and Global-Nest Exploration improves convergence by dynamically adjusting inertia for diversity and incorporating a global-nest exploration inspired by bird swarming behavior.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.max_inertia = 0.9\n        self.min_inertia = 0.4\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Calculate adaptive inertia\n            inertia = self.max_inertia - (self.max_inertia - self.min_inertia) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions with adaptive coefficients and inertia\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning with global-nest exploration\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                nest_info = self.best_personal_positions[best_neighbor] * np.exp(-np.linalg.norm(self.particles[i] - self.best_global_position))\n                self.velocities[i] = (inertia * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (nest_info - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 85, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05701 with standard deviation 0.00338.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05566420889428503, 0.06232136484416628, 0.0568045826501149, 0.05576378304689267, 0.062435885495112586, 0.05690661608028502, 0.052008532736418256, 0.05814191098251509, 0.05306239128739687]}}
{"id": "2ec983d7-1988-418f-a4f6-e79b5cda5bc6", "fitness": 0.057759979407847974, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ incorporates adaptive inertia weight and velocity clamping to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            # Adaptive inertia weight\n            w = self.w_max - ((self.w_max - self.w_min) * (self.func_eval_count / self.budget))\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n                \n                # Velocity clamping\n                vel_max = (bounds_ub - bounds_lb) * 0.1\n                self.velocities[i] = np.clip(self.velocities[i], -vel_max, vel_max)\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 86, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05776 with standard deviation 0.00272.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05923179688585489, 0.06140681159617278, 0.05645236791940211, 0.059339317840455985, 0.06151914589828256, 0.0565536840727614, 0.05529766352508059, 0.057303536624960016, 0.05273549030766145]}}
{"id": "3e3c9a67-5853-409b-a76a-71d3617b632f", "fitness": 0.056768194261981736, "name": "APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with adaptive neighborhood size based on convergence for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, int((1 - self.func_eval_count / self.budget) * (self.pop_size // 5)))  # Change made here\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 87, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05677 with standard deviation 0.00299.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05592892251256831, 0.06140681159617278, 0.05670205647216808, 0.05602906790161233, 0.06151914589828256, 0.056803883721624704, 0.052253173896202765, 0.057303536624960016, 0.0529671497342441]}}
{"id": "ae242cfd-ffdf-41fd-befe-0e5019b3943e", "fitness": 0.058561770425543704, "name": "APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with improved dynamic learning using neighborhood's worst score.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                worst_neighbor = neighbors[np.argmax(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[worst_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 88, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05856 with standard deviation 0.00311.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05628703630501275, 0.06140681159617278, 0.06186464853700102, 0.056387873424745716, 0.06151914589828256, 0.06197812403311742, 0.05258677511984755, 0.057303536624960016, 0.05772198229075354]}}
{"id": "007a78d0-26ca-49a5-809a-11af98d973b5", "fitness": 0.05637090895741262, "name": "APSO_DTA_Plus_Plus", "description": "APSO-DTA++ incorporates adaptive learning rates and hybrid perturbation strategies, enhancing convergence speed and robustness in diverse optimization landscapes.", "code": "import numpy as np\n\nclass APSO_DTA_Plus_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - np.exp(-self.func_eval_count / self.budget))\n            adapt_c2 = self.c2 * np.exp(-self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                # Adjust velocity with adaptive learning and hybrid perturbation\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            hybrid_perturbation = perturbation + 0.5 * np.random.rand(self.pop_size, self.dim) * np.sign(self.best_global_position - self.particles)\n            self.particles += hybrid_perturbation\n            \n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 89, "feedback": "The algorithm APSO_DTA_Plus_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05637 with standard deviation 0.00319.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05576197589235332, 0.06140681159617278, 0.0556480880498621, 0.05586173319339016, 0.06151914589828256, 0.0557477564070894, 0.05209979604486992, 0.057303536624960016, 0.051989336909733286]}}
{"id": "1b54cdfd-e1fa-469b-8195-43fe45944457", "fitness": 0.05740385982167947, "name": "APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with adaptive inertia weight dynamically adjusts particle exploration based on convergence progress.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.9  # Inertia weight (adjusted)\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 90, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05740 with standard deviation 0.00276.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056308602493771454, 0.06140681159617278, 0.05827720166452155, 0.056409485346224475, 0.06151914589828256, 0.05838249412257357, 0.05260673187018172, 0.057303536624960016, 0.054420728778427074]}}
{"id": "54168c88-744b-406e-844c-8b92839f1d1f", "fitness": 0.057434187879800785, "name": "APSO_DTA_Plus", "description": "APSO-DTA+ with Enhanced Global Attraction balances exploration and exploitation by increasing the influence of the global best position.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget) * 1.1  # 1.1 factor for enhanced global attraction\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 91, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05743 with standard deviation 0.00296.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.059021100159402096, 0.06140681159617278, 0.05565774858767536, 0.05912776687461918, 0.06151914589828256, 0.055757436298491725, 0.0551158312689044, 0.057303536624960016, 0.051998313609698976]}}
{"id": "34329e29-18ec-45b2-9c28-b826d446073a", "fitness": 0.05775559081492819, "name": "APSO_DTA_Plus", "description": "Incorporate an additional adaptive inertia weight adjustment to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * ((self.budget - self.func_eval_count) / self.budget) * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 92, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05776 with standard deviation 0.00285.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056107504672555986, 0.06140681159617278, 0.05956344989743545, 0.05620806017424007, 0.06151914589828256, 0.059671728528786216, 0.052417408276158706, 0.057303536624960016, 0.05560267166576194]}}
{"id": "4a82e61f-2b92-497e-81a3-c2ef68beb819", "fitness": 0.05622803468201535, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ introduces a diversity-preserving mechanism and adaptive inertia weight to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                diversity_factor = np.random.rand(self.dim)  # Diversity-enhancing factor\n                self.velocities[i] = (w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) +\n                                      diversity_factor * (np.mean(self.particles, axis=0) - self.particles[i]))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 93, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05623 with standard deviation 0.00329.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05504664292085437, 0.06140681159617278, 0.055924976460749454, 0.05514498703486137, 0.06151914589828256, 0.056025201413430814, 0.05143444669140451, 0.057303536624960016, 0.052246563497422294]}}
{"id": "6f9102e4-2448-43a2-815a-6a08e3d485b7", "fitness": 0.05735626460860664, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ integrates adaptive inertia weight and neighborhood-based perturbation to improve convergence and solution quality.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n    \n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update inertia weight\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (self.func_eval_count / self.budget)\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning with neighborhood-based perturbation\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                perturbation = np.random.normal(0, self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget)), self.dim)\n                self.velocities[i] = (inertia_weight * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6) +\n                                      perturbation)\n            \n            self.particles += self.velocities\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 94, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05736 with standard deviation 0.00276.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.056384183287500944, 0.06140681159617278, 0.058054081336524455, 0.056485206586140424, 0.06151914589828256, 0.058158806830864496, 0.05267732148428439, 0.057303536624960016, 0.05421728783272972]}}
{"id": "c4d5b11a-c4ef-4ddf-a0c2-5361cf166c60", "fitness": 0.05828360932994154, "name": "APSO_DTA_PP", "description": "APSO-DTA++ incorporates adaptive velocity control and Lévy flight-inspired perturbations to enhance exploration and convergence balance.  ", "code": "import numpy as np\n\nclass APSO_DTA_PP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Lévy flight-inspired perturbation\n            levy_factor = 0.01 * np.random.standard_cauchy((self.pop_size, self.dim))\n            self.particles += levy_factor\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 95, "feedback": "The algorithm APSO_DTA_PP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05828 with standard deviation 0.00245.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.0597738046310381, 0.06140681159617278, 0.05751759283855762, 0.05988201943252458, 0.06151914589828256, 0.057621384407208764, 0.05581394356904379, 0.057303536624960016, 0.05371424497168564]}}
{"id": "31a0675e-59cb-4897-82ea-3c7ec1b5c9c3", "fitness": -Infinity, "name": "APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ with Adaptive Velocity Clamping and Niche-Based Selection for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.max_velocity = 0.2 * (func.bounds.ub - func.bounds.lb)  # Adaptive velocity clamping\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n                \n                # Apply adaptive velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -self.max_velocity, self.max_velocity)\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 96, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {}}
{"id": "b5173846-70c7-42ce-b77d-1f94bd35f9c0", "fitness": 0.06021721879799745, "name": "APSO_DTA_Plus", "description": "Refine APSO_DTA_Plus by enhancing particle velocity updates to improve convergence rate and precision.", "code": "import numpy as np\n\nclass APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Dynamic neighborhood learning\n            neighborhood_size = max(1, self.pop_size // 5)\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                \n                # Change: Enhance velocity update mechanism with improved personal influence\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      2 * adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 97, "feedback": "The algorithm APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06022 with standard deviation 0.00447.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.06584728993232503, 0.06283158895237717, 0.055996722580746616, 0.0659712903139007, 0.06294734845881034, 0.05609709409392838, 0.061341470255047326, 0.05860902619008046, 0.05231313840476104]}}
{"id": "947f437a-8b06-4ddd-9f20-dc1ed4f12fd0", "fitness": 0.05665036326430485, "name": "APSO_DTA_Plus_Refined", "description": "APSO-DTA+ with Adaptive Dynamic Neighborhood Learning enhances convergence by dynamically adjusting neighborhood sizes and learning rates based on performance feedback.", "code": "import numpy as np\n\nclass APSO_DTA_Plus_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Initial cognitive component\n        self.c2 = 1.5  # Initial social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n        \n        # Normalize particles to the function's bounds\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n        \n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n                \n                # Update personal best\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n                \n                # Update global best\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n            \n            # Update velocities and positions with adaptive coefficients\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n            personal_dist = np.linalg.norm(self.best_personal_positions - self.particles, axis=1, keepdims=True)\n            global_dist = np.linalg.norm(self.best_global_position - self.particles, axis=1, keepdims=True)\n            \n            # Adaptive dynamic neighborhood learning\n            adaptive_neighborhood_size = max(1, self.pop_size // (5 + int(5 * (1 - self.func_eval_count / self.budget))))\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, adaptive_neighborhood_size, replace=False)\n                best_neighbor = neighbors[np.argmin(self.best_personal_scores[neighbors])]\n                self.velocities[i] = (self.w * self.velocities[i] +\n                                      adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i]) / (personal_dist[i] + 1e-6) +\n                                      adapt_c2 * r2[i] * (self.best_personal_positions[best_neighbor] - self.particles[i]) / (global_dist[i] + 1e-6))\n            \n            self.particles += self.velocities\n            \n            # Dynamic temperature annealing inspired perturbation\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n            \n            # Keep particles inside bounds\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 98, "feedback": "The algorithm APSO_DTA_Plus_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05665 with standard deviation 0.00316.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05503069852376852, 0.06140681159617278, 0.05723861877405667, 0.05512901154455907, 0.06151914589828256, 0.05734156543361235, 0.05141960306510418, 0.057303536624960016, 0.0534642779182275]}}
{"id": "9a9e43d6-52ce-41a0-bf50-9ac6503b676d", "fitness": 0.05734537388077829, "name": "Enhanced_APSO_DTA_Plus", "description": "Enhanced APSO-DTA+ integrates a multi-phase velocity adaptation strategy and a dynamic restart mechanism to accelerate convergence while maintaining diversity.", "code": "import numpy as np\n\nclass Enhanced_APSO_DTA_Plus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.initial_temp = 1.0  # Initial temperature for annealing\n        self.final_temp = 0.01  # Final temperature for annealing\n        self.particles = np.random.rand(self.pop_size, dim)\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.pop_size, dim))\n        self.best_personal_positions = np.copy(self.particles)\n        self.best_personal_scores = np.full(self.pop_size, np.inf)\n        self.best_global_position = np.zeros(dim)\n        self.best_global_score = np.inf\n        self.func_eval_count = 0\n        self.phase_switch = self.budget // 3\n        self.dynamic_restart_threshold = 30  # Threshold for dynamic restart\n\n    def __call__(self, func):\n        bounds_lb = func.bounds.lb\n        bounds_ub = func.bounds.ub\n\n        self.particles = bounds_lb + self.particles * (bounds_ub - bounds_lb)\n\n        while self.func_eval_count < self.budget:\n            for i in range(self.pop_size):\n                current_score = func(self.particles[i])\n                self.func_eval_count += 1\n\n                if current_score < self.best_personal_scores[i]:\n                    self.best_personal_scores[i] = current_score\n                    self.best_personal_positions[i] = self.particles[i].copy()\n\n                if current_score < self.best_global_score:\n                    self.best_global_score = current_score\n                    self.best_global_position = self.particles[i].copy()\n\n            r1 = np.random.rand(self.pop_size, self.dim)\n            r2 = np.random.rand(self.pop_size, self.dim)\n            adapt_c1 = self.c1 * (1.0 - self.func_eval_count / self.budget)\n            adapt_c2 = self.c2 * (self.func_eval_count / self.budget)\n\n            if self.func_eval_count < self.phase_switch:\n                velocity_weight = 0.9\n            elif self.func_eval_count < 2 * self.phase_switch:\n                velocity_weight = 0.5\n            else:\n                velocity_weight = 0.3\n\n            for i in range(self.pop_size):\n                inertia = velocity_weight * self.velocities[i]\n                cognitive = adapt_c1 * r1[i] * (self.best_personal_positions[i] - self.particles[i])\n                social = adapt_c2 * r2[i] * (self.best_global_position - self.particles[i])\n                self.velocities[i] = inertia + cognitive + social\n\n            self.particles += self.velocities\n\n            temp = self.initial_temp * ((self.final_temp / self.initial_temp) ** (self.func_eval_count / self.budget))\n            perturbation = np.random.normal(0, temp, (self.pop_size, self.dim))\n            self.particles += perturbation\n\n            self.particles = np.clip(self.particles, bounds_lb, bounds_ub)\n\n            if self.func_eval_count % self.dynamic_restart_threshold == 0:\n                diverse_particles = np.random.rand(self.pop_size, self.dim)\n                self.particles = np.where(np.random.rand(self.pop_size, self.dim) < 0.1, \n                                          bounds_lb + diverse_particles * (bounds_ub - bounds_lb), \n                                          self.particles)\n        \n        return self.best_global_position, self.best_global_score", "configspace": "", "generation": 99, "feedback": "The algorithm Enhanced_APSO_DTA_Plus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05735 with standard deviation 0.00273.", "error": "", "parent_ids": ["7c564eac-6f71-469c-9583-895c39785958"], "operator": null, "metadata": {"aucs": [0.05655294036271197, 0.06140681159617278, 0.057850923604179094, 0.056654289041314865, 0.06151914589828256, 0.05795516548559687, 0.052834548854716834, 0.057303536624960016, 0.05403100345906964]}}
