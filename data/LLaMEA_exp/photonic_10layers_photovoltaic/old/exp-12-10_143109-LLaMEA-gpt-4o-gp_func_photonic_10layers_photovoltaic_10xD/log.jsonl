{"id": "77f8586d-7c3f-4748-8992-df2b555187de", "fitness": 0.055721636698716104, "name": "AdaptiveSymbioticEvolution", "description": "\"Adaptive Symbiotic Evolution\" - a novel metaheuristic that adapts symbiotic relationships for cooperative problem-solving by dynamically adjusting parameters based on dimensionality and fitness landscape.", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Find the best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                if self.best_fitness < np.mean(fitness):\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n            # Symbiotic evolution: pair individuals for crossover\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Mutation\n            offspring = self._mutate(offspring, bounds)\n\n            # Replace population\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate:\n                offspring[i] += np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05572 with standard deviation 0.00456.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.054044331997331496, 0.05967200405345452, 0.054449591152394006, 0.04914258850115116, 0.054191313786692064, 0.049503659992730764, 0.05796753800707388, 0.06411136634344383, 0.05841233645417321]}}
{"id": "85d3028b-7403-4106-a16a-60a83fcece23", "fitness": 0.055721636698716104, "name": "AdaptiveSymbioticEvolution", "description": "Enhancing mutation rate adjustment by using the median instead of mean for improved robustness against outliers in fitness.", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Find the best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                if self.best_fitness < np.median(fitness):  # Change mean to median here\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n            # Symbiotic evolution: pair individuals for crossover\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Mutation\n            offspring = self._mutate(offspring, bounds)\n\n            # Replace population\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate:\n                offspring[i] += np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05572 with standard deviation 0.00456.", "error": "", "parent_ids": ["77f8586d-7c3f-4748-8992-df2b555187de"], "operator": null, "metadata": {"aucs": [0.054044331997331496, 0.05967200405345452, 0.054449591152394006, 0.04914258850115116, 0.054191313786692064, 0.049503659992730764, 0.05796753800707388, 0.06411136634344383, 0.05841233645417321]}}
{"id": "78cb63e6-b2a7-4909-91cb-0d56646950c6", "fitness": 0.05529182112793474, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "\"Enhanced Adaptive Symbiotic Evolution\" - an improved metaheuristic that leverages dynamic parameter tuning, diversity maintenance, and adaptive differential mutation strategies for enhanced convergence and search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.diversity_threshold = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate current population\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Find the best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Calculate diversity\n            diversity = np.std(self.population, axis=0).mean()\n\n            # Adaptation based on success ratio and diversity\n            if evaluations > self.budget // 10:\n                if self.best_fitness < np.mean(fitness):\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                    if diversity < self.diversity_threshold:\n                        self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n            # Symbiotic evolution: pair individuals for crossover\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive differential mutation\n            offspring = self._adaptive_mutate(offspring, bounds, fitness)\n\n            # Replace population\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _adaptive_mutate(self, offspring, bounds, fitness):\n        scale_factor = 0.5\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate:\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[idxs]\n                mutant_vector = x1 + scale_factor * (x2 - x3)\n                offspring[i] = np.clip(mutant_vector + np.random.normal(0, mutation_strength, self.dim), bounds[0], bounds[1])\n        return offspring", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05529 with standard deviation 0.00472.", "error": "", "parent_ids": ["77f8586d-7c3f-4748-8992-df2b555187de"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "fcc19289-716d-44e6-9d23-ecbada68d264", "fitness": 0.05627432346001782, "name": "AdaptiveSymbioticEvolution", "description": "\"Enhanced Adaptive Symbiotic Evolution\" - an improved metaheuristic incorporating fitness diversity maintenance and adaptive mutation strength based on solution proximity.", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive mutation strength based on proximity to best solution\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05627 with standard deviation 0.00482.", "error": "", "parent_ids": ["77f8586d-7c3f-4748-8992-df2b555187de"], "operator": null, "metadata": {"aucs": [0.05646997827140965, 0.05967200405345452, 0.0546494426165981, 0.04845848352140991, 0.054191313786692064, 0.04968403336633331, 0.060602902358866784, 0.06411136634344383, 0.05862938682195218]}}
{"id": "e6a09acb-c95c-4900-ac6b-e3e314492ca6", "fitness": 0.05595464126850694, "name": "AdaptiveSymbioticEvolution", "description": "\"Enhanced Adaptive Symbiotic Evolution with Elite Preservation\" - an improved metaheuristic that maintains population diversity, adapts mutation strength, and now preserves elite solutions across generations.", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.elite_fraction = 0.1  # New line\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            elite_count = int(self.elite_fraction * self.population_size)  # New line\n            elite_indices = np.argsort(fitness)[:elite_count]  # New line\n            offspring[elite_indices] = self.population[elite_indices]  # New line\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05595 with standard deviation 0.00487.", "error": "", "parent_ids": ["fcc19289-716d-44e6-9d23-ecbada68d264"], "operator": null, "metadata": {"aucs": [0.05609756028684454, 0.05967200405345452, 0.05394575143172731, 0.04845848352140991, 0.054191313786692064, 0.049047172660500404, 0.06020113946600991, 0.06411136634344383, 0.05786697986647993]}}
{"id": "69e15c61-e028-4c8c-b999-8b2495d53ff9", "fitness": -Infinity, "name": "SelfAdaptiveSymbioticEvolution", "description": "\"Self-Adaptive Symbiotic Evolution\" - an enhanced algorithm with dynamic population adjustment, fitness diversity preservation, and self-adaptive parameter tuning for efficient exploration and exploitation.", "code": "import numpy as np\n\nclass SelfAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.dynamic_pop_size = self.initial_pop_size\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.dynamic_pop_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.dynamic_pop_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                # Dynamic population size adjustment\n                if self.best_fitness < avg_fitness:\n                    self.dynamic_pop_size = min(self.initial_pop_size + 5, self.dynamic_pop_size + 1)\n                else:\n                    self.dynamic_pop_size = max(self.initial_pop_size - 5, self.dynamic_pop_size - 1)\n                self.population = np.resize(self.population, (self.dynamic_pop_size, self.dim))\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive mutation strength based on proximity to best solution\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.dynamic_pop_size, self.dynamic_pop_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.dynamic_pop_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.dynamic_pop_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 5, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["fcc19289-716d-44e6-9d23-ecbada68d264"], "operator": null, "metadata": {}}
{"id": "09707826-8f99-4143-8f3a-76b519f7d466", "fitness": 0.056858374890436644, "name": "AdaptiveSymbioticEvolution", "description": "\"Enhanced Adaptive Symbiotic Evolution with dynamic population resizing and self-adjusting crossover rate based on diversity metrics.\"", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                # Adjust crossover rate based on diversity\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive mutation strength based on proximity to best solution\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05686 with standard deviation 0.00419.", "error": "", "parent_ids": ["fcc19289-716d-44e6-9d23-ecbada68d264"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05122710005338915, 0.054191313786692064, 0.052373146744917665, 0.0573465429682698, 0.06411136634344383, 0.0618780093536232]}}
{"id": "4270415f-90ea-44a9-9445-1286a8a32cd8", "fitness": -Infinity, "name": "AdaptiveSymbioticEvolution", "description": "\"Enhanced Adaptive Symbiotic Evolution with improved diversity metric and dynamic population scaling based on convergence speed.\"", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                # Adjust crossover rate based on improved diversity metric\n                diversity = np.ptp(self.population, axis=0).mean()  # Changed line\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.ptp(self.population, axis=0).max())  # Changed line\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive mutation strength based on proximity to best solution\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n            # Dynamic population scaling based on convergence speed\n            if evaluations % (self.budget // 20) == 0:  # Changed line\n                self.population_size = max(10, self.population_size - 1)\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(self.population_size, self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 7, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_ids": ["09707826-8f99-4143-8f3a-76b519f7d466"], "operator": null, "metadata": {}}
{"id": "193440bd-2e44-41e8-bfae-b151a12bdb9f", "fitness": 0.05692762836021253, "name": "AdaptiveSymbioticEvolution", "description": "\"Adaptive Symbiotic Evolution with dynamic population control and strategy adaptation based on fitness landscape analysis.\"", "code": "import numpy as np\n\nclass AdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                # Adjust crossover rate based on diversity and fitness variance\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n                \n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Adaptive mutation based on proximity to best solution\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00467.", "error": "", "parent_ids": ["09707826-8f99-4143-8f3a-76b519f7d466"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.058663101571948206, 0.04897074153017622, 0.054191313786692064, 0.05329411975931264, 0.057153340176343215, 0.06411136634344383, 0.06300188105993243]}}
{"id": "11172d5e-98af-4313-b092-f24404eaf432", "fitness": 0.05692762836021253, "name": "HierarchicalAdaptiveSymbioticEvolution", "description": "\"Hierarchical Adaptive Symbiotic Evolution with enhanced diversity control and multi-layer strategy adaptation based on dynamic clustering analysis of the population.\"", "code": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass HierarchicalAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                self._adapt_mutation_rate(avg_fitness, fitness_std)\n                self._adapt_crossover_rate()\n                self._adjust_population_size(fitness_std, evaluations)\n                self._strategy_adaptation(fitness)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            mutation_strength_scaler = self._calculate_mutation_strength_scaler()\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _adapt_mutation_rate(self, avg_fitness, fitness_std):\n        if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n            self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n        else:\n            self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n    def _adapt_crossover_rate(self):\n        diversity = np.std(self.population, axis=0).mean()\n        self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n    def _adjust_population_size(self, fitness_std, evaluations):\n        if fitness_std < 0.1 and self.population_size > 5:\n            self.population_size = max(5, self.population_size - 1)\n        elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n            self.population_size = min(100, self.population_size + 1)\n\n    def _strategy_adaptation(self, fitness):\n        fitness_gradient = np.gradient(fitness)\n        if np.mean(fitness_gradient) < 0:\n            self.mutation_rate *= 1.1\n            self.crossover_rate *= 0.9\n\n    def _calculate_mutation_strength_scaler(self):\n        proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n        mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n        return mutation_strength_scaler\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 9, "feedback": "The algorithm HierarchicalAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00467.", "error": "", "parent_ids": ["193440bd-2e44-41e8-bfae-b151a12bdb9f"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.058663101571948206, 0.04897074153017622, 0.054191313786692064, 0.05329411975931264, 0.057153340176343215, 0.06411136634344383, 0.06300188105993243]}}
{"id": "ea7b7329-d8a4-4453-acc5-51a5c36f16b8", "fitness": 0.05692878905922367, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with fitness diversity-driven elitism and mutative convergence acceleration for improved optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00407.", "error": "", "parent_ids": ["193440bd-2e44-41e8-bfae-b151a12bdb9f"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05205403036439893, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "32fd34fe-38d1-4699-9f12-a48f2a4e8e2f", "fitness": 0.05691400512115205, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adaptive Symbiotic Evolution with enhanced diversity-driven elitism and feedback-informed dynamic parameter adjustment for robust optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n        \n        mutation_decay = 0.99  # new: decay factor for mutation rate\n        exploration_phase = int(0.2 * self.budget)  # new: exploration phase duration\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n            \n            # new: adjust mutation rate based on remaining budget\n            if evaluations > exploration_phase:\n                self.mutation_rate *= mutation_decay\n                self.mutation_rate = max(0.01, self.mutation_rate)\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05691 with standard deviation 0.00409.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.051920974921754404, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "f51e3e00-7f3b-45a6-9cb8-619b0f7d4a52", "fitness": 0.05692878905922367, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Refined mutation strategy to enhance convergence by dynamically tuning mutation strength based on variance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            # Dynamic mutation strength adjustment based on population fitness variance\n            mutation_strength = (bounds[1] - bounds[0]) * (self.mutation_rate * fitness_std)\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00407.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05205403036439893, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "5b15b7a1-d1ed-4cee-8a9f-446c598cc8a4", "fitness": 0.05692878905922367, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with adaptive crossover rate relaxation based on fitness improvement trends for refined optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9  # First change\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00407.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05205403036439893, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "a6487dc1-1872-4e4d-914f-e8f4aae96535", "fitness": 0.05692878905922367, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Refined mutation rate scaling based on proximity to best solution for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-6))  # Slight change\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00407.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05205403036439893, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "e0e8b9e6-5ad4-4beb-a9a1-4aab186cf17c", "fitness": 0.05652928385444711, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduced adaptive mutation based on population diversity for enhanced convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate * (1 + np.std(offspring))\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05653 with standard deviation 0.00467.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.04845848352140991, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "9e9c2198-ebaf-4313-a626-eda0b18d6b40", "fitness": 0.056754568387287874, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with improved dynamic adaptation of mutation and crossover rates based on fitness convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.2)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.2)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.6 + 0.4 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 2)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.05\n                    self.crossover_rate *= 0.95\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 16, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05675 with standard deviation 0.00473.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05831301479062845, 0.04845848352140991, 0.054191313786692064, 0.052967726898929146, 0.057153340176343215, 0.06411136634344383, 0.0626330789540801]}}
{"id": "b00624e3-1a48-46e9-bff4-130d5bc2768f", "fitness": 0.05692878905922367, "name": "AdaptiveCoevolutionaryStrategy", "description": "Adaptive Co-evolutionary Strategy with dynamic parameters and fitness landscape learning to enhance optimization.", "code": "import numpy as np\n\nclass AdaptiveCoevolutionaryStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n            \n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveCoevolutionaryStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05693 with standard deviation 0.00407.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05763510374952996, 0.05205403036439893, 0.054191313786692064, 0.052373146744917665, 0.057153340176343215, 0.06411136634344383, 0.0618780093536232]}}
{"id": "92c4d161-9b38-42fe-a93a-0e0cc9135921", "fitness": 0.05625142603249681, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Modified mutation strategy with an adaptive mutation rate based on average proximity to improve convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            # Elitism: Preserve the best individuals\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptation based on success ratio and fitness landscape\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                if self.best_fitness < avg_fitness - 0.1 * fitness_std:\n                    self.mutation_rate = min(1.0, self.mutation_rate + 0.1)\n                else:\n                    self.mutation_rate = max(0.1, self.mutation_rate - 0.1)\n\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / np.max(np.std(self.population, axis=0)))\n\n                # Dynamic population size adjustment\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                # Strategy adaptation based on fitness landscape assessment\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate *= 1.1\n                    self.crossover_rate *= 0.9\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / np.max(proximity))\n            avg_proximity = np.mean(proximity)  # New line\n            self.mutation_rate = self.mutation_rate * (1 + avg_proximity / np.max(proximity))  # Modified line\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            # Insert elite individuals back into the population\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 18, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05625 with standard deviation 0.00518.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.05657253406981122, 0.0605241458538589, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.060719412191055255, 0.0650478495601845, 0.0578268685971034]}}
{"id": "12c35ef1-3316-4ddc-813e-870345cc0357", "fitness": 0.057177426968020764, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with multi-objective-driven diversity maintenance and convergence acceleration through adaptive operator learning.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 19, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00447.", "error": "", "parent_ids": ["ea7b7329-d8a4-4453-acc5-51a5c36f16b8"], "operator": null, "metadata": {"aucs": [0.05570070417286099, 0.05967200405345452, 0.05699976526699946, 0.04866914970439695, 0.0573371295556071, 0.05161837087102161, 0.05958197219184258, 0.06411136634344383, 0.06090638055255981]}}
{"id": "0875afbe-fd34-45d4-af9e-01a2a61d0e8c", "fitness": 0.057177426968020764, "name": "DynamicAdaptiveSymbioticEvolution", "description": "Dynamic Adaptive Symbiotic Evolution with enhanced diversity preservation and feedback-driven mutation control to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass DynamicAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = np.clip(self.mutation_rate * 1.1, 0.1, 1.0)\n                    self.crossover_rate = np.clip(self.crossover_rate * 0.9, 0.1, 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 20, "feedback": "The algorithm DynamicAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00447.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.05570070417286099, 0.05967200405345452, 0.05699976526699946, 0.04866914970439695, 0.0573371295556071, 0.05161837087102161, 0.05958197219184258, 0.06411136634344383, 0.06090638055255981]}}
{"id": "999f8abb-9992-4d16-bbcc-e20caba7225f", "fitness": 0.05645821407626247, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with dynamic population control, local search intensification, and adaptive mutation strategies to improve convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_pop_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.local_search_prob = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                if np.random.rand() < self.local_search_prob:\n                    self._local_search(bounds, func, elite_indices)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _local_search(self, bounds, func, elite_indices):\n        for idx in elite_indices:\n            candidate = self.population[idx] + np.random.normal(0, 0.1 * (bounds[1] - bounds[0]), self.dim)\n            candidate = np.clip(candidate, bounds[0], bounds[1])\n            candidate_fitness = func(candidate)\n            if candidate_fitness < func(self.population[idx]):\n                self.population[idx] = candidate\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 21, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05646 with standard deviation 0.00453.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.056946008688182226, 0.049081169736039154, 0.058129100874675044, 0.050057538282309744, 0.05831209584707009, 0.06411136634344383, 0.05852385590057796]}}
{"id": "bdb2044b-08ac-4a9c-9e12-0b109c4ba4fa", "fitness": 0.05604584739642656, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with adaptive learning rates based on dynamic landscape analysis and reinforcement learning mechanisms for adaptive parameter fine-tuning.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n        reward_history = []\n        \n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:  # Learning phase trigger\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.05)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.95)\n\n                landscape_complexity = np.mean(np.abs(fitness_gradient))\n                reward = -landscape_complexity\n                reward_history.append(reward)\n                if len(reward_history) >= 10:  # Sliding window of 10 evaluations\n                    avg_reward = np.mean(reward_history[-10:])\n                    self.mutation_rate *= 1.05 if avg_reward > 0 else 0.95\n                    self.crossover_rate *= 0.95 if avg_reward > 0 else 1.05\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 22, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05605 with standard deviation 0.00429.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.053378774350334224, 0.05967200405345452, 0.05390867170771463, 0.04845848352140991, 0.0573371295556071, 0.0525659882624282, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "10e3a533-1e47-4434-a2bc-d2cb157c94ce", "fitness": 0.05543521266976497, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with adaptive diversity control and dynamic exploration-exploitation balancing for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                entropy = -np.sum((fitness/fitness.sum()) * np.log2(fitness/fitness.sum() + 1e-8))\n                exploration_exploitation_balance = 0.5 + 0.5 * (entropy / np.log2(self.population_size))\n\n                self.mutation_rate *= exploration_exploitation_balance\n                self.crossover_rate *= (1.0 - exploration_exploitation_balance)\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05544 with standard deviation 0.00486.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.060962527929926624, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "3cbd7454-c46c-44b4-bb3d-1a976b00ae1b", "fitness": 0.057177426968020764, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Improved diversity and adaptability by adjusting elitism rate dynamically based on fitness variance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                \n                self.elitism_rate = 0.05 + 0.05 * (1 - fitness_std / (np.abs(avg_fitness) + 1e-8))  # line changed\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05718 with standard deviation 0.00447.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.05570070417286099, 0.05967200405345452, 0.05699976526699946, 0.04866914970439695, 0.0573371295556071, 0.05161837087102161, 0.05958197219184258, 0.06411136634344383, 0.06090638055255981]}}
{"id": "d8a3f758-7778-4a40-b979-26826b0c9051", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhanced Adaptive Symbiotic Evolution with refined mutation strategy and dynamic elitism based on convergence rate.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n            \n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Dynamic elitism based on convergence rate\n            if evaluations > 0.3 * self.budget and self.best_fitness < 0.2 * np.mean(fitness):\n                self.elitism_rate = min(0.2, self.elitism_rate * 1.05)\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 25, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\")", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {}}
{"id": "86a9f4f7-40a4-48d3-951a-851cc9bb12e4", "fitness": 0.05609614222598569, "name": "AdvancedSymbioticEvolution", "description": "Advanced Symbiotic Evolution with dynamic operator adaptation, leveraging fitness landscape analysis to enhance convergence and diversity.", "code": "import numpy as np\n\nclass AdvancedSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + int(2.5 * np.sqrt(dim))\n        self.mutation_rate = 0.4\n        self.crossover_rate = 0.6\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.2 + 0.8 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.4 + 0.6 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.05 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.3 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(120, self.population_size + 2)\n\n                fitness_gradient = np.gradient(fitness)\n                if np.mean(fitness_gradient) < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 26, "feedback": "The algorithm AdvancedSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05610 with standard deviation 0.00441.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.057660264022417085, 0.05058913903018236, 0.054191313786692064, 0.0493245420179389, 0.05749189537484778, 0.06411136634344383, 0.058533968444285045]}}
{"id": "9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a dynamic adjustment for mutation and crossover rates based on the improvement ratio to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 27, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["12c35ef1-3316-4ddc-813e-870345cc0357"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "828b966a-fca7-4f3e-a171-8e2bb290e882", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Refine the balance between exploration and exploitation by adjusting the mutation strategy based on the improvement ratio and enhance solution diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(0.8, self.mutation_rate * 1.15)  # Modified mutation rate adjustment\n                    self.crossover_rate = max(0.2, self.crossover_rate * 0.85)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "8a06f534-30bd-41be-b6b8-45b3d1e58b4b", "fitness": 0.056066839776988155, "name": "DynamicSymbioticEvolution", "description": "Enhance convergence by introducing dynamic population sizing and multi-parent crossover to maintain diversity and adaptively exploit search space.", "code": "import numpy as np\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                diversity = np.std(self.population, axis=0).mean()\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - np.std(fitness) / (np.abs(np.mean(fitness)) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                improvement_ratio = (self.best_fitness - fitness[min_idx]) / (np.abs(np.mean(fitness)) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._multi_parent_crossover(parents, bounds)\n            mutation_strength_scaler = 1 - (np.linalg.norm(self.population - self.best_solution, axis=1) / \n                                            (np.max(np.linalg.norm(self.population - self.best_solution, axis=1)) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _multi_parent_crossover(self, parents, bounds):\n        offspring = np.empty((self.population_size, self.dim))\n        for i in range(self.population_size):\n            if np.random.rand() < self.crossover_rate:\n                selected_parents = parents[np.random.choice(len(parents), 3, replace=False)]\n                offspring[i] = np.mean(selected_parents, axis=0)\n            else:\n                offspring[i] = parents[i]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 29, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05607 with standard deviation 0.00409.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05443880032738235, 0.05967200405345452, 0.05478608185270417, 0.051196050983083996, 0.054191313786692064, 0.05023261640492083, 0.05814645564410825, 0.06411136634344383, 0.0578268685971034]}}
{"id": "13ce485d-9b46-4ad8-aa03-6fcee567d686", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Fine-tune the balance between exploration and exploitation by adjusting the mutation rate based on population diversity and budget consumption.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1 * (1 + diversity))\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9 * (1 - evaluations/self.budget))\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 30, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "d518858a-4e7a-482b-8d87-c6644fbd02af", "fitness": 0.05609447852164531, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Integrate adaptive local search with dynamic population adaptation to enhance exploration and exploitation balance in optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            local_search_pop = self._local_search(offspring, func, bounds)\n            self.population = local_search_pop\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                mutation = np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n                offspring[i] += mutation\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _local_search(self, population, func, bounds):\n        # Perform a simple local search around each individual\n        local_search_radius = (bounds[1] - bounds[0]) * 0.05\n        for i in range(self.population_size):\n            candidate = population[i] + np.random.uniform(-local_search_radius, local_search_radius, self.dim)\n            if func(candidate) < func(population[i]):\n                population[i] = np.clip(candidate, bounds[0], bounds[1])\n        return population", "configspace": "", "generation": 31, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05609 with standard deviation 0.00450.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05570809494709905, 0.05967200405345452, 0.05390867170771463, 0.05064907812293162, 0.054191313786692064, 0.04901355500464144, 0.05976935413172724, 0.06411136634344383, 0.0578268685971034]}}
{"id": "47c070f0-3ad7-4dc3-9cc7-3031dbadd5ea", "fitness": 0.05754132020315087, "name": "AdaptiveDynamicPopulationEvolution", "description": "Implement a self-adaptive strategy to dynamically adjust population size based on convergence speed and population diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveDynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n            convergence_speed = (self.best_fitness - fitness[min_idx]) / (self.best_fitness + 1e-8)\n\n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n            \n            if fitness_std < 0.1 and convergence_speed < 0.01:\n                self.population_size = max(5, self.population_size - 1)\n            elif fitness_std > 0.5 and convergence_speed > 0.1 and evaluations + self.population_size <= self.budget:\n                self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 32, "feedback": "The algorithm AdaptiveDynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "e21a5a1f-dc91-4050-9f71-1ec30fe228a2", "fitness": 0.05662391830631877, "name": "AdvancedAdaptiveSymbioticEvolution", "description": "Integrate multi-layer learning rates to dynamically adjust exploration and exploitation balance, enhancing convergence speed and solution quality.", "code": "import numpy as np\n\nclass AdvancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.learning_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = max(0.1, self.mutation_rate * (1 + self.learning_rate * (fitness_std / (np.abs(avg_fitness) + 1e-8))))\n                self.crossover_rate = max(0.1, self.crossover_rate * (1 + self.learning_rate * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 33, "feedback": "The algorithm AdvancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05662 with standard deviation 0.00530.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05409647497963388, 0.05967200405345452, 0.05480959922084405, 0.04916995754423081, 0.054191313786692064, 0.04982842028923329, 0.06462684781563055, 0.06411136634344383, 0.059109280723705915]}}
{"id": "330883f6-bde6-4922-998c-c1a4fd59d2f4", "fitness": 0.05592280697182608, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce diversity-based scaling to mutation and crossover rates for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate * (1.0 + np.std(self.population, axis=0).mean())  # Changed line\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 34, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05592 with standard deviation 0.00461.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05580886959901643, 0.04845848352140991, 0.054191313786692064, 0.05073007463333201, 0.057153340176343215, 0.06411136634344383, 0.05988902367213311]}}
{"id": "60258e88-0ba0-4fe2-9eb7-25e676616da4", "fitness": 0.05754132020315087, "name": "EnhancedFeedbackSymbioticEvolution", "description": "Introduce enhanced feedback mechanisms and adaptive scalability based on population performance metrics for improved optimization efficiency.", "code": "import numpy as np\n\nclass EnhancedFeedbackSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedFeedbackSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "91547f8e-b6ad-4c79-9eb6-f0335db7ed20", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Dynamically adapt population size and diversity-driven mutation to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.diversity_threshold = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - diversity / self.diversity_threshold)\n                self.crossover_rate = 0.5 + 0.5 * (fitness_std / (np.abs(avg_fitness) + 1e-8))\n\n                if diversity < self.diversity_threshold and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif diversity > self.diversity_threshold and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 36, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {}}
{"id": "c36a1e37-ddb8-4a42-93c1-c51b4f3e89ed", "fitness": 0.05635528866965356, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Incorporate dynamic learning rates for mutation and crossover based on population diversity and improvement stagnation to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.learning_rate = 0.05\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n\n            # Adjust mutation and crossover rates dynamically\n            self.mutation_rate += self.learning_rate * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate += self.learning_rate * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            # Adapt population size\n            if fitness_std < 0.1 and self.population_size > 5:\n                self.population_size = max(5, self.population_size - 1)\n            elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                self.population_size = min(100, self.population_size + 1)\n\n            improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n            if improvement_ratio < 0:\n                self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 37, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05636 with standard deviation 0.00376.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05389701889316145, 0.05967200405345452, 0.05393215315671884, 0.05107195848470658, 0.054191313786692064, 0.05410314633903324, 0.05780835116579752, 0.06411136634344383, 0.058410285803873974]}}
{"id": "4c32e98d-1133-4da2-8b68-6ac18d0b8aeb", "fitness": 0.0567165169918321, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance diversity by probabilistically adjusting mutation rate based on best solution proximity to avoid premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            self.mutation_rate *= (1 + 0.1 * np.random.uniform(-1, 1)) # Adjust mutation rate\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05672 with standard deviation 0.00474.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499241281807665, 0.06097830138105931, 0.055376318868419205, 0.05062622851436349, 0.05699193761422938, 0.049113981958355035, 0.0589383705347708, 0.06554520412996778, 0.05788589710724723]}}
{"id": "77c01c6c-7e7f-4630-b61f-b5dfba9e3cf1", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance selection and diversification by integrating a multi-armed bandit strategy to allocate resources dynamically.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.arm_rewards = np.zeros(3)  # New for bandit\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                # Arm selection logic using UCB (Upper Confidence Bound)\n                arm = np.argmax(self.arm_rewards + np.sqrt(2 * np.log(evaluations) / (self.arm_rewards + 1)))\n\n                if arm == 0 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif arm == 1 and fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n                elif arm == 2:\n                    self.crossover_rate *= np.random.rand()  # Diversify crossover\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n                # Update arm rewards based on improvement\n                self.arm_rewards[arm] += improvement_ratio\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 39, "feedback": "An exception occurred: IndexError('index 15 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 15 is out of bounds for axis 0 with size 15')", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {}}
{"id": "bef34751-c733-48af-9193-674fc086fc5b", "fitness": 0.055774098539535584, "name": "RefinedAdaptiveSymbioticEvolution", "description": "Incorporate an adaptive learning rate for mutation and crossover based on historical performance trends to further enhance convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.historical_fitness = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            self.historical_fitness.append(np.mean(fitness))\n            \n            if len(self.historical_fitness) > 5:\n                improvement_trend = np.polyfit(range(len(self.historical_fitness[-5:])), self.historical_fitness[-5:], 1)[0]\n                adjustment_factor = 1.0 + np.clip(improvement_trend, -0.1, 0.1)\n                self.mutation_rate = np.clip(self.mutation_rate * adjustment_factor, 0.1, 1.0)\n                self.crossover_rate = np.clip(self.crossover_rate * (2.0 - adjustment_factor), 0.1, 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 40, "feedback": "The algorithm RefinedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05577 with standard deviation 0.00451.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.054625694294184846, 0.05967200405345452, 0.05390867170771463, 0.050020115741953974, 0.054191313786692064, 0.04901355500464144, 0.05859729732663155, 0.06411136634344383, 0.0578268685971034]}}
{"id": "984b6b09-b4e1-4f49-ad03-b6931ea740d5", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Refine parent selection by introducing diversity preservation to improve solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness, diversity)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness, diversity):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities *= (1 + diversity)  # Adjusted for diversity preservation\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 41, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "8f4060c1-b80e-4574-b47f-9a56660090c3", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adaptively adjust population size more frequently for faster response to convergence dynamics.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 20:  # Changed from // 10 to // 20\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 42, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "5c7baab2-06f1-4d0c-816b-1b57ddf29933", "fitness": -Infinity, "name": "DynamicNeighborhoodAdaptiveEvolution", "description": "Introduce adaptive dynamic neighborhood sizing and feedback-driven mutation scaling to balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass DynamicNeighborhoodAdaptiveEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n            \n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n            neighborhood_size = np.maximum(1, int(self.population_size * (fitness_std / (np.abs(avg_fitness) + 1e-8))))\n\n            if fitness_std < 0.1 and self.population_size > 5:\n                self.population_size = max(5, self.population_size - 1)\n            elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                self.population_size = min(100, self.population_size + 1)\n\n            fitness_gradient = np.gradient(fitness)\n            improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n            if improvement_ratio < 0:\n                self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness, neighborhood_size)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness, neighborhood_size):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        selected_indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        for i in range(len(selected_indices)):\n            local_indices = np.argsort(fitness)[:neighborhood_size]\n            selected_indices[i] = np.random.choice(local_indices)\n        return self.population[selected_indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 43, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {}}
{"id": "fded2fc2-489b-4e57-995c-47be9782342a", "fitness": 0.05702158701005119, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Implement a decay factor to gradually reduce mutation rate over time to refine convergence towards the end of the optimization process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                decay_factor = (self.budget - evaluations) / self.budget\n                self.mutation_rate *= decay_factor\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 44, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05702 with standard deviation 0.00467.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.0535385684808507, 0.06073578421911363, 0.058088266286626444, 0.04856293661425104, 0.05536232803525465, 0.0531650843021394, 0.057153340176343215, 0.06419732926518606, 0.062390645710695525]}}
{"id": "b0a396ef-1684-4fe4-9f8b-046d8fd242a4", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive elitism and use diversity-based adaptive crossover to balance exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.elitism_rate = 0.05 + 0.15 * (fitness_std / (np.max(fitness) + 1e-8))  # Adaptive elitism\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "46f6b7a4-b44f-4ce9-8f19-6890951afe13", "fitness": 0.055716398612789084, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Modify elite population integration and mutation strategy to enhance exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[-elite_count:] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i] * 1.2:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05572 with standard deviation 0.00497.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.0539581881438308, 0.04845848352140991, 0.054861294285675655, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.06092856902569277]}}
{"id": "664db9ab-c1d2-43b5-8d3a-8a31d81d6752", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adjust elitism strategy by dynamically altering elite count and introducing random restart for stagnant populations.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            if np.var(fitness) < 1e-5:  # Random restart condition\n                self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n            else:\n                self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 47, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "c5e112b9-ddc1-4091-bf84-72257674c05c", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance convergence by incorporating a fitness-based dynamic mutation rate adjustment.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * (1.1 + 0.1 * (self.best_fitness - fitness[min_idx]) / (np.abs(avg_fitness) + 1e-8)))\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "b5d96842-3cf0-4f53-8a15-b763ce8eeb66", "fitness": 0.055959373213272205, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance exploitation by incorporating a local search strategy to refine the best solution.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                    \n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n            self.best_solution = self._local_search(self.best_solution, func, bounds)  # Line changed\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])\n    \n    def _local_search(self, solution, func, bounds):  # Line added\n        step_size = (bounds[1] - bounds[0]) * 0.01\n        for _ in range(10):\n            candidate = solution + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, bounds[0], bounds[1])\n            if func(candidate) < func(solution):\n                solution = candidate\n        return solution", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05596 with standard deviation 0.00462.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.054723327067689564, 0.05967200405345452, 0.05438968338508743, 0.04936051996361146, 0.054497979632656235, 0.04944890089122567, 0.058704935271137515, 0.06448901015330766, 0.05834799850127981]}}
{"id": "3615ce69-4866-47e2-89b7-f9336198e6dc", "fitness": 0.055523804119825354, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance convergence by adjusting crossover rate based on standard deviation of population fitness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.3 * (fitness_std / (np.max(fitness) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05552 with standard deviation 0.00485.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.0541513745974338, 0.04845848352140991, 0.054191313786692064, 0.04923346006503937, 0.05795460054495405, 0.06467265580738024, 0.058089557741454634]}}
{"id": "27474302-f6bf-41c8-8882-7a113e4641a0", "fitness": 0.05754132020315087, "name": "AdaptiveElitistSymbioticEvolution", "description": "Adaptive Elitist Symbiotic Evolution with Dynamic Population Control: Introduces adaptive elitism and dynamic population sizing to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveElitistSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n                \n                improvement_ratio = (self.best_fitness - fitness[min_idx]) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 51, "feedback": "The algorithm AdaptiveElitistSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "f7544065-24da-43b7-962e-de85df110f65", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a memory mechanism to keep track of best solutions and adaptively adjust mutation rates based on historical performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.best_solutions_memory = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n                self.best_solutions_memory.append(self.best_solution)\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "c2640ad3-1d75-48da-9dd3-cb3e93621031", "fitness": 0.057159244100882356, "name": "EnhancedAdaptiveSymbioticEvolutionV2", "description": "Introduce adaptive scaling of mutation strength and crossover rate using fitness landscape smoothness metrics to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                fitness_landscape_smoothness = np.var(np.gradient(fitness)) / (fitness_std + 1e-8)\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_landscape_smoothness)\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05716 with standard deviation 0.00437.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053714012502111386, 0.06011906905291642, 0.058088266286626444, 0.0508508398838452, 0.05429378140485208, 0.05276334566563845, 0.05761084856066356, 0.06460238784059213, 0.062390645710695525]}}
{"id": "f1a112c6-770a-4675-b6a1-c8670941f5fd", "fitness": 0.05529182112793474, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance the algorithm by adjusting the mutation strength based on the latest improvement in fitness scores.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 + 0.5 * (proximity / (np.max(proximity) + 1e-8))  # Adjusted line 1\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05529 with standard deviation 0.00472.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "933378cc-4ad6-41e9-9c01-6288627b8668", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolutionWithRestart", "description": "Implement an adaptive diversity-driven restart mechanism to prevent premature convergence and improve exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionWithRestart:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.restart_threshold = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n            \n            if fitness_std < self.restart_threshold:\n                self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n                continue\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolutionWithRestart got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "e4afd7fd-e41d-4179-a5e6-f40927a3eacc", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive elitism rate adjustment based on population diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                \n                self.elitism_rate = 0.05 + 0.15 * (1.0 - diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 56, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "8094f29a-dff9-4f23-86cf-6220b82e2d49", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance convergence by dynamically balancing exploration and exploitation using entropy-based population diversity and adaptive mutation strategies.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            entropy = -np.sum((fitness / fitness.sum()) * np.log(fitness / fitness.sum() + 1e-10))\n            normalized_entropy = entropy / np.log(self.population_size)\n            self.mutation_rate = 0.1 + 0.9 * (1.0 - normalized_entropy)\n\n            if evaluations > self.budget // 10:\n                diversity = np.std(self.population, axis=0).mean()\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if normalized_entropy < 0.5 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif normalized_entropy > 0.8 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(np.mean(fitness)) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 57, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {}}
{"id": "ee90774d-3540-471f-b9e4-49094b5aaba8", "fitness": 0.05700723190648693, "name": "MemoryEnhancedAdaptiveSymbioticEvolution", "description": "Implement dynamic memory-based self-adaptation that leverages historical success data to fine-tune mutation and crossover rates, improving convergence and robustness.", "code": "import numpy as np\n\nclass MemoryEnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.memory = {'mutation': [], 'crossover': []}\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.memory['mutation'].append(self.mutation_rate)\n                self.memory['crossover'].append(self.crossover_rate)\n                \n                if len(self.memory['mutation']) > 5:\n                    self.memory['mutation'].pop(0)\n                if len(self.memory['crossover']) > 5:\n                    self.memory['crossover'].pop(0)\n                \n                historical_mutation = np.mean(self.memory['mutation'])\n                historical_crossover = np.mean(self.memory['crossover'])\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8)) * (1 + historical_mutation)\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8)) * (1 + historical_crossover)\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 58, "feedback": "The algorithm MemoryEnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05701 with standard deviation 0.00395.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.056675371848973644, 0.05967200405345452, 0.05390867170771463, 0.0515171890888656, 0.05431692376581709, 0.05292778526968678, 0.06082508071984194, 0.06411136634344383, 0.05911069436058436]}}
{"id": "156b87e0-aa15-452e-a976-adcf4ceec659", "fitness": 0.05678644489600136, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adjust mutation strength based on average fitness improvement to enhance adaptability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            mutation_strength_scaler *= np.mean(fitness_gradient) / (np.abs(avg_fitness) + 1e-8)\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05679 with standard deviation 0.00442.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05567625871120685, 0.05967200405345452, 0.055932205387097755, 0.04927118266044017, 0.05579554987678004, 0.05084292084726527, 0.059755166146444605, 0.06411136634344383, 0.06002135003787923]}}
{"id": "5fc6273f-2e9f-4819-b483-80ba06a91395", "fitness": 0.05674159746122582, "name": "RefinedAdaptiveSymbioticEvolution", "description": "Introduce adaptive learning rates for mutation and crossover based on convergence speed and population diversity to enhance exploitation and exploration balance.", "code": "import numpy as np\n\nclass RefinedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.initial_mutation_rate = 0.5\n        self.initial_crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                mutation_rate = self.initial_mutation_rate * (1.0 - diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                crossover_rate = self.initial_crossover_rate * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                fitness_gradient = np.gradient(fitness)\n                convergence_speed = np.abs(np.mean(fitness_gradient))\n                if convergence_speed < 0.01:\n                    mutation_rate = min(1.0, mutation_rate * 1.05)\n                    crossover_rate = max(0.1, crossover_rate * 0.95)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds, crossover_rate)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler, mutation_rate)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds, crossover_rate):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler, mutation_rate):\n        mutation_strength = (bounds[1] - bounds[0]) * mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 60, "feedback": "The algorithm RefinedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05674 with standard deviation 0.00558.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.054382868683389485, 0.06278227962623506, 0.054071026129650424, 0.04944819017212865, 0.05695775283397286, 0.049160685340556065, 0.058335142340435464, 0.06753386696249908, 0.05800256506216528]}}
{"id": "ac6de374-5683-4ed5-9d0e-455d40cad24a", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adjust elite preservation strategy to enhance solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.05  # Changed from 0.1 to 0.05\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "8cc0d405-8aa9-4dce-a36c-51ec670834bf", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adjust the mutation strength based on the fitness improvement rate to enhance search efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                improvement_factor = 1 - np.abs((fitness[i] - self.best_fitness) / (fitness[i] + 1e-8))  # Change here\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i] * improvement_factor, self.dim)  # Change here\n        return np.clip(offspring, bounds[0], bounds[1]) ", "configspace": "", "generation": 62, "feedback": "An exception occurred: NameError(\"name 'fitness' is not defined\").", "error": "NameError(\"name 'fitness' is not defined\")", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {}}
{"id": "14c067cd-52a2-4e9b-aa8f-5a0e822dd187", "fitness": 0.05691570808725656, "name": "MemoryEnhancedSymbioticEvolution", "description": "Implement a historical memory of successful mutation strategies to dynamically guide parameter adjustments, enhancing the balance between exploration and exploitation.", "code": "import numpy as np\n\nclass MemoryEnhancedSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.memory_size = 5\n        self.memory = []\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if len(self.memory) == self.memory_size:\n                    self.memory.pop(0)\n                self.memory.append((self.mutation_rate, self.crossover_rate))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                else:\n                    self.mutation_rate, self.crossover_rate = np.mean(self.memory, axis=0)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 63, "feedback": "The algorithm MemoryEnhancedSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05692 with standard deviation 0.00470.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.06085095313611222, 0.05831301479062845, 0.049267379505055775, 0.054191313786692064, 0.0525659882624282, 0.057153340176343215, 0.06411136634344383, 0.06249722982399564]}}
{"id": "07aef424-1e40-42fa-b4b1-ec49fd9885e4", "fitness": 0.05754132020315087, "name": "RefinedAdaptiveSymbioticEvolution", "description": "Integrate adaptive elitism and dynamic scaling of the mutation strength based on fitness improvement to enhance convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.min_mutation_rate = 0.1\n        self.max_mutation_rate = 1.0\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n\n            self.mutation_rate = np.clip(\n                0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8)),\n                self.min_mutation_rate, self.max_mutation_rate\n            )\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            fitness_gradient = np.gradient(fitness)\n            improvement_ratio = (self.best_fitness - fitness[min_idx]) / (np.abs(avg_fitness) + 1e-8)\n            if improvement_ratio > 0:\n                self.mutation_rate = max(self.min_mutation_rate, self.mutation_rate * 0.9)\n                self.crossover_rate = min(self.max_mutation_rate, self.crossover_rate * 1.1)\n\n            elite_count = max(1, int(0.1 * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 64, "feedback": "The algorithm RefinedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "987a4448-b5b4-472d-9f28-4b7c5ba8c542", "fitness": 0.055774098539535584, "name": "EnhancedAdaptiveSymbioticEvolutionV2", "description": "Incorporate adaptive learning rate decay and diversity preservation to improve convergence stability and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.learning_rate_decay = 0.995  # New parameter for adaptive decay\n        self.diversity_threshold = 0.1  # New parameter for diversity preservation\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                # Adaptive adjustment with decay\n                self.mutation_rate *= self.learning_rate_decay\n                self.crossover_rate *= self.learning_rate_decay\n\n                if diversity < self.diversity_threshold:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 1.1)\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 65, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolutionV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05577 with standard deviation 0.00451.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.054625694294184846, 0.05967200405345452, 0.05390867170771463, 0.050020115741953974, 0.054191313786692064, 0.04901355500464144, 0.05859729732663155, 0.06411136634344383, 0.0578268685971034]}}
{"id": "edcd75bf-91dc-4616-b2e3-3ec289fbe78c", "fitness": 0.055774098539535584, "name": "AdaptiveLearningEvolution", "description": "Introduce adaptive learning of parameters using historical performance to dynamically adjust the mutation and crossover rates for better convergence.", "code": "import numpy as np\n\nclass AdaptiveLearningEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.performance_history = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n            self.performance_history.append(np.min(fitness))\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if len(self.performance_history) > 10:\n                improvement_trend = np.diff(self.performance_history[-10:])\n                improvement_ratio = np.mean(improvement_trend)\n                self.mutation_rate = 0.5 + 0.5 * np.tanh(improvement_ratio)\n                self.crossover_rate = 0.5 + 0.5 * np.tanh(-improvement_ratio)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 66, "feedback": "The algorithm AdaptiveLearningEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05577 with standard deviation 0.00451.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.054625694294184846, 0.05967200405345452, 0.05390867170771463, 0.050020115741953974, 0.054191313786692064, 0.04901355500464144, 0.05859729732663155, 0.06411136634344383, 0.0578268685971034]}}
{"id": "ae8367c4-1e00-4bf1-83b9-75aa033e4c9f", "fitness": 0.056781961797724115, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Apply a sinusoidal adaptation to the crossover rate for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                \n                self.crossover_rate *= 1 + 0.1 * np.sin(np.pi * evaluations / self.budget)  # Sinusoidal adjustment\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05678 with standard deviation 0.00541.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.059791784223102606, 0.05390867170771463, 0.048535910078275624, 0.05947435843786186, 0.04901355500464144, 0.061920732776113874, 0.06411136634344383, 0.060990490647753526]}}
{"id": "fff4d994-501d-4934-a0df-7e7016013cf6", "fitness": 0.05754132020315087, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive adjustment for population size based on diversity and fitness variations to enhance exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 68, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05754 with standard deviation 0.00460.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05499872376964343, 0.05967200405345452, 0.05786828762457841, 0.04845848352140991, 0.0573371295556071, 0.052967726898929146, 0.0595668798672786, 0.06411136634344383, 0.06289128019401291]}}
{"id": "5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4", "fitness": 0.05825920069901896, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Add stochastic gradient descent-based local search for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce gradient descent-based local search\n            offspring[min_idx] -= 0.01 * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05826 with standard deviation 0.00378.", "error": "", "parent_ids": ["9d59a15e-7c9f-42fb-91d5-0f6f4aaebbf1"], "operator": null, "metadata": {"aucs": [0.05743497127459729, 0.05967200405345452, 0.05832247102125576, 0.05205675961699607, 0.05751521313931074, 0.05257927768995896, 0.06047444156489301, 0.06411136634344383, 0.06216630158726044]}}
{"id": "17a3ccb7-e1fa-4d17-ae6f-97ff580b9375", "fitness": 0.058210330833859895, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Integrate dynamic learning rate adaptation in gradient-descent local search for enhanced convergence efficiency.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.learning_rate = 0.01\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n                \n                # Adjust learning rate based on fitness improvement\n                self.learning_rate *= 1.05 if improvement_ratio < 0 else 0.95\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Apply adaptive learning rate in local search\n            offspring[min_idx] -= self.learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05821 with standard deviation 0.00376.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05735256228388108, 0.05967200405345452, 0.05832200407264987, 0.0520670507798503, 0.05749974006642522, 0.05257862148480574, 0.06012410976444471, 0.06411136634344383, 0.06216551865578379]}}
{"id": "26728385-9312-4ea1-b288-6702730916b5", "fitness": 0.05797341873808464, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduced adaptive learning rate for the gradient descent-based local search to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce adaptive gradient descent-based local search\n            learning_rate = 0.01 * (1.0 / (1.0 + evaluations / self.budget))\n            offspring[min_idx] -= learning_rate * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 71, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05797 with standard deviation 0.00398.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.057087244311176844, 0.05967200405345452, 0.05788086330164499, 0.05071015648117794, 0.05747398523440295, 0.052975083188838146, 0.05920821060758652, 0.06411136634344383, 0.06264185512103604]}}
{"id": "a5fd7673-a19e-4ab7-9a09-875f727622b0", "fitness": 0.05798551431908526, "name": "RefinedSymbioticEvolution", "description": "Leverage adaptive population size, dynamic learning rate adjustment, and hybrid global-local search for enhanced convergence in diverse optimization landscapes.", "code": "import numpy as np\n\nclass RefinedSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Enhanced gradient descent-based local search with dynamic step size\n            learning_rate = 0.01 * (1.0 - evaluations / self.budget)\n            offspring[min_idx] -= learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 72, "feedback": "The algorithm RefinedSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05799 with standard deviation 0.00390.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05701191714558773, 0.05967200405345452, 0.057879998093620766, 0.05111225598426716, 0.05747113207821697, 0.0529745770925476, 0.05899512677895591, 0.06411136634344383, 0.06264125130167286]}}
{"id": "1bcfa172-6b62-4de6-b7e0-6eec26066987", "fitness": 0.05685282922190433, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive dynamic mutation and crossover rates based on convergence speed to improve solution diversity and optimality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.previous_best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.previous_best_fitness = self.best_fitness\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adapt mutation and crossover rates based on convergence speed\n            improvement_rate = (self.previous_best_fitness - self.best_fitness) / (np.abs(self.previous_best_fitness) + 1e-8)\n            if improvement_rate > 0.01:\n                self.mutation_rate = max(0.1, self.mutation_rate * 0.9)\n                self.crossover_rate = min(1.0, self.crossover_rate * 1.1)\n            else:\n                self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce gradient descent-based local search\n            fitness_gradient = np.gradient(fitness)\n            offspring[min_idx] -= 0.01 * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 73, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05685 with standard deviation 0.00653.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.06488476710705215, 0.05390867170771463, 0.048755512006364965, 0.056967510828628165, 0.04901355500464144, 0.057153340176343215, 0.06987445060868136, 0.0578268685971034]}}
{"id": "4057d386-4de0-4396-a0b8-c926c04096f6", "fitness": 0.0582490093910418, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Incorporate a momentum-based update in the gradient descent step for improved local convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.momentum = 0.9  # Initialize a momentum factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce momentum in gradient descent-based local search\n            offspring[min_idx] -= self.momentum * 0.01 * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05825 with standard deviation 0.00368.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05722064802315008, 0.05967200405345452, 0.058321990805293544, 0.05229614568738472, 0.05748486336279346, 0.05297586533612586, 0.05951541260188353, 0.06411136634344383, 0.06264278830584669]}}
{"id": "a1a3004b-2b59-4201-88f6-0625ff2a41bd", "fitness": 0.05613601913744605, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce dynamic adaptive mutation and crossover strategies based on diversity and historical improvements to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Update mutation and crossover strategies based on population diversity and improvements\n            diversity = np.std(self.population, axis=0).mean()\n            improvement = (self.best_fitness - np.mean(fitness)) / (np.abs(np.mean(fitness)) + 1e-8)\n            self.mutation_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n            self.crossover_rate = 0.7 - 0.5 * max(0, improvement)\n\n            if evaluations > self.budget // 10:\n                fitness_std = np.std(fitness)\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce gradient descent-based local search\n            fitness_gradient = np.gradient(fitness)\n            offspring[min_idx] -= 0.01 * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05614 with standard deviation 0.00441.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05597532933839644, 0.048948489812295826, 0.054191313786692064, 0.05180921608919287, 0.057153340176343215, 0.06411136634344383, 0.06007232567658605]}}
{"id": "b8ee1cff-9118-4bc7-8c79-a8b60594d2f5", "fitness": 0.05620962568180795, "name": "MemoryEnhancedSymbioticEvolution", "description": "Introduce memory-based adaptive mutation and crossover strategies to better balance exploration and exploitation.", "code": "import numpy as np\n\nclass MemoryEnhancedSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.initial_mutation_rate = 0.5\n        self.initial_crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.memory_mutation_rate = []\n        self.memory_crossover_rate = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                if len(self.memory_mutation_rate) > 5:\n                    self.initial_mutation_rate = np.mean(self.memory_mutation_rate[-5:])\n                self.memory_mutation_rate.append(self.initial_mutation_rate)\n\n                if len(self.memory_crossover_rate) > 5:\n                    self.initial_crossover_rate = np.mean(self.memory_crossover_rate[-5:])\n                self.memory_crossover_rate.append(self.initial_crossover_rate)\n\n                self.mutation_rate = self.initial_mutation_rate * (1 - fitness[min_idx] / (avg_fitness + 1e-8))\n                self.crossover_rate = self.initial_crossover_rate * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            fitness_gradient = np.gradient(fitness)\n            offspring[min_idx] -= 0.01 * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 76, "feedback": "The algorithm MemoryEnhancedSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05621 with standard deviation 0.00524.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.06355645095692597, 0.0540800451050939, 0.04845848352140991, 0.058054973898912565, 0.04916885088570666, 0.057153340176343215, 0.06411136634344383, 0.058012333287825846]}}
{"id": "e038dd05-6ce4-4034-8ade-c5e7a850d731", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolutionV2", "description": "Introduce adaptive step size in gradient descent-based local search and diversify the population via non-uniform mutation to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - np.std(fitness) / (np.abs(np.mean(fitness)) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if np.std(fitness) < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif np.std(fitness) > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(np.mean(fitness)) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            step_size = 0.01 / (1 + evaluations / self.budget)\n            offspring[min_idx] -= step_size * np.gradient(fitness)[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                non_uniform_strength = mutation_strength * ((1 - evaluations / self.budget) ** 2)\n                offspring[i] += np.random.normal(0, non_uniform_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 77, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {}}
{"id": "098b18b1-0755-449a-b3af-0832d418eb83", "fitness": 0.05602208075200857, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Incorporate adaptive learning rates and dynamic parameter control to enhance exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.learning_rate = 0.01\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce adaptive gradient descent-based local search\n            local_search_idx = np.random.choice(range(self.population_size), size=1, replace=False)\n            offspring[local_search_idx] -= self.learning_rate * fitness_gradient[local_search_idx] \n            self.adjust_learning_rate(fitness[min_idx])\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def adjust_learning_rate(self, current_best_fitness):\n        if current_best_fitness < self.best_fitness:\n            self.learning_rate *= 1.05\n        else:\n            self.learning_rate *= 0.95\n        self.learning_rate = max(0.001, min(self.learning_rate, 0.1))", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05602 with standard deviation 0.00432.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05423656759006834, 0.059973665468523785, 0.05393984149269704, 0.05199731001844976, 0.054191313786692064, 0.04901355500464144, 0.05848711289292541, 0.06411136634344383, 0.05824799417063542]}}
{"id": "2f8cc42f-ffa6-494d-b75d-4c76f8bd7333", "fitness": 0.05529182112793474, "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by incorporating adaptive differential evolution with local search.", "code": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            # Adaptive mutation and crossover based on success history\n            mutation_factor = np.clip(np.random.normal(self.mutation_factor, 0.1), 0.5, 1.0)\n            crossover_prob = np.clip(np.random.normal(self.crossover_prob, 0.1), 0.5, 1.0)\n\n            offspring = self._differential_evolution(self.population, fitness, mutation_factor, crossover_prob, bounds)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce adaptive local search around the best solution found\n            for i in range(elite_count):\n                gradient_step = 0.01 * (self.best_solution - offspring[i])\n                offspring[i] = np.clip(offspring[i] + gradient_step, bounds[0], bounds[1])\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _differential_evolution(self, population, fitness, mutation_factor, crossover_prob, bounds):\n        offspring = np.empty_like(population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = population[indices]\n            mutant_vector = np.clip(a + mutation_factor * (b - c), bounds[0], bounds[1])\n            cross_points = np.random.rand(self.dim) < crossover_prob\n            offspring[i] = np.where(cross_points, mutant_vector, population[i])\n        return offspring", "configspace": "", "generation": 79, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05529 with standard deviation 0.00472.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.05967200405345452, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "a0711a0b-cdb5-4b2b-8ed0-0b10a34f7393", "fitness": 0.05562569259218456, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive sampling and elitist reinforcement to optimize population by focusing on promising solutions and diversifying search.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.adaptive_sampling_rate = 0.2\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Adaptive sampling\n            additional_samples = int(self.adaptive_sampling_rate * self.population_size)\n            if evaluations + additional_samples <= self.budget:\n                random_samples = np.random.uniform(bounds[0], bounds[1], (additional_samples, self.dim))\n                sample_fitness = np.apply_along_axis(func, 1, random_samples)\n                evaluations += additional_samples\n                best_sample_idx = np.argmin(sample_fitness)\n                if sample_fitness[best_sample_idx] < self.best_fitness:\n                    self.best_solution = random_samples[best_sample_idx].copy()\n                    self.best_fitness = sample_fitness[best_sample_idx]\n\n            offspring[min_idx] -= 0.01 * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 80, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05563 with standard deviation 0.00446.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05489932310946999, 0.05967200405345452, 0.05393751321112561, 0.04976860098053226, 0.054191313786692064, 0.04903970516849465, 0.057153340176343215, 0.06411136634344383, 0.05785806650010494]}}
{"id": "f801c35f-ca04-412d-bbe2-a58bb0c2afef", "fitness": 0.05825920069901896, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance local search with adaptive learning rate for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                \n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            # Introduce gradient descent-based local search with adaptive learning rate\n            learning_rate = 0.01 * (1 - improvement_ratio)\n            offspring[min_idx] -= learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05826 with standard deviation 0.00378.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.05743497127459729, 0.05967200405345452, 0.05832247102125576, 0.05205675961699607, 0.05751521313931074, 0.05257927768995896, 0.06047444156489301, 0.06411136634344383, 0.06216630158726044]}}
{"id": "c9ae73e6-d2ab-4eae-a1d2-a6c7eabacfc7", "fitness": 0.05552150592656427, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Adaptively balance exploration and exploitation by integrating velocity-based search and adaptive mutation control to efficiently navigate diverse landscapes.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.velocities = None\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n\n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            if fitness_std < 0.1 and self.population_size > 5:\n                self.population_size = max(5, self.population_size - 1)\n            elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            # Introduce velocity-based search mechanism\n            inertia_weight = 0.7\n            cognitive_component = 1.5\n            social_component = 1.5\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.velocities = (inertia_weight * self.velocities +\n                               cognitive_component * r1 * (self.population - offspring) +\n                               social_component * r2 * (self.best_solution - self.population))\n            offspring += self.velocities\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = np.clip(offspring, bounds[0], bounds[1])\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05552 with standard deviation 0.00492.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.053290786960609626, 0.061172128023812444, 0.05390867170771463, 0.04845848352140991, 0.054191313786692064, 0.04901355500464144, 0.057720379393651045, 0.06411136634344383, 0.0578268685971034]}}
{"id": "bd540626-2dbe-4a1e-a867-65fd9167b72f", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Enhance population diversity and solution refinement by introducing adaptive learning rates and merging with a Pareto-based selection mechanism.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + int(2.5 * np.sqrt(dim))  # Increased base population size\n        self.mutation_rate = 0.6  # Slightly higher initial mutation rate\n        self.crossover_rate = 0.75  # Adjusted crossover rate\n        self.elitism_rate = 0.15  # Increased elitism rate\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n                \n                self.mutation_rate = 0.2 + 0.8 * (1.0 - diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = 0.6 + 0.4 * (diversity / (np.abs(avg_fitness) + 1e-8))\n                \n                if diversity < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif diversity > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(120, self.population_size + 1)\n\n                # Pareto-based selection mechanism\n                sorted_indices = np.lexsort((fitness,))\n                self.population = self.population[sorted_indices]\n                fitness = fitness[sorted_indices]\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n            \n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            fitness_gradient = np.gradient(fitness)\n            learning_rate = 0.01 * (1 - evaluations / self.budget)\n            offspring[min_idx] -= learning_rate * fitness_gradient[min_idx] \n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        probabilities = 1.0 / (1.0 + fitness)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(len(self.population), self.population_size, p=probabilities)\n        return self.population[indices]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 83, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 23').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 23')", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {}}
{"id": "7078fe98-a461-417c-af8f-a0fa6951e244", "fitness": 0.061482138844085786, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive learning rate for local search and improved parent selection using tournament method.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06148 with standard deviation 0.00508.", "error": "", "parent_ids": ["5a2fb4c1-49e7-4614-ba4f-6e3cb7650fd4"], "operator": null, "metadata": {"aucs": [0.058335788071067984, 0.06512739119221822, 0.06148257008619884, 0.053011739238058575, 0.060381886820731534, 0.05578179705691455, 0.06263278139055717, 0.07046781482744935, 0.06611748091357583]}}
{"id": "931d4fb1-16be-4995-978f-fa6f6e8bd535", "fitness": 0.05555655268646869, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce differential evolution strategy with adaptive mutation scaling and elitism retention.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._differential_evolution(parents, bounds)\n            offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _differential_evolution(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(self.population_size):\n            idxs = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[idxs]\n            mutant = np.clip(a + self.mutation_rate * (b - c), bounds[0], bounds[1])\n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            offspring[i] = np.where(cross_points, mutant, parents[i])\n        return offspring", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05556 with standard deviation 0.00465.", "error": "", "parent_ids": ["7078fe98-a461-417c-af8f-a0fa6951e244"], "operator": null, "metadata": {"aucs": [0.05558703392197628, 0.05967200405345452, 0.05390867170771463, 0.04851125984182414, 0.054191313786692064, 0.04904711574966614, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "016aec70-f787-4541-ba99-799da20b9ce6", "fitness": 0.06133552038827117, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Refine mutation strategy and adaptively adjust crossover rate based on diversity.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.4 + 0.6 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim) * (1 - mutation_strength_scaler[i])\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 86, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06134 with standard deviation 0.00456.", "error": "", "parent_ids": ["7078fe98-a461-417c-af8f-a0fa6951e244"], "operator": null, "metadata": {"aucs": [0.058335788071067984, 0.06566347056740596, 0.05962551920762238, 0.05680001688235281, 0.060137371065313805, 0.05453905788707336, 0.06263278139055717, 0.07023486738494245, 0.06405081103810462]}}
{"id": "ce9efe75-8394-4c2e-bde9-f0e660f8ce5f", "fitness": 0.059619285513113435, "name": "DynamicPopulationAdaptiveEvolution", "description": "Introduce dynamic population adaptation with a focus on diversity preservation and targeted elitism for enhanced convergence.", "code": "import numpy as np\n\nclass DynamicPopulationAdaptiveEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + int(2 * np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.mean(np.std(self.population, axis=0))\n\n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            if diversity < 0.1:\n                self.population_size = min(100, self.population_size + 2)\n            elif diversity > 0.5 and self.population_size > self.initial_population_size:\n                self.population_size = max(self.initial_population_size, self.population_size - 2)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            mutation_strength_scaler = (1 - (fitness - fitness[min_idx]) / (np.abs(avg_fitness) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * fitness_std)))\n            offspring[min_idx] -= adaptive_learning_rate * np.gradient(fitness)[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicPopulationAdaptiveEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05962 with standard deviation 0.00518.", "error": "", "parent_ids": ["7078fe98-a461-417c-af8f-a0fa6951e244"], "operator": null, "metadata": {"aucs": [0.0577011538780029, 0.06624657057577765, 0.057157598969079015, 0.05221774629092624, 0.05844102495770753, 0.052616281757113526, 0.062194418160471, 0.06799023890628031, 0.06200853612266277]}}
{"id": "4308048c-bd0c-4f38-8e9d-267bc1dc057b", "fitness": 0.06160215784537932, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a dynamic crossover strategy adjusting based on fitness diversity to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 88, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06160 with standard deviation 0.00521.", "error": "", "parent_ids": ["7078fe98-a461-417c-af8f-a0fa6951e244"], "operator": null, "metadata": {"aucs": [0.058335788071067984, 0.06590619977127132, 0.06148257008619884, 0.053011739238058575, 0.060381886820731534, 0.05575237817292977, 0.06263278139055717, 0.07079859614402284, 0.06611748091357583]}}
{"id": "f96804a8-fdb5-4741-9cee-ed6fbd3441cb", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolutionV2", "description": "Introduce adaptive learning rate and mutation strategy based on population diversity and fitness gradient to enhance convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = np.clip(1 - (proximity / (np.max(proximity) + 1e-8)), 0.5, 1.0)\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 89, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {}}
{"id": "79584384-43e2-4c87-ad2c-234c5b0c8e0b", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolutionV2", "description": "Introduce adaptive elitism with diversity-based scaling to enhance robustness against premature convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolutionV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            diversity_scaler = (diversity / (np.abs(avg_fitness) + 1e-8))\n            elite_count = int(elite_count * (1.0 + diversity_scaler))\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population[:min(elite_count, elite_population.shape[0])]\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 90, "feedback": "An exception occurred: IndexError('index 15 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 15 is out of bounds for axis 0 with size 15')", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {}}
{"id": "5e16adc1-f899-4653-b930-451c9a2f9016", "fitness": 0.0555363367804727, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a self-adaptive mutation strength strategy based on historical performance to enhance convergence speed and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n        self.historical_mutation_strength = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n\n            # Historical mutation strength adjustment\n            avg_improvement = self._calculate_average_improvement(fitness)\n            mutation_strength_scaler = self._adjust_mutation_strength(avg_improvement)\n            self.historical_mutation_strength.append(mutation_strength_scaler)\n            if len(self.historical_mutation_strength) > 10:\n                self.historical_mutation_strength.pop(0)\n\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler, self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _calculate_average_improvement(self, fitness):\n        prev_avg_fitness = np.inf if not self.historical_mutation_strength else np.mean(self.historical_mutation_strength)\n        current_avg_fitness = np.mean(fitness)\n        improvement = prev_avg_fitness - current_avg_fitness\n        return improvement\n\n    def _adjust_mutation_strength(self, improvement):\n        if improvement > 0:\n            return min(2.0, self.mutation_rate * (1 + improvement))\n        else:\n            return max(0.1, self.mutation_rate * (1 + improvement))", "configspace": "", "generation": 91, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05554 with standard deviation 0.00447.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.05384965658153551, 0.05967200405345452, 0.05390867170771463, 0.04987280991839216, 0.0544187586416256, 0.04901355500464144, 0.057153340176343215, 0.06411136634344383, 0.0578268685971034]}}
{"id": "245c37c4-56ff-413b-a626-b5236659ef13", "fitness": 0.05671358513075597, "name": "EnhancedInertiaSymbioticEvolution", "description": "Integrate adaptive inertia weight and dynamic multi-parent crossover for enhanced convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedInertiaSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.inertia_weight = 0.9\n        self.population = None\n        self.velocities = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n            \n            self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            \n            if fitness_std < 0.1 and self.population_size > 5:\n                self.population_size = max(5, self.population_size - 1)\n            elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._multi_parent_crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n            self.velocities = self.inertia_weight * self.velocities + np.random.uniform(-1, 1, (self.population_size, self.dim))\n            self.population += self.velocities\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _multi_parent_crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                mix_ratio = np.random.uniform(size=self.dim)\n                offspring[i] = mix_ratio * parents[i] + (1 - mix_ratio) * parents[i+1]\n                offspring[i+1] = (1 - mix_ratio) * parents[i] + mix_ratio * parents[i+1]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedInertiaSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05671 with standard deviation 0.00418.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.05639819306885374, 0.05967200405345452, 0.05484318770459806, 0.0508127370581033, 0.054191313786692064, 0.05117203214263044, 0.060364014891472806, 0.06411136634344383, 0.05885741712755499]}}
{"id": "01843be0-a05d-4105-a2f8-0f6daaf47dee", "fitness": -Infinity, "name": "EnhancedLocalizedAdaptiveSymbioticEvolution", "description": "Enhance exploitation by utilizing an adaptive local search guided by the elite population to refine solutions near the best-known fitness.", "code": "import numpy as np\n\nclass EnhancedLocalizedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            # Local search enhancement\n            local_search_radius = 0.1 * (bounds[1] - bounds[0])\n            for elite in elite_population:\n                refined = elite + np.random.uniform(-local_search_radius, local_search_radius, self.dim)\n                refined = np.clip(refined, bounds[0], bounds[1])\n                refined_fitness = func(refined)\n                evaluations += 1\n                if refined_fitness < self.best_fitness:\n                    self.best_fitness = refined_fitness\n                    self.best_solution = refined.copy()\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 93, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {}}
{"id": "43934af9-4c9e-4ccd-be8e-8cc407385bc5", "fitness": 0.05997566797550988, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Slightly increase the elitism rate to retain more top solutions for convergence improvement.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.15  # Increased from 0.1 to 0.15\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05998 with standard deviation 0.00516.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.05819132387491355, 0.0647334324731027, 0.057910872105790934, 0.05282262811020344, 0.05926407403504963, 0.05262254665563504, 0.06246777724203478, 0.06959138391074338, 0.062176973372115474]}}
{"id": "c5f63151-31f8-4dff-a2e5-93f58f07ab9b", "fitness": 0.06160215784537932, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce adaptive mutation and crossover scaling based on historical performance to fine-tune exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n        historical_improvement = []\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n\n                historical_improvement.append(improvement_ratio)\n                if len(historical_improvement) > 5:\n                    historical_improvement.pop(0)\n                \n                avg_improvement = np.mean(historical_improvement)\n                if avg_improvement < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 95, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06160 with standard deviation 0.00521.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.058335788071067984, 0.06590619977127132, 0.06148257008619884, 0.053011739238058575, 0.060381886820731534, 0.05575237817292977, 0.06263278139055717, 0.07079859614402284, 0.06611748091357583]}}
{"id": "bd63ed8e-bba0-4438-aeb8-6d3deb20a18a", "fitness": -Infinity, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a multi-faceted mutation strategy incorporating adaptive scaling and directional bias to refine solution quality.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.2)  # Adjusted scaling\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.85)  # Adjusted scaling\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler, fitness_gradient[min_idx]) # Directional bias\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler, gradient):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                directional_mutation = np.sign(gradient) * mutation_strength\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim) + directional_mutation\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 96, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {}}
{"id": "81b6086a-b487-438d-a405-1a9e0041f8d0", "fitness": 0.06097397632090537, "name": "EnhancedDifferentialSymbioticEvolution", "description": "Introduce an enhanced adaptive strategy using differential evolution principles for dynamic mutation and crossover adjustments based on population convergence and diversity.", "code": "import numpy as np\n\nclass EnhancedDifferentialSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.8\n        self.crossover_rate = 0.9\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            avg_fitness = np.mean(fitness)\n            fitness_std = np.std(fitness)\n            diversity = np.std(self.population, axis=0).mean()\n\n            self.mutation_rate = 0.2 + 0.8 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n            self.crossover_rate = 0.7 + 0.3 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n\n            if evaluations > 0.5 * self.budget:\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedDifferentialSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06097 with standard deviation 0.00475.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.05957528462417927, 0.06446362199416045, 0.05993605018549364, 0.053965392652361, 0.05844526847772369, 0.05460177339152994, 0.06399371936065745, 0.06939305327486167, 0.06439162292718126]}}
{"id": "f7bbf5c8-9306-484d-9cc7-721c2a189e9e", "fitness": 0.06160215784537932, "name": "FeedbackDrivenSymbioticEvolution", "description": "Incorporate a feedback-driven parameter adaptation strategy that adjusts mutation and crossover rates based on performance trends to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass FeedbackDrivenSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                # Update mutation and crossover rates based on recent performance trend\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                # Adjust population size dynamically based on fitness stability\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler):\n        mutation_strength = (bounds[1] - bounds[0]) * self.mutation_rate\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 98, "feedback": "The algorithm FeedbackDrivenSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06160 with standard deviation 0.00521.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.058335788071067984, 0.06590619977127132, 0.06148257008619884, 0.053011739238058575, 0.060381886820731534, 0.05575237817292977, 0.06263278139055717, 0.07079859614402284, 0.06611748091357583]}}
{"id": "80c35ddc-6d25-4822-8fa7-c6f4ad74aa30", "fitness": 0.06165917469580995, "name": "EnhancedAdaptiveSymbioticEvolution", "description": "Introduce a dynamic and adaptive mutation strategy based on fitness convergence to enhance local search capabilities.", "code": "import numpy as np\n\nclass EnhancedAdaptiveSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + int(2 * np.sqrt(dim))\n        self.mutation_rate = 0.5\n        self.crossover_rate = 0.7\n        self.elitism_rate = 0.1\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = np.inf\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub])\n        self.population = np.random.uniform(bounds[0], bounds[1], (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            fitness = np.apply_along_axis(func, 1, self.population)\n            evaluations += self.population_size\n\n            elite_count = max(1, int(self.elitism_rate * self.population_size))\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elite_population = self.population[elite_indices]\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = self.population[min_idx].copy()\n\n            if evaluations > self.budget // 10:\n                avg_fitness = np.mean(fitness)\n                fitness_std = np.std(fitness)\n                diversity = np.std(self.population, axis=0).mean()\n\n                self.mutation_rate = 0.1 + 0.9 * (1.0 - fitness_std / (np.abs(avg_fitness) + 1e-8))\n                self.crossover_rate = 0.5 + 0.5 * (diversity / (np.max(np.std(self.population, axis=0)) + 1e-8))\n                self.crossover_rate = max(0.3, self.crossover_rate - 0.1 * (fitness_std / (np.abs(avg_fitness) + 1e-8)))\n\n                if fitness_std < 0.1 and self.population_size > 5:\n                    self.population_size = max(5, self.population_size - 1)\n                elif fitness_std > 0.5 and evaluations + self.population_size <= self.budget:\n                    self.population_size = min(100, self.population_size + 1)\n\n                fitness_gradient = np.gradient(fitness)\n                improvement_ratio = (fitness[min_idx] - self.best_fitness) / (np.abs(avg_fitness) + 1e-8)\n                if improvement_ratio < 0:\n                    self.mutation_rate = min(1.0, self.mutation_rate * 1.1)\n                    self.crossover_rate = max(0.1, self.crossover_rate * 0.9)\n\n            parents = self._select_parents(fitness)\n            offspring = self._crossover(parents, bounds)\n            proximity = np.linalg.norm(self.population - self.best_solution, axis=1)\n            mutation_strength_scaler = 1 - (proximity / (np.max(proximity) + 1e-8))\n            adaptive_mutation_strength = self.mutation_rate * (1 + 0.5 * (1 - np.tanh(fitness[min_idx] / (np.abs(avg_fitness) + 1e-8))))\n            offspring = self._mutate(offspring, bounds, mutation_strength_scaler, adaptive_mutation_strength)\n\n            if elite_count > 0:\n                offspring[:elite_count] = elite_population\n\n            adaptive_learning_rate = 0.01 * (1.0 / (1.0 + np.exp(-5 * improvement_ratio)))\n            offspring[min_idx] -= adaptive_learning_rate * fitness_gradient[min_idx]\n\n            self.population = offspring\n\n        return self.best_solution\n\n    def _select_parents(self, fitness):\n        tournament_size = 3\n        indices = np.random.randint(0, len(self.population), (self.population_size, tournament_size))\n        tournament_fitness = fitness[indices]\n        winners = indices[np.arange(self.population_size), np.argmin(tournament_fitness, axis=1)]\n        return self.population[winners]\n\n    def _crossover(self, parents, bounds):\n        offspring = np.empty_like(parents)\n        for i in range(0, self.population_size, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                offspring[i][:crossover_point] = parents[i][:crossover_point]\n                offspring[i][crossover_point:] = parents[i+1][crossover_point:]\n                offspring[i+1][:crossover_point] = parents[i+1][:crossover_point]\n                offspring[i+1][crossover_point:] = parents[i][crossover_point:]\n            else:\n                offspring[i], offspring[i+1] = parents[i], parents[i+1]\n        return np.clip(offspring, bounds[0], bounds[1])\n\n    def _mutate(self, offspring, bounds, mutation_strength_scaler, adaptive_mutation_strength):\n        mutation_strength = (bounds[1] - bounds[0]) * adaptive_mutation_strength\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate * mutation_strength_scaler[i]:\n                offspring[i] += np.random.normal(0, mutation_strength * mutation_strength_scaler[i], self.dim)\n        return np.clip(offspring, bounds[0], bounds[1])", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06166 with standard deviation 0.00526.", "error": "", "parent_ids": ["4308048c-bd0c-4f38-8e9d-267bc1dc057b"], "operator": null, "metadata": {"aucs": [0.058966377811331516, 0.06600587577564976, 0.06149195087223558, 0.053011739238058575, 0.05942637604684009, 0.05604628463806349, 0.06265367409742784, 0.07116471141478176, 0.06616558236790093]}}
