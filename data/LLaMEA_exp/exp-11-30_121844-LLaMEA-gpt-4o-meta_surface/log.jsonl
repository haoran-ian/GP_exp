{"id": "00acd1c9-7ace-4c2b-b727-acaadd0bccfa", "fitness": 0.6775207714016176, "name": "AdaptivePSO", "description": "A novel Particle Swarm Optimization (PSO) variant with adaptive inertia and velocity clamping for efficient exploration and exploitation in dynamic search spaces.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                self.velocities[i] = np.clip(self.velocities[i], -1.0, 1.0)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.9181312600029, 0.12352482044081026, 0.9909062337611425]}}
{"id": "04838701-b123-4cea-92ad-d54d66be7c22", "fitness": 0.6638375368473998, "name": "AdaptivePSO", "description": "Introduce a random restarting mechanism to escape local optima and improve convergence.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                self.velocities[i] = np.clip(self.velocities[i], -1.0, 1.0)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Random restart mechanism\n            if eval_count % (self.budget // 10) == 0:  # Restart every 10% of the budget\n                worst_indices = np.argsort(self.personal_best_values)[-int(self.swarm_size * 0.1):]\n                self.positions[worst_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(worst_indices), self.dim))\n                self.velocities[worst_indices] = np.random.uniform(-1.0, 1.0, (len(worst_indices), self.dim))\n                for idx in worst_indices:\n                    self.personal_best_values[idx] = float('inf')\n                    self.personal_best_positions[idx] = self.positions[idx]\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": ["00acd1c9-7ace-4c2b-b727-acaadd0bccfa"], "operator": null, "metadata": {"aucs": [0.9432886865213359, 0.11890855342032047, 0.9293153706005427]}}
{"id": "118fef79-c58b-4e35-9393-ab10eddeb377", "fitness": 0.7144663464136215, "name": "AdaptivePSO", "description": "A refined version of Adaptive Particle Swarm Optimization (PSO) with enhanced exploration capacities using dynamic velocity bounds.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": ["00acd1c9-7ace-4c2b-b727-acaadd0bccfa"], "operator": null, "metadata": {"aucs": [0.9909430056744358, 0.15701293948269757, 0.9954430940837307]}}
{"id": "bcb82220-bdca-42f9-97c0-7a590a3b2dde", "fitness": 0.41104442520002077, "name": "AdaptivePSO", "description": "Enhanced exploration through dynamic swarm resizing.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Dynamic swarm resizing\n            if eval_count % (self.budget // 10) == 0:\n                self.swarm_size = max(10, int(self.swarm_size * 0.9))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": ["118fef79-c58b-4e35-9393-ab10eddeb377"], "operator": null, "metadata": {"aucs": [0.9617038349356858, 0.11890855342032047, 0.15252088724405588]}}
{"id": "af16e75b-3201-458f-89c7-67117f6555f7", "fitness": 0.45143107347103956, "name": "AdaptivePSO", "description": "Enhanced AdaptivePSO with dynamic component coefficients to improve convergence speed and exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                self.c1 = 2.0 - eval_count / (2 * self.budget)\n                self.c2 = 2.0 + eval_count / (2 * self.budget)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.38 on similar problems with similar landscape features.", "error": "", "parent_ids": ["118fef79-c58b-4e35-9393-ab10eddeb377"], "operator": null, "metadata": {"aucs": [0.13531993454109303, 0.9915437023493987, 0.227429583522627]}}
{"id": "41a4a16e-60a8-42bf-88b1-4e62255768e2", "fitness": 0.41104442520002077, "name": "AdaptivePSO", "description": "Introducing a random restart mechanism to escape local optima by resetting a fraction of the swarm.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Random restart a fraction of the swarm to escape local optima\n            if eval_count % (self.budget // 10) == 0:  # Every 10% of the budget\n                num_to_restart = self.swarm_size // 5  # Restart 20% of the swarm\n                indices_to_restart = np.random.choice(self.swarm_size, num_to_restart, replace=False)\n                self.positions[indices_to_restart] = np.random.uniform(self.lower_bound, self.upper_bound, (num_to_restart, self.dim))\n                self.velocities[indices_to_restart] = np.random.uniform(-1.0, 1.0, (num_to_restart, self.dim))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": ["118fef79-c58b-4e35-9393-ab10eddeb377"], "operator": null, "metadata": {"aucs": [0.9617038349356858, 0.11890855342032047, 0.15252088724405588]}}
{"id": "ff11ec10-897f-4459-9652-33eb367195f6", "fitness": 0.8672380031993591, "name": "AdaptivePSO", "description": "Enhanced Adaptive PSO with dynamic swarm size reduction for improved convergence rate.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Reduce swarm size dynamically for faster convergence\n            if eval_count > self.budget * 0.5:\n                self.swarm_size = max(1, int(self.swarm_size * 0.9))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87 with standard deviation 0.14 on similar problems with similar landscape features.", "error": "", "parent_ids": ["118fef79-c58b-4e35-9393-ab10eddeb377"], "operator": null, "metadata": {"aucs": [0.6671468900995459, 0.9881743142580506, 0.9463928052404811]}}
{"id": "e25bfcf2-5307-4bec-a373-673938be8ad5", "fitness": 0.6858162016881414, "name": "AdaptivePSO", "description": "Enhanced Adaptive PSO with dynamic learning factors for better exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n\n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Dynamically adjust learning factors\n            self.c1 = 2.5 - (eval_count / self.budget) * 1.5\n            self.c2 = 0.5 + (eval_count / self.budget) * 1.5\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Reduce swarm size dynamically for faster convergence\n            if eval_count > self.budget * 0.5:\n                self.swarm_size = max(1, int(self.swarm_size * 0.9))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.42 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ff11ec10-897f-4459-9652-33eb367195f6"], "operator": null, "metadata": {"aucs": [0.9925414620032832, 0.09310407488774253, 0.9718030681733986]}}
{"id": "29d2550b-2e0d-46cc-9676-4d4c49d04a3d", "fitness": 0.9699758768890497, "name": "AdaptivePSO", "description": "Introduce a stochastic perturbation in velocity update for enhanced exploration.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                stochastic_perturbation = np.random.normal(0, 0.1, self.dim)  # Line modified\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity + stochastic_perturbation\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Reduce swarm size dynamically for faster convergence\n            if eval_count > self.budget * 0.5:\n                self.swarm_size = max(1, int(self.swarm_size * 0.9))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["ff11ec10-897f-4459-9652-33eb367195f6"], "operator": null, "metadata": {"aucs": [0.9802285074726018, 0.9590681877522996, 0.9706309354422478]}}
{"id": "1a46126a-d283-481f-ad9b-e536ad164cf7", "fitness": 0.885264005243911, "name": "AdaptivePSO", "description": "Integrate dynamic learning factors and a decay mechanism to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdaptivePSO:\n    def __init__(self, budget, dim, swarm_size=30, inertia_bounds=(0.4, 0.9), c1=2.0, c2=2.0):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.c1 = c1\n        self.c2 = c2\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (swarm_size, dim))\n        self.velocities = np.random.uniform(-1.0, 1.0, (swarm_size, dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(swarm_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def __call__(self, func):\n        eval_count = 0\n        while eval_count < self.budget:\n            # Evaluate fitness\n            for i in range(self.swarm_size):\n                fitness = func(self.positions[i])\n                eval_count += 1\n                if fitness < self.personal_best_values[i]:\n                    self.personal_best_values[i] = fitness\n                    self.personal_best_positions[i] = self.positions[i]\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight\n            inertia_weight = self.inertia_bounds[1] - ((self.inertia_bounds[1] - self.inertia_bounds[0]) * (eval_count / self.budget))\n            \n            # Update velocities and positions with dynamic learning factors\n            for i in range(self.swarm_size):\n                c1_decay = self.c1 * (1 - eval_count / self.budget)\n                c2_growth = self.c2 * (eval_count / self.budget)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = c1_decay * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_velocity = c2_growth * r2 * (self.global_best_position - self.positions[i])\n                stochastic_perturbation = np.random.normal(0, 0.1, self.dim)\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity + stochastic_perturbation\n\n                # Clamp velocities to prevent excessive movement\n                velocity_bound = 1.0 - (eval_count / self.budget) * 0.5\n                self.velocities[i] = np.clip(self.velocities[i], -velocity_bound, velocity_bound)\n\n                # Update positions\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n\n            # Introduce a decay mechanism in swarm size for faster convergence\n            if eval_count > self.budget * 0.5:\n                self.swarm_size = max(1, int(self.swarm_size * 0.8))  # Changed rate\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.05 on the real problem.", "error": "", "parent_ids": ["29d2550b-2e0d-46cc-9676-4d4c49d04a3d"], "operator": null, "metadata": {"aucs": [0.9201499813914463, 0.8103685158875329, 0.925273518452754]}}
