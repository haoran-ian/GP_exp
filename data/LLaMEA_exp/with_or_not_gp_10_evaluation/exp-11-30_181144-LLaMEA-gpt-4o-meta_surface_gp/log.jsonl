{"id": "d20daf78-7bfa-4aca-a46e-88fdf20a119d", "fitness": 0.5385333333333334, "name": "DynamicPSO", "description": "A novel Particle Swarm Optimization (PSO) variant using dynamic inertia weight and local search to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 0, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001, 0.50005, 0.55365, 0.5619000000000001]}}
{"id": "4fae1bac-7e9a-4be1-a267-f219c48e54a5", "fitness": 0.5379166666666666, "name": "DynamicPSO", "description": "Enhanced convergence by altering the frequency of local search adjustments to improve global best updates.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 8 == 0:  # Change: Alter the frequency of local search from 10 to 8\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 1, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736, 0.50005, 0.5401, 0.5736]}}
{"id": "1a11b750-ffcc-4fe2-bb56-139ad01ae4c5", "fitness": 0.4637333333333334, "name": "DynamicPSO", "description": "An enhanced PSO with adaptive cognitive and social parameters, improving convergence balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                # Adjusting cognitive and social coefficients\n                self.c1 = 2.5 - 0.5 * (self.func_evals / self.budget)\n                self.c2 = 1.5 + 0.5 * (self.func_evals / self.budget)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 2, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004, 0.50005, 0.48424999999999996, 0.40690000000000004]}}
{"id": "d2da6565-d7e7-4772-ae9c-dc9f1f60f71f", "fitness": 0.5243666666666668, "name": "DynamicPSO", "description": "Introduce a velocity clamping mechanism to limit particle speeds, enhancing convergence stability in PSO.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n        self.velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # New line\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)  # New line\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 3, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775, 0.50005, 0.5952999999999999, 0.47775]}}
{"id": "6c1c2634-ad7e-4c87-aea3-76f953605c96", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced DynamicPSO by introducing adaptive mutation to increase diversity and avoid local optima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Apply mutation for diversity\n            if t % 5 == 0:\n                mutation = np.random.normal(0, 0.01, self.dim)\n                self.positions += mutation\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 4, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "f2535c1f-f76b-4cae-ba95-55ed2ebfee59", "fitness": 0.70887, "name": "DynamicPSO", "description": "An enhanced Particle Swarm Optimization (PSO) variant incorporating adaptive velocity scaling to improve convergence speed and solution precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 5, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["d20daf78-7bfa-4aca-a46e-88fdf20a119d"], "operator": null, "metadata": {"aucs": [0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6839999999999999, 0.7314, 0.71595, 0.6603, 0.7314, 0.71595]}}
{"id": "dde1f3e8-3634-4896-9f51-2007ed576f6d", "fitness": 0.6549499999999999, "name": "DynamicPSO", "description": "Enhanced the DynamicPSO by increasing adaptive velocity scaling factor to improve convergence precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling increased slightly\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 6, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.62975, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725]}}
{"id": "eb58c138-7b1c-4eda-ae64-85fc3c2e1e76", "fitness": 0.7016833333333333, "name": "DynamicPSO", "description": "Introduce a dynamic number of particles based on the dimensionality to balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(30, 5 + self.dim)  # Dynamic number of particles based on dimensionality\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 7, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.7106, 0.6549, 0.6953, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.76905, 0.7106, 0.6549, 0.6953]}}
{"id": "0217a5f0-1171-4356-bf4f-1b171ed331be", "fitness": 0.6827715346185413, "name": "DynamicPSO", "description": "Enhanced Particle Swarm Optimization (PSO) with adaptive velocity scaling and periodic local search to improve solution precision.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 8, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.09 on similar problems with similar landscape features.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [1.0, 0.7002032671489776, 0.6905197521291431, 0.6186499999999999, 0.68225, 0.62975, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725, 0.6186499999999999, 0.68225, 0.6725]}}
{"id": "1484665f-280d-46e3-9d4a-3b48868fbb47", "fitness": 0.9793552688146114, "name": "DynamicPSO", "description": "Introduced velocity clamping to prevent overly large velocity values, aiding in more controlled particle exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 9, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["f2535c1f-f76b-4cae-ba95-55ed2ebfee59"], "operator": null, "metadata": {"aucs": [0.9907941377704881, 0.9905458654629009, 0.9567258032104453]}}
{"id": "4683c188-e036-48b9-bb46-64dfe693d3a1", "fitness": 0.6973333333333334, "name": "DynamicPSO", "description": "Incorporated a dynamic adjustment of the cognitive parameter based on the iteration count to enhance exploration in early stages and exploitation in later stages.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 2.0 - 1.5 * (t / eval_budget)  # Dynamic cognitive parameter adjustment\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 10, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001, 0.71085, 0.65595, 0.7252000000000001]}}
{"id": "c6ab171d-74a1-4ff6-bb10-1201fee34ea5", "fitness": 0.66315, "name": "DynamicPSO", "description": "Enhanced global best update by incorporating simulated annealing for better exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best with simulated annealing\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                temperature = 1 / (t + 1)  # Simulated annealing schedule\n                if candidate_value < self.global_best_value or np.exp((self.global_best_value - candidate_value) / temperature) > np.random.rand():\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 11, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615, 0.6024, 0.7255499999999999, 0.6615]}}
{"id": "a5ba3783-4bff-4807-9116-cbb31a92f522", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced the local search by increasing the perturbation frequency to every 5 iterations to explore the solution space more effectively.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed from 10 to 5\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 12, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "2793ec50-9983-49ce-b5c4-15c9f5198aa2", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced convergence by introducing a nonlinear inertia weight decay and an additional random perturbation in velocities.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * np.sin((t / eval_budget) * (np.pi / 2)) # Changed linear to nonlinear inertia\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] += np.random.normal(0, 0.05, self.dim) # Added random perturbation\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 13, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "28e2c8e1-abab-41c3-b013-455c47b32ac5", "fitness": 0.7087166666666666, "name": "DynamicPSO", "description": "Enhanced exploration through adaptive inertia weight tuning that dynamically adjusts based on fitness improvements.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            # Dynamically adjust inertia weight based on global best improvement\n            if t > 0 and self.global_best_value < previous_global_best:\n                w = self.w_min\n            else:\n                w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n\n            previous_global_best = self.global_best_value\n\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 14, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.63565, 0.80445, 0.68605, 0.63565, 0.80445, 0.68605, 0.63565, 0.80445, 0.68605, 0.63565, 0.80445, 0.68605, 0.63565, 0.80445, 0.68605]}}
{"id": "ad8183b3-b49f-41f6-8db2-e00c8b6acc87", "fitness": 0.5691, "name": "DynamicPSO", "description": "Introduced adaptive cognitive parameter scaling to dynamically adjust exploration and exploitation balance during optimization.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.c1 = 2.5 - 0.5 * (t / eval_budget)  # Adaptive cognitive scaling\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 15, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5761499999999999, 0.5343, 0.59685, 0.5761499999999999, 0.5343, 0.59685, 0.5761499999999999, 0.5343, 0.59685, 0.5761499999999999, 0.5343, 0.59685, 0.5761499999999999, 0.5343, 0.59685]}}
{"id": "46a037dc-05d0-4773-91fe-f589983dbdb5", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Added periodic adaptive memory sharing to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Periodic adaptive memory sharing\n            if t % 20 == 0:  # Added line\n                self.global_best_position = np.mean(self.personal_best_positions, axis=0)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 16, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "cd9d0b7b-d5bf-4c3f-b585-6c92829dbfe0", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced local search by increasing perturbation frequency for improved exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed from 10 to 5\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 17, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "7e22a8d4-c0eb-4042-b21b-2f948d654ade", "fitness": 0.7856833333333334, "name": "DynamicPSO", "description": "Introduced dynamic particle count adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = min(30, max(10, dim))  # Dynamic adjustment of particle count\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 18, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79 with standard deviation 0.09 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.59675, 0.83995, 0.82925, 0.59675, 0.83995, 0.82925, 0.8245, 0.83995, 0.82925, 0.8245, 0.83995, 0.82925, 0.59675, 0.83995, 0.82925]}}
{"id": "d4ebbb94-9fe2-418e-843a-619dbd30cec3", "fitness": 0.9601898376253465, "name": "DynamicPSO", "description": "Enhanced exploration by increasing velocity scaling to intensify particle movement.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 1.1  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 19, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.03 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9156638801398832, 0.9784342021377911, 0.9864714305983652]}}
{"id": "53a4d0a4-5759-4604-9cf9-b1414e54975d", "fitness": 0.6408, "name": "DynamicPSO", "description": "Added dynamic adjustment of cognitive and social parameters for improved convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 2.5 - 2.0 * (t / eval_budget)  # Dynamic adjustment\n            self.c2 = 1.5 + 2.0 * (t / eval_budget)  # Dynamic adjustment\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 20, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6101, 0.6469, 0.6654, 0.6101, 0.6469, 0.6654, 0.6101, 0.6469, 0.6654, 0.6101, 0.6469, 0.6654, 0.6101, 0.6469, 0.6654]}}
{"id": "088387b5-431a-45ed-a27c-4ff1bcaf81fc", "fitness": 0.6312833333333333, "name": "DynamicPSO", "description": "Adjusted cognitive and social parameters dynamically based on iteration progress to enhance the exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 2.5 - t * 1.5 / eval_budget  # Dynamic adjustment of c1\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 21, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.57585, 0.67685, 0.64115, 0.57585, 0.67685, 0.64115, 0.57585, 0.67685, 0.64115, 0.57585, 0.67685, 0.64115, 0.57585, 0.67685, 0.64115]}}
{"id": "72f00f6e-1408-4448-9b29-0c053b1a7640", "fitness": 0.6928333333333333, "name": "DynamicPSO", "description": "Introduced an adaptive social parameter to better balance exploration and exploitation based on iteration progress.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c2 = 2.0 - (t / eval_budget)  # Adaptive social parameter\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 22, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692]}}
{"id": "90cea002-060d-44fc-886a-b16c4d5ab0ae", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced perturbation mechanism by increasing local search frequency for improved exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Increased frequency of perturbation\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 23, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "270374db-7295-4aa6-8952-5ffe87920136", "fitness": 0.8416000000000001, "name": "DynamicPSO", "description": "Enhanced DynamicPSO by introducing a random subset of particle updates to increase exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            subset_indices = np.random.choice(self.num_particles, size=self.num_particles // 2, replace=False)\n            for i in subset_indices:\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 24, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.84535, 0.81255, 0.8533999999999999, 0.84535, 0.81255, 0.8533999999999999, 0.84535, 0.81255, 0.8533999999999999, 0.84535, 0.81255, 0.8533999999999999, 0.84535, 0.88005, 0.8533999999999999]}}
{"id": "b9d49481-7e80-4d63-9317-f078d293c85b", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhanced local search by updating the perturbation scale to improve convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.05, self.dim)  # Updated perturbation scale\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 25, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "8713f646-e455-4b3f-9904-d9b8b2d1666c", "fitness": 0.6482833333333334, "name": "DynamicPSO", "description": "Introduced an adaptive inertia weight strategy to enhance convergence by adjusting exploration and exploitation over time.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_evals / self.budget)  # Change here\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 26, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219]}}
{"id": "fc76aefc-0e59-49aa-a620-b2d62fe8c276", "fitness": 0.6057166666666667, "name": "DynamicPSO", "description": "Enhanced cognitive component by increasing the influence of personal experience, promoting more diverse exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.5  # Cognitive parameter increased\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 27, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61 with standard deviation 0.06 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.51805, 0.6386000000000001, 0.6605, 0.51805, 0.6386000000000001, 0.6605, 0.51805, 0.6386000000000001, 0.6605, 0.51805, 0.6386000000000001, 0.6605, 0.51805, 0.6386000000000001, 0.6605]}}
{"id": "a6181cba-8e56-406f-aa9c-aaa6e448489f", "fitness": 0.6482833333333334, "name": "DynamicPSO", "description": "Introduced a dynamic inertia weight adjustment to balance exploration and exploitation based on the evaluation progress.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_evals / self.budget)  # Changed line\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 28, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219, 0.7193499999999999, 0.6036, 0.6219]}}
{"id": "7cbd0855-ec15-49b2-9959-8714bd84c8e4", "fitness": 0.690144879276915, "name": "DynamicPSO", "description": "Introduced temporary reduction of cognitive component to enhance exploration and escape local optima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                if t % 15 == 0:  # Reduce cognitive influence every 15 iterations\n                    self.velocities[i] *= 0.7 \n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 29, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.43 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9903587213530017, 0.9927479200509111, 0.0873279964268322]}}
{"id": "98dfeaaa-1da0-4bc6-9b3f-c652b30355c3", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Introduced dynamic perturbation scaling to enhance local search efficacy around the global best.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1 * (1 - t / eval_budget), self.dim)  # Dynamic perturbation scaling\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 30, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "be02dda7-a4a3-44c8-ad55-b5ea22d36595", "fitness": 0.53665, "name": "DynamicPSO", "description": "Introduced non-linear inertia weight strategy to enhance exploration-exploitation balance and convergence speed.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * ((t / eval_budget) ** 2)  # Non-linear inertia weight\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 31, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516]}}
{"id": "698d9c0f-f607-4d88-b827-6135c98005e3", "fitness": 0.6307833333333334, "name": "DynamicPSO", "description": "Introduced a nonlinear inertia weight decay to enhance exploration and exploitation balance in DynamicPSO.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_min + (self.w_max - self.w_min) * np.exp(-t / eval_budget)  # Nonlinear inertia weight decay\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 32, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.54085, 0.69495, 0.65655, 0.54085, 0.69495, 0.65655, 0.54085, 0.69495, 0.65655, 0.54085, 0.69495, 0.65655, 0.54085, 0.69495, 0.65655]}}
{"id": "7c5172bc-d711-4986-8459-ecc44b166fc6", "fitness": 0.8377666666666667, "name": "DynamicPSO", "description": "Introduced stochastic inertia weight adjustment for enhanced exploration-exploitation balance.  ", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = np.random.uniform(self.w_min, self.w_max)  # Stochastic inertia weight adjustment\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 33, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268]}}
{"id": "fe3d1e5b-ffbd-4210-8c22-e4e15a1ae12e", "fitness": 0.6797833333333332, "name": "DynamicPSO", "description": "Enhanced exploration balance by adding a diverse initialization step to improve coverage of the search space.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        # Diverse initialization of positions\n        self.positions = np.random.laplace(loc=0.0, scale=1.0, size=(self.num_particles, self.dim))\n        self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 34, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6709499999999999, 0.6599999999999999, 0.7083999999999999, 0.6709499999999999, 0.6599999999999999, 0.7083999999999999, 0.6709499999999999, 0.6599999999999999, 0.7083999999999999, 0.6709499999999999, 0.6599999999999999, 0.7083999999999999, 0.6709499999999999, 0.6599999999999999, 0.7083999999999999]}}
{"id": "0065d2f9-f084-4a53-8d2b-abdb59bbd159", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Incorporate a random reset mechanism to diversify particle positions occasionally, enhancing exploration and preventing premature convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Random reset mechanism\n            if t % 20 == 0:  \n                self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 35, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "128bc9d7-f0d0-4b48-8696-80ad5a7aa9db", "fitness": 0.8377666666666667, "name": "DynamicPSO", "description": "Implement stochastic inertia weight to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = np.random.uniform(self.w_min, self.w_max)  # Stochastic inertia weight\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 36, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268]}}
{"id": "9a134bea-6a1b-42f2-a5ef-14c0829b00a4", "fitness": 0.6481333333333332, "name": "DynamicPSO", "description": "Incorporating adaptive inertia weight and particle diversity preservation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            # Adaptive inertia weight based on global best improvement\n            if t > 0 and self.global_best_value < previous_best_value:\n                w *= 1.05\n            previous_best_value = self.global_best_value\n\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 37, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.62005, 0.6069, 0.7174499999999999, 0.62005, 0.6069, 0.7174499999999999, 0.62005, 0.6069, 0.7174499999999999, 0.62005, 0.6069, 0.7174499999999999, 0.62005, 0.6069, 0.7174499999999999]}}
{"id": "25f9b0d1-ba94-4a1d-875b-3d465194a43d", "fitness": 0.6535666666666666, "name": "DynamicPSO", "description": "Introduced dynamic inertia weight adjustment based on fitness improvement to enhance convergence efficiency.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            if self.global_best_value < np.inf:  # Adjust inertia weight if improvement detected\n                w -= 0.05\n            \n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 38, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.65615, 0.6775, 0.62705, 0.65615, 0.6775, 0.62705, 0.65615, 0.6775, 0.62705, 0.65615, 0.6775, 0.62705, 0.65615, 0.6775, 0.62705]}}
{"id": "ceb19bbe-e37b-42d6-b7dc-43353d02886b", "fitness": 0.9696941861728128, "name": "DynamicPSO", "description": "Introduced a periodic swarm reset mechanism to enhance global exploration by diversifying particle positions every few iterations.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Periodic reset of particle positions\n            if t % 15 == 0:  # Reset condition every 15 iterations\n                self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 39, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9781739572466273, 0.9885216265389328, 0.9423869747328784]}}
{"id": "f0a435cf-149e-4d4a-ae7c-72faeab9c374", "fitness": 0.47835, "name": "DynamicPSO", "description": "Enhanced velocity clamping for finer control, improving convergence speed and accuracy.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 40, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525]}}
{"id": "8dcc0bf3-366b-4723-9b6c-8be3acbc0e39", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhanced the balance between exploration and exploitation by introducing a dynamic update for the inertia weight that depends on the overall improvement in the global best value.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        prev_global_best_value = self.global_best_value\n        for t in range(eval_budget):\n            # Dynamic inertia weight based on improvement\n            if prev_global_best_value > self.global_best_value:\n                w = self.w_min + (self.w_max - self.w_min) * ((eval_budget - t) / eval_budget)\n                prev_global_best_value = self.global_best_value\n            else:\n                w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 41, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "66f70f56-66f8-4ccb-ac36-f169c0c96c21", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced the local search mechanism by increasing the frequency of perturbations around the global best position.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Increased frequency\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 42, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "cb89d442-ba83-46af-a876-d6f3fddbb789", "fitness": 0.16666666666666666, "name": "DynamicPSO", "description": "Enhanced position update with non-linear cognitive components for improved exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) ** 1.5\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i]) ** 1.5\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 43, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0]}}
{"id": "fe6be717-c527-44f1-8ac0-04d4a8a9c761", "fitness": 0.7301166666666667, "name": "DynamicPSO", "description": "Introduced an adaptive inertia weight strategy based on convergence speed to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            # Changed line: Adapt inertia weight on convergence speed\n            w = self.w_max - (self.w_max - self.w_min) * ((t / eval_budget) ** 0.5)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 44, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7917, 0.7379, 0.66075, 0.7917, 0.7379, 0.66075, 0.7917, 0.7379, 0.66075, 0.7917, 0.7379, 0.66075, 0.7917, 0.7379, 0.66075]}}
{"id": "e9e583fe-7474-4b82-80e2-5ef91b63b81a", "fitness": 0.6502666666666667, "name": "DynamicPSO", "description": "Introduced a dynamic adjustment in the cognitive and social parameters to improve convergence speed and solution quality.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 1.5 + 0.5 * np.sin(2 * np.pi * t / eval_budget)  # Dynamic adjustment of c1\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 45, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.08 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7589, 0.63655, 0.55535, 0.7589, 0.63655, 0.55535, 0.7589, 0.63655, 0.55535, 0.7589, 0.63655, 0.55535, 0.7589, 0.63655, 0.55535]}}
{"id": "5bb0908b-29d0-4d90-9496-6af18ea9dafc", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced local search efficiency by optimizing perturbation frequency.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed perturbation frequency from 10 to 5\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 46, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "4de71a07-5436-4b0f-8ada-25854d31a4a3", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced exploration using adaptive velocity scaling based on diversity, improving solution accuracy.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                diversity = np.mean(np.std(self.positions, axis=0))\n                self.velocities[i] = w * (1 + diversity) * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 47, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "00032fd7-8643-4611-8a87-29ee422c9182", "fitness": 0.6379333333333332, "name": "DynamicPSO", "description": "Enhanced local search by using Lvy flight perturbation for wider exploration around the global best.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                levy_flight = np.random.normal(0, 0.1, self.dim) * np.random.standard_cauchy(self.dim)  # Lvy flight perturbation\n                candidate_position = np.clip(self.global_best_position + levy_flight, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 48, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5812999999999999, 0.6979500000000001, 0.63455, 0.5812999999999999, 0.6979500000000001, 0.63455, 0.5812999999999999, 0.6979500000000001, 0.63455, 0.5812999999999999, 0.6979500000000001, 0.63455, 0.5812999999999999, 0.6979500000000001, 0.63455]}}
{"id": "33436027-1c8f-48c6-a708-48cbac0267b1", "fitness": 0.7075604291859586, "name": "DynamicPSO", "description": "Introduced a dynamic cognitive parameter to enhance individual exploration capability over time.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 1.5 + 0.5 * np.cos(np.pi * t / eval_budget)  # Dynamic cognitive parameter\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 49, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.37 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.18186667848153226, 0.9667235021513345, 0.9740911069250089]}}
{"id": "a6d49704-3ef1-4bec-b553-0e4f83bc9729", "fitness": 0.5742833333333333, "name": "DynamicPSO", "description": "Implemented dynamic velocity scaling based on iteration progress for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9 + 0.1 * (1 - t / eval_budget)  # Dynamic velocity scaling based on progress\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 50, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5107999999999999, 0.5729, 0.63915, 0.5107999999999999, 0.5729, 0.63915, 0.5107999999999999, 0.5729, 0.63915, 0.5107999999999999, 0.5729, 0.63915, 0.5107999999999999, 0.5729, 0.63915]}}
{"id": "d6166a0b-f1fe-4e96-86a6-c1aabf1e888a", "fitness": 0.6758666666666666, "name": "DynamicPSO", "description": "Introduced a decay mechanism for the social parameter `c2` to enhance convergence towards the global best solution.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            c2_decay = self.c2 * (1 - t / eval_budget)  # Decay for c2\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n\n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = c2_decay * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 51, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545]}}
{"id": "30eafc4d-64a3-443a-a69f-e0925acdd2f1", "fitness": 0.6758666666666666, "name": "DynamicPSO", "description": "Introduced a decay factor to the social component in velocity update, fostering diverse exploration in later stages.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i]) * (1 - t / eval_budget)  # Added decay factor\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 52, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545, 0.70845, 0.6336999999999999, 0.68545]}}
{"id": "ae6172f5-9461-43c2-86fd-deecc2b3a406", "fitness": 0.5513266666666666, "name": "DynamicPSO", "description": "Introduced random inertia weight scaling for better balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget) * np.random.rand()  # Random inertia weight scaling\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 53, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.55 with standard deviation 0.06 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.51995, 0.63025, 0.50005, 0.5386, 0.63025, 0.50005, 0.51995, 0.63025, 0.50005, 0.51995, 0.63025, 0.50005, 0.51995, 0.63025]}}
{"id": "799ef8c9-fd37-4f67-a17f-84a0dbfab303", "fitness": 0.7588666666666665, "name": "DynamicPSO", "description": "Enhanced exploration by introducing a nonlinear inertia weight decrease and an adaptive velocity scaling based on iteration progress.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_min + (self.w_max - self.w_min) * ((eval_budget - t) / eval_budget)**2  # Nonlinear inertia\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9 + 0.1 * (t / eval_budget)  # Adaptive velocity scaling based on progress\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 54, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7283, 0.78905, 0.75925, 0.7283, 0.78905, 0.75925, 0.7283, 0.78905, 0.75925, 0.7283, 0.78905, 0.75925, 0.7283, 0.78905, 0.75925]}}
{"id": "9853dac4-57ba-45e7-bb44-d5f57192d705", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "In DynamicPSO, improved the perturbation magnitude for local search around the global best to enhance exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.2, self.dim)  # Increased perturbation magnitude\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 55, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "223351d2-f29d-4282-96b6-5d586bff0e13", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Improved local search by using a smaller perturbation to refine the exploration around the global best.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.05, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 56, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "dc20df38-d5d4-4a5e-9c16-345d248132bd", "fitness": 0.6986833333333332, "name": "DynamicPSO", "description": "Incorporate exponential decay in the inertia weight for improved convergence speed.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max * np.exp(-t / eval_budget)  # Exponential decay of inertia weight\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 57, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.71445, 0.7059500000000001, 0.67565, 0.71445, 0.7059500000000001, 0.67565, 0.71445, 0.7059500000000001, 0.67565, 0.71445, 0.7059500000000001, 0.67565, 0.71445, 0.7059500000000001, 0.67565]}}
{"id": "0ce96f4b-4bee-45b1-a3d5-4006dcffffad", "fitness": 0.6928333333333333, "name": "DynamicPSO", "description": "Introduce a dynamic social parameter to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c2 = 2.0 - (t / eval_budget)  # Dynamic social parameter\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 58, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692, 0.75425, 0.65505, 0.6692]}}
{"id": "d0bed8ef-e4d5-4d67-ba0c-e2ad7b19c157", "fitness": 0.7074872851945934, "name": "DynamicPSO", "description": "Introduced an adaptive local search frequency based on the convergence rate to enhance exploration around the global best position.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Adaptive local search around global best\n            if t % max(1, eval_budget // 20) == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 59, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.40 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9907941377704881, 0.9905458654629009, 0.14112185235039143]}}
{"id": "b91cb2c8-14f6-46ed-b8e0-eddd032c6d89", "fitness": 0.6665333333333333, "name": "DynamicPSO", "description": "Enhanced global best perturbation for better exploration in complex landscapes.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.standard_cauchy(self.dim) * 0.1\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 60, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999]}}
{"id": "8584f2be-e3d5-42f6-89a3-271abe15c01d", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Introduced a momentum term in the velocity update to enhance exploration and convergence in the search space.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component + 0.1 * self.velocities[i-1]\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 61, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "52f7dfdc-b5de-4d6f-9e1c-419d566cd39e", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhanced local search strategy by adjusting the perturbation scale based on the iteration count.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation_scale = 0.1 * (1 - t / eval_budget)  # Adjust perturbation scale\n                perturbation = np.random.normal(0, perturbation_scale, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 62, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "41c73339-b99b-497f-a658-fe622e1eae53", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced global best update frequency by changing local search interval to improve convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed local search frequency\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 63, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "45abf72c-548c-4295-8d1a-6742c0b9daee", "fitness": 0.6545166666666665, "name": "DynamicPSO", "description": "Introduced an adaptive inertia weight strategy based on fitness progress to enhance convergence speed and accuracy.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        previous_best_value = np.inf  # Initialize to track improvement\n        for t in range(eval_budget):\n            improvement = abs(previous_best_value - self.global_best_value) / max(1, previous_best_value)\n            previous_best_value = self.global_best_value\n            w = self.w_max - (self.w_max - self.w_min) * (improvement if improvement > 0 else t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 64, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6609499999999999, 0.6469, 0.6557, 0.6609499999999999, 0.6469, 0.6557, 0.6609499999999999, 0.6469, 0.6557, 0.6609499999999999, 0.6469, 0.6557, 0.6609499999999999, 0.6469, 0.6557]}}
{"id": "9cf6cd02-08cd-40b8-b53c-5742c3974d14", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Adaptive population size increase halfway through the budget for enhanced solution exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            if t == eval_budget // 2:  # mid-budget increase\n                self.num_particles += 5  # increase particle count\n                new_positions = np.random.uniform(self.lower_bound, self.upper_bound, (5, self.dim))\n                self.positions = np.vstack([self.positions, new_positions])\n                new_velocities = np.random.uniform(-1, 1, (5, self.dim))\n                self.velocities = np.vstack([self.velocities, new_velocities])\n                self.personal_best_positions = np.vstack([self.personal_best_positions, new_positions])\n                self.personal_best_values = np.append(self.personal_best_values, np.full(5, np.inf))\n                \n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 65, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "4a6adcfa-33e1-4f82-a6f6-2be5c595fbb0", "fitness": 0.7060666666666665, "name": "DynamicPSO", "description": "Introduced dynamic velocity scaling based on iteration count to facilitate better exploration and exploitation balance in particle motion.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9 + 0.1 * (t / eval_budget)  # Dynamic velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 66, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.77545, 0.66255, 0.6802, 0.77545, 0.66255, 0.6802, 0.77545, 0.66255, 0.6802, 0.77545, 0.66255, 0.6802, 0.77545, 0.66255, 0.6802]}}
{"id": "ff020c0b-dfd2-4d78-8afd-6ac7eaa706d3", "fitness": 0.5967, "name": "DynamicPSO", "description": "Introduced a non-linear inertia weight update to improve convergence speed and exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            # Non-linear inertia weight update\n            w = self.w_max - (self.w_max - self.w_min) * (np.sin((np.pi / 2) * (t / eval_budget)))**2\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 67, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5815, 0.60065, 0.60795, 0.5815, 0.60065, 0.60795, 0.5815, 0.60065, 0.60795, 0.5815, 0.60065, 0.60795, 0.5815, 0.60065, 0.60795]}}
{"id": "c0ebff97-960a-415b-8254-6ae7b3b2eed7", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced particle diversity by adding a slight random perturbation to velocities for increased exploration. ", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] += np.random.normal(0, 0.1, self.dim)  # Added random perturbation to velocities\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 68, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "42fe7e0e-747f-43a1-add7-722629bcfd68", "fitness": 0.72062958703606, "name": "DynamicPSO", "description": "Introduced a decay factor to gradually reduce adaptive velocity scaling, allowing more precise convergence over time.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9 * (1 - t / eval_budget)  # Decaying adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 69, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.38 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9909163923495562, 0.9945082391941373, 0.17646412956448643]}}
{"id": "8ff93543-f331-4a11-b7a3-8555de728a3e", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced local search by increasing the frequency of perturbation checks around the global best position.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Changed frequency from every 10 to every 5 iterations\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 70, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "1a6f7492-42d2-43b6-bf8b-456ea89193ae", "fitness": 0.6665333333333333, "name": "DynamicPSO", "description": "Enhanced global exploration by using a Lvy flight strategy for perturbations during local search.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.standard_cauchy(self.dim) * 0.1  # Lvy flight step\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 71, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999, 0.6506000000000001, 0.6335500000000001, 0.7154499999999999]}}
{"id": "28958028-7ba6-4895-a7ef-31c4b6ce2b1d", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced global exploration by increasing the frequency of local search around the global best position.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Increased frequency of local search\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 72, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "da3ced9d-182e-4d9a-b869-03ea7ab557be", "fitness": 0.66036, "name": "DynamicPSO", "description": "Introduced dynamic adaptation of cognitive and social parameters to enhance convergence speed and robustness.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            # Dynamic adaptation of cognitive and social parameters\n            self.c1 = 2.5 - 1.5 * (t / eval_budget)\n            self.c2 = 0.5 + 1.5 * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 73, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6677, 0.6778, 0.65795, 0.6677, 0.56595, 0.65795, 0.6677, 0.6778, 0.65795, 0.6677, 0.6778, 0.65795, 0.6677, 0.6778, 0.65795]}}
{"id": "99d6060f-f7ee-438f-a2df-618135ba179d", "fitness": 0.6390166666666667, "name": "DynamicPSO", "description": "Introduced dynamic social parameter scaling to enhance adaptability and convergence speed.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c2 = 2.0 - 1.5 * (t / eval_budget)  # Dynamic social parameter scaling\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 74, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5715, 0.65785, 0.6877, 0.5715, 0.65785, 0.6877, 0.5715, 0.65785, 0.6877, 0.5715, 0.65785, 0.6877, 0.5715, 0.65785, 0.6877]}}
{"id": "62be8e96-8ea5-4b37-82db-744403bb38d5", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhance global exploration by adjusting perturbation magnitude dynamically based on iteration progress.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1 * (1 - t / eval_budget), self.dim)  # Dynamic perturbation\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 75, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "efa0009a-4db7-4206-b745-42825663392b", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Introduced adaptive mutation in the local search phase to enhance exploration capability.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim) * (1 - t / eval_budget)  # Adaptive mutation\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 76, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "f39cb2d7-36c2-44f1-8142-97579ed215da", "fitness": 0.53665, "name": "DynamicPSO", "description": "Enhanced dynamic inertia weight adjustment to improve convergence balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            # Modified line: dynamic inertia weight adjustment\n            w = self.w_max - (self.w_max - self.w_min) * ((t / eval_budget) ** 2)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 77, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516]}}
{"id": "9ccc8de7-93ee-45e7-9fc8-215c1fcb762a", "fitness": 0.66036, "name": "DynamicPSO", "description": "Enhanced particle exploration by dynamically adjusting cognitive and social parameters.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            self.c1 = 2.5 - 1.5 * (t / eval_budget)  # Dynamic cognitive parameter\n            self.c2 = 0.5 + 1.5 * (t / eval_budget)  # Dynamic social parameter\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 78, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6677, 0.6778, 0.65795, 0.6677, 0.56595, 0.65795, 0.6677, 0.6778, 0.65795, 0.6677, 0.6778, 0.65795, 0.6677, 0.6778, 0.65795]}}
{"id": "dfc8ec2a-a4c3-42dd-b953-f18fd35cc3ae", "fitness": 0.9782383651976828, "name": "DynamicPSO", "description": "Introduced an adaptive inertia weight reset mechanism to enhance solution refinement by periodically boosting exploration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            if t % 20 == 0: w = self.w_max  # Inertia weight reset\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 79, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9907941377704881, 0.9905458654629009, 0.9533750923596593]}}
{"id": "2ed1ae3e-9310-4071-bbdd-8332aa65869e", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced local search by increasing perturbation frequency around the global best to improve convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Increased frequency of perturbation\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 80, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "e37cac81-392a-4899-9b28-ae4feafbdede", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Introduced a dynamic local search radius and adaptive perturbation scaling to enhance global best convergence behavior.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation_scale = np.exp(-t / eval_budget) * 0.1  # Adaptive scaling\n                perturbation = np.random.normal(0, perturbation_scale, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 81, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "51ed840c-4a6a-426f-8ef7-cab3ae713d29", "fitness": 0.6807833333333332, "name": "DynamicPSO", "description": "Enhanced exploration by alternating global and local best updates based on random probability, improving diversity in the search process.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Randomly alternate between global and local best\n            if np.random.rand() < 0.5:\n                candidate_value = self.personal_best_values[np.random.choice(self.num_particles)]\n                candidate_position = self.personal_best_positions[np.random.choice(self.num_particles)]\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 82, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.62355, 0.729, 0.6898, 0.62355, 0.729, 0.6898, 0.62355, 0.729, 0.6898, 0.62355, 0.729, 0.6898, 0.62355, 0.729, 0.6898]}}
{"id": "ff86699e-5140-475b-9fa3-4f821e6a173d", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhanced local search by periodically increasing perturbation magnitude to escape potential local optima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation_magnitude = 0.1 if t < eval_budget / 2 else 0.2  # Modify perturbation magnitude\n                perturbation = np.random.normal(0, perturbation_magnitude, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 83, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "fa30f1f4-1ea3-43ff-99b8-fb7740dceed4", "fitness": 0.5008333333333332, "name": "DynamicPSO", "description": "Introduced a nonlinear inertia weight decay to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_min + (self.w_max - self.w_min) * np.cos(np.pi * t / (2 * eval_budget))  # Nonlinear inertia weight decay\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 84, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.50 with standard deviation 0.07 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.51225, 0.40859999999999996, 0.58165, 0.51225, 0.40859999999999996, 0.58165, 0.51225, 0.40859999999999996, 0.58165, 0.51225, 0.40859999999999996, 0.58165, 0.51225, 0.40859999999999996, 0.58165]}}
{"id": "88281720-7286-4543-92ae-3e0ce52e77d7", "fitness": 0.7231666666666666, "name": "DynamicPSO", "description": "Enhanced local search by increasing perturbation frequency to explore the search space more thoroughly.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 5 == 0:  # Increased local search frequency\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 85, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975, 0.7208, 0.73895, 0.70975]}}
{"id": "88d79ecb-35a2-4201-b82f-07cca8433840", "fitness": 0.53665, "name": "DynamicPSO", "description": "Introduced dynamic inertia weight adjustment and global best perturbation with adaptive Gaussian noise for enhanced exploration and convergence control.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * ((t / eval_budget) ** 2)  # Dynamic inertia adaptation\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1 / (t + 1), self.dim)  # Adaptive Gaussian noise\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 86, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516, 0.50005, 0.5939, 0.516]}}
{"id": "5ac8e408-69cd-4478-8aec-6f42a5525f09", "fitness": 0.6498333333333334, "name": "DynamicPSO", "description": "Introduced periodic global best re-evaluation to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n            # New: Re-evaluate the global best every 20 iterations\n            if t % 20 == 0:\n                reevaluated_value = func(self.global_best_position)\n                self.func_evals += 1\n                if reevaluated_value < self.global_best_value:\n                    self.global_best_value = reevaluated_value\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 87, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58925, 0.6403, 0.71995, 0.58925, 0.6403, 0.71995, 0.58925, 0.6403, 0.71995, 0.58925, 0.6403, 0.71995, 0.58925, 0.6403, 0.71995]}}
{"id": "32bd3774-fbfc-4adf-9eeb-2f6eb3f91113", "fitness": 0.47835, "name": "DynamicPSO", "description": "Fine-tune velocity clamping for nuanced exploration and improved convergence.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.95  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 88, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.48 with standard deviation 0.04 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525, 0.50005, 0.5097499999999999, 0.42525]}}
{"id": "02c34148-2bde-453b-b4da-b255e3748222", "fitness": 0.9793552688146114, "name": "DynamicPSO", "description": "Introduced adaptive inertia weight based on the ratio of current evaluations to the total budget for dynamic balance between exploration and exploitation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (self.func_evals / self.budget)  # Adaptive inertia\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 89, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.98 with standard deviation 0.02 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9907941377704881, 0.9905458654629009, 0.9567258032104453]}}
{"id": "c5b1bdeb-a0ee-4bcb-9c36-2c1f3b566015", "fitness": 0.8377666666666667, "name": "DynamicPSO", "description": "Integrated random inertia weight adjustment to maintain diversity and enhance global search capability.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = np.random.uniform(self.w_min, self.w_max)  # Random inertia weight adjustment\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 90, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268]}}
{"id": "fa2afbb2-ff5e-4fb3-90e1-a3c215af34b1", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Incorporate a dynamic inertia weight updating mechanism to enhance convergence speed and solution accuracy.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            # Dynamic inertia weight based on performance\n            if self.global_best_value < np.inf:\n                w = self.w_max - (self.w_max - self.w_min) * ((self.global_best_value ** 0.5) / eval_budget)\n            else:\n                w = self.w_max\n\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 91, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "c139176e-ce59-4025-a432-b1d3b93ec64b", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Incorporate a small perturbation to the velocity update to enhance exploration and prevent stagnation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                perturbation = np.random.normal(0, 0.05, self.dim)  # Small perturbation\n                self.velocities[i] = np.clip(self.velocities[i] + perturbation, -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 92, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "87408a78-1ceb-48e4-80b8-1d86e2ed5411", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Improved convergence by periodically resetting the global best position to encourage exploration and avoid local minima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n            # Periodic global best reset\n            if t % 15 == 0: \n                self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 93, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "fc1bbcd5-1eb9-4a1d-8436-958af9f48ec9", "fitness": 0.1667166666666666, "name": "DynamicPSO", "description": "Enhanced global exploration by introducing a small random perturbation to the global best position at every iteration.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n            \n            # Add random perturbation to global best position\n            self.global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 94, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05, 0.50005, 4.999999999999449e-05, 4.999999999999449e-05]}}
{"id": "d0eacdd3-1c35-41a8-8c98-86e4cc714460", "fitness": 0.16666666666666666, "name": "DynamicPSO", "description": "Introduced a dynamic inertia weight adjustment based on the best personal improvement rate to enhance convergence speed and exploration-exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            best_improvement = np.min(self.personal_best_values) - self.global_best_value\n            w = self.w_max - (self.w_max - self.w_min) * (best_improvement / max(1e-10, np.abs(self.global_best_value)))\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 95, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.24 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0]}}
{"id": "9ae92253-3191-4e55-8f0f-02512ce9ede8", "fitness": 0.6504333333333333, "name": "DynamicPSO", "description": "Enhanced exploration by introducing random reinitialization for stagnating particles to escape local optima.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n            # Reinitialize stagnating particles\n            if t % 15 == 0:\n                stagnating_particles = np.where(self.personal_best_values == np.inf)[0]\n                for i in stagnating_particles:\n                    self.positions[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    \n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 96, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045, 0.58995, 0.6409, 0.72045]}}
{"id": "ab08a300-2ad9-4d92-bc44-0b7066d1a06f", "fitness": 0.8377666666666667, "name": "DynamicPSO", "description": "Introduced random inertia weight variation to enhance exploration and exploitation balance in the particle swarm optimization.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = np.random.uniform(self.w_min, self.w_max)  # Random inertia weight variation\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 97, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.03 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268, 0.87825, 0.80825, 0.8268]}}
{"id": "ba705e16-5601-4ab2-a1cb-37bd6a338cbf", "fitness": 0.26475, "name": "DynamicPSO", "description": "Enhanced exploration by introducing random particle reinitialization to prevent local optima stagnation.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = self.c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n                \n                # Random reinitialization for stagnated particles\n                if np.random.rand() < 0.05:\n                    self.positions[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 98, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.26 on similar problems with similar landscape features.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.6145499999999999, 0.17964999999999998, 4.999999999999449e-05, 0.6145499999999999, 0.17964999999999998, 4.999999999999449e-05, 0.6145499999999999, 0.17964999999999998, 4.999999999999449e-05, 0.6145499999999999, 0.17964999999999998, 4.999999999999449e-05, 0.6145499999999999, 0.17964999999999998, 4.999999999999449e-05]}}
{"id": "614fae22-e1cf-46cf-b1a8-a8dd895cd909", "fitness": 0.9165782935078083, "name": "DynamicPSO", "description": "Introduced adaptive cognitive and social factors to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass DynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.c1 = 2.0  # Cognitive parameter\n        self.c2 = 2.0  # Social parameter\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = np.copy(self.positions)\n        self.personal_best_values = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.func_evals = 0\n\n    def __call__(self, func):\n        eval_budget = self.budget // self.num_particles\n        for t in range(eval_budget):\n            w = self.w_max - (self.w_max - self.w_min) * (t / eval_budget)\n            adaptive_c1 = self.c1 * (1 - t / eval_budget)  # Adaptive cognitive factor\n            adaptive_c2 = self.c2 * (t / eval_budget)  # Adaptive social factor\n            for i in range(self.num_particles):\n                if self.func_evals >= self.budget:\n                    break\n                value = func(self.positions[i])\n                self.func_evals += 1\n                if value < self.personal_best_values[i]:\n                    self.personal_best_values[i] = value\n                    self.personal_best_positions[i] = self.positions[i]\n                if value < self.global_best_value:\n                    self.global_best_value = value\n                    self.global_best_position = self.positions[i]\n            \n            for i in range(self.num_particles):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = adaptive_c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                social_component = adaptive_c2 * r2 * (self.global_best_position - self.positions[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.velocities[i] *= 0.9  # Adaptive velocity scaling\n                self.velocities[i] = np.clip(self.velocities[i], -2, 2)  # Velocity clamping\n                self.positions[i] += self.velocities[i]\n                self.positions[i] = np.clip(self.positions[i], self.lower_bound, self.upper_bound)\n            \n            # Local search around global best\n            if t % 10 == 0:\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate_position = np.clip(self.global_best_position + perturbation, self.lower_bound, self.upper_bound)\n                candidate_value = func(candidate_position)\n                self.func_evals += 1\n                if candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = candidate_position\n\n        return self.global_best_position, self.global_best_value", "configspace": "", "generation": 99, "feedback": "The algorithm DynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.06 on the real problem.", "error": "", "parent_ids": ["1484665f-280d-46e3-9d4a-3b48868fbb47"], "operator": null, "metadata": {"aucs": [0.9079696033745726, 0.9900949514663792, 0.8516703256824733]}}
