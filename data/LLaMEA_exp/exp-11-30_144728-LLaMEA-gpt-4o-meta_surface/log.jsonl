{"id": "770a1172-d1c6-40b4-a30c-541cd65af118", "fitness": 0.05825902884918858, "name": "AGB_PSO", "description": "Adaptive Gradient-Based Particle Swarm Optimization (AGB-PSO) combining particle swarm dynamics with adaptive gradient steps to efficiently explore and exploit the search space.", "code": "import numpy as np\n\nclass AGB_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n\n    def __call__(self, func):\n        # Initialize particle positions and velocities\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        \n        # Global best initialization\n        global_best_position = None\n        global_best_value = np.inf\n        \n        # Main optimization loop\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.num_particles):\n                # PSO velocity update\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                # Adaptation: Gradient-based update\n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n                \n                # Update positions with bounded check\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 0, "feedback": "The algorithm AGB_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.057833842043296335, 0.03273720736698105, 0.08420603713728836]}}
{"id": "75026ba2-2e40-440c-895c-186a3d80f5a7", "fitness": 0.5747428406005807, "name": "AGB_PSO_DE", "description": "Hybrid PSO with Adaptive Gradient and Differential Evolution Mutation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 3       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 1, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57 with standard deviation 0.11 on similar problems with similar landscape features.", "error": "", "parent_ids": ["770a1172-d1c6-40b4-a30c-541cd65af118"], "operator": null, "metadata": {"aucs": [0.6686354722005152, 0.6400562709094008, 0.41553677869182604]}}
{"id": "5eabab9a-ecfa-44b4-b1bd-c445d958ae9d", "fitness": 0.1866014336005195, "name": "AGB_PSO_DE", "description": "Introduced Random Initialization of Inertia Weight to enhance the balance between exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = np.random.uniform(0.5, 0.9)  # Random initialization of inertia weight\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 3       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 2, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.17 on similar problems with similar landscape features.", "error": "", "parent_ids": ["75026ba2-2e40-440c-895c-186a3d80f5a7"], "operator": null, "metadata": {"aucs": [0.03455600891024624, 0.4196683133265158, 0.1055799785647965]}}
{"id": "5007f567-900f-4752-b289-c92b459b8dea", "fitness": 0.53335713908489, "name": "AGB_PSO_DE", "description": "Incorporate a randomization factor into velocity updates to enhance exploration capabilities.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 3       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component * np.random.rand(self.dim))\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 3, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.53 with standard deviation 0.34 on similar problems with similar landscape features.", "error": "", "parent_ids": ["75026ba2-2e40-440c-895c-186a3d80f5a7"], "operator": null, "metadata": {"aucs": [0.07591357214428407, 0.6439648991661125, 0.8801929459442736]}}
{"id": "7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda", "fitness": 0.6704011999246822, "name": "AGB_PSO_DE", "description": "Adjusted the number of differential mutations to improve diversity in the search space.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 5       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 4, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.39 on similar problems with similar landscape features.", "error": "", "parent_ids": ["75026ba2-2e40-440c-895c-186a3d80f5a7"], "operator": null, "metadata": {"aucs": [0.889422942802009, 0.12226909958166832, 0.999511557390369]}}
{"id": "39e84fcb-4203-4554-867a-b0a24f29d3e6", "fitness": 0.42795286551738304, "name": "AGB_PSO_DE", "description": "Introduced adaptive inertia weight to enhance exploration and exploitation balance dynamically.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 5       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = ((0.5 + np.random.rand()/2.0) * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 5, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.29 on similar problems with similar landscape features.", "error": "", "parent_ids": ["7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda"], "operator": null, "metadata": {"aucs": [0.06435292649685942, 0.7660950484509498, 0.45341062160434]}}
{"id": "708df240-2749-4f7d-8862-81e075f7665b", "fitness": 0.03798348046159535, "name": "AGB_PSO_DE", "description": "Enhanced gradient estimation and mutation diversity for improved exploration.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.9  # DE mutation factor\n        self.num_mutations = 5       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 6, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.01 on similar problems with similar landscape features.", "error": "", "parent_ids": ["7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda"], "operator": null, "metadata": {"aucs": [0.025992171938463038, 0.05036266404589462, 0.03759560540042839]}}
{"id": "8d3a4806-707e-4412-a7c5-d03d35d8f8ba", "fitness": 0.26171132778824674, "name": "AGB_PSO_DE", "description": "Enhance exploration by applying adaptive mutation factor in the differential evolution step.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 5       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + np.random.uniform(0.5, 1.0) * (x2 - x3)  # Adaptive mutation factor\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 7, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.27 on similar problems with similar landscape features.", "error": "", "parent_ids": ["7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda"], "operator": null, "metadata": {"aucs": [0.05626796019284208, 0.0806609539316796, 0.6482050692402185]}}
{"id": "4324f7d7-d7c9-4523-9a34-3a78977c3d98", "fitness": 0.04464474287140378, "name": "AGB_PSO_DE", "description": "Introduced inertia weight decay for improved convergence and increased mutation diversity.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8\n        self.num_mutations = 5\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n            \n            self.inertia_weight *= 0.99  # Add inertia weight decay\n\n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 8, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.04 with standard deviation 0.02 on similar problems with similar landscape features.", "error": "", "parent_ids": ["7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda"], "operator": null, "metadata": {"aucs": [0.02871731888404483, 0.03199207072598531, 0.0732248390041812]}}
{"id": "0d2e3246-7444-45ee-a5f6-7f09e6bba699", "fitness": 0.046280669204383895, "name": "AGB_PSO_DE", "description": "Improved the convergence rate by slightly increasing the number of differential mutations, enhancing exploration capabilities.", "code": "import numpy as np\n\nclass AGB_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_particles = 30\n        self.inertia_weight = 0.7\n        self.cognitive_constant = 1.5\n        self.social_constant = 1.5\n        self.gradient_step_size = 0.1\n        self.mutation_factor = 0.8  # DE mutation factor\n        self.num_mutations = 6       # Number of differential mutations\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.num_particles, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n        \n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                current_value = func(positions[i])\n                evaluations += 1\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = positions[i]\n                    \n                if current_value < global_best_value:\n                    global_best_value = current_value\n                    global_best_position = positions[i]\n                    \n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.num_particles):\n                cognitive_component = self.cognitive_constant * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                social_component = self.social_constant * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = (self.inertia_weight * velocities[i] + cognitive_component + social_component)\n                \n                grad_estimate = self.estimate_gradient(func, positions[i])\n                velocities[i] += self.gradient_step_size * grad_estimate\n\n                # Differential Evolution Mutation\n                idxs = np.random.choice(self.num_particles, 5, replace=False)\n                x1, x2, x3 = positions[idxs[:3]]\n                mutation_vector = x1 + self.mutation_factor * (x2 - x3)\n                positions[i] = positions[i] + velocities[i] + mutation_vector\n                positions[i] = np.clip(positions[i], self.lower_bound, self.upper_bound)\n        \n        return global_best_position, global_best_value\n\n    def estimate_gradient(self, func, position, epsilon=1e-5):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed_position = np.copy(position)\n            perturbed_position[i] += epsilon\n            f_x_plus_eps = func(perturbed_position)\n            \n            perturbed_position[i] -= 2 * epsilon\n            f_x_minus_eps = func(perturbed_position)\n            \n            grad[i] = (f_x_plus_eps - f_x_minus_eps) / (2 * epsilon)\n        \n        return grad", "configspace": "", "generation": 9, "feedback": "The algorithm AGB_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.01 on the real problem.", "error": "", "parent_ids": ["7f289d6f-d7c5-47a0-84d2-4fed5cb7dfda"], "operator": null, "metadata": {"aucs": [0.04054332349274414, 0.05975886167908151, 0.03853982244132603]}}
