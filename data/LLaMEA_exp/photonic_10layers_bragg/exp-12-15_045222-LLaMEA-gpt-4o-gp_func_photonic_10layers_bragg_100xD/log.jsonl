{"id": "92a9d50b-fdec-4747-b0a0-dbebd5c22850", "fitness": 0.07855259783391326, "name": "HybridPSO_DE", "description": "A hybrid Particle Swarm Optimization (PSO) and Differential Evolution (DE) algorithm leveraging adaptive strategies for balancing exploration and exploitation within a constrained budget.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n        \n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n                \n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                \n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    \n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07855 with standard deviation 0.00566.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.08389740255833422, 0.0810414086392689, 0.07071898230413665]}}
{"id": "b9f76f07-b6ee-4e40-831c-26f7fbedf931", "fitness": 0.07723353912939357, "name": "HybridPSO_DE", "description": "Enhanced exploitation by modifying the PSO cognitive parameter `c1` to balance convergence.", "code": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter - modified for better exploitation\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n        \n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n                \n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n                \n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                \n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    \n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07723 with standard deviation 0.00696.", "error": "", "parent_ids": ["92a9d50b-fdec-4747-b0a0-dbebd5c22850"], "operator": null, "metadata": {"aucs": [0.07067059105405793, 0.07415700101887668, 0.0868730253152461]}}
{"id": "296998ab-d40f-4e62-83b5-1eb8b3dd5d83", "fitness": 0.08090956686823321, "name": "ImprovedHybridPSO_DE", "description": "An improved hybrid PSO-DE algorithm with adaptive parameter tuning and dynamic population resizing for enhanced exploration-exploitation balance in black box optimization.", "code": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self):\n        # Adapt inertia weight and scaling factor based on progress\n        self.w = max(0.4, self.w * 0.99)\n        self.F = max(0.4, self.F * 0.99)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing: halve the population size every third of the budget\n            if evaluations >= self.budget / 3 and evaluations < (2 * self.budget) / 3:\n                self.population_size = max(10, self.initial_population_size // 2)\n                \n            elif evaluations >= (2 * self.budget) / 3:\n                self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters()\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08091 with standard deviation 0.00769.", "error": "", "parent_ids": ["92a9d50b-fdec-4747-b0a0-dbebd5c22850"], "operator": null, "metadata": {"aucs": [0.08588519476740708, 0.07004806599191349, 0.08679543984537907]}}
{"id": "42922ac2-1cab-4d3e-8b4b-68421c46da95", "fitness": 0.08322537511577681, "name": "EnhancedHybridOptimizer", "description": "Enhanced Hybrid Optimizer using Adaptive Differential Evolution and Particle Swarm Optimization with Adaptive Population and Mutation Strategies for Robust Black Box Optimization.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Dynamically adjust parameters based on iteration progress\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * progress)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Update each particle's position using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing and adaptive parameter tuning\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08323 with standard deviation 0.00470.", "error": "", "parent_ids": ["296998ab-d40f-4e62-83b5-1eb8b3dd5d83"], "operator": null, "metadata": {"aucs": [0.07816448918590568, 0.08203239541872953, 0.0894792407426952]}}
{"id": "7f8eac7b-ac3e-421c-855e-85abaa368603", "fitness": 0.08761040020252127, "name": "EnhancedHybridOptimizer", "description": "Enhanced Hybrid Optimizer with refined dynamic parameter adaptation for improved convergence in black box optimization.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Dynamically adjust parameters based on iteration progress\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * progress * np.sin(progress * np.pi))  # slightly refined CR adaptation\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Update each particle's position using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing and adaptive parameter tuning\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08761 with standard deviation 0.00253.", "error": "", "parent_ids": ["42922ac2-1cab-4d3e-8b4b-68421c46da95"], "operator": null, "metadata": {"aucs": [0.08817114635787648, 0.0842712835414926, 0.09038877070819473]}}
{"id": "837929e1-6fc8-4733-9a77-3632e9170198", "fitness": 0.09008784311168268, "name": "EnhancedHybridOptimizer", "description": "Refined Enhanced Hybrid Optimizer with a more adaptive crossover probability for improved convergence.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Dynamically adjust parameters based on iteration progress\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))  # removing progress multiplier for more adaptive CR\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Update each particle's position using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing and adaptive parameter tuning\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09009 with standard deviation 0.00244.", "error": "", "parent_ids": ["7f8eac7b-ac3e-421c-855e-85abaa368603"], "operator": null, "metadata": {"aucs": [0.09255006032916513, 0.08676042160109254, 0.09095304740479038]}}
{"id": "46d2e8ce-bf53-4081-885e-a755b67c2155", "fitness": 0.08850505748331387, "name": "EnhancedHybridOptimizer", "description": "Introduced a dynamic DE scaling factor for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Dynamically adjust parameters based on iteration progress\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress)) + 0.3 * progress  # Added dynamic component to F\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))  # removing progress multiplier for more adaptive CR\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Update each particle's position using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing and adaptive parameter tuning\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08851 with standard deviation 0.00236.", "error": "", "parent_ids": ["837929e1-6fc8-4733-9a77-3632e9170198"], "operator": null, "metadata": {"aucs": [0.08943976879163884, 0.0852612921384539, 0.09081411151984886]}}
{"id": "ab62f738-d6e0-48c4-af07-d5bafae36c52", "fitness": 0.08370918461261619, "name": "EnhancedHybridOptimizer", "description": "Enhanced Dynamic Hybrid Optimizer with adaptive inertia, scaling, and crossover strategies based on population diversity to improve exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n\n    def adapt_parameters(self, iteration, max_iterations, diversity):\n        # Dynamically adjust parameters based on iteration progress and population diversity\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + 0.1 * np.sin(np.pi * progress) * (1 - diversity)\n        self.CR = 0.9 - 0.5 * np.sin(progress * np.pi) * diversity\n\n    def calculate_diversity(self, particles):\n        # Calculate population diversity as the standard deviation of the population\n        return np.mean(np.std(particles, axis=0))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        # Initialize the positions and velocities of particles\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            # Calculate diversity\n            diversity = self.calculate_diversity(particles)\n\n            # Update each particle's position using PSO and DE strategies\n            for i in range(self.population_size):\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # DE Mutation and Crossover\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                # Boundary handling\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                # Evaluate the trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Update personal best\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    # Update global best\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population resizing and adaptive parameter tuning\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations, diversity)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08371 with standard deviation 0.00186.", "error": "", "parent_ids": ["837929e1-6fc8-4733-9a77-3632e9170198"], "operator": null, "metadata": {"aucs": [0.083453467396849, 0.08156969346621756, 0.086104392974782]}}
{"id": "e59f7715-bac6-4063-8a6e-0c801131e72c", "fitness": 0.09141050813818337, "name": "AdaptiveParticleDELevyOptimizer", "description": "Adaptive Particle-DE Hybrid Optimizer with Levy Flight strategy for enhanced exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09141 with standard deviation 0.00322.", "error": "", "parent_ids": ["837929e1-6fc8-4733-9a77-3632e9170198"], "operator": null, "metadata": {"aucs": [0.09190170920099572, 0.0950839829934873, 0.0872458322200671]}}
{"id": "a0a1d0f8-9e44-4074-b05a-6174e282ea21", "fitness": 0.08714192756897572, "name": "AdaptiveParticleDELevyOptimizer", "description": "Improved Adaptive Particle-DE Hybrid Optimizer with Tuned Parameters and Enhanced Diversity Control.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter, increased for better exploration\n        self.c2 = 2.0  # social parameter\n        self.F = 0.6  # DE scaling factor, slightly increased\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08714 with standard deviation 0.00137.", "error": "", "parent_ids": ["e59f7715-bac6-4063-8a6e-0c801131e72c"], "operator": null, "metadata": {"aucs": [0.08899051265754232, 0.08572484395571067, 0.08671042609367419]}}
{"id": "21c9848e-e96a-4e32-8632-2a7eb59e5ea2", "fitness": 0.08671968383602546, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer by refining parameter adaptation and introducing noise for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.5 + (0.1 * np.sin(np.pi * progress))  # Adjusted DE scaling factor\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def noise(self, scale=0.001):  # New function to introduce small noise\n        return np.random.normal(0, scale, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n                \n                trial_vector += self.noise()  # Introduce noise to trial vector\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08672 with standard deviation 0.00936.", "error": "", "parent_ids": ["e59f7715-bac6-4063-8a6e-0c801131e72c"], "operator": null, "metadata": {"aucs": [0.09733504653692748, 0.08825477276800353, 0.07456923220314537]}}
{"id": "412ac634-5e03-4206-87aa-6a427c68d3e6", "fitness": 0.09144555688678353, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer with Levy Flight strategy utilizing dynamic alpha scaling for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09145 with standard deviation 0.00342.", "error": "", "parent_ids": ["e59f7715-bac6-4063-8a6e-0c801131e72c"], "operator": null, "metadata": {"aucs": [0.09241598406923024, 0.09506240274151667, 0.0868582838496037]}}
{"id": "7224b9d2-0d0a-45b3-bbbb-3cd40ddd35b0", "fitness": -Infinity, "name": "EnhancedParticleDELevyOptimizer", "description": "Enhanced Particle-DE Hybrid Optimizer with dynamic parameter adaptation and adaptive Levy Flight to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w_init, self.w_final = 0.7, 0.4\n        self.c1_init, self.c1_final = 2.5, 1.5\n        self.c2_init, self.c2_final = 2.0, 2.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.alpha_init, self.alpha_final = 0.01, 0.02\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = self.w_init - (self.w_init - self.w_final) * progress\n        self.c1 = self.c1_init - (self.c1_init - self.c1_final) * progress\n        self.c2 = self.c2_init + (self.c2_final - self.c2_init) * progress\n        self.alpha = self.alpha_init + (self.alpha_final - self.alpha_init) * progress\n\n    def levy_flight(self, scale):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "An exception occurred: AttributeError(\"'EnhancedParticleDELevyOptimizer' object has no attribute 'w'\").", "error": "AttributeError(\"'EnhancedParticleDELevyOptimizer' object has no attribute 'w'\")", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {}}
{"id": "16890ca2-02cb-4b6c-857b-7f5f80bb04da", "fitness": 0.08494003101653624, "name": "EnhancedHybridParticleDEOptimizer", "description": "Enhanced Hybrid Particle-DE Optimizer with Adaptive Levy Flight and Stochastic Tuning for dynamic exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedHybridParticleDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Levy flight scaling factor\n        self.sigma = 0.1  # additional stochastic tuning parameter\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n        self.sigma = 0.1 * (1 + 0.5 * np.sin(np.pi * progress))  # Dynamic sigma scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]) +\n                                 self.sigma * np.random.normal(size=self.dim))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridParticleDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08494 with standard deviation 0.00687.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09106302914801245, 0.0753446497346123, 0.08841241416698398]}}
{"id": "143da402-77bd-4bf4-90e8-86d41145e4f2", "fitness": 0.09133276225120364, "name": "AdaptiveParticleDELevyOptimizer", "description": "Slightly increase the cognitive parameter to enhance individual exploration capabilities.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.1  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09133 with standard deviation 0.00256.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09493851778887608, 0.0892091540920289, 0.08985061487270596]}}
{"id": "c1c72b39-65dd-456b-8158-f2083e15c7ff", "fitness": 0.09093950379001052, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer incorporating adaptive mutation scale and improved Levy flight for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                \n                # Adjusting the DE scaling factor for better exploration\n                self.F = 0.5 + 0.2 * np.cos(iteration / max_iterations * np.pi) \n\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 + 0.1 * np.sin(iteration / max_iterations * np.pi)))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09094 with standard deviation 0.00241.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09383525252781788, 0.08792390339663847, 0.0910593554455752]}}
{"id": "cfa9b7fe-5cab-4729-90c6-141d764af826", "fitness": 0.08113393309844137, "name": "AdaptiveParticleDELevyOptimizer", "description": "Refined Adaptive Particle-DE Hybrid Optimizer with enhanced exploration and local search dynamics.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.4:  # Modified Levy flight perturbation probability\n                    trial_vector += self.levy_flight(self.alpha * 1.5)  # Enhanced Levy flight scale\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08113 with standard deviation 0.00307.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.08411155722088037, 0.08238001305599141, 0.07691022901845235]}}
{"id": "d0d24ecf-45fc-4f78-84b4-c3170dcf6338", "fitness": 0.0865106164748017, "name": "AdaptiveParticleDELevyOptimizer", "description": "Fine-tune adaptive parameters and Levy flight scale for enhanced global exploration and convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.02  # Scaling factor for Levy flight (adjusted)\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.5 + (0.1 * np.cos(np.pi * progress))  # Adjusted inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.02 * (1 + 0.5 * np.cos(np.pi * progress))  # Adjusted dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08651 with standard deviation 0.00891.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09480213739888821, 0.09057665397228587, 0.07415305805323102]}}
{"id": "5b48c44d-8404-4245-815c-efc87d119a71", "fitness": 0.09136204513264712, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer with Levy Flight strategy utilizing dynamic beta scaling and strategic population resizing for superior convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.beta = 1.5  # New scaling factor\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n        self.beta = 1.5 * (1 + 0.3 * np.sin(np.pi * progress))  # Dynamic beta scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(8, self.initial_population_size // 2)  # Slight adjustment\n                else:\n                    self.population_size = max(4, self.initial_population_size // 3)  # Slight adjustment\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09136 with standard deviation 0.00330.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.0919507355530309, 0.09507319070315634, 0.08706220914175411]}}
{"id": "d2f0702a-4e99-4f3d-aac1-6a18afad44ce", "fitness": 0.08322246694571223, "name": "AdaptiveParticleDELevyOptimizer", "description": "A self-adaptive particle swarm and differential evolution hybrid optimizer enhanced with progressive Levy flight perturbation and dynamic parameter control for improved global search efficiency.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1/3)\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                levy_prob = 0.3 + 0.2 * (global_best_score / func(trial_vector))\n                if np.random.rand() < levy_prob:  # Adjusted Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08322 with standard deviation 0.00279.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.0811490290652147, 0.08134684638387935, 0.08717152538804263]}}
{"id": "e19c93ed-2a7e-40bd-9c4d-26572254972d", "fitness": 0.07782097840708053, "name": "EnhancedAdaptiveParticleDEOptimizer", "description": "Adaptive Hybrid Particle-DE Optimizer with Modified Dynamic Parameters and Strategic Synergistic Exploration for Enhanced Convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.7  # Increased inertia weight for exploration\n        self.c1 = 1.5  # Enhanced cognitive parameter for local search\n        self.c2 = 1.5  # Enhanced social parameter for global search\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.5 + (0.2 * np.cos(np.pi * progress))\n        self.F = 0.5 + (0.2 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.4 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(10, self.initial_population_size // 3)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm EnhancedAdaptiveParticleDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07782 with standard deviation 0.00726.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.08752252819858497, 0.07589232437695637, 0.07004808264570028]}}
{"id": "c2d0abfb-065d-4bdc-8c2a-b4fc31aa31cb", "fitness": 0.08834104517028034, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer with modified inertia weight for improved balance between exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.7  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08834 with standard deviation 0.01149.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09732460585719105, 0.09557025506319816, 0.07212827459045179]}}
{"id": "3d19c6c4-6c9d-4b78-b72a-293adaed641e", "fitness": 0.08506866567826203, "name": "ConvergenceAwareParticleDELevyOptimizer", "description": "Incorporate a convergence awareness mechanism in the Adaptive Particle-DE Hybrid Optimizer to dynamically adjust exploration-exploitation balance via entropy-based diversity metrics for better performance.  ", "code": "import numpy as np\n\nclass ConvergenceAwareParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations, diversity):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n        diversity_factor = (1 - diversity)  # Higher diversity should push towards exploration\n        self.c1 = 1.0 + diversity_factor\n        self.c2 = 2.0 - diversity_factor\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def calculate_diversity(self, positions):\n        mean_position = np.mean(positions, axis=0)\n        diversity = np.linalg.norm(positions - mean_position, axis=1).mean()\n        return diversity / (np.linalg.norm(positions.max(axis=0) - positions.min(axis=0)))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            diversity = self.calculate_diversity(particles)\n            self.adapt_parameters(iteration, max_iterations, diversity)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "The algorithm ConvergenceAwareParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08507 with standard deviation 0.00578.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.08961033956549869, 0.08868804558428178, 0.07690761188500561]}}
{"id": "9e3fccde-072b-45fb-a063-8d6f60e47b43", "fitness": 0.08412140272628972, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced Particle-DE-Levy Hybrid Optimizer with dynamic population control and adaptive exploration-exploitation balance for superior convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.exploration_exploitation_ratio = 0.5\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))\n        self.exploration_exploitation_ratio = 0.5 + 0.5 * np.cos(np.pi * progress)\n        \n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < self.exploration_exploitation_ratio:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(self.min_population_size * 2, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(self.min_population_size, self.initial_population_size // 4)\n                particles = particles[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08412 with standard deviation 0.00971.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.0879854384249602, 0.07077392203131228, 0.0936048477225967]}}
{"id": "cc244c3b-4556-4376-971c-cafa8d8b9972", "fitness": 0.08872361735042988, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced Adaptive Particle-DE Hybrid Optimizer with Levy Flight and Dynamic Population Resizing for more efficient exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.dynamic_population = True\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def resize_population(self, iteration, max_iterations):\n        if self.dynamic_population:\n            if iteration < max_iterations // 3:\n                self.population_size = self.initial_population_size\n            elif iteration < 2 * max_iterations // 3:\n                self.population_size = max(10, self.initial_population_size // 2)\n            else:\n                self.population_size = max(5, self.initial_population_size // 4)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            self.resize_population(iteration, max_iterations)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08872 with standard deviation 0.00354.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09132866353684777, 0.09111754377717274, 0.08372464473726915]}}
{"id": "0c5afef7-a361-4629-a448-667cb7883588", "fitness": 0.09065297530331044, "name": "AdaptiveParticleDELevyOptimizer", "description": "Adaptive Particle-DE Hybrid Optimizer with enhanced dynamic alpha scaling and diversified population adaptation for improved convergence stability.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.3 * np.cos(np.pi * progress))  # Enhanced dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(12, self.initial_population_size // 2)  # Diversified population adaptation\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09065 with standard deviation 0.00302.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.09431758702272663, 0.08691795934451318, 0.0907233795426915]}}
{"id": "3307ec7c-e23b-4ee0-9846-2426f20159d4", "fitness": 0.09389168669972574, "name": "AdaptiveParticleDELevyOptimizer", "description": "Introduced an adaptive inertia weight strategy to dynamically balance exploration and exploitation for improved convergence.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09389 with standard deviation 0.00109.", "error": "", "parent_ids": ["412ac634-5e03-4206-87aa-6a427c68d3e6"], "operator": null, "metadata": {"aucs": [0.0945784477306959, 0.09473779772914426, 0.09235881463933704]}}
{"id": "eb09df24-b170-4e46-b911-5098fccb803a", "fitness": 0.08600982595020006, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration by introducing a mutation mechanism based on the best particle in the swarm.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n                \n                # Introduce a new mutation mechanism based on the global best\n                if np.random.rand() < 0.3:\n                    trial_vector = global_best_position + self.F * (x2 - x3)\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08601 with standard deviation 0.00991.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09190309443847722, 0.0940802166950625, 0.07204616671706043]}}
{"id": "63c80a68-3d0f-4954-a88c-ecd5580b578b", "fitness": 0.09315062094553561, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive strategies for balancing exploration-exploitation using randomized hyperparameter adjustments based on swarm diversity and dynamic thresholding.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.diversity_threshold = 0.1  # Initial diversity threshold\n\n    def adapt_parameters(self, iteration, max_iterations, diversity):\n        progress = iteration / max_iterations\n        self.w = 0.5 - (0.3 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress)) + 0.2 * diversity\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi)) + 0.1 * (1 - diversity)\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def calculate_diversity(self, particles):\n        centroid = np.mean(particles, axis=0)\n        diversity = np.mean(np.linalg.norm(particles - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            diversity = self.calculate_diversity(particles)\n            if diversity < self.diversity_threshold:  # Dynamic threshold adjustment\n                self.population_size = max(5, self.initial_population_size // 4)\n            else:\n                self.population_size = self.initial_population_size\n\n            self.adapt_parameters(iteration, max_iterations, diversity)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09315 with standard deviation 0.00135.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09382110464806093, 0.09435857668572478, 0.09127218150282113]}}
{"id": "4f4ace2a-b23e-43bd-a494-34b90617d8aa", "fitness": 0.0863810196831593, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive strategy by incorporating dynamic control of mutation and crossover rates based on convergence trends to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations, convergence_trend):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))\n        self.F = 0.4 + 0.1 * np.abs(convergence_trend) * (1 - progress)\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi)) * np.abs(convergence_trend)\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n        previous_best_score = global_best_score\n\n        while evaluations < self.budget:\n            convergence_trend = (previous_best_score - global_best_score) / (1e-9 + abs(previous_best_score))\n            previous_best_score = global_best_score\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations, convergence_trend)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08638 with standard deviation 0.00775.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09321114267134711, 0.09038346924272012, 0.07554844713541065]}}
{"id": "0c5fa324-d1e3-40ce-883b-96883101a31e", "fitness": 0.09171666076209824, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration with adaptive scaling factor for mutation and modified Levy flight strategy.  ", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress)) + 0.1 * progress  # Enhanced DE scaling factor\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.015 * (1 + 0.5 * np.cos(np.pi * progress))  # Modified alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1.5, self.dim) * scale  # Modified Levy flight step\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09172 with standard deviation 0.00307.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09404236165430757, 0.09372332606504419, 0.08738429456694297]}}
{"id": "bb667954-1cda-45b2-81f1-82f494c8150a", "fitness": 0.0895218416589284, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive parameters with a quadratic function for better balance in exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress**2)) * (0.5 + 0.5 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress**2))\n        self.CR = 0.9 - (0.5 * np.sin(progress**2 * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08952 with standard deviation 0.00421.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09522471610136007, 0.08815548161941777, 0.08518532725600736]}}
{"id": "9a614125-e679-4411-b665-4a5f7f9e3349", "fitness": 0.0786494695166754, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced convergence by introducing a dynamically adjusting population size and opposition-based learning for better exploration-exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.5 + 0.4 * (0.5 - progress)  # Dynamic inertia weight\n        self.F = 0.5 + 0.4 * np.sin(np.pi * progress)\n        self.CR = 0.9 * (0.5 + 0.5 * np.cos(np.pi * progress))\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def opposition_based_learning(self, population, lb, ub):\n        opposition_population = lb + ub - population\n        return np.clip(opposition_population, lb, ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % 10 == 0:\n                opposition_population = self.opposition_based_learning(particles, lb, ub)\n                opposition_scores = np.array([func(p) for p in opposition_population])\n                evaluations += self.population_size\n\n                for i in range(self.population_size):\n                    if opposition_scores[i] < personal_best_scores[i]:\n                        personal_best_positions[i] = opposition_population[i]\n                        personal_best_scores[i] = opposition_scores[i]\n\n                        if opposition_scores[i] < global_best_score:\n                            global_best_position = opposition_population[i]\n                            global_best_score = opposition_scores[i]\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07865 with standard deviation 0.00361.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.082535794288627, 0.07956651907883516, 0.07384609518256402]}}
{"id": "9ad57660-e612-4eb4-807d-63b136251068", "fitness": 0.08563715638546383, "name": "AdaptiveParticleDELevyOptimizer", "description": "Introduced an adaptive velocity scaling factor to improve convergence speed by modifying the velocity update equation.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                adaptive_velocity_scale = 1.2  # New adaptive velocity scaling factor\n                velocities[i] = (adaptive_velocity_scale * self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08564 with standard deviation 0.00909.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09544591503899214, 0.08792153883963638, 0.073544015277763]}}
{"id": "838bcab0-83da-4a97-9fc8-278daac09838", "fitness": 0.08483630827679223, "name": "ImprovedAdaptiveParticleDELevyOptimizer", "description": "Introduced adaptive particle swarm optimization with dynamic mutation and crossover strategy, leveraging chaotic maps for parameter tuning to enhance convergence speed and solution diversity.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5\n        self.c1 = 1.0\n        self.c2 = 2.0\n        self.F = 0.5\n        self.CR = 0.9\n        self.alpha = 0.01\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        chaos_factor = 4.0 * progress * (1 - progress)  # Logistic map for chaotic behavior\n        self.w = 0.5 + 0.3 * np.cos(np.pi * chaos_factor)\n        self.F = 0.5 + 0.2 * np.sin(np.pi * chaos_factor)\n        self.CR = 0.9 - 0.5 * np.sin(np.pi * chaos_factor)\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * chaos_factor))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_mutation(self, position, bounds, chaos_factor):\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n        chaotic_factor = np.random.rand(self.dim) * np.abs(ub - lb) * chaos_factor\n        return np.clip(position + chaotic_factor, lb, ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = self.chaotic_mutation(trial_vector, bounds, self.alpha)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm ImprovedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08484 with standard deviation 0.01103.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.08609861380422701, 0.07074597380428416, 0.09766433722186552]}}
{"id": "5fb77186-7d92-490d-bff0-039cc212a019", "fitness": 0.09213410793440731, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced the adaptive strategy by integrating differential evolution's mutation and crossover with a stochastic selection to improve convergence reliability and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.35 + (0.15 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.5 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.8 - (0.4 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(2 * np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09213 with standard deviation 0.00463.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09807033370504448, 0.08677792876472423, 0.09155406133345323]}}
{"id": "a4bab8ee-6902-4d1b-8abf-f039fa918681", "fitness": 0.09388576303761782, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration by introducing a dynamic population size adjustment based on convergence rate, improving global search capability.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 5) == 0:  # Adjusted interval for dynamic population\n                convergence_rate = np.std(personal_best_scores) / np.mean(personal_best_scores)\n                if convergence_rate < 0.1:\n                    self.population_size = min(self.population_size + 5, self.initial_population_size * 2)\n                else:\n                    self.population_size = max(10, self.initial_population_size // 2)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09389 with standard deviation 0.00109.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09457609068797201, 0.09473050007472117, 0.0923506983501603]}}
{"id": "bee1f753-5800-4d06-b393-ac3c3c9f0fc5", "fitness": 0.09389168669972574, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration by modifying population size reduction strategy to improve convergence speed at later stages.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 3)  # Change line\n                else:\n                    self.population_size = max(5, self.initial_population_size // 5)  # Change line\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09389 with standard deviation 0.00109.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.0945784477306959, 0.09473779772914426, 0.09235881463933704]}}
{"id": "37fd802b-8605-4c72-8683-aaf7367f58d0", "fitness": 0.07573913951320728, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive particle DE algorithm with dynamic population resizing and adaptive mutation to optimize black-box functions efficiently.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        # Introducing adaptive strategy for inertia weight and other parameters\n        self.w = 0.5 + 0.3 * np.cos(np.pi * progress) * (0.5 + 0.5 * np.sin(2 * np.pi * progress))\n        self.F = 0.5 + 0.2 * np.sin(np.pi * progress)\n        self.CR = 0.9 - 0.3 * np.cos(progress * np.pi)\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(2 * np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07574 with standard deviation 0.00548.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.0747585412620726, 0.08288113297891586, 0.06957774429863339]}}
{"id": "338d61a7-0f61-403f-a990-b83b28b53a8f", "fitness": 0.08720010346393554, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration by integrating a random walk strategy with adaptive scaling to improve convergence stability.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.random_walk_scaling = 0.05  # scaling for random walk\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def random_walk(self):\n        return np.random.normal(0, self.random_walk_scaling, self.dim)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i] + self.random_walk(), lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08720 with standard deviation 0.00226.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.08997555371056232, 0.08442764104476486, 0.08719711563647947]}}
{"id": "cc10f7ce-7d7f-4b5e-aa35-a810cb251daf", "fitness": 0.0811315918939222, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive strategy using dynamic population resizing and chaotic maps for improved exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_map(self, value):\n        return 4 * value * (1 - value)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n        chaotic_value = np.random.rand()\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                chaotic_value = self.chaotic_map(chaotic_value)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]) * chaotic_value)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08113 with standard deviation 0.00558.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.08732415339855781, 0.07380532734387757, 0.08226529493933121]}}
{"id": "9be8f2a4-fbda-4d37-8e2a-44cdd37cc60d", "fitness": 0.09152398225266385, "name": "AdaptiveParticleDELevyOptimizer", "description": "Enhanced dynamic mutation strategy and modified inertia weight adaptation for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.3 + (0.2 * np.cos(np.pi * progress))  # Modified adaptive inertia weight\n        self.F = 0.5 + (0.1 * np.sin(np.pi * progress))  # Adjusted scaling factor\n        self.CR = 0.9 - (0.3 * np.sin(progress * np.pi))  # Adjusted crossover probability\n        self.alpha = 0.02 * (1 + 0.5 * np.cos(np.pi * progress))  # Increased dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09152 with standard deviation 0.00297.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09572680620512375, 0.0895600776694434, 0.08928506288342442]}}
{"id": "35361ff7-1e78-4ee7-9059-ac3ea0919e2e", "fitness": 0.0923825218489636, "name": "RefinedAdaptiveParticleDELevyOptimizer", "description": "Introduced a dynamic population resizing strategy and combined adaptive parameter tuning with a stochastic ranking mechanism for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass RefinedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            # Dynamic population adjustment\n            if iteration % 10 == 0 and iteration > 0:\n                ranks = np.argsort(personal_best_scores)\n                best_ranks = ranks[:self.population_size // 2]\n                selected_indices = np.random.choice(best_ranks, self.population_size, replace=True)\n                particles = particles[selected_indices]\n                velocities = velocities[selected_indices]\n                personal_best_positions = personal_best_positions[selected_indices]\n                personal_best_scores = personal_best_scores[selected_indices]\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm RefinedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09238 with standard deviation 0.00361.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09626244799092876, 0.08757332017774921, 0.09331179737821282]}}
{"id": "dd6fe353-8ce2-4b5d-8070-afb944b814d4", "fitness": 0.0664801132020864, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced convergence by introducing dynamic learning parameters and chaotic initialization to increase exploration and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.3 * np.cos(np.pi * progress)\n        self.c1 = 2.5 - 1.5 * progress  # Adaptive cognitive parameter\n        self.c2 = 1.5 + 1.5 * progress  # Adaptive social parameter\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_initialization(self, lb, ub):\n        chaotic_sequence = np.sin(np.pi * np.random.rand(self.population_size, self.dim))\n        return lb + (ub - lb) * (chaotic_sequence + 1) / 2\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = self.chaotic_initialization(lb, ub)\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06648 with standard deviation 0.00579.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.058407937995265446, 0.06930616675257162, 0.07172623485842211]}}
{"id": "99d96341-8f73-4b0f-90e4-541a79123309", "fitness": 0.09100723826925501, "name": "AdaptiveParticleDELevyOptimizer", "description": "Improved convergence by incorporating dynamic population size scaling based on performance, enhancing diversity and solution quality.", "code": "import numpy as np\n\nclass AdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + (0.1 * np.cos(np.pi * progress)) * (0.5 + 0.5 * np.cos(np.pi * progress))  # Adaptive inertia weight\n        self.F = 0.4 + (0.1 * np.sin(np.pi * progress))\n        self.CR = 0.9 - (0.5 * np.sin(progress * np.pi))\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(np.pi * progress))  # Dynamic alpha scaling\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(8, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm AdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09101 with standard deviation 0.00242.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09436823496011759, 0.0898691998397475, 0.08878428000789995]}}
{"id": "af1112be-340a-49ed-ad03-291832644c2d", "fitness": 0.09486841561535016, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced balancing of global and local search by introducing a rotational dynamic adaptation of parameters for diverse search capability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09487 with standard deviation 0.00142.", "error": "", "parent_ids": ["3307ec7c-e23b-4ee0-9846-2426f20159d4"], "operator": null, "metadata": {"aucs": [0.09646942622431531, 0.09512260203092104, 0.09301321859081413]}}
{"id": "947dfcb2-ef25-4cf6-be15-ad9482cae833", "fitness": 0.08538302906227986, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Introducing a hierarchical parameter adaptation mechanism and dynamic population resizing strategy to enhance exploratory and exploitative capabilities of the optimizer.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.3 * np.cos(progress * np.pi)\n        self.F = 0.5 + 0.25 * np.sin(progress * 2 * np.pi)\n        self.CR = 0.8 + 0.1 * np.cos(progress * 2 * np.pi)\n        self.alpha = 0.01 * (1 + 0.3 * np.sin(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 5) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 3)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08538 with standard deviation 0.00403.", "error": "", "parent_ids": ["af1112be-340a-49ed-ad03-291832644c2d"], "operator": null, "metadata": {"aucs": [0.0898810562184108, 0.08617323227323759, 0.0800947986951912]}}
{"id": "02d3ed2e-0246-4616-a70b-41fdb7d163e3", "fitness": 0.09127796279015699, "name": "ChaoticAdaptiveParticleDELevyOptimizer", "description": "Integrate a multi-phase adaptation strategy with chaotic dynamics to enhance global-local balance and convergence speed.", "code": "import numpy as np\n\nclass ChaoticAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        # Use a chaotic sequence for parameter modulation\n        progress = iteration / max_iterations\n        chaotic_seq = np.sin((progress + 0.1) * np.pi)\n        self.w = 0.4 + 0.1 * (chaotic_seq + 1) / 2\n        self.F = 0.5 + 0.2 * chaotic_seq\n        self.CR = 0.8 + 0.1 * chaotic_seq\n        self.alpha = 0.01 * (1 + 0.5 * chaotic_seq)\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm ChaoticAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09128 with standard deviation 0.00206.", "error": "", "parent_ids": ["af1112be-340a-49ed-ad03-291832644c2d"], "operator": null, "metadata": {"aucs": [0.09412818307965964, 0.08933221556669657, 0.09037348972411474]}}
{"id": "03d4118e-1cb5-4c51-b5e9-e8a12ee01f24", "fitness": 0.0928182258259207, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhance dynamic adaptation by introducing periodic stochastic perturbations in parameter adaptation for added diversity and robustness.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        if iteration % 5 == 0:  # Add stochastic perturbation\n            self.w *= (1 + np.random.uniform(-0.05, 0.05))\n            self.F *= (1 + np.random.uniform(-0.05, 0.05))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09282 with standard deviation 0.00387.", "error": "", "parent_ids": ["af1112be-340a-49ed-ad03-291832644c2d"], "operator": null, "metadata": {"aucs": [0.09472509755987213, 0.0874220741182492, 0.09630750579964076]}}
{"id": "673a7d0f-1157-46e6-a2d8-bd0de8105765", "fitness": 0.09493566079428124, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Improved exploration by incorporating time-varying perturbation strength in Levy flights.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09494 with standard deviation 0.00144.", "error": "", "parent_ids": ["af1112be-340a-49ed-ad03-291832644c2d"], "operator": null, "metadata": {"aucs": [0.09644775482559431, 0.09536106292783542, 0.09299816462941402]}}
{"id": "f93f2610-bbee-4010-a2ab-69bbbdac09a5", "fitness": 0.09507997945941375, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration and convergence via adaptive mutation scaling and hybrid levy-DE mutation with sinusoidal adaptation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09508 with standard deviation 0.00204.", "error": "", "parent_ids": ["673a7d0f-1157-46e6-a2d8-bd0de8105765"], "operator": null, "metadata": {"aucs": [0.09705854142026915, 0.09590170961480582, 0.09227968734316627]}}
{"id": "59cac0b5-2fe8-4314-add6-b804d27e1738", "fitness": -Infinity, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptation and convergence via dynamic population resizing and adaptive levy-flight scaling in a hybrid PSO-DE framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.min_population_size = 5\n        self.max_population_size = 40\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def dynamic_population_resizing(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        if progress < 0.5:\n            self.population_size = int(self.initial_population_size + (self.max_population_size - self.initial_population_size) * progress)\n        else:\n            self.population_size = int(self.max_population_size - (self.max_population_size - self.min_population_size) * (progress - 0.5) * 2)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            self.dynamic_population_resizing(iteration, max_iterations)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {}}
{"id": "e7fc2da3-d484-41b2-b17a-05e7b4c8c9ae", "fitness": 0.08897551951004705, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced convergence by adjusting the inertia weight more dynamically during the search process for better performance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) - np.sin(angle)) / 2  # Dynamic sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08898 with standard deviation 0.00654.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09754899098992276, 0.08166912252643377, 0.08770844501378461]}}
{"id": "fc9e7a05-6c92-44e5-af34-ec4c1d42255e", "fitness": 0.09146331194873636, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Improved exploration-exploitation balance by introducing mutation diversity and dynamic crossover probability adjustment for better convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3) + np.random.normal(0, 0.1, self.dim)  # Added mutation diversity\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09146 with standard deviation 0.00158.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.08936563824600197, 0.09183643857888313, 0.09318785902132398]}}
{"id": "cdf06845-bb17-4d3d-9ae1-f7d89b9c766a", "fitness": 0.09080577528239812, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration and convergence by integrating an adaptive mutation scaling with chaos theory inspired logistic map adaptation in a hybrid Levy-DE mutation framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        # Using a logistic map for parameter modulation inspired by chaos theory\n        logistic_map = 4 * progress * (1 - progress)\n        self.w = 0.4 + 0.1 * logistic_map\n        self.F = 0.5 + 0.2 * np.sin(2 * np.pi * logistic_map)\n        self.CR = 0.8 + 0.1 * np.cos(2 * np.pi * logistic_map)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(2 * np.pi * logistic_map))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09081 with standard deviation 0.00461.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09565539675223911, 0.08461630156388, 0.09214562753107525]}}
{"id": "16cf6714-5b61-4311-aacd-cef6f98a5bd7", "fitness": 0.08690934065782134, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive exploration using exponential decay in parameter adaptation and dynamic population size adjustment for improved convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        # Changed line: Introduce exponential decay for parameter adaptation\n        self.F *= np.exp(-0.1 * progress)\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Changed line: Dynamic population size adjustment\n            if iteration % (max_iterations // 3) == 0:\n                self.population_size = max(5, int(self.initial_population_size * (0.9 ** (iteration // (max_iterations // 3)))))\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08691 with standard deviation 0.00384.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.0884246285316298, 0.09066400895482163, 0.08163938448701258]}}
{"id": "e9241745-7d00-49b7-b19f-c267967ce3ef", "fitness": 0.0763168218935737, "name": "RefinedParticleDELevyOptimizer", "description": "Improved dynamic parameter adaptation and hybrid particle-DE mutation with interleaved exploration-exploitation phases for enhanced convergence.", "code": "import numpy as np\n\nclass RefinedParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5\n        self.c1 = 1.0\n        self.c2 = 2.0\n        self.F = 0.5\n        self.CR = 0.9\n        self.alpha = 0.01\n        self.exploration_phase = True\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        self.exploration_phase = progress < 0.5  # Switch phases mid-way\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                if self.exploration_phase:\n                    particles[i] = np.clip(trial_vector, lb, ub)\n                else:\n                    particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                if np.random.rand() < 0.3:\n                    particles[i] += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                trial_score = func(particles[i])\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = particles[i]\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = particles[i]\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm RefinedParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07632 with standard deviation 0.00643.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.06722368644835819, 0.08100817083640433, 0.08071860839595857]}}
{"id": "0181dc87-40e1-4032-a590-2295724c2cdb", "fitness": 0.09263868753867599, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced adaptive mutation and crossover dynamics with improved Levy flight perturbation for better exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.15 * np.sin(angle)  # Adjusted range for F adaptation\n        self.CR = 0.8 + 0.15 * np.cos(angle)  # Adjusted range for CR adaptation\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))  # Increased alpha for stronger perturbations\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09264 with standard deviation 0.00136.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09335394252624585, 0.09382399739201153, 0.0907381226977706]}}
{"id": "d1875a99-f622-43df-a5cb-17aed4a72341", "fitness": 0.09507997945941375, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration and convergence via adaptive parameter modulation, cooperative strategies, and dynamic population resizing in a hybrid levy-particle swarm-DE framework.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09508 with standard deviation 0.00204.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09705854142026915, 0.09590170961480582, 0.09227968734316627]}}
{"id": "f9cde631-0724-4c39-945c-ecdda7bc32e3", "fitness": 0.0925166331692205, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration and convergence via adaptive mutation scaling and hybrid levy-DE mutation with sinusoidal adaptation, now with improved convergence by modifying DE crossover strategy and using dynamic mutation probability.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.mutation_prob = 0.3  # Initial mutation probability\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        self.mutation_prob = 0.3 + 0.2 * (1 - np.cos(angle)) / 2  # Dynamic mutation probability\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < self.mutation_prob:  # Levy flight perturbation with dynamic probability\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09252 with standard deviation 0.00263.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09560090236374941, 0.09276763957387091, 0.0891813575700412]}}
{"id": "4dcba102-6567-4e5b-9bbf-b29b33bfb450", "fitness": 0.06420780288672667, "name": "ImprovedAdaptiveParticleDELevyOptimizer", "description": "Improved exploration and convergence using dynamic population sizing, adaptive parameter control, and a novel chaos-inducing perturbation strategy.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.1 * np.cos(progress * np.pi)\n        self.F = 0.5 + 0.1 * np.sin(progress * np.pi)\n        self.CR = 0.8 + 0.2 * np.sin(progress * np.pi)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(progress * 2 * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaos_perturbation(self, iteration, max_iterations):\n        beta = 1.5\n        chaos_factor = 0.5 * (1 + np.sin(2 * np.pi * (iteration / max_iterations) ** beta))\n        return chaos_factor\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_vector += self.chaos_perturbation(iteration, max_iterations)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(10, self.initial_population_size // 3)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm ImprovedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06421 with standard deviation 0.00442.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.059095457901157444, 0.06365514663589322, 0.06987280412312935]}}
{"id": "53db2215-ab34-44bd-835d-b59f4950fd12", "fitness": 0.08545904078362727, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "Improved dynamic adaptation through multi-phase strategy with enhanced inertia and diversity control for better convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.3 + 0.2 * np.cos(angle)  # Adjusted for enhanced exploration-exploitation balance\n        self.F = 0.4 + 0.3 * np.sin(angle)\n        self.CR = 0.7 + 0.2 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08546 with standard deviation 0.00842.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09567818774430203, 0.08564135148622964, 0.07505758312035016]}}
{"id": "474bb701-5247-471a-b4e5-83e687ee2395", "fitness": 0.08509235217579618, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Improved adaptive exploration and exploitation via enhanced diversity control.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.6  # DE scaling factor (modified)\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.02  # Scaling factor for Levy flight (modified)\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.75 + 0.15 * np.cos(angle)  # modified crossover probability range\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08509 with standard deviation 0.00818.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09207589868221755, 0.0895873946237482, 0.07361376322142277]}}
{"id": "8cd966d0-6921-4487-ac5e-dc042cbf0550", "fitness": 0.0804300644696394, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced convergence and exploration using hybrid adaptive strategies with perturbation and diversity boost.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.7  # Adjusted inertia weight for better exploration\n        self.c1 = 1.5  # Increased cognitive parameter for stronger personal learning\n        self.c2 = 1.5  # Reduced social parameter for balanced social learning\n        self.F = 0.6  # Increased DE scaling factor for stronger exploration\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.3 * (np.cos(angle) + 1) / 2  # More aggressive sinusoidal adaptation\n        self.F = 0.6 + 0.3 * np.sin(angle)  # Increased dynamic range for F\n        self.CR = 0.85 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08043 with standard deviation 0.00799.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.08761545004776361, 0.08439042344361125, 0.06928431991754336]}}
{"id": "62437255-7502-47f4-8379-685549584341", "fitness": -Infinity, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Refined exploration and convergence by enhancing mutation strategy and adaptive parameters while maintaining the structure.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3 + 0.1 * np.sin(angle):  # Increased perturbation chance\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "An exception occurred: NameError(\"name 'angle' is not defined\").", "error": "NameError(\"name 'angle' is not defined\")", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {}}
{"id": "58fc5e12-9e95-42ee-8596-683c63320c3a", "fitness": 0.08420845855293346, "name": "ImprovedAdaptiveParticleDEGaussianOptimizer", "description": "Improved exploration and convergence via adaptive mutation scaling with adaptive population size and enhanced diversity through Gaussian perturbation.", "code": "import numpy as np\n\nclass ImprovedAdaptiveParticleDEGaussianOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30  # Increased initial population size for better exploration\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.3 + 0.2 * (np.cos(angle) + 1) / 2  # More dynamic sinusoidal adaptation\n        self.F = 0.6 + 0.1 * np.sin(angle)\n        self.CR = 0.85 + 0.1 * np.cos(angle)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))  # Increased scaling for Levy\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector + np.random.normal(0, 0.01, self.dim), lb, ub)  # Gaussian noise\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm ImprovedAdaptiveParticleDEGaussianOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08421 with standard deviation 0.00839.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.0939697947169652, 0.07348221967704693, 0.08517336126478825]}}
{"id": "c1aeedc8-4a73-428b-bdcf-9105cbafff0d", "fitness": 0.08465095129276394, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced dynamic balancing of exploration and exploitation through adaptive particle influence and efficient parameter modulation using a novel sigmoid-based adaptation scheme.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        sigmoid = 1 / (1 + np.exp(-10 * (progress - 0.5)))  # New sigmoid-based modulation\n        self.w = 0.4 + 0.1 * sigmoid\n        self.F = 0.5 + 0.2 * sigmoid\n        self.CR = 0.8 + 0.1 * (1 - sigmoid)\n        self.alpha = 0.01 * (1 + 0.5 * sigmoid)\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08465 with standard deviation 0.01019.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09742365183085255, 0.08404300037384471, 0.07248620167359454]}}
{"id": "fb95a789-f4a6-4ea4-8685-a439897e7ab2", "fitness": 0.09351284782677283, "name": "EnhancedAdaptiveParticleDELevyOptimizer", "description": "Enhanced exploration and exploitation through refined parameter adaptation and dynamic crossover spread.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi  # Use a full rotation angle for parameter modulation\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2  # Smooth sinusoidal adaptation\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.75 + 0.15 * np.cos(angle)  # Slight adjustment for wider exploration\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)  # Adjust scaling factor\n                mutant_vector = x1 + F_adj * (x2 - x3)  # Adjusted scaling factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:  # Levy flight perturbation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09351 with standard deviation 0.00220.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09574694690841612, 0.0942765683931156, 0.09051502817878676]}}
{"id": "bd8ecbee-8895-4fd4-b5e1-08186eeafe81", "fitness": -Infinity, "name": "EnhancedDynamicPopulationOptimizer", "description": "Introduce a dynamic population size coupled with adaptive parameter tuning and enhanced exploitation via a novel differential evolution-inspired mutation.", "code": "import numpy as np\n\nclass EnhancedDynamicPopulationOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - (iteration / max_iterations) ** 0.5)  # Adjust scaling factor for exploitation\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                self.population_size = max(5, int(self.initial_population_size * (1 - progress)))\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "An exception occurred: NameError(\"name 'progress' is not defined\").", "error": "NameError(\"name 'progress' is not defined\")", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {}}
{"id": "40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a", "fitness": 0.09510487381012737, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "An enhanced optimizer leveraging dynamic population adjustments and adaptive hybrid strategies for robust exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.00202.", "error": "", "parent_ids": ["f93f2610-bbee-4010-a2ab-69bbbdac09a5"], "operator": null, "metadata": {"aucs": [0.09705860466698424, 0.09593481134219506, 0.09232120542120281]}}
{"id": "8b640145-5d38-4bc6-a757-ffe1b6766853", "fitness": 0.08755128071163876, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "Leveraging adaptive repartitioning of exploration and exploitation phases with dynamic swarm adjustments to enhance convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5\n        self.c1 = 1.0\n        self.c2 = 2.0\n        self.F = 0.5\n        self.CR = 0.9\n        self.alpha = 0.01\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def dynamic_swarm_adjustment(self, evaluations, budget):\n        if evaluations < budget / 2:\n            return self.initial_population_size\n        elif evaluations < (3 * budget) / 4:\n            return max(10, self.initial_population_size // 2)\n        else:\n            return max(5, self.initial_population_size // 4)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            self.population_size = self.dynamic_swarm_adjustment(evaluations, self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08755 with standard deviation 0.00452.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09022514215014943, 0.09124842842791325, 0.08118027155685359]}}
{"id": "6699ca63-79b6-48c1-9888-32afdd4f20ae", "fitness": 0.07530549479769655, "name": "RefinedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer enhancing exploration and exploitation balance through adaptive parameters and particle prioritization for efficient convergence in black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # increased cognitive parameter for better personal exploration\n        self.c2 = 1.5  # adjusted social parameter for balanced social influence\n        self.F = 0.6  # slightly increased DE scaling factor for broader search\n        self.CR = 0.85  # adjusted DE crossover probability\n        self.alpha = 0.02  # increased scaling factor for more impactful Levy flights\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.6 + 0.2 * np.sin(angle)\n        self.CR = 0.85 + 0.1 * np.cos(angle)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.02):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def prioritize_particles(self, particles, scores):\n        sorted_indices = np.argsort(scores)\n        return particles[sorted_indices], scores[sorted_indices]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            particles, personal_best_scores = self.prioritize_particles(particles, personal_best_scores)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm RefinedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07531 with standard deviation 0.00803.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08466384065109978, 0.07620725281402518, 0.06504539092796469]}}
{"id": "9747a527-3337-4fa2-97b5-93f5e76fcdc1", "fitness": 0.07969589650715614, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "A refined optimizer with slightly enhanced crossover rates for improved exploration and convergence.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.95  # DE crossover probability  # Changed from 0.9 to 0.95\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07970 with standard deviation 0.00989.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09366338765176419, 0.07341050819356876, 0.07201379367613547]}}
{"id": "59e462d9-1dd0-4b15-a3f3-e1fc0fca14ac", "fitness": 0.07941818942541072, "name": "RefinedMultiSwarmHybridOptimizer", "description": "A refined optimizer that introduces multi-swarm dynamic cooperation and hybrid global-local search mechanisms for enhanced exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass RefinedMultiSwarmHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.num_swarms = 3\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle) * np.cos(progress * np.pi)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n        swarms = [np.random.rand(self.population_size, self.dim) * (ub - lb) + lb for _ in range(self.num_swarms)]\n        velocities = [np.random.rand(self.population_size, self.dim) * (ub - lb) / 5 for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(swarm) for swarm in swarms]\n        personal_best_scores = [np.array([func(p) for p in swarm]) for swarm in swarms]\n        global_best_position = min((p for sublist in personal_best_positions for p in sublist), key=func)\n        global_best_score = func(global_best_position)\n\n        evaluations = self.num_swarms * self.population_size\n        max_iterations = self.budget // (self.num_swarms * self.population_size)\n        iteration = 0\n\n        while evaluations < self.budget:\n            for s in range(self.num_swarms):\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[s][i] = (self.w * velocities[s][i] +\n                                        self.c1 * r1 * (personal_best_positions[s][i] - swarms[s][i]) +\n                                        self.c2 * r2 * (global_best_position - swarms[s][i]))\n\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x1, x2, x3 = swarms[s][indices]\n                    F_adj = self.F * (1 - iteration / max_iterations)\n                    mutant_vector = x1 + F_adj * (x2 - x3)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    trial_vector = np.where(crossover, mutant_vector, swarms[s][i])\n\n                    swarms[s][i] = np.clip(swarms[s][i] + velocities[s][i], lb, ub)\n                    trial_vector = np.clip(trial_vector, lb, ub)\n\n                    if np.random.rand() < 0.3:\n                        trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                    trial_score = func(trial_vector)\n                    evaluations += 1\n\n                    if trial_score < personal_best_scores[s][i]:\n                        personal_best_positions[s][i] = trial_vector\n                        personal_best_scores[s][i] = trial_score\n\n                        if trial_score < global_best_score:\n                            global_best_position = trial_vector\n                            global_best_score = trial_score\n\n                    if evaluations >= self.budget:\n                        break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "The algorithm RefinedMultiSwarmHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07942 with standard deviation 0.00409.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08382294153787995, 0.07396325750835697, 0.08046836922999523]}}
{"id": "8252447b-5458-46c0-88aa-cb5e0e2dfd05", "fitness": 0.08044540311971704, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer with dynamic parameter adaptation and a blend of Particle Swarm, Differential Evolution, and Levy Flight for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        if progress > 0.5:\n            self.c1, self.c2 = self.c2, self.c1\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F + 0.1 * np.sin(np.pi * iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, int(self.initial_population_size / 1.5))\n                else:\n                    self.population_size = max(5, int(self.initial_population_size / 3))\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08045 with standard deviation 0.00846.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09094693910375773, 0.08016331931401754, 0.07022595094137585]}}
{"id": "31c367f2-d2eb-4672-845d-cfb7d5414751", "fitness": 0.08809659859074222, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "Introducing a slight variation in the DE scaling factor adaptation using a cosine function to enhance exploration in the optimization process.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.cos(angle)  # Changed sin to cos for F adaptation\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08810 with standard deviation 0.00921.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09458808470670044, 0.09462874824769285, 0.07507296281783338]}}
{"id": "dde2a8fd-e2ce-4212-bd77-61c1d5d1b51a", "fitness": 0.08843659274921715, "name": "EnhancedAdaptiveParticleDELevyChaosOptimizer", "description": "A novel optimizer combining dynamic multi-phase population control and adaptive chaos-based strategies for enhanced exploration and exploitation.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyChaosOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_map(self, x, iteration, max_iterations):\n        # Logistic map for chaos-based exploration\n        r = 4.0 - 3.0 * iteration / max_iterations\n        return r * x * (1 - x)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                # Apply chaotic perturbation\n                trial_vector = np.clip(trial_vector + self.chaotic_map(np.random.rand(self.dim), iteration, max_iterations), lb, ub)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyChaosOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08844 with standard deviation 0.00914.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.07557726144287624, 0.09594446124356015, 0.09378805556121506]}}
{"id": "9eaaad29-617e-4fc0-a96d-a3db41e55559", "fitness": 0.07756282050265732, "name": "RefinedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer utilizing adaptive strategy variations and dynamic parameter scaling with non-linear progression for enhanced exploration and precision in black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.7  # Adjusted inertia weight for better convergence\n        self.c1 = 1.5  # Increased cognitive parameter to focus more on exploration\n        self.c2 = 1.5  # Balanced social parameter for exploration and exploitation\n        self.F = 0.5\n        self.CR = 0.9\n        self.alpha = 0.02  # Slightly higher scaling factor for Levy flight to explore diverse areas\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.5 + 0.3 * (1 - np.cos(np.pi * progress))\n        self.F = 0.4 + 0.3 * (1 - np.cos(2 * np.pi * progress))\n        self.CR = 0.7 + 0.2 * (1 - np.cos(2 * np.pi * progress))\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(2 * np.pi * progress))\n\n    def levy_flight(self, scale=0.02):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.5:  # Increase chance of Levy flight to encourage exploration\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm RefinedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07756 with standard deviation 0.00389.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08234910179518828, 0.07282583869514603, 0.07751352101763764]}}
{"id": "75303308-7f08-41ae-8758-32ad3109dfa3", "fitness": 0.08556337647152745, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "A novel optimizer that introduces a dynamic adaptive mechanism for parameter tuning and exploration balance using chaotic maps and beta distribution for improved black-box optimization.", "code": "import numpy as np\nfrom scipy.stats import beta\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_map(self, iteration, max_iterations):\n        return 4 * (iteration / max_iterations) * (1 - iteration / max_iterations)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1 = beta.rvs(2, 5, size=self.dim)  # More exploration\n                r2 = beta.rvs(5, 1, size=self.dim)  # More exploitation\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                chaotic_factor = self.chaotic_map(iteration, max_iterations)\n                mutant_vector = x1 + self.F * (x2 - x3) * chaotic_factor\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08556 with standard deviation 0.00776.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08591999024132235, 0.09488625266406037, 0.07588388650919964]}}
{"id": "0990abf7-59e5-4142-9127-e417e1700c93", "fitness": 0.08820686702538454, "name": "AdvancedAdaptiveParticleDELevyOptimizerV3", "description": "A sophisticated optimizer utilizing adaptive population dynamics, dynamic parameter tuning, and hybridized exploration techniques for effective convergence in black-box optimization.", "code": "import numpy as np\n\nclass AdvancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.7  # increased inertia weight for exploration\n        self.c1 = 1.5  # increased cognitive parameter for better personal search\n        self.c2 = 1.5  # reduced social parameter for diversified exploration\n        self.F = 0.6  # increased DE scaling factor for better exploration\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.02  # increased scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.2 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.3 * np.sin(angle)\n        self.CR = 0.7 + 0.2 * np.cos(angle)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.02):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm AdvancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08821 with standard deviation 0.00076.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08780170823883826, 0.08927261457693181, 0.08754627826038353]}}
{"id": "d0858205-7f4b-47f9-8965-0a828e53074e", "fitness": 0.09422640180200818, "name": "ChaoticallyEnhancedAdaptiveParticleDELevyOptimizer", "description": "A novel optimizer enhancing exploration and exploitation balance via dynamic parameter adaptation and chaotic sequences for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass ChaoticallyEnhancedAdaptiveParticleDELevyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def chaotic_sequence(self, size):\n        x = 0.7  # initial value for the chaotic sequence\n        sequence = np.zeros(size)\n        for i in range(size):\n            x = 4 * x * (1 - x)  # logistic map\n            sequence[i] = x\n        return sequence\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            chaos = self.chaotic_sequence(self.population_size)\n            for i in range(self.population_size):\n                r1, r2 = chaos[i] * np.random.rand(self.dim), chaos[i] * np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm ChaoticallyEnhancedAdaptiveParticleDELevyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09423 with standard deviation 0.00229.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09438952785082699, 0.09134206478628637, 0.09694761276891117]}}
{"id": "a143a57d-f33f-4167-b21f-bce3e86056b1", "fitness": 0.08161424888176323, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "An advanced optimizer integrating dynamic swarming behavior, adaptive mutation, and strategic population resizing to enhance convergence speed and robustness in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.3 * (1 - progress)\n        self.F = 0.5 + 0.3 * np.sin(progress * np.pi)\n        self.CR = 0.9 - 0.1 * np.cos(progress * np.pi)\n        self.alpha = 0.01 * (1 + 0.5 * np.cos(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08161 with standard deviation 0.00226.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08369239192926625, 0.0826712992017814, 0.07847905551424206]}}
{"id": "36c35c88-0f5c-46b2-8dbd-0d07f1149184", "fitness": 0.09205382546416585, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "Improved the inertia weight adaptation to enhance exploration and exploitation balance in optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.2 * (np.cos(angle) + 1) / 2  # increased amplitude for w\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09205 with standard deviation 0.00390.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09321315030055055, 0.09614422243344944, 0.08680410365849756]}}
{"id": "659e49f1-6dfd-480b-8d11-49d415691e17", "fitness": 0.08346373876514146, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "Optimized hybrid algorithm integrating adaptive techniques and balanced exploration-exploitation with stochastic control for enhanced convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * np.pi\n        self.w = 0.4 + 0.3 * np.cos(angle)\n        self.F = 0.5 + 0.3 * np.sin(angle)\n        self.CR = 0.7 + 0.2 * np.cos(angle)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations) * np.random.rand()\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.4:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n                particles = particles[:self.population_size]\n                velocities = velocities[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08346 with standard deviation 0.00717.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09102563774469241, 0.08552870964623382, 0.07383686890449814]}}
{"id": "621205df-874e-4650-95d9-a865050aad94", "fitness": 0.08855631772851062, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "A refined optimizer with a slight enhancement in the mutation strategy to improve convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3) + 0.1 * (global_best_position - x1)  # Modified\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08856 with standard deviation 0.00873.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09589678243962885, 0.09348806329267867, 0.07628410745322434]}}
{"id": "6ed7c20b-7460-47a5-9dac-90c548e817c7", "fitness": 0.09510487381012737, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "A refined optimizer introducing dynamic inertia weight scaling for improved convergence and exploration balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.00202.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09705860466698424, 0.09593481134219506, 0.09232120542120281]}}
{"id": "7474ee4a-c89d-4ffa-8d00-6498480fff27", "fitness": 0.07845773369033744, "name": "RefinedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer that integrates adaptive parameter tuning with dynamic population control and strategic local search enhancements for improved convergence in black-box optimization.", "code": "import numpy as np\n\nclass RefinedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # increased cognitive parameter\n        self.c2 = 1.5  # decreased social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.02  # Increased scaling factor for Levy flight\n        self.beta = 0.8  # Additional parameter for balancing exploration and exploitation\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.3 * (1 - progress) ** 2  # quadratic decay\n        self.F = 0.5 + 0.3 * np.sin(2 * np.pi * progress)\n        self.CR = 0.7 + 0.2 * np.cos(2 * np.pi * progress)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(2 * np.pi * progress))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 5) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 3)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "The algorithm RefinedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07846 with standard deviation 0.00970.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.06504132047605415, 0.08762523734688399, 0.0827066432480742]}}
{"id": "cb052e7b-b643-4156-8ef4-221c8fbe4c51", "fitness": 0.08394866159390472, "name": "RefinedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer using adaptive parameters with mechanisms for resourceful exploration and intensive local search for improved convergence.", "code": "import numpy as np\n\nclass RefinedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.6  # DE scaling factor\n        self.CR = 0.8  # DE crossover probability\n        self.alpha = 0.02  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.6 + 0.2 * np.sin(angle)\n        self.CR = 0.7 + 0.15 * np.cos(angle)\n        self.alpha = 0.02 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.02):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n            if iteration % (max_iterations // 4) == 0:\n                self.population_size = max(5, int(self.initial_population_size * (1 - iteration / max_iterations)))\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm RefinedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08395 with standard deviation 0.00277.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.08193349736804445, 0.08786508358428613, 0.08204740382938358]}}
{"id": "449b4639-b0c7-4d7c-a1d2-57e3875924b1", "fitness": -Infinity, "name": "RefinedAdaptiveHybridOptimizerV1", "description": "A refined optimizer that enhances exploration and convergence by incorporating adaptive mutation, crossover strategies, and dynamic parameter tuning based on swarm diversity and convergence feedback.", "code": "import numpy as np\n\nclass RefinedAdaptiveHybridOptimizerV1:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations, diversity):\n        progress = iteration / max_iterations\n        self.w = 0.4 + 0.3 * (1 - progress) * diversity  # Adaptive inertia\n        self.F = 0.4 + 0.4 * np.sin(progress * np.pi)  # Adaptive DE scaling factor\n        self.CR = 0.7 + 0.2 * np.cos(progress * np.pi) * diversity  # Adaptive crossover\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            diversity = np.std(personal_best_positions, axis=0).mean() / (ub - lb).mean()\n            self.adapt_parameters(iteration, max_iterations, diversity)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * diversity)\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                self.population_size = max(5, int(self.initial_population_size * (1 - progress)))\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "An exception occurred: NameError(\"name 'progress' is not defined\").", "error": "NameError(\"name 'progress' is not defined\")", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {}}
{"id": "f0bd2583-2aa7-4efd-96a4-92ac26425198", "fitness": 0.0905925250313772, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "Improved diversity by adding mutation to the velocity update for enhanced exploration.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                mutation = 0.01 * np.random.normal(size=self.dim)  # Mutation added here\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]) +\n                                 mutation)\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09059 with standard deviation 0.00252.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.0882369557444157, 0.0940878560716033, 0.08945276327811258]}}
{"id": "069f4de3-93f2-4855-8825-431fb3a01ad7", "fitness": 0.08475467632699522, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "The algorithm introduces an adaptive mutation step and a dynamic restart mechanism to enhance exploration and convergence capabilities in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.restart_count = 0  # Count restarts\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def restart_population(self, lb, ub):\n        self.restart_count += 1\n        return np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3 or iteration % 10 == 0:  # Added adaptive mutation\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            if iteration > 0 and iteration % (max_iterations // 2) == 0:  # Dynamic restart mechanism\n                particles = self.restart_population(lb, ub)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08475 with standard deviation 0.00693.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09010459550959848, 0.08919165266344298, 0.0749677808079442]}}
{"id": "299b0bdb-c618-4934-9a35-47b9f55ae0b9", "fitness": 0.07242155730876969, "name": "OptimizedAdaptiveMetaheuristicV3", "description": "An optimized metaheuristic combining adaptive evolutionary strategies and dynamic parameter tuning for enhanced exploration-exploitation balance in black-box optimization.", "code": "import numpy as np\n\nclass OptimizedAdaptiveMetaheuristicV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.6  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 2.5  # social parameter\n        self.F = 0.6  # DE scaling factor\n        self.CR = 0.85  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        self.w = 0.5 + 0.3 * np.cos(progress * np.pi)\n        self.F = 0.5 + 0.25 * np.sin(progress * np.pi)\n        self.CR = 0.7 + 0.15 * (np.cos(progress * np.pi) + 1) / 2\n        self.alpha = 0.02 * (1 + 0.3 * np.sin(progress * np.pi))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.2:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 3) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(10, self.initial_population_size // 3)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm OptimizedAdaptiveMetaheuristicV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07242 with standard deviation 0.00122.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.0738342931257363, 0.07086381768418959, 0.07256656111638315]}}
{"id": "058e4d40-c61a-4e9f-aeae-b551c9e129df", "fitness": 0.08614205953209216, "name": "AdvancedDynamicLevyDEOptimizer", "description": "An advanced optimizer that integrates adaptive dynamic parameters, strategic exploration via Levy flights, and enhanced differential evolution for superior exploration and exploitation balance.", "code": "import numpy as np\n\nclass AdvancedDynamicLevyDEOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.15 * (np.cos(angle) + 1) / 2  # Increased dynamic range\n        self.F = 0.5 + 0.25 * np.sin(angle)  # Increased flexibility\n        self.CR = 0.8 + 0.15 * np.cos(angle)  # Improved crossover adaptability\n        self.alpha = 0.01 * (1 + 0.6 * np.sin(angle))  # Enhanced exploratory capability\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm AdvancedDynamicLevyDEOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08614 with standard deviation 0.00823.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.0949234309005309, 0.08836336751588059, 0.07513938017986499]}}
{"id": "27dad330-2db0-4c8f-979b-1a4623858f74", "fitness": 0.09510487381012737, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "A refined optimizer with enhanced exploration using a dynamic blend of adaptive strategies and Levy flights.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.00202.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09705860466698424, 0.09593481134219506, 0.09232120542120281]}}
{"id": "608ea920-d3e3-46b4-94e4-6f724ec7571f", "fitness": 0.09491404470010352, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "An enhanced optimizer with dynamic strategy refinement for improved exploration and convergence by adjusting DE scaling factor based on iteration progress.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle) * (1.2 - progress)  # Adjusted scaling factor\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09491 with standard deviation 0.00182.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09722534948384065, 0.09472802744539555, 0.09278875717107438]}}
{"id": "be17a8f8-7b2c-42fc-84c2-0d0d43e4c5eb", "fitness": 0.07125199494357155, "name": "AdaptiveMultiStrategyOptimizer", "description": "Introducing adaptive multi-strategy exploration and convergence control with dynamic feedback for optimized performance in black-box problems.", "code": "import numpy as np\n\nclass AdaptiveMultiStrategyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.w = 0.6\n        self.c1 = 1.5\n        self.c2 = 2.0\n        self.F = 0.6\n        self.CR = 0.9\n        self.alpha = 0.01\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.5 + 0.1 * np.cos(angle)\n        self.F = 0.6 + 0.1 * np.sin(angle)\n        self.CR = 0.85 + 0.05 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self.adapt_parameters(iteration, max_iterations)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                mutant_vector = x1 + self.F * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 5) == 0:\n                if evaluations < (2 * self.budget) / 3:\n                    self.population_size = max(15, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(10, self.initial_population_size // 3)\n\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm AdaptiveMultiStrategyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07125 with standard deviation 0.00746.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.07086275607843284, 0.08057954835097714, 0.062313680401304694]}}
{"id": "8e955924-30ea-4e9e-add1-f1bbd49305fb", "fitness": 0.09101757836744188, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "A refined optimizer using dynamic chaos-driven parameter adaptation for enhanced exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        chaos_factor = (iteration / max_iterations) * (1 - iteration / max_iterations)\n        self.w = 0.4 + 0.3 * chaos_factor\n        self.F = 0.5 + 0.3 * np.sin(np.pi * chaos_factor)\n        self.CR = 0.8 + 0.2 * chaos_factor\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(np.pi * chaos_factor))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09102 with standard deviation 0.00304.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09530774918858054, 0.08864210326607391, 0.08910288264767119]}}
{"id": "89d76d0c-167c-4125-bb0e-ab3c60eecad0", "fitness": 0.09039714704595521, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "An enhanced optimizer utilizing adaptive parameter control with chaotic maps and multi-elitism strategies to improve exploration-exploitation balance and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        chaotic_factor = 4 * progress * (1 - progress)  # Logistic map for chaotic behavior\n        self.w = 0.4 + 0.1 * chaotic_factor\n        self.F = 0.5 + 0.2 * chaotic_factor\n        self.CR = 0.8 + 0.1 * chaotic_factor\n        self.alpha = 0.01 * (1 + 0.5 * chaotic_factor)\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09040 with standard deviation 0.00347.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09479479865271889, 0.0900952587893139, 0.08630138369583285]}}
{"id": "bdeaefeb-b28a-46b4-b0b4-89c3a3e7da52", "fitness": 0.09165505259317593, "name": "EnhancedAdaptiveParticleDELevyOptimizerV2", "description": "Introduced a nonlinear dynamic adjustment for the cognitive parameter to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        # Change made here: Introduced a nonlinear dynamic adjustment for c1\n        self.c1 = 1.0 + 0.5 * np.sin(progress * np.pi)\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09166 with standard deviation 0.00256.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09147264855200132, 0.09487665456839023, 0.08861585465913624]}}
{"id": "226c3392-af21-4b95-97b3-0983edee6be6", "fitness": 0.09510487381012737, "name": "EnhancedAdaptiveParticleDELevyOptimizerV3", "description": "An enhanced optimizer combining dynamic population adjustments, progressive learning rate reduction, and adaptive hybrid strategies for improved exploration and convergence in black-box optimization.", "code": "import numpy as np\n\nclass EnhancedAdaptiveParticleDELevyOptimizerV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.0  # cognitive parameter\n        self.c2 = 2.0  # social parameter\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # DE crossover probability\n        self.alpha = 0.01  # Scaling factor for Levy flight\n        self.learning_rate = 0.1  # initial learning rate for progressiveness\n\n    def adapt_parameters(self, iteration, max_iterations):\n        progress = iteration / max_iterations\n        angle = progress * 2 * np.pi\n        self.w = 0.4 + 0.1 * (np.cos(angle) + 1) / 2\n        self.F = 0.5 + 0.2 * np.sin(angle)\n        self.CR = 0.8 + 0.1 * np.cos(angle)\n        self.alpha = 0.01 * (1 + 0.5 * np.sin(angle))\n        self.learning_rate *= 0.98  # progressively reduce learning rate\n\n    def levy_flight(self, scale=0.01):\n        u = np.random.normal(0, 1, self.dim) * scale\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / 3))\n        return step\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = np.array(bounds.lb), np.array(bounds.ub)\n\n        particles = np.random.rand(self.population_size, self.dim) * (ub - lb) + lb\n        velocities = np.random.rand(self.population_size, self.dim) * (ub - lb) / 5\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n        max_iterations = self.budget // self.population_size\n        iteration = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = particles[indices]\n                F_adj = self.F * (1 - iteration / max_iterations)\n                mutant_vector = x1 + F_adj * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover, mutant_vector, particles[i])\n\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                if np.random.rand() < 0.3:\n                    trial_vector += self.levy_flight(self.alpha * (1 - iteration / max_iterations))\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n\n                if evaluations >= self.budget:\n                    break\n\n            if iteration % (max_iterations // 4) == 0:\n                if evaluations < (3 * self.budget) / 4:\n                    self.population_size = max(10, self.initial_population_size // 2)\n                else:\n                    self.population_size = max(5, self.initial_population_size // 4)\n\n            self.adapt_parameters(iteration, max_iterations)\n            iteration += 1\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm EnhancedAdaptiveParticleDELevyOptimizerV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09510 with standard deviation 0.00202.", "error": "", "parent_ids": ["40db64a0-7102-4f1b-8ab0-8dc2c6ff4b5a"], "operator": null, "metadata": {"aucs": [0.09705860466698424, 0.09593481134219506, 0.09232120542120281]}}
