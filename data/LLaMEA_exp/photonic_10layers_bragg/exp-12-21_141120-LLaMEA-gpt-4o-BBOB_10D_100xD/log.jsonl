{"id": "8a25717d-42a3-4060-8da3-6d68aeeac666", "fitness": 0.09968297683269314, "name": "AHSO", "description": "Adaptive Hybrid Swarm Optimization (AHSO) combining particle swarm and genetic algorithm dynamics to balance exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    cutpoint = np.random.randint(1, self.dim - 1)\n                    child1 = np.concatenate((population[parents[0], :cutpoint],\n                                             population[parents[1], cutpoint:]))\n                    child2 = np.concatenate((population[parents[1], :cutpoint],\n                                             population[parents[0], cutpoint:]))\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 0, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09968 with standard deviation 0.04163.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.14894560226022624, 0.16610614381970956, 0.15112995396125184, 0.08748937441596893, 0.08363607902461445, 0.08120582769763929, 0.05663516935939972, 0.07714443165397222, 0.044854209301456005]}}
{"id": "f4efc9a3-204d-4671-a8d6-ca25140fa7f3", "fitness": 0.09656534649409053, "name": "AHSO", "description": "Enhanced Adaptive Hybrid Swarm Optimization (EAHSO) with dynamic inertia weight adjustment and elite selection for improved convergence.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.final_inertia_weight = 0.4  # New final inertia weight\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Dynamic inertia weight adjustment\n            self.inertia_weight = (self.final_inertia_weight +\n                                   (0.9 - self.final_inertia_weight) *\n                                   ((self.budget - evaluations) / self.budget))\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            elite_size = self.population_size // 10  # New elite selection\n            elite_indices = np.argsort(scores)[:elite_size]\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    cutpoint = np.random.randint(1, self.dim - 1)\n                    child1 = np.concatenate((population[parents[0], :cutpoint],\n                                             population[parents[1], cutpoint:]))\n                    child2 = np.concatenate((population[parents[1], :cutpoint],\n                                             population[parents[0], cutpoint:]))\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring, preserving elites\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_worst_idx = worst_idx[~np.in1d(worst_idx, elite_indices)]\n            population[non_elite_worst_idx] = offspring[:len(non_elite_worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 1, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09657 with standard deviation 0.04743.", "error": "", "parent_ids": ["8a25717d-42a3-4060-8da3-6d68aeeac666"], "operator": null, "metadata": {"aucs": [0.16203654425410974, 0.16610614381970956, 0.1551021182991088, 0.08696761881610515, 0.07940004781166177, 0.06350247543714327, 0.04487140426475256, 0.06509069448705418, 0.046011071257169744]}}
{"id": "a444b778-055c-4e55-b8ef-96c20a1d667e", "fitness": 0.09578999927428872, "name": "E_AHSO", "description": "Enhanced Adaptive Hybrid Swarm Optimization (E-AHSO) incorporating adaptive inertia weight and differential evolution-inspired mutation for improved convergence and exploration-exploitation balance.", "code": "import numpy as np\n\nclass E_AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.evaluations = 0\n\n    def adaptive_inertia_weight(self):\n        w = self.inertia_weight_max - ((self.inertia_weight_max - self.inertia_weight_min) * (self.evaluations / self.budget))\n        return w\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            self.evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics with adaptive inertia)\n            w = self.adaptive_inertia_weight()\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Differential Evolution-inspired Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    cutpoint = np.random.randint(1, self.dim - 1)\n                    child1 = np.concatenate((population[parents[0], :cutpoint],\n                                             population[parents[1], cutpoint:]))\n                    child2 = np.concatenate((population[parents[1], :cutpoint],\n                                             population[parents[0], cutpoint:]))\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Differential Evolution-inspired Mutation\n            F = 0.8\n            mutation_population = []\n            for individual in offspring:\n                if np.random.rand() < self.mutation_prob:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = population[indices]\n                    mutant = a + F * (b - c)\n                    mutant = np.clip(mutant, lb, ub)\n                    mutation_population.append(mutant)\n                else:\n                    mutation_population.append(individual)\n            offspring = np.array(mutation_population)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 2, "feedback": "The algorithm E_AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09579 with standard deviation 0.04952.", "error": "", "parent_ids": ["8a25717d-42a3-4060-8da3-6d68aeeac666"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.17839500621271254, 0.14794092546802862, 0.08594193586186327, 0.07940004781166177, 0.06554398868056022, 0.03395901902921317, 0.06689617248150637, 0.044943852934657524]}}
{"id": "c7d19e1a-931a-4e21-8f56-574651103c34", "fitness": 0.10405429170021539, "name": "AHSO", "description": "Enhanced the crossover operation with a blend crossover method to increase offspring diversity.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 3, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10405 with standard deviation 0.04342.", "error": "", "parent_ids": ["8a25717d-42a3-4060-8da3-6d68aeeac666"], "operator": null, "metadata": {"aucs": [0.16045027825610048, 0.16610614381970956, 0.16576921747054785, 0.08594193586186327, 0.08474153135598128, 0.0705664886050198, 0.06000050173469851, 0.06043505741886479, 0.08247747077915302]}}
{"id": "45afdeca-9f04-4c26-a1c0-ef8b6bafdcba", "fitness": -Infinity, "name": "AHSO", "description": "Improve AHSO by integrating adaptive parameter tuning and crowding distance for diversity preservation.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive inertia weight\n            inertia_weight = self.max_inertia_weight - (evaluations / self.budget) * (self.max_inertia_weight - self.min_inertia_weight)\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation with crowding\n            offspring = []\n            crowding_distances = self._calculate_crowding_distances(population)\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False, p=crowding_distances)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score\n\n    def _calculate_crowding_distances(self, population):\n        # Calculate crowding distances for diversity\n        population_size = len(population)\n        distances = np.zeros(population_size)\n        for i in range(self.dim):\n            sorted_indices = np.argsort(population[:, i])\n            sorted_pop = population[sorted_indices]\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for j in range(1, population_size - 1):\n                distances[sorted_indices[j]] += (sorted_pop[j + 1, i] - sorted_pop[j - 1, i]) / (np.max(population[:, i]) - np.min(population[:, i]) + 1e-9)\n        return distances / np.sum(distances)", "configspace": "", "generation": 4, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {}}
{"id": "3594b01a-8062-4ad4-ae87-b562a3e9f424", "fitness": 0.10344236837881318, "name": "AHSO", "description": "Introduced adaptive parameters and enhanced mutation to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5 + np.random.rand() * 1.5  # Adaptive\n        self.c2 = 1.5 + np.random.rand() * 1.5  # Adaptive\n        self.inertia_weight = 0.5 + np.random.rand() * 0.5  # Adaptive\n        self.mutation_prob = 0.2  # Increased\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  \n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            gaussian_mutation = np.random.normal(0, 0.1, offspring.shape)  # Gaussian mutation\n            offspring[mutation_mask] += gaussian_mutation[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 5, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10344 with standard deviation 0.04630.", "error": "", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {"aucs": [0.1972184498265005, 0.147587601957486, 0.1527619104232708, 0.07814535368608078, 0.07250353081702066, 0.08099282140344322, 0.0625836368962156, 0.0643255266528997, 0.07486248374640136]}}
{"id": "efff715e-2824-40fe-a4a4-7c4380941a08", "fitness": 0.09428838029232738, "name": "EnhancedAHSO", "description": "Enhance diversity and convergence by combining self-adaptive differential evolution with dynamic parameter tuning.", "code": "import numpy as np\n\nclass EnhancedAHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.f = 0.8  # Differential evolution scaling factor\n        self.cr = 0.9  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Differential Evolution (DE) - Mutation and Crossover\n            offspring = []\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + self.f * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n                trial = np.array([mutant[j] if np.random.rand() < self.cr else population[i, j] for j in range(self.dim)])\n                offspring.append(trial)\n            \n            # Evaluate offspring\n            offspring_scores = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n\n            # Select the best individuals\n            for i in range(self.population_size):\n                if offspring_scores[i] < scores[i]:\n                    population[i] = offspring[i]\n                    scores[i] = offspring_scores[i]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 6, "feedback": "The algorithm EnhancedAHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09429 with standard deviation 0.04736.", "error": "", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {"aucs": [0.15554445350598511, 0.16637367772534817, 0.15035509753868692, 0.09553644326235988, 0.07940004781166177, 0.06035727167834826, 0.04434966281178543, 0.048546676171654424, 0.04813209212511638]}}
{"id": "dd0b8862-19c1-4948-909d-d75f2bb66bb6", "fitness": 0.0947345173565231, "name": "AHSO", "description": "Introduce adaptive inertia weight for improved exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = ((0.5 + np.random.rand() / 2) * velocities +  # Adaptive inertia weight\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 7, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09473 with standard deviation 0.04289.", "error": "", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {"aucs": [0.14656595760167657, 0.16621830836255203, 0.14650423257367762, 0.08594193586186327, 0.07940004781166177, 0.05953621177033486, 0.05419888621876545, 0.062438201315554887, 0.05180687469262146]}}
{"id": "a3c0550d-7f2d-4b34-83fb-3c488fe24b20", "fitness": 0.10163874112070843, "name": "AHSO", "description": "Introduced adaptive inertia weight adjustment to dynamically balance exploration and exploitation during optimization.  ", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            self.inertia_weight = 0.9 - (0.4 * evaluations / self.budget)  # Adaptive inertia weight change\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 8, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10164 with standard deviation 0.04593.", "error": "", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {"aucs": [0.15689740912834538, 0.16610614381970956, 0.1715044363624253, 0.08594193586186327, 0.07940004781166177, 0.06923500552301298, 0.06249021630217477, 0.07510917255015548, 0.04806430272702744]}}
{"id": "2959fb44-df58-4c8e-84c1-45a257ef803d", "fitness": 0.10504182914748819, "name": "AHSO", "description": "Introduce an adaptive inertia weight to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 9, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10504 with standard deviation 0.03384.", "error": "", "parent_ids": ["c7d19e1a-931a-4e21-8f56-574651103c34"], "operator": null, "metadata": {"aucs": [0.13980063237007545, 0.16610614381970956, 0.14295240911844576, 0.09356166958360335, 0.07940004781166177, 0.06049106791488679, 0.07468992995371093, 0.09520654405679951, 0.09316801769850058]}}
{"id": "6d65497b-f37c-4e4a-9a61-0517025ccc43", "fitness": -Infinity, "name": "EnhancedAHSO", "description": "Enhance dynamic adaptation by integrating a Lévy flight mechanism for exploration and an adaptive learning factor for exploitation.", "code": "import numpy as np\n\nclass EnhancedAHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget\n            adaptive_c1 = self.c1 - (self.c1 - 1.5) * evaluations / self.budget\n            adaptive_c2 = self.c2 + (2.5 - self.c2) * evaluations / self.budget\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - population) +\n                          adaptive_c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Introduce Lévy flight for further exploration\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring = offspring + levy_steps * (ub - lb) * 0.01\n            offspring = np.clip(offspring, lb, ub)\n\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 10, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {}}
{"id": "b266cb64-f0c8-4205-a451-f7f71aaf41c9", "fitness": 0.10153632896647972, "name": "AHSO", "description": "Adjust velocity update by including a global communication factor to enhance convergence.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            # Modified velocity update with global communication factor\n            gcf = np.random.rand(self.dim)  # Global communication factor\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population) +\n                          gcf * (global_best_position - population))  # Include gcf\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 11, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10154 with standard deviation 0.05461.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.19637673182485116, 0.16610614381970956, 0.1608008887568002, 0.08679439251727705, 0.07940004781166177, 0.07669159084366173, 0.06527714181535349, 0.03029069338504109, 0.052089329923961425]}}
{"id": "24c5b83c-f0eb-4553-82fa-1d0fb456166c", "fitness": 0.08995597528537919, "name": "EnhancedAHSO", "description": "Introduce dynamic subpopulation regrouping and learning coefficients to enhance convergence speed and solution quality.", "code": "import numpy as np\n\nclass EnhancedAHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.base_inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.subpop_size = 10\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions with adaptive inertia weight\n            self.inertia_weight = self.base_inertia_weight * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Regroup subpopulations dynamically\n            np.random.shuffle(population)\n            for i in range(0, self.population_size, self.subpop_size):\n                subpop = population[i:i+self.subpop_size]\n                subpop_scores = scores[i:i+self.subpop_size]\n                worst_idx = np.argsort(subpop_scores)[-self.subpop_size//2:]\n                best_idx = np.argsort(subpop_scores)[:self.subpop_size//2]\n\n                # Crossover within subpopulation best individuals\n                for wi, bi in zip(worst_idx, best_idx):\n                    if np.random.rand() < self.crossover_prob:\n                        alpha = np.random.uniform(0, 1, self.dim)\n                        subpop[wi] = alpha * subpop[wi] + (1 - alpha) * subpop[bi]\n                \n                # Mutation\n                mutation_mask = np.random.rand(*subpop.shape) < self.mutation_prob\n                mutation_values = np.random.uniform(lb, ub, subpop.shape)\n                subpop[mutation_mask] = mutation_values[mutation_mask]\n\n                # Update subpopulation in the main population\n                population[i:i+self.subpop_size] = subpop\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedAHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08996 with standard deviation 0.05417.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.14658579798295823, 0.17859452673958742, 0.15778913089961666, 0.08594193586186327, 0.07940004781166177, 0.06123032825808006, 0.044154005631149684, 0.026351775492524987, 0.02955622889097065]}}
{"id": "716f8ea5-ab5b-4a49-b45b-0c597ec86c0c", "fitness": 0.10012658531507997, "name": "AHSO", "description": "Introduce adaptive mutation rate to improve diversity in the population.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            self.mutation_prob = 0.1 + 0.4 * (1 - evaluations / self.budget)  # Adaptive mutation rate\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 13, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10013 with standard deviation 0.04319.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.1509772123158123, 0.16610614381970956, 0.151672016330487, 0.09353463673276474, 0.08673742716634336, 0.061927667958599386, 0.07090662028551231, 0.085893943580714, 0.033383599645777084]}}
{"id": "415c470d-b45d-4e76-b57d-01ba4b152492", "fitness": 0.10099793535424854, "name": "AHSO", "description": "Introduce an adaptive learning factor to dynamically adjust exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive learning factor adjustment\n            self.c1 = 1.5 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 14, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10100 with standard deviation 0.04412.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.15234191691468035, 0.16610614381970956, 0.16576921747054785, 0.08594193586186327, 0.07940004781166177, 0.06833157762913433, 0.06689258938668374, 0.0779521318086066, 0.04624585748534937]}}
{"id": "bd407ad4-70f3-441c-8a44-779f5f60b60c", "fitness": 0.09988090976435332, "name": "AHSO", "description": "Introduce velocity clamping to improve convergence stability in AHSO.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.velocity_clamp = 0.1  # New line added for velocity clamp\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -self.velocity_clamp, self.velocity_clamp)  # Line modified for clamping\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 15, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09988 with standard deviation 0.04498.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.14873532044118098, 0.16610614381970956, 0.14873339567382005, 0.12023202235168684, 0.09274810025197688, 0.07785106923517326, 0.05007802307279452, 0.05336900770478348, 0.04107510532805425]}}
{"id": "5c3907b0-2458-4961-a641-6cbe4fcd3307", "fitness": 0.10347445237435061, "name": "AHSO", "description": "Enhance exploration by introducing non-linear crossover and mutation rates to adapt dynamically with evaluations.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            self.crossover_prob = 0.5 + 0.5 * (1 - evaluations / self.budget)  # non-linear crossover\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            self.mutation_prob = 0.2 * (1 - evaluations / self.budget)  # non-linear mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 16, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10347 with standard deviation 0.04151.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.15780465277386435, 0.16610614381970956, 0.15771371732196315, 0.09884926457084975, 0.07953774465302954, 0.07012755914533475, 0.06502238739171529, 0.06842395296008064, 0.06768464873260849]}}
{"id": "9ccf18ce-7f3e-4c4e-9ebd-d81fb4ecccd8", "fitness": 0.0981950257179232, "name": "AHSO", "description": "Introduce dynamic crossover probability based on population diversity to enhance exploration.", "code": "import numpy as np\n\nclass AHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.4 + 0.5 * evaluations / self.budget  \n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                # Dynamic crossover probability adjustment\n                self.crossover_prob = 0.5 + 0.5 * np.std(population) / (ub - lb).max()  \n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover change\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Replace worst half of the population with offspring\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            population[worst_idx] = offspring[:len(worst_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 17, "feedback": "The algorithm AHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09820 with standard deviation 0.03994.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.14579187443328423, 0.16610614381970956, 0.14470750998398874, 0.0915565180550546, 0.0819740725813356, 0.06102267383497628, 0.0738959424998552, 0.056023104928465406, 0.06267739132463912]}}
{"id": "c77bd6e1-27dc-45c8-bef9-4b990de6447d", "fitness": 0.10549127669645929, "name": "AHSO_Improved", "description": "Combine adaptive inertia weight with dynamic parameter adjustment and elite preservation strategy to improve convergence.", "code": "import numpy as np\n\nclass AHSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight with dynamic parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Preserve elites and replace non-elites\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 18, "feedback": "The algorithm AHSO_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10549 with standard deviation 0.03997.", "error": "", "parent_ids": ["2959fb44-df58-4c8e-84c1-45a257ef803d"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16610614381970956, 0.15603999183266193, 0.08594193586186327, 0.08800679825178703, 0.0648459722836513, 0.062027642383335024, 0.07682282745629121, 0.09054113339043934]}}
{"id": "19eddd2d-87c1-4faa-aa03-883c8bb52eb3", "fitness": 0.10787527680994866, "name": "AHSO_Improved", "description": "Introduce velocity clamping and elite crossover to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight with dynamic parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))  # Velocity clamping\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.uniform(lb, ub, offspring.shape)\n            offspring[mutation_mask] = mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Preserve elites and replace non-elites\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            # Elite crossover\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 19, "feedback": "The algorithm AHSO_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10788 with standard deviation 0.04058.", "error": "", "parent_ids": ["c77bd6e1-27dc-45c8-bef9-4b990de6447d"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16635304731365996, 0.15900513179516573, 0.08594193586186327, 0.07940004781166177, 0.07569829950860107, 0.09347546070377277, 0.10418951569030799, 0.047725007616110426]}}
{"id": "177cb173-9957-4dbd-bc3c-05fe3ee76023", "fitness": 0.11269668377658121, "name": "AHSO_Improved", "description": "Refine mutation strategy to increase diversity by introducing Gaussian perturbation.", "code": "import numpy as np\n\nclass AHSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight with dynamic parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))  # Velocity clamping\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.normal(0, 0.1 * (ub - lb), offspring.shape)  # Gaussian perturbation\n            offspring[mutation_mask] += mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Preserve elites and replace non-elites\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            # Elite crossover\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 20, "feedback": "The algorithm AHSO_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11270 with standard deviation 0.03730.", "error": "", "parent_ids": ["19eddd2d-87c1-4faa-aa03-883c8bb52eb3"], "operator": null, "metadata": {"aucs": [0.17241374126835574, 0.16610614381970956, 0.14973911922048577, 0.08875991066590716, 0.07984772089935399, 0.0684522244949618, 0.09455585315481274, 0.10973757129888184, 0.08465786916676243]}}
{"id": "44cf8199-f030-480a-a91e-8be94c738fa9", "fitness": -Infinity, "name": "AHSO_Improved_v2", "description": "Introduce adaptive mutation rate and inertia weight decay for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Improved_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.9  # Start with higher inertia weight\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        \n        # Adaptive mutation rate parameters\n        min_mutation_prob = 0.05\n        max_mutation_prob = 0.3\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Decay inertia weight over time\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))  # Velocity clamping\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Adaptive Mutation\n            current_mutation_prob = max_mutation_prob - (max_mutation_prob - min_mutation_prob) * (evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < current_mutation_prob\n            mutation_values = np.random.normal(0, 0.1 * (ub - lb), offspring.shape)  # Gaussian perturbation\n            offspring[mutation_mask] += mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Preserve elites and replace non-elites\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            # Elite crossover\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 21, "feedback": "An exception occurred: AttributeError(\"'list' object has no attribute 'shape'\").", "error": "AttributeError(\"'list' object has no attribute 'shape'\")", "parent_ids": ["177cb173-9957-4dbd-bc3c-05fe3ee76023"], "operator": null, "metadata": {}}
{"id": "482c7345-def4-4142-87d1-6fcbb3aeaf84", "fitness": -Infinity, "name": "AHSO_Improved", "description": "Enhance exploitation by introducing a local search step using Gaussian perturbation of the global best.", "code": "import numpy as np\n\nclass AHSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            # Update personal and global bests\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update velocities and positions (PSO dynamics)\n            # Adaptive inertia weight with dynamic parameter adjustment\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))  # Velocity clamping\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Genetic Algorithm Crossover and Mutation\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)  # Blend crossover\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            # Mutation\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            mutation_values = np.random.normal(0, 0.1 * (ub - lb), offspring.shape)  # Gaussian perturbation\n            offspring[mutation_mask] += mutation_values[mutation_mask]\n\n            # Ensure the offspring are within bounds\n            offspring = np.clip(offspring, lb, ub)\n\n            # Preserve elites and replace non-elites\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            # Elite crossover\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Local search around global best\n            if evaluations + self.population_size <= self.budget:\n                local_perturbation = np.random.normal(0, 0.1 * (ub - lb), global_best_position.shape)\n                local_search_positions = global_best_position + local_perturbation\n                local_search_positions = np.clip(local_search_positions, lb, ub)\n                local_scores = np.array([func(pos) for pos in local_search_positions])\n                evaluations += len(local_search_positions)\n                best_local_idx = np.argmin(local_scores)\n                if local_scores[best_local_idx] < global_best_score:\n                    global_best_position = local_search_positions[best_local_idx]\n                    global_best_score = local_scores[best_local_idx]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 22, "feedback": "An exception occurred: TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 23. Katsuura (iid=1 dim=10)>, -1.5099878474536474').", "error": "TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 23. Katsuura (iid=1 dim=10)>, -1.5099878474536474')", "parent_ids": ["177cb173-9957-4dbd-bc3c-05fe3ee76023"], "operator": null, "metadata": {}}
{"id": "5c951da6-66a7-45b7-932a-a71063bc9bbc", "fitness": 0.11602900362255442, "name": "AHSO_Enhanced", "description": "Enhance diversity and convergence by integrating Levy flight mutations and adaptive learning rates into the AHSO framework.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 23, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11603 with standard deviation 0.05933.", "error": "", "parent_ids": ["177cb173-9957-4dbd-bc3c-05fe3ee76023"], "operator": null, "metadata": {"aucs": [0.24425580400517066, 0.16789341829560478, 0.16307505360062924, 0.09204260077016002, 0.08193555455478008, 0.08123923877821881, 0.09670022213813945, 0.07288392940026767, 0.04423521106001904]}}
{"id": "b144ac94-7c1d-4cce-8397-a964a83b8189", "fitness": 0.11156704548175018, "name": "AHSO_Enhanced", "description": "Enhance exploration by dynamically adjusting the mutation probability based on the current budget usage.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            self.mutation_prob = 0.2 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation probability\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 24, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11157 with standard deviation 0.03699.", "error": "", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16634956576452453, 0.16307505360062924, 0.08643438589370733, 0.08452448675102853, 0.07630991192190117, 0.0964657597008961, 0.09720196371639245, 0.07465323699827742]}}
{"id": "9232da3a-3834-4ead-9108-7203c9bb4b23", "fitness": 0.11011773899306597, "name": "AHSO_Enhanced_Chaotic", "description": "Integrate self-adaptive parameter control and chaotic maps to enhance exploration and exploitation balance in the AHSO framework.", "code": "import numpy as np\n\nclass AHSO_Enhanced_Chaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.chaotic_map = self.logistic_map\n        self.chaotic_param = 0.7\n        self.chaos_sequence = self.generate_chaos_sequence(self.budget, self.chaotic_param)\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def logistic_map(self, x):\n        return 4.0 * x * (1 - x)\n\n    def generate_chaos_sequence(self, length, x0):\n        sequence = np.zeros(length)\n        x = x0\n        for i in range(length):\n            x = self.chaotic_map(x)\n            sequence[i] = x\n        return sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Self-adaptive parameter tuning using chaotic sequence\n            self.c1 = 1.5 + self.chaos_sequence[evaluations % self.budget] * 2.5\n            self.c2 = 1.5 + self.chaos_sequence[evaluations % self.budget] * 2.5\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 25, "feedback": "The algorithm AHSO_Enhanced_Chaotic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11012 with standard deviation 0.03735.", "error": "", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {"aucs": [0.15936991856717575, 0.16610614381970956, 0.15838691541474959, 0.08649229094748367, 0.08002559378576601, 0.07179223001582546, 0.09519181495327533, 0.07224495213262716, 0.1014497913009812]}}
{"id": "d98d7465-b4a0-4cff-9ce2-f290a6f1a9ab", "fitness": 0.11123922474785547, "name": "AHSO_Enhanced", "description": "A small tweak in the mutation probability to balance exploration and exploitation in the optimization process.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.25  # Adjusted mutation probability for better balance\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 26, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11124 with standard deviation 0.03715.", "error": "", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {"aucs": [0.15914505941619717, 0.16610614381970956, 0.16307505360062924, 0.08938773144654355, 0.08376501092252187, 0.07042517922561498, 0.0981636125671217, 0.08987164326079411, 0.08121358847156712]}}
{"id": "c9d3fc39-5507-4b37-8e16-8844b897dd24", "fitness": 0.11306191252052317, "name": "AHSO_Enhanced_Refined", "description": "Enhance exploration and exploitation by implementing dynamic population size and adaptive inertia weight in the AHSO framework.", "code": "import numpy as np\n\nclass AHSO_Enhanced_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 10\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.min_inertia_weight = 0.4\n        self.max_inertia_weight = 0.9\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            inertia_weight = self.max_inertia_weight - (self.max_inertia_weight - self.min_inertia_weight) * (evaluations / self.budget)\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            population_size = self.final_population_size + int((self.initial_population_size - self.final_population_size) * (1 - evaluations / self.budget))\n            population_size = max(self.final_population_size, population_size)\n            population = population[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 27, "feedback": "The algorithm AHSO_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11306 with standard deviation 0.03388.", "error": "", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16610614381970956, 0.14977100025892254, 0.08594193586186327, 0.08935375853208216, 0.06559181401568148, 0.09599844160075244, 0.10284360242102364, 0.10286147118627864]}}
{"id": "0a45773f-33d7-46e8-8a30-a76cc4205b39", "fitness": -Infinity, "name": "AHSO_Enhanced", "description": "Introduce dynamic population control and adaptive crossover based on convergence to improve exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            adaptive_crossover_prob = self.crossover_prob * (1 - evaluations / self.budget)\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < adaptive_crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n            \n            # Dynamic population size adjustment\n            if evaluations / self.budget < 0.5:\n                self.population_size = min(100, self.population_size + 1)\n            else:\n                self.population_size = max(20, self.population_size - 1)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 28, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (51,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (51,10) (50,10) ')", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {}}
{"id": "87280768-30a6-4c8c-a536-809cb748efe9", "fitness": 0.11912047528897639, "name": "AHSO_Enhanced", "description": "Incorporate exponential decay in inertia weight to improve convergence speed and stability.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 29, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11912 with standard deviation 0.05465.", "error": "", "parent_ids": ["5c951da6-66a7-45b7-932a-a71063bc9bbc"], "operator": null, "metadata": {"aucs": [0.24575283503201528, 0.16610614381970956, 0.1501788553016945, 0.0933102489946882, 0.08609494738167522, 0.0792891221655242, 0.09910777240909052, 0.08684297289119569, 0.06540137960519454]}}
{"id": "d9fe484b-954d-472a-a588-fee62013df19", "fitness": 0.1169591527327376, "name": "AHSO_Adaptive", "description": "Introduce adaptive mutation probability and dynamic population size adjustment to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 10\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Start with higher mutation probability\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += population_size\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(population_size, 2)])\n\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Adaptively reduce the population size\n            population_size = max(self.final_population_size, int(self.initial_population_size * (1 - evaluations / self.budget)))\n            population = population[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n            # Update mutation probability dynamically\n            self.mutation_prob = 0.2 * (1 - evaluations / self.budget) + 0.05\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 30, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11696 with standard deviation 0.03084.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.149382018111352, 0.16610614381970956, 0.157442193511516, 0.08787418039819694, 0.09529897053048897, 0.07777091958081084, 0.1019914001467388, 0.09757404759664201, 0.11919250089918343]}}
{"id": "30c93a0b-a001-45eb-8047-12b96b44bfb2", "fitness": 0.11278413890580818, "name": "AHSO_Adaptive", "description": "Integrate dynamic adaptive parameters with diversity preservation to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.05\n        self.c2_initial = 2.05\n        self.inertia_weight_initial = 0.729\n        self.mutation_prob_initial = 0.2\n        self.crossover_prob_initial = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            progress_ratio = evaluations / self.budget\n            self.inertia_weight = self.inertia_weight_initial * (0.4 ** progress_ratio)\n            self.c1 = self.c1_initial * (1 - progress_ratio) + 1.5 * progress_ratio\n            self.c2 = self.c2_initial * progress_ratio + 1.5 * (1 - progress_ratio)\n            self.mutation_prob = self.mutation_prob_initial * (1 - progress_ratio) + 0.1 * progress_ratio\n            self.crossover_prob = self.crossover_prob_initial * (1 - progress_ratio) + 0.9 * progress_ratio\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 31, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11278 with standard deviation 0.03348.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14923311771026482, 0.16610614381970956, 0.15580845459188652, 0.09565542602130894, 0.09322880296515124, 0.074428443789332, 0.1046578356219886, 0.10556994638291994, 0.07036907924971203]}}
{"id": "2565e263-ac28-458f-a5d0-71996de584c9", "fitness": 0.10670690775164746, "name": "AHSO_Enhanced", "description": "Introduce adaptive mutation probability based on convergence rate to enhance exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        last_global_best_score = np.inf\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            \n            # Adjust mutation probability based on convergence improvement\n            if global_best_score < last_global_best_score:\n                self.mutation_prob = max(0.1, self.mutation_prob * 0.9)\n            else:\n                self.mutation_prob = min(0.5, self.mutation_prob * 1.1)\n            last_global_best_score = global_best_score\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 32, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10671 with standard deviation 0.03779.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.15247754841762706, 0.16610614381970956, 0.15054326002978802, 0.0933102489946882, 0.08243843051929256, 0.06927182543421473, 0.10017069548275093, 0.09336086565709589, 0.05268315140966018]}}
{"id": "4f755648-ce33-448d-ae03-003da4993e6b", "fitness": 0.11146160351975534, "name": "AHSO_Refined", "description": "Enhance exploration with adaptive inertia weights and dynamic mutation based on convergence speed.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.mutation_prob_initial = 0.3\n        self.mutation_prob_final = 0.1\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            progress_ratio = evaluations / self.budget\n            self.inertia_weight = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * progress_ratio\n            self.mutation_prob = self.mutation_prob_initial - (self.mutation_prob_initial - self.mutation_prob_final) * progress_ratio\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 33, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11146 with standard deviation 0.03926.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.16750622600894216, 0.16610614381970956, 0.16307505360062924, 0.08594193586186327, 0.07940004781166177, 0.06817980770327514, 0.0956974399852426, 0.09958496815729923, 0.07766280872917508]}}
{"id": "9b3c8bdf-09c6-46ed-889f-8553029641bc", "fitness": 0.11461429960909784, "name": "AHSO_Enhanced", "description": "Enhance global exploration by introducing an adaptive crossover rate based on the current evaluation ratio.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (evaluations / self.budget)  # Changed line for adaptive crossover\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 34, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11461 with standard deviation 0.02770.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.1447713066874302, 0.16610614381970956, 0.14490088419404246, 0.09367224037160526, 0.0986812429912376, 0.08069805022227683, 0.09781810803245439, 0.10426934343293537, 0.10061137673018894]}}
{"id": "3186cc8d-8d3b-41d4-b90c-b80ef6c8ddb1", "fitness": -Infinity, "name": "AHSO_Enhanced", "description": "Introduce adaptive mutation scaling based on population diversity to enhance exploration.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            diversity_scaling = np.std(population, axis=0) / (ub - lb)  # New line for adaptive mutation\n            offspring[mutation_mask] += levy_steps[mutation_mask] * diversity_scaling  # Modified line\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 35, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (103,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (103,) (10,) ')", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {}}
{"id": "10320820-0095-4805-a676-5104c4c3242e", "fitness": 0.11698449100556838, "name": "AHSO_Adaptive", "description": "Introduce adaptive crossover and mutation rates based on convergence progress to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.initial_inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.initial_crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            progress = evaluations / self.budget\n            self.inertia_weight = self.initial_inertia_weight * (0.4 ** progress)\n            self.crossover_prob = self.initial_crossover_prob * (1 - progress)\n            self.mutation_prob = 0.2 + 0.3 * progress  # Increase mutation as convergence progresses\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 36, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11698 with standard deviation 0.03870.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.19240523045739255, 0.16610614381970956, 0.14456748461392277, 0.0951697735360878, 0.08049730443519465, 0.07950861226319428, 0.09814794207329347, 0.11138102176248155, 0.08507690608883878]}}
{"id": "e152d62a-8bf1-4133-a767-f9e307e64b3c", "fitness": 0.11119563737465284, "name": "AHSO_Adaptive", "description": "Introduce adaptive mutation rates based on diversity measures to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.base_mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def adaptive_mutation(self, diversity):\n        max_mutation_prob = 0.4\n        return self.base_mutation_prob + (max_mutation_prob - self.base_mutation_prob) * diversity\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n        return np.tanh(diversity / np.sqrt(self.dim))  # Normalize and compress diversity measure\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            diversity = self.calculate_diversity(population)\n            mutation_prob = self.adaptive_mutation(diversity)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 37, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11120 with standard deviation 0.03092.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14801298526811912, 0.16610614381970956, 0.14544576611310545, 0.09418847978104483, 0.08557224852410994, 0.08859946832658083, 0.10209297084606517, 0.09505973691569924, 0.07568293677744131]}}
{"id": "6819daf8-b465-46a1-9af5-a176f7c64c74", "fitness": 0.10976510978201753, "name": "AHSO_Enhanced", "description": "Improve diversity by increasing the mutation probability to enhance exploration.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.25  # Increased mutation probability for enhanced exploration\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 38, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10977 with standard deviation 0.03189.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14309905147460988, 0.16795684518234522, 0.1450605239307371, 0.09528886916962598, 0.08385301266004264, 0.06894430152055064, 0.09888727768371108, 0.1007903026080158, 0.08400580380851941]}}
{"id": "3b3af8af-f49e-4b31-a96c-c372027eaef2", "fitness": 0.10835232941667483, "name": "AHSO_Enhanced", "description": "Increase the population size to enhance exploration of the search space.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60  # Changed from 50 to 60\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 39, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10835 with standard deviation 0.03637.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.1503720898352029, 0.16610614381970956, 0.1563092990691215, 0.08913768358705232, 0.08451725372065677, 0.08293163960978522, 0.10023640065193173, 0.08549260975069028, 0.06006784470592319]}}
{"id": "ee1015ae-6ffe-4d66-92b5-903a27e060c8", "fitness": 0.11097275322964857, "name": "AHSO_Enhanced", "description": "Introduce adaptive mutation probability based on evaluation progress to enhance convergence.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget)) \n            self.mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Changed line for adaptive mutation probability\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 40, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11097 with standard deviation 0.03081.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14557005134004586, 0.16610614381970956, 0.14550001255401968, 0.09540814544837262, 0.08436577599529294, 0.08082527455533228, 0.10185476522061421, 0.10083902941150469, 0.07828558072194536]}}
{"id": "932d12ce-48d3-4271-ada9-64077c218d06", "fitness": 0.1077848822567143, "name": "AHSO_Adaptive", "description": "Integrate adaptive differential mutation and dynamic crossover rate to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.initial_crossover_prob = 0.9\n        self.final_crossover_prob = 0.6\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def differential_mutation(self, base, r1, r2, F=0.8):\n        return base + F * (r1 - r2)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            crossover_prob = self.initial_crossover_prob - (\n                (self.initial_crossover_prob - self.final_crossover_prob) * (evaluations / self.budget))\n            \n            offspring = []\n            for i in range(self.population_size // 2):\n                if np.random.rand() < crossover_prob:\n                    parents = np.random.choice(self.population_size, 3, replace=False)\n                    base, r1, r2 = population[parents]\n                    mutant = self.differential_mutation(base, r1, r2)\n                    mutant = np.clip(mutant, lb, ub)\n                    \n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * mutant + (1 - alpha) * population[i]\n                    child2 = alpha * population[i] + (1 - alpha) * mutant\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 41, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10778 with standard deviation 0.03408.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14457402938262376, 0.16610614381970956, 0.15140018232902508, 0.08884263049594665, 0.08201333210307005, 0.07219052096349177, 0.10000744889668223, 0.09145887851571355, 0.07347077380416611]}}
{"id": "1b661c1f-4751-4642-bb2a-4ed49fb68d2b", "fitness": 0.11174025985272722, "name": "AHSO_Enhanced", "description": "Introduce adaptive crossover probability based on the diversity of the population to improve exploration.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            avg_dist = np.mean(np.linalg.norm(population - np.mean(population, axis=0), axis=1))\n            self.crossover_prob = 0.5 + 0.5 * (1 - avg_dist / np.linalg.norm(ub - lb))  # Changed line for adaptive crossover\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 42, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11174 with standard deviation 0.03324.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.15139768352157568, 0.16610614381970956, 0.15118288064958318, 0.08981746360630416, 0.09619677247033176, 0.08045477999202755, 0.10132635770584697, 0.10157825404223508, 0.06760200286693085]}}
{"id": "0bbd532f-748f-48a8-a3ba-059e36a12b9d", "fitness": 0.11797985215121527, "name": "AHSO_Enhanced", "description": "Enhance global exploration by adjusting Levy flight parameter for better diversity.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.3  # Modified Levy flight parameter for enhanced exploration\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 43, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11798 with standard deviation 0.03172.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.1505789509103609, 0.16610614381970956, 0.16547736771953492, 0.09418847978104483, 0.08386877989771979, 0.08303263067316935, 0.10028847701321497, 0.10921562767172699, 0.1090622118744562]}}
{"id": "d5feac18-b02f-465b-8b85-88ccc4ba5185", "fitness": 0.1125105233494797, "name": "AHSO_Enhanced", "description": "Introduce adaptive learning coefficients c1 and c2 to balance exploration and exploitation dynamically.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            # Adaptive learning coefficients\n            self.c1 = 2.0 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n            self.c2 = 2.0 - 0.5 * np.sin(np.pi * evaluations / self.budget)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 44, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11251 with standard deviation 0.04070.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.1801137019262541, 0.16610614381970956, 0.14943612011747687, 0.0877483554818087, 0.09064426737726539, 0.07886470046301919, 0.10030793080955747, 0.10776518419619929, 0.051608305954026545]}}
{"id": "48b44135-1453-4d8d-9c10-634ad428b252", "fitness": 0.11097275322964857, "name": "AHSO_Enhanced", "description": "Improve convergence speed by dynamically adjusting the mutation probability based on evaluation progress.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            self.mutation_prob = 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation probability\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 45, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11097 with standard deviation 0.03081.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14557005134004586, 0.16610614381970956, 0.14550001255401968, 0.09540814544837262, 0.08436577599529294, 0.08082527455533228, 0.10185476522061421, 0.10083902941150469, 0.07828558072194536]}}
{"id": "059b493c-20ec-4d0a-b379-7fdb77bd473e", "fitness": 0.11097275322964857, "name": "AHSO_Enhanced", "description": "Adaptively adjust the mutation probability based on convergence progress to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Change here: Adjust mutation probability based on convergence progress\n            self.mutation_prob = 0.2 * (1 - (evaluations / self.budget))\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 46, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11097 with standard deviation 0.03081.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14557005134004586, 0.16610614381970956, 0.14550001255401968, 0.09540814544837262, 0.08436577599529294, 0.08082527455533228, 0.10185476522061421, 0.10083902941150469, 0.07828558072194536]}}
{"id": "07e9e3a5-804e-48ae-afc3-e43af5a3741f", "fitness": 0.11097275322964857, "name": "AHSO_Enhanced", "description": "Use dynamic mutation probability to adaptively balance exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Change made below: dynamic mutation probability\n            self.mutation_prob = 0.2 * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 47, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11097 with standard deviation 0.03081.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.14557005134004586, 0.16610614381970956, 0.14550001255401968, 0.09540814544837262, 0.08436577599529294, 0.08082527455533228, 0.10185476522061421, 0.10083902941150469, 0.07828558072194536]}}
{"id": "f9017655-1716-43fc-8dab-a798e69be5f3", "fitness": 0.11276550801042544, "name": "AHSO_Enhanced", "description": "Adjust the elite fraction to balance exploration and exploitation for enhanced performance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.15  # Adjusted elite fraction to 15% for better balance\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 48, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11277 with standard deviation 0.03594.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.15507792419441568, 0.16610614381970956, 0.15150826834886555, 0.09434176048513288, 0.09337521322668052, 0.07208027456129185, 0.10351863004899498, 0.12060449525978334, 0.058276862148954445]}}
{"id": "85d80819-b7f3-4b41-a8ca-bfe606af6a65", "fitness": -Infinity, "name": "AHSO_Adaptive", "description": "Introduce adaptive population size and chaotic maps for velocity update to enhance exploration and exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.initial_population_size = self.population_size\n        self.chaos_map = 4.0\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            self.population_size = int(self.initial_population_size * (1 + 0.5 * np.sin(np.pi * evaluations / self.budget)))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population) * np.sin(self.chaos_map * r2))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 49, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (53,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (53,10) (50,10) ')", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {}}
{"id": "069b4079-34fc-42e4-941f-d58cd9acbc6b", "fitness": 0.1167426639077058, "name": "AHSO_Enhanced", "description": "Introduce a dynamic scaling factor for velocity to adaptively adjust exploration and exploitation phases.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            dynamic_scaling = 1 - evaluations / self.budget  # New line for dynamic scaling factor\n            velocities = dynamic_scaling * (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 50, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11674 with standard deviation 0.04238.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.1990812076519175, 0.16610614381970956, 0.14423699023404468, 0.10376470793298054, 0.10146379744706557, 0.08316727714382288, 0.10075988029021432, 0.09949475096221494, 0.0526092196873823]}}
{"id": "28801d93-007c-4e9b-a7ab-4e1453bc7f3a", "fitness": -Infinity, "name": "AHSO_Adaptive", "description": "Enhance convergence by introducing adaptive population size control and stochastic ranking to balance exploration and exploitation effectively.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def stochastic_ranking(self, pop, scores, probabilities):\n        indices = np.arange(len(scores))\n        for i in range(len(scores)):\n            for j in range(len(scores) - 1):\n                if (np.random.rand() < probabilities[j] and scores[j] > scores[j + 1]) or (scores[j] > scores[j + 1]):\n                    indices[j], indices[j + 1] = indices[j + 1], indices[j]\n                    scores[j], scores[j + 1] = scores[j + 1], scores[j]\n        return indices\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(population_size, 2)])\n\n            offspring = np.array(offspring)\n            mutation_mask = np.random.rand(*offspring.shape) < self.mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-population_size // 2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n\n            probabilities = np.linspace(0.5, 1.0, len(scores))\n            sorted_indices = self.stochastic_ranking(population, scores, probabilities)\n            population = population[sorted_indices]\n            scores = scores[sorted_indices]\n\n            if evaluations > self.budget // 2:\n                population_size = max(10, population_size - 1)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 51, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (49,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (49,10) (50,10) ')", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {}}
{"id": "4ab12e96-991f-47c1-b5f0-06ad069edd8f", "fitness": 0.1688992622318156, "name": "AHSO_Enhanced", "description": "Introduce dynamic mutation probability scaling for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 52, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16890 with standard deviation 0.17833.", "error": "", "parent_ids": ["87280768-30a6-4c8c-a536-809cb748efe9"], "operator": null, "metadata": {"aucs": [0.6669086323595488, 0.16610614381970956, 0.14550001255401968, 0.09540814544837262, 0.08436577599529294, 0.08082527455533228, 0.10185476522061421, 0.10083902941150469, 0.07828558072194536]}}
{"id": "319a6d16-595e-4b09-9f3b-95df4690c226", "fitness": 0.12008511324503518, "name": "AHSO_Enhanced", "description": "Introduce dynamic velocity scaling for improved convergence speed adjustment.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            velocities *= np.exp(-evaluations / self.budget)  # Dynamic velocity scaling\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 53, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12009 with standard deviation 0.02723.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.14925316621402163, 0.16630465685417772, 0.1545553825291106, 0.11084384046656903, 0.0961745785321877, 0.10499587418837997, 0.1041069778747129, 0.08466478915762865, 0.10986675338852836]}}
{"id": "bc0fc1fc-6df7-4075-977e-522399375b62", "fitness": 0.1128465819561863, "name": "AHSO_Adaptive", "description": "Enhance exploration-exploitation balance with adaptive inertia and elite-guided mutation strategy.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            inertia_weight = self.final_inertia_weight + (self.initial_inertia_weight - self.final_inertia_weight) \\\n                             * (1 - evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 54, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11285 with standard deviation 0.03241.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16789341829560478, 0.14420770415345918, 0.08594193586186327, 0.07957692246048742, 0.10114794246367742, 0.09595158558292982, 0.09743336997865759, 0.08437731382060232]}}
{"id": "15175bf1-6871-4dc4-8ff8-551a4bcd8881", "fitness": 0.11587562640293239, "name": "AHSO_Enhanced", "description": "Incorporate adaptive crossover probability for improved adaptability during optimization.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                self.crossover_prob = 0.5 + 0.2 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 55, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11588 with standard deviation 0.03218.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.1577508908219376, 0.16610614381970956, 0.15612454429988376, 0.100617671518197, 0.09809360346429197, 0.07467607881068239, 0.10118949084386009, 0.09125384584478935, 0.09706836820303977]}}
{"id": "6017d2b7-2b8b-4315-9812-cedf6326819b", "fitness": 0.11111732044670118, "name": "AHSO_Enhanced", "description": "Refine inertia weight update to linear decay for balanced exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 - 0.329 * (evaluations / self.budget)  # Changed line for linear decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 56, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11112 with standard deviation 0.03487.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.1606228573573597, 0.16610614381970956, 0.14857991176758756, 0.08608298298451145, 0.08238878588793941, 0.07257175942493743, 0.09941941645303809, 0.08049890111952185, 0.1037851252057056]}}
{"id": "c433db46-1a09-4a3f-9056-56887f2ac792", "fitness": -Infinity, "name": "AHSO_Adaptive", "description": "Enhance exploration through adaptive population resizing and dynamic crossover strategy with adaptive elitism.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.population_size = self.initial_population_size\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            adaptive_crossover_prob = self.crossover_prob * (1 - evaluations / self.budget)\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < adaptive_crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            if evaluations < self.budget / 2:\n                population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            else:\n                elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n                population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n            self.population_size = int(self.initial_population_size * (1 + (0.5 * evaluations / self.budget)))\n            self.population_size = min(self.population_size, self.budget - evaluations)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 57, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (51,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (51,10) (50,10) ')", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {}}
{"id": "00b733fe-dfcb-443b-862c-fb703a293a2e", "fitness": 0.12108876816768771, "name": "AHSO_Enhanced", "description": "Adjust dynamic mutation probability scaling to include exponential decay for refined exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - (evaluations / self.budget)**2)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 58, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12109 with standard deviation 0.05355.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.24482649155010483, 0.16610614381970956, 0.15397930819496863, 0.09418847978104483, 0.08117341055879412, 0.09165427539495807, 0.1025749523756303, 0.08444075781188887, 0.07085509402209023]}}
{"id": "eb12fc3b-4b3f-4566-877b-d25ff7b98fe3", "fitness": 0.10902732752160497, "name": "AHSO_Refined", "description": "Incorporate adaptive inertia weight with cosine decay and dynamic crossover rate for robust search exploration and exploitation.  ", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.mutation_prob = 0.2\n        self.initial_crossover_prob = 0.9\n        self.final_crossover_prob = 0.5\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Cosine decay for inertia weight\n            self.inertia_weight = self.final_inertia_weight + 0.5 * (self.initial_inertia_weight - self.final_inertia_weight) * (1 + np.cos(np.pi * evaluations / self.budget))\n            # Dynamic crossover probability\n            crossover_prob = self.final_crossover_prob + (self.initial_crossover_prob - self.final_crossover_prob) * (1 - evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 59, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10903 with standard deviation 0.03491.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.1495765001479913, 0.16610614381970956, 0.1549618899119788, 0.08594193586186327, 0.0814600713978696, 0.08382235378934366, 0.09810062996990365, 0.09276652371386529, 0.06850989908191962]}}
{"id": "a7b827fd-8efa-4f1f-ade6-1f500963568f", "fitness": 0.10678251393383882, "name": "AHSO_Refined", "description": "Introduce adaptive inertia weight and dynamic crossover strategy for improved convergence in diverse landscapes.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            inertia_weight = (self.final_inertia_weight + \n                              (self.initial_inertia_weight - self.final_inertia_weight) * \n                              ((self.budget - evaluations) / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    child1 = 0.5 * (population[parents[0]] + population[parents[1]])\n                    child2 = 0.5 * (population[parents[1]] + population[parents[0]])\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 60, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10678 with standard deviation 0.03803.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.16120538337964907, 0.16610614381970956, 0.14330449308936755, 0.08594193586186327, 0.08695504230305284, 0.06899069302679606, 0.09182542241425085, 0.10186050297486016, 0.05485300853500008]}}
{"id": "524751be-64d2-4307-93cb-8723c8ad7a00", "fitness": 0.10869415577631575, "name": "AHSO_Enhanced", "description": "Tweak inertia weight decay for improved global search in AHSO_Enhanced.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.5 ** (evaluations / self.budget))  # Changed line for more aggressive decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 61, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10869 with standard deviation 0.03541.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15042682222758663, 0.17130721441678443, 0.14993713093034045, 0.08760755297275225, 0.0797698055469167, 0.07946499900894965, 0.10011639305864006, 0.0843427628288268, 0.07527472099604471]}}
{"id": "30830e2a-814a-4ea5-ac41-48d99ff1ed4e", "fitness": 0.1175504278443323, "name": "AHSO_Adaptive", "description": "Implement adaptive learning rates for velocity and position updates to enhance convergence in dynamic environments.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.adaptive_lr = 0.5  # Adaptive learning rate for velocity and position updates\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            \n            # Adaptive learning rate for position update\n            lr = self.adaptive_lr * (1 - evaluations / self.budget)\n            population = population + lr * velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 62, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11755 with standard deviation 0.03455.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15824004496092425, 0.16610614381970956, 0.16242256378522146, 0.12102584619407142, 0.09577260907636842, 0.10352271047306638, 0.09465859494155304, 0.06398779873008265, 0.09221753861799342]}}
{"id": "27bbe94b-9df3-4dde-a7bf-cdf2de10e72e", "fitness": 0.10869415577631575, "name": "AHSO_Enhanced", "description": "Enhance convergence speed by adapting the inertia weight decay rate.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.5 ** (evaluations / self.budget))  # Adapted line for faster decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 63, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10869 with standard deviation 0.03541.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15042682222758663, 0.17130721441678443, 0.14993713093034045, 0.08760755297275225, 0.0797698055469167, 0.07946499900894965, 0.10011639305864006, 0.0843427628288268, 0.07527472099604471]}}
{"id": "4eab0f09-c961-4e60-89ef-92886fd683be", "fitness": 0.11135190625311525, "name": "AHSO_Enhanced", "description": "Introduce adaptive inertia weight to enhance convergence speed in dynamic environments.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.9 + 0.1 * (1 - evaluations / self.budget))  # Changed line for adaptive inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 64, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11135 with standard deviation 0.03237.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.140132746695265, 0.16610614381970956, 0.15786839588569213, 0.0887823165823276, 0.07940513653956893, 0.07559053780314151, 0.09864026918778901, 0.0906253519894391, 0.10501625777510426]}}
{"id": "66e50d0c-6c31-4267-97f8-a6a76769ab2a", "fitness": 0.1103521527890948, "name": "AHSO_Enhanced", "description": "Adjust elite fraction based on evaluations to dynamically balance exploration and exploitation.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            # Introduce dynamic scaling of mutation probability\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            self.elite_fraction = 0.1 * (1 + 0.5 * (evaluations / self.budget))  # Changed line for dynamic elite fraction\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 65, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11035 with standard deviation 0.03136.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.14514405195026558, 0.16610614381970956, 0.14621674446434518, 0.09418847978104483, 0.07946696824320665, 0.07773849417613088, 0.10178689852935463, 0.10036318601818772, 0.08215840811960817]}}
{"id": "254d20d1-7f43-4fa2-859d-fd3843c10bb3", "fitness": 0.12108360370637368, "name": "EnhancedMetaheuristic", "description": "Integrate adaptive learning rates and chaotic maps to enhance exploration and exploitation dynamics.", "code": "import numpy as np\n\nclass EnhancedMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.learning_rate = 0.1\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        chaotic_value = np.random.rand()\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities *= self.learning_rate\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            chaotic_value = self.chaotic_map(chaotic_value)\n            self.learning_rate = 0.1 + 0.9 * chaotic_value\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 66, "feedback": "The algorithm EnhancedMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12108 with standard deviation 0.03696.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15452495354358475, 0.16610614381970956, 0.16036494338583318, 0.1243864598441371, 0.11040294556606545, 0.09727384083559232, 0.1452917196744924, 0.07547159204034926, 0.05592983464759904]}}
{"id": "6edcc595-0b3c-4184-b1af-2af9763dcb2d", "fitness": -Infinity, "name": "AHSO_Improved", "description": "Enhance exploration via adaptive velocity scaling and dynamic population resizing for improved convergence.", "code": "import numpy as np\n\nclass AHSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocity_scaling_factor = 0.2 + 0.6 * (1 - evaluations / self.budget)\n            velocities = np.clip(velocities, -velocity_scaling_factor * (ub - lb), velocity_scaling_factor * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(population_size, 2)])\n\n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Dynamically resize the population size for diversity\n            population_size = self.initial_population_size + int(20 * np.sin(np.pi * evaluations / self.budget))\n            if evaluations + population_size > self.budget:\n                population_size = self.budget - evaluations\n            population = population[:population_size]\n            velocities = velocities[:population_size]\n            personal_best_positions = personal_best_positions[:population_size]\n            personal_best_scores = personal_best_scores[:population_size]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 67, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (53,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (53,10) (50,10) ')", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {}}
{"id": "c818982c-f45e-4dbb-8f29-1c6298ff663c", "fitness": 0.12228661576819487, "name": "AHSO_Enhanced", "description": "Integrate adaptive inertia weight and archive-based elitism to enhance convergence efficiency.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.inertia_weight_min = 0.4\n        self.inertia_weight_max = 0.9\n        self.elite_archive_size = 5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        elite_archive = []\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = (self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n            \n            elite_archive.extend(population[elite_idx])\n            if len(elite_archive) > self.elite_archive_size:\n                elite_archive = elite_archive[-self.elite_archive_size:]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 68, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12229 with standard deviation 0.05135.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.24404934929652167, 0.16789341829560478, 0.14420770415345918, 0.08594193586186327, 0.07957692246048742, 0.1011479424636278, 0.09595158558292982, 0.09743336997865759, 0.08437731382060232]}}
{"id": "030d8637-4d31-4fd9-88c3-a9cafa6547c3", "fitness": 0.10268032460641546, "name": "AHSO_Adaptive", "description": "Integrate adaptive parameter control with opposition-based learning to enhance convergence speed and exploration capability.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def opposition_based_population(self, population, lb, ub):\n        return lb + ub - population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            opposition_population = self.opposition_based_population(population, lb, ub)\n            combined_population = np.vstack((population, opposition_population))\n            combined_scores = np.array([func(ind) for ind in combined_population])\n            evaluations += len(combined_population) - len(population)\n            \n            sorted_indices = np.argsort(combined_scores)\n            population = combined_population[sorted_indices[:self.population_size]]\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 69, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10268 with standard deviation 0.04423.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.17256203007656745, 0.16610614381970956, 0.15242909163522178, 0.08594193586186327, 0.07940004781166177, 0.06877376192836326, 0.06589651012923203, 0.07846815159035814, 0.05454524860476195]}}
{"id": "01f1c326-40e5-4b8b-8744-3e362f1af2fb", "fitness": 0.1128465819561808, "name": "AHSO_Refined", "description": "Integrate self-adaptive particle velocities and adaptive elite retention to improve convergence speed and solution precision.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Linear inertia weight reduction\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 70, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11285 with standard deviation 0.03241.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16789341829560478, 0.14420770415345918, 0.08594193586186327, 0.07957692246048742, 0.1011479424636278, 0.09595158558292982, 0.09743336997865759, 0.08437731382060232]}}
{"id": "7b0e9957-1b19-4229-aeac-f11305e80106", "fitness": 0.1128465819561808, "name": "AHSO_Adaptive", "description": "Integrate adaptive velocity scaling and self-adaptive mutation rates for improved convergence speed and robustness.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.base_mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.velocity_scale = 0.2\n    \n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) / \n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            evaluations_ratio = evaluations / self.budget\n            self.inertia_weight = 0.9 - 0.5 * evaluations_ratio\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -self.velocity_scale * (ub - lb), self.velocity_scale * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.base_mutation_prob * (1 - evaluations_ratio)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 71, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11285 with standard deviation 0.03241.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16789341829560478, 0.14420770415345918, 0.08594193586186327, 0.07957692246048742, 0.1011479424636278, 0.09595158558292982, 0.09743336997865759, 0.08437731382060232]}}
{"id": "1362fb00-ce08-46f9-8bdb-8afb8baaf99a", "fitness": 0.1182724864345221, "name": "AHSO_Enhanced", "description": "Enhance velocity update using chaotic maps for better global search and convergence.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2  # Higher mutation probability for diversity\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1  # Preserving top 10% as elites\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, size):\n        # Levy distribution using Mantegna's algorithm\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Update the velocities using a chaotic map for improved search\n            chaotic_factor = 4.0 * (self.inertia_weight - 0.5) ** 2\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (chaotic_factor * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 72, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11827 with standard deviation 0.03182.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.16513547667861828, 0.16610614381970956, 0.14125990657607213, 0.10695521936506147, 0.10530815371121793, 0.10837579711186174, 0.10602061092196391, 0.1051709535136417, 0.06012011621255209]}}
{"id": "287934b6-2ec5-46cc-8ab7-4576b3814d1a", "fitness": -Infinity, "name": "AHSO_Chaotic", "description": "Introduce diversification through chaotic maps and adaptive parameter adjustment for improved convergence.", "code": "import numpy as np\n\nclass AHSO_Chaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def chaotic_map(self, size):\n        return np.random.rand(size) * np.sin(np.random.rand(size) * np.pi)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            chaotic_steps = self.chaotic_map(offspring.shape)\n            combined_steps = levy_steps * chaotic_steps\n            offspring[mutation_mask] += combined_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 73, "feedback": "An exception occurred: TypeError(\"'tuple' object cannot be interpreted as an integer\").", "error": "TypeError(\"'tuple' object cannot be interpreted as an integer\")", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {}}
{"id": "e5169599-5c92-4817-bd08-e7006de271de", "fitness": 0.12033668611487514, "name": "AHSO_Adaptive", "description": "Integrate adaptive velocity clamping and chaotic mutation to enhance convergence and diversity.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n        chaotic_value = np.random.rand()\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            max_vel = 0.2 * (ub - lb) * (1 - evaluations / self.budget)\n            velocities = np.clip(velocities, -max_vel, max_vel)\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            chaotic_value = self.chaotic_map(chaotic_value)\n            chaotic_mutation_mask = np.random.rand(*offspring.shape) < chaotic_value\n            offspring[chaotic_mutation_mask] += self.levy_flight(offspring.shape)[chaotic_mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 74, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12034 with standard deviation 0.04386.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.19557556696231493, 0.16610614381970956, 0.15271964230300106, 0.08894363948942674, 0.08564595284678922, 0.0908093871632828, 0.1044093831070082, 0.14586214811036358, 0.052958311231980026]}}
{"id": "ca60886e-9eba-43ea-ab12-a13cfd9752d5", "fitness": 0.10730681694686182, "name": "AHSO_Refined", "description": "Integrate adaptive learning rates and chaos-based initialization for enhanced convergence stability and diversity.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.learning_rate_min = 0.4\n        self.learning_rate_max = 0.9\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def chaotic_initialization(self, lb, ub):\n        # Logistic map for chaotic initialization\n        x0 = 0.7\n        population = np.zeros((self.population_size, self.dim))\n        for i in range(self.population_size):\n            x0 = 4 * x0 * (1 - x0)  # Logistic map equation\n            population[i] = lb + (ub - lb) * x0\n        return population\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.chaotic_initialization(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning rate based on progress\n            learning_rate = self.learning_rate_min + (self.learning_rate_max - self.learning_rate_min) * (1 - evaluations / self.budget)\n            self.inertia_weight = learning_rate * 0.729\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 75, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10731 with standard deviation 0.02919.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15093780817014268, 0.14647794014811422, 0.14411834681375435, 0.09384891822447539, 0.08010665305114362, 0.0787436305818926, 0.0786011722705744, 0.10280506406802115, 0.09012181919363804]}}
{"id": "bdeefd68-f438-42af-8651-bfc464580d03", "fitness": 0.108560834168147, "name": "AHSO_Enhanced_Refined", "description": "Implement adaptive inertia weight and tournament selection to enhance exploration-exploitation and maintain diversity.", "code": "import numpy as np\n\nclass AHSO_Enhanced_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def tournament_selection(self, scores, num_competitors=3):\n        competitors_idx = np.random.choice(self.population_size, num_competitors, replace=False)\n        return competitors_idx[np.argmin(scores[competitors_idx])]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive inertia weight\n            self.inertia_weight = (self.inertia_weight_final + \n                                  (self.inertia_weight_initial - self.inertia_weight_final) * \n                                  ((self.budget - evaluations) / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = [self.tournament_selection(scores) for _ in range(2)]\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 76, "feedback": "The algorithm AHSO_Enhanced_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10856 with standard deviation 0.03927.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16610614381970956, 0.15636585569454797, 0.08599170383390387, 0.08989774241530435, 0.09154623352451685, 0.09524519867902015, 0.08698716462069855, 0.045818419937226795]}}
{"id": "b926f189-b0d2-4f74-855e-8dd655f7e6fb", "fitness": 0.11128438797730492, "name": "AHSO_Adaptive", "description": "Integrate adaptive learning rates with dynamic convergence pressure to efficiently navigate complex landscapes.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n\n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning rates based on convergence speed\n            if evaluations < 0.3 * self.budget:  # Early stage\n                learning_rate = 0.9\n            elif evaluations < 0.7 * self.budget:  # Mid stage\n                learning_rate = 0.5\n            else:  # Late stage\n                learning_rate = 0.2\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          learning_rate * self.c1 * r1 * (personal_best_positions - population) +\n                          learning_rate * self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 77, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11128 with standard deviation 0.03884.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [0.1610715787927255, 0.16610614381970956, 0.16028646720015283, 0.08625758230390101, 0.08478426922212301, 0.08420071861529621, 0.0998136498580191, 0.10672298304643602, 0.052316098937380984]}}
{"id": "4a1e5e20-19ee-4292-b883-6a821fc7e868", "fitness": -Infinity, "name": "AHSO_Enhanced_V2", "description": "Integrate adaptive learning rates for particle velocities and crossover blurring to enhance convergence and exploration.", "code": "import numpy as np\n\nclass AHSO_Enhanced_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        learning_rate = np.linspace(0.9, 0.4, self.budget // self.population_size)\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            lr_index = evaluations // self.population_size\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          learning_rate[lr_index] * (self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population)))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                parents = np.random.choice(self.population_size, 2, replace=False)\n                if np.random.rand() < self.crossover_prob:\n                    alpha = np.random.uniform(-0.1, 1.1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[parents])\n\n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 78, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {}}
{"id": "efa9d00c-4af5-48e2-808d-a200c3454681", "fitness": 0.2008779131627616, "name": "AHSO_Adaptive", "description": "Introduce adaptive learning factors and Levy flights alongside a dynamic mutation probability for a balanced exploration-exploitation approach.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 79, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20088 with standard deviation 0.28460.", "error": "", "parent_ids": ["4ab12e96-991f-47c1-b5f0-06ad069edd8f"], "operator": null, "metadata": {"aucs": [1.0, 0.16610614381970956, 0.15532425776884706, 0.09399854093424387, 0.09165109440746211, 0.06471906254676019, 0.06253402207201464, 0.08856143651202575, 0.08500666040379123]}}
{"id": "fe41e453-48c7-416c-a230-22f89fae4d90", "fitness": 0.09314656038288331, "name": "AHSO_Adaptive_MultiSwarm", "description": "Employ adaptive multi-swarm cooperation with differential evolution strategies and dynamic parameter tuning for enhanced exploration-exploitation balance.", "code": "import numpy as np\n\nclass AHSO_Adaptive_MultiSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.num_swarms = 5\n        self.F = 0.8  # Differential evolution factor\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        populations = [np.random.uniform(lb, ub, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.population_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [np.copy(pop) for pop in populations]\n        personal_best_scores = [np.full(self.population_size, np.inf) for _ in range(self.num_swarms)]\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for k in range(self.num_swarms):\n                scores = np.array([func(ind) for ind in populations[k]])\n                evaluations += len(populations[k])\n\n                better_positions = scores < personal_best_scores[k]\n                personal_best_positions[k][better_positions] = populations[k][better_positions]\n                personal_best_scores[k][better_positions] = scores[better_positions]\n\n                min_score_idx = np.argmin(personal_best_scores[k])\n                if personal_best_scores[k][min_score_idx] < global_best_score:\n                    global_best_position = personal_best_positions[k][min_score_idx]\n                    global_best_score = personal_best_scores[k][min_score_idx]\n\n                # Adaptive learning factors\n                self.c1 = self.c1_init * (1 - evaluations / self.budget)\n                self.c2 = self.c2_init * (evaluations / self.budget)\n\n                self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                velocities[k] = (self.inertia_weight * velocities[k] +\n                                 self.c1 * r1 * (personal_best_positions[k] - populations[k]) +\n                                 self.c2 * r2 * (global_best_position - populations[k]))\n                velocities[k] = np.clip(velocities[k], -0.2 * (ub - lb), 0.2 * (ub - lb))\n                populations[k] += velocities[k]\n                populations[k] = np.clip(populations[k], lb, ub)\n\n                # Differential evolution step\n                for i in range(self.population_size):\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = populations[k][indices]\n                    mutant = np.clip(x0 + self.F * (x1 - x2), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant, populations[k][i])\n                    trial_score = func(trial)\n                    evaluations += 1\n                    if trial_score < scores[i]:\n                        populations[k][i] = trial\n                        personal_best_positions[k][i] = trial\n                        personal_best_scores[k][i] = trial_score\n\n            # Multi-swarm cooperation\n            if evaluations < self.budget:\n                center_positions = np.mean(np.array(personal_best_positions), axis=1)\n                for k in range(self.num_swarms):\n                    r3 = np.random.rand(self.population_size, self.dim)\n                    populations[k] += r3 * (center_positions.mean(axis=0) - populations[k])\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 80, "feedback": "The algorithm AHSO_Adaptive_MultiSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09315 with standard deviation 0.04805.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.16131453855517874, 0.16610614381970956, 0.14209461824563885, 0.08594193586186327, 0.07940004781166177, 0.07806477069623385, 0.044419408901595014, 0.03716769593776259, 0.04380988361630611]}}
{"id": "146c6a48-6137-432f-a511-fac14fe167ac", "fitness": 0.10467655887016043, "name": "AHSO_Adaptive", "description": "Enhance global search by introducing a dynamic inertia weight scaling using cosine decay for improved convergence.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            # Updated inertia weight using cosine decay\n            self.inertia_weight = 0.729 * (0.5 + 0.5 * np.cos(np.pi * evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 81, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10468 with standard deviation 0.04012.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15040135337019844, 0.16882674470026338, 0.15317957916412717, 0.08594193586186327, 0.09220465349257756, 0.08773791327561364, 0.042889590857652204, 0.08899145164971944, 0.07191580745942883]}}
{"id": "84dbb3d3-f792-493b-b13e-eb7f2fe3d9fd", "fitness": -Infinity, "name": "AHSO_Refined", "description": "Incorporate dynamic elite learning and adaptive velocity clamping to enhance convergence speed and precision in an adaptive PSO framework.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n\n            velocity_clamp = 0.1 + 0.1 * (evaluations / self.budget)\n            velocities = np.clip(velocities, -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n\n            dynamic_elite = (1 - evaluations / self.budget) * population[elite_idx]\n            population[non_elite_idx] = offspring[:len(non_elite_idx)] + dynamic_elite[:len(non_elite_idx)]\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 82, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (25,10) (5,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (25,10) (5,10) ')", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {}}
{"id": "1e9aa045-2980-47df-af03-2af3983d8ef3", "fitness": 0.10708685474028422, "name": "AHSO_Enhanced", "description": "Enhance balance by dynamically adjusting inertia and learning factors based on swarm diversity alongside an adaptive mutation strategy.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            current_diversity = self.diversity(population)\n            self.c1 = self.c1_init * (1 - evaluations / self.budget) * (1 + current_diversity)\n            self.c2 = self.c2_init * (evaluations / self.budget) * (1 - current_diversity)\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget)) * (1 + current_diversity)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget) * (1 + current_diversity)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 83, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10709 with standard deviation 0.04488.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.18633374011174209, 0.16610614381970956, 0.14895155512687397, 0.08594193586186327, 0.0835377272194825, 0.06564937547947314, 0.09266262229223854, 0.083371624117064, 0.051226968634110914]}}
{"id": "b5adbb7e-a957-40e3-96b5-c7e8567f8069", "fitness": 0.09344095507369593, "name": "AHSO_Enhanced", "description": "Enhance convergence by integrating adaptive inertia weight with gradient-based local search, and a diversity mechanism to avoid premature convergence.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight_max = 0.9\n        self.inertia_weight_min = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def gradient_search(self, position, func):\n        grad = np.zeros(self.dim)\n        epsilon = 1e-8\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = epsilon\n            grad[i] = (func(position + step) - func(position - step)) / (2 * epsilon)\n        return -0.01 * grad\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            inertia_weight = (self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) *\n                              (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n            offspring = np.clip(offspring, lb, ub)\n\n            for i, child in enumerate(offspring):\n                if np.random.rand() < 0.1:  # Apply local search with some probability\n                    offspring[i] = child + self.gradient_search(child, func)\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 84, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09344 with standard deviation 0.04982.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15727199353720234, 0.16610614381970956, 0.15458761891894246, 0.08594193586186327, 0.08381564933287022, 0.06893377215175556, 0.03514847266100651, 0.05731350099251298, 0.031849508387400416]}}
{"id": "4a28174d-48ae-4272-8b3e-d506b23b66b2", "fitness": 0.10742354898270723, "name": "AHSO_Cooperative", "description": "Introduce adaptive learning factors, Lévy flights, dynamic mutation probability, and a cooperative co-evolution strategy for improved exploration and convergence.", "code": "import numpy as np\n\nclass AHSO_Cooperative:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.subcomponent_size = max(2, self.dim // 5)\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            # Cooperative Co-evolution Strategy\n            for i in range(0, self.dim, self.subcomponent_size):\n                subcomponent_idx = slice(i, min(i + self.subcomponent_size, self.dim))\n                sub_population = population[:, subcomponent_idx]\n                sub_velocities = velocities[:, subcomponent_idx]\n\n                r1, r2 = np.random.rand(2, self.population_size, subcomponent_idx.stop - subcomponent_idx.start)\n                sub_velocities = (self.inertia_weight * sub_velocities +\n                                  self.c1 * r1 * (personal_best_positions[:, subcomponent_idx] - sub_population) +\n                                  self.c2 * r2 * (global_best_position[subcomponent_idx] - sub_population))\n                sub_velocities = np.clip(sub_velocities, -0.2 * (ub[subcomponent_idx] - lb[subcomponent_idx]), 0.2 * (ub[subcomponent_idx] - lb[subcomponent_idx]))\n                sub_population = sub_population + sub_velocities\n                sub_population = np.clip(sub_population, lb[subcomponent_idx], ub[subcomponent_idx])\n                population[:, subcomponent_idx] = sub_population\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 85, "feedback": "The algorithm AHSO_Cooperative got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10742 with standard deviation 0.03856.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15963535483184144, 0.1690411978532813, 0.14345581501863558, 0.08611260130481257, 0.10199302451670333, 0.07363505061990838, 0.09479943867610774, 0.08951635090397192, 0.04862310711910278]}}
{"id": "7bacb0f8-2cf4-4066-8608-0c36ec8eaabb", "fitness": -Infinity, "name": "AHSO_Adaptive_Enhanced", "description": "Incorporate adaptive multi-swarm strategies with inter-swarm communication and chaos-based exploration to enhance diversity and convergence speed.", "code": "import numpy as np\n\nclass AHSO_Adaptive_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.num_swarms = 3\n        self.swarms = [self.init_swarm() for _ in range(self.num_swarms)]\n        self.inertia_weight = 0.729\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def init_swarm(self):\n        return {\n            'population': np.random.rand(self.population_size, self.dim),\n            'velocities': np.random.rand(self.population_size, self.dim) - 0.5,\n            'personal_best_positions': None,\n            'personal_best_scores': np.full(self.population_size, np.inf),\n            'global_best_position': None,\n            'global_best_score': np.inf\n        }\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def chaotic_sequence(self, size):\n        x = 0.7\n        seq = np.empty(size)\n        for i in range(size):\n            x = 4 * x * (1 - x)\n            seq[i] = x\n        return seq\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n        global_best_position = None\n        global_best_score = np.inf\n\n        while evaluations < self.budget:\n            for swarm in self.swarms:\n                population, velocities = swarm['population'], swarm['velocities']\n                scores = np.array([func(ind) for ind in population])\n                evaluations += len(population)\n\n                better_positions = scores < swarm['personal_best_scores']\n                swarm['personal_best_positions'][better_positions] = population[better_positions]\n                swarm['personal_best_scores'][better_positions] = scores[better_positions]\n\n                min_score_idx = np.argmin(swarm['personal_best_scores'])\n                if swarm['personal_best_scores'][min_score_idx] < swarm['global_best_score']:\n                    swarm['global_best_position'] = swarm['personal_best_positions'][min_score_idx]\n                    swarm['global_best_score'] = swarm['personal_best_scores'][min_score_idx]\n\n                if swarm['global_best_score'] < global_best_score:\n                    global_best_position = swarm['global_best_position']\n                    global_best_score = swarm['global_best_score']\n\n                # Adaptive learning factors\n                self.c1 = self.c1_init * (1 - evaluations / self.budget)\n                self.c2 = self.c2_init * (evaluations / self.budget)\n\n                self.inertia_weight *= 0.99\n                r1, r2 = np.random.rand(2, self.population_size, self.dim)\n                velocities = (self.inertia_weight * velocities +\n                              self.c1 * r1 * (swarm['personal_best_positions'] - population) +\n                              self.c2 * r2 * (swarm['global_best_position'] - population))\n                velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n                population = population + velocities\n                population = np.clip(population, lb, ub)\n\n                chaotic_factor = self.chaotic_sequence(self.population_size * self.dim).reshape(self.population_size, self.dim)\n                population += chaotic_factor * (ub - lb) * 0.05\n\n                offspring = []\n                for _ in range(self.population_size // 2):\n                    if np.random.rand() < self.crossover_prob:\n                        parents = np.random.choice(self.population_size, 2, replace=False)\n                        alpha = np.random.uniform(0, 1, self.dim)\n                        child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                        child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                        offspring.extend([child1, child2])\n                    else:\n                        offspring.extend(population[np.random.choice(self.population_size, 2)])\n\n                offspring = np.array(offspring)\n                dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n                mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n                levy_steps = self.levy_flight(offspring.shape)\n                offspring[mutation_mask] += levy_steps[mutation_mask]\n\n                offspring = np.clip(offspring, lb, ub)\n\n                elite_count = int(self.elite_fraction * self.population_size)\n                elite_idx = np.argsort(scores)[:elite_count]\n                worst_idx = np.argsort(scores)[-self.population_size//2:]\n                non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n                population[non_elite_idx] = offspring[:len(non_elite_idx)]\n                elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n                population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n                swarm['population'] = population\n                swarm['velocities'] = velocities\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 86, "feedback": "An exception occurred: TypeError(\"'NoneType' object does not support item assignment\").", "error": "TypeError(\"'NoneType' object does not support item assignment\")", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {}}
{"id": "fe6eb93a-0a2e-4582-b657-d6b737116f03", "fitness": 0.1131188836677644, "name": "AHSO_Adaptive", "description": "Enhance local search by incorporating a dynamic adjustment to the mutation probability based on population diversity.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget) * np.std(population) / (ub - lb) # Adjusted line\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 87, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11312 with standard deviation 0.04561.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.19742207536608636, 0.16680587506824263, 0.16265040324270907, 0.09399854093424387, 0.09208179542496597, 0.07737686096818197, 0.07441859230092551, 0.07236340656377016, 0.08095240314075414]}}
{"id": "e7871fa2-5eeb-4846-86b0-9eab9c68c7bf", "fitness": 0.10758729349083056, "name": "AHSO_Refined", "description": "Introduce a self-adaptive mutation strategy with space contraction and dynamic inertia for improved convergence.", "code": "import numpy as np\n\nclass AHSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight_init = 0.9\n        self.inertia_weight_end = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        space_factor = 1.0\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = (self.inertia_weight_end + \n                                   (self.inertia_weight_init - self.inertia_weight_end) * \n                                   (1 - evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * space_factor * (ub - lb), 0.2 * space_factor * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Space contraction\n            space_factor *= 0.99\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 88, "feedback": "The algorithm AHSO_Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10759 with standard deviation 0.03983.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16610614381970956, 0.16059812015882158, 0.08594193586186327, 0.08059318694076911, 0.09138558716278777, 0.091071625245426, 0.07942501031402838, 0.05407498692567436]}}
{"id": "fe12d3b4-9d23-443e-8de2-13c19cf148e1", "fitness": 0.10420143473021298, "name": "AHSO_Adaptive", "description": "Introduce a slight adjustment to improve mutation probability dynamics based on remaining evaluations.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - (2 * evaluations / self.budget))\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 89, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10420 with standard deviation 0.03953.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.1535232721580908, 0.16620094277705288, 0.14931795403406212, 0.09399854093424387, 0.09155489664819472, 0.06861292400923169, 0.046226138026449926, 0.07866557057951362, 0.08971267340507727]}}
{"id": "aa5ab89b-f3e5-403a-af3d-ef26775aed5f", "fitness": 0.10616995402490643, "name": "AHSO_Adaptive", "description": "Enhance convergence by adjusting mutation probability scaling to balance exploration and exploitation more effectively.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * ((1 - evaluations / self.budget) ** 2)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 90, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10617 with standard deviation 0.03599.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.14610709298159552, 0.16610614381970956, 0.1520786143321441, 0.09399854093424387, 0.09171057688537343, 0.08043647256245579, 0.05795395842867479, 0.08359295728122285, 0.08354522899873806]}}
{"id": "a19a7a20-1beb-461a-a048-136a82010510", "fitness": 0.10591327900798778, "name": "AHSO_Enhanced", "description": "Enhance the exploration-exploitation balance by integrating a variable neighborhood search strategy and adaptive inertia weight along with enhanced crossover and mutation mechanisms.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight_init = 0.9\n        self.inertia_weight_end = 0.4\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def variable_neighborhood_search(self, position, scale):\n        perturbation = np.random.uniform(-scale, scale, position.shape)\n        return position + perturbation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = (self.inertia_weight_init - (self.inertia_weight_init - self.inertia_weight_end) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n            # Implementing variable neighborhood search on the global best\n            scale = 0.1 * (ub - lb) * (1 - evaluations / self.budget)\n            global_best_position = self.variable_neighborhood_search(global_best_position, scale)\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 91, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10591 with standard deviation 0.03837.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15908904498839493, 0.16610614381970956, 0.1541642875169803, 0.08594193586186327, 0.08048725428700443, 0.07797277722203699, 0.08185399291377027, 0.07246729832888132, 0.07513677613324887]}}
{"id": "e5944ce4-1b8b-4995-8bab-d981a9acf18d", "fitness": 0.11208033395800834, "name": "EnhancedAHSO", "description": "Enhance exploration and exploitation by integrating dynamic swarm intelligence with adaptive particle dynamics and multi-parent crossover.", "code": "import numpy as np\n\nclass EnhancedAHSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.0\n        self.c2_init = 2.0\n        self.inertia_weight = 0.9\n        self.mutation_prob = 0.1\n        self.crossover_prob = 0.8\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors with dynamic inertia\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 3, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[2]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 92, "feedback": "The algorithm EnhancedAHSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11208 with standard deviation 0.03553.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.16018618158483922, 0.16610614381970956, 0.14462482558459766, 0.09058548798574328, 0.08165808765836913, 0.08645418055876741, 0.0960849944970864, 0.12252477967821973, 0.060498324254742775]}}
{"id": "ad8d42ef-0f96-4ef7-9518-d1ebe805dd0a", "fitness": -Infinity, "name": "AHSO_Adaptive_Enhanced", "description": "Enhance the adaptability by dynamically adjusting population size and integrating a diversity mechanism to foster exploration and prevent premature convergence.", "code": "import numpy as np\n\nclass AHSO_Adaptive_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.min_population_size = 20\n        self.max_population_size = 100\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        dynamic_population_size = self.population_size\n        population = np.random.uniform(lb, ub, (dynamic_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (dynamic_population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(dynamic_population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, dynamic_population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            diversity = np.std(population, axis=0).mean()\n            dynamic_population_size = max(self.min_population_size, int(self.max_population_size * (1 - diversity)))\n\n            offspring = []\n            for _ in range(dynamic_population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(dynamic_population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(dynamic_population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * dynamic_population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-dynamic_population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 93, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,10) (50,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,10) (50,10) ')", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {}}
{"id": "50416f3a-0a24-4df1-ab2a-6a8d497e5c05", "fitness": 0.11250611279647361, "name": "AHSO_Adaptive", "description": "Enhance the velocity update mechanism by introducing an additional dynamic velocity scaling factor to improve convergence speed and stability.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocity_scaling_factor = 0.5 + 0.5 * (evaluations / self.budget)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population)) * velocity_scaling_factor\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 94, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11251 with standard deviation 0.05616.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.22962524060330514, 0.1676654660628799, 0.15204511257677478, 0.11488034737088049, 0.08886711646776158, 0.07225402659824454, 0.059840063502655694, 0.07673333246128711, 0.050644309524473186]}}
{"id": "8ac57d6f-13d5-4d0b-8a5b-04d54c10918b", "fitness": 0.10716760981315845, "name": "AHSO_Enhanced", "description": "Introduce a diversity-preserving mechanism using crowding distance to maintain solution diversity and enhance exploration, combined with dynamic parameter adaptation based on convergence trends.", "code": "import numpy as np\n\nclass AHSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n        \n    def crowding_distance(self, scores):\n        sorted_indices = np.argsort(scores)\n        sorted_scores = scores[sorted_indices]\n        distances = np.zeros_like(scores)\n        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(scores) - 1):\n            distances[sorted_indices[i]] = sorted_scores[i+1] - sorted_scores[i-1]\n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            crowding_distances = self.crowding_distance(scores[non_elite_idx])\n            diverse_selection = np.argsort(crowding_distances)[::-1][:len(non_elite_idx)]\n            population[non_elite_idx] = offspring[diverse_selection]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 95, "feedback": "The algorithm AHSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10717 with standard deviation 0.03692.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.14887325177643973, 0.16625314881150266, 0.15734724657197896, 0.09399854093424387, 0.09154404696808438, 0.08157843021293332, 0.07063860536924549, 0.08962796965579156, 0.0646472480182061]}}
{"id": "f1932a7e-0a22-432d-885c-b10897ed3d8a", "fitness": 0.10811732824089859, "name": "AHSO_Adaptive", "description": "Enhance population diversity by adjusting the levy flight parameter for mutation.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size, alpha):\n        sigma = (np.math.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                 (np.math.gamma((1 + alpha) / 2) * alpha * 2 ** ((alpha - 1) / 2))) ** (1 / alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            adaptive_alpha = self.alpha + 0.1 * (evaluations / self.budget)  # Adjust alpha according to progress\n            levy_steps = self.levy_flight(offspring.shape, adaptive_alpha)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 96, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10812 with standard deviation 0.04038.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.14794430007875892, 0.18088138948654964, 0.15418410381118974, 0.09632990423234922, 0.10191931880347938, 0.06574584630413427, 0.05761365387928119, 0.08610938884002173, 0.08232804873232324]}}
{"id": "6217651d-d382-409c-bb87-ca2965c2e188", "fitness": 0.10802575035243699, "name": "AHSO_ChaoticAdaptive", "description": "Enhance exploration by integrating chaotic maps with an adaptive hybrid swarm optimization using Levy flights and dynamic mutation probabilities.", "code": "import numpy as np\n\nclass AHSO_ChaoticAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.2\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n        self.chaos_map = self.init_chaos_map()\n\n    def init_chaos_map(self):\n        x = np.random.rand()\n        chaos_map = []\n        for _ in range(1000):\n            x = 4 * x * (1 - x)  # Logistic map\n            chaos_map.append(x)\n        return np.array(chaos_map)\n\n    def chaotic_sequence(self, index):\n        return self.chaos_map[index % len(self.chaos_map)]\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            for i in range(offspring.shape[0]):\n                chaos_factor = self.chaotic_sequence(i)\n                offspring[i] += chaos_factor * (ub - lb) * np.random.rand(self.dim)\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 97, "feedback": "The algorithm AHSO_ChaoticAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10803 with standard deviation 0.03758.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.16146817110022382, 0.15301420014600542, 0.15327683984006002, 0.07375296512583807, 0.08756781029418748, 0.06641147518655965, 0.07132463328899918, 0.07972057410889954, 0.1256950840811597]}}
{"id": "e007df3f-4fec-4c0e-a074-cfe100ff6927", "fitness": 0.10983423247088937, "name": "AHSO_Adaptive", "description": "Enhance AHSO_Adaptive by adjusting learning factors initialization and mutation strategy for improved convergence.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.0  # Adjusted learning factor initialization\n        self.c2_init = 1.0  # Adjusted learning factor initialization\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.25  # Adjusted mutation probability\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 98, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10983 with standard deviation 0.03522.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.1468495156373183, 0.1665057426969464, 0.16305896900106076, 0.0908732943516658, 0.0868057771002847, 0.09078429462338744, 0.07972565983321644, 0.08617591513782952, 0.07772892385629504]}}
{"id": "708fd7a3-4b8a-45a3-91d0-75e5b3e70a79", "fitness": 0.10376163613371839, "name": "AHSO_Adaptive", "description": "Slightly increase the mutation probability to enhance exploration near the end of the budget.", "code": "import numpy as np\n\nclass AHSO_Adaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_init = 2.5\n        self.c2_init = 0.5\n        self.inertia_weight = 0.729\n        self.mutation_prob = 0.3  # Increased mutation probability\n        self.crossover_prob = 0.7\n        self.elite_fraction = 0.1\n        self.alpha = 1.5\n\n    def levy_flight(self, size):\n        sigma = (np.math.gamma(1 + self.alpha) * np.sin(np.pi * self.alpha / 2) /\n                 (np.math.gamma((1 + self.alpha) / 2) * self.alpha * 2 ** ((self.alpha - 1) / 2))) ** (1 / self.alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / np.abs(v) ** (1 / self.alpha)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        while evaluations < self.budget:\n            scores = np.array([func(ind) for ind in population])\n            evaluations += len(population)\n\n            better_positions = scores < personal_best_scores\n            personal_best_positions[better_positions] = population[better_positions]\n            personal_best_scores[better_positions] = scores[better_positions]\n            \n            min_score_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_score_idx] < global_best_score:\n                global_best_position = personal_best_positions[min_score_idx]\n                global_best_score = personal_best_scores[min_score_idx]\n\n            # Adaptive learning factors\n            self.c1 = self.c1_init * (1 - evaluations / self.budget)\n            self.c2 = self.c2_init * (evaluations / self.budget)\n\n            self.inertia_weight = 0.729 * (0.4 ** (evaluations / self.budget))\n            r1, r2 = np.random.rand(2, self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            velocities = np.clip(velocities, -0.2 * (ub - lb), 0.2 * (ub - lb))\n            population = population + velocities\n            population = np.clip(population, lb, ub)\n\n            offspring = []\n            for _ in range(self.population_size // 2):\n                if np.random.rand() < self.crossover_prob:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    alpha = np.random.uniform(0, 1, self.dim)\n                    child1 = alpha * population[parents[0]] + (1 - alpha) * population[parents[1]]\n                    child2 = alpha * population[parents[1]] + (1 - alpha) * population[parents[0]]\n                    offspring.extend([child1, child2])\n                else:\n                    offspring.extend(population[np.random.choice(self.population_size, 2)])\n            \n            offspring = np.array(offspring)\n            dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n            mutation_mask = np.random.rand(*offspring.shape) < dynamic_mutation_prob\n            levy_steps = self.levy_flight(offspring.shape)\n            offspring[mutation_mask] += levy_steps[mutation_mask]\n\n            offspring = np.clip(offspring, lb, ub)\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_idx = np.argsort(scores)[:elite_count]\n            worst_idx = np.argsort(scores)[-self.population_size//2:]\n            non_elite_idx = np.setdiff1d(worst_idx, elite_idx, assume_unique=True)\n            population[non_elite_idx] = offspring[:len(non_elite_idx)]\n            elite_offspring = np.array([population[elite_idx[i % elite_count]] for i in range(len(non_elite_idx))])\n            population[non_elite_idx] = 0.5 * population[non_elite_idx] + 0.5 * elite_offspring\n\n        return global_best_position, global_best_score", "configspace": "", "generation": 99, "feedback": "The algorithm AHSO_Adaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10376 with standard deviation 0.04087.", "error": "", "parent_ids": ["efa9d00c-4af5-48e2-808d-a200c3454681"], "operator": null, "metadata": {"aucs": [0.15237408414558462, 0.16610614381970956, 0.1560716922728561, 0.09399854093424387, 0.0916062856570119, 0.0721537634515953, 0.061223453587396226, 0.08934678385313033, 0.05097397748193755]}}
